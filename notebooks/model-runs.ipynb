{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "import configparser\n",
    "config = configparser.ConfigParser()\n",
    "config.read(\"../config.ini\")\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "class PatientClinicalDataset(Dataset):\n",
    "    \"\"\"\n",
    "    from csv, so getitem would be something like .loc[idx]\n",
    "    \"\"\"\n",
    "    def __init__(self, csv_file_path):\n",
    "        self.csv_file_path = csv_file_path\n",
    "        self.df = pd.read_csv(self.csv_file_path).drop([\"time\", \"event\"], axis=1)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        patient_series = self.df.iloc[idx]\n",
    "        return patient_series # includes the submitter_id!\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.df.shape[0]\n",
    "\n",
    "\n",
    "class PatientRNASeqDataset(Dataset):\n",
    "    \"\"\"\n",
    "    a csv file, 534 rows and ~20000 columns for normalized RNA-seq counts\n",
    "    \"\"\"\n",
    "    def __init__(self, rna_file_path):\n",
    "        self.rna_file_path = rna_file_path\n",
    "        self.df = pd.read_csv(self.rna_file_path)\n",
    "        self.df.set_index(\"submitter_id\", inplace=True)\n",
    "\n",
    "    def __getitem__(self, case_id):\n",
    "        gene_expressions = list(self.df.loc[case_id])\n",
    "        tensor_gene_expressions = torch.tensor(gene_expressions, dtype=torch.float32).unsqueeze(0)\n",
    "        return tensor_gene_expressions # [1, 19962]\n",
    "\n",
    "\n",
    "class PatientWSIDataset(Dataset):\n",
    "    \"\"\"\n",
    "    dataset for accessing a patient's list of patches features, each is of shape (1, n_patches, n_features)\n",
    "    \"\"\"\n",
    "    def __init__(self, wsi_dir):\n",
    "\n",
    "        self.wsi_dir = wsi_dir\n",
    "        self.case_ids = list(os.listdir(self.wsi_dir))\n",
    "        self.dict_case_id_path = {\n",
    "            c: os.path.join(self.wsi_dir, c) + \"/patches_features.npy\" for c in self.case_ids\n",
    "        }\n",
    "\n",
    "    def __getitem__(self, case_id):\n",
    "        # grab the list of 5 clusters for this case_id\n",
    "\n",
    "        case_npy_file = self.dict_case_id_path[case_id]\n",
    "        patches_features = np.load(case_npy_file, allow_pickle=True).item()\n",
    "        \n",
    "        cluster_ids = self.clustering(patches_features)\n",
    "\n",
    "        features_list = list(patches_features.values())\n",
    "        unique_clusters = np.unique(cluster_ids)\n",
    "        n_clusters = len(unique_clusters)\n",
    "\n",
    "        list_phenotype_tensors = [] # list of tensors, each tensor is a cluster's features of shape i.e. (1, 15 patches in this cluster, 512 as output of resnet18)\n",
    "\n",
    "        for cluster in unique_clusters:\n",
    "            cluster_features = [features for features, c in zip(features_list, cluster_ids) if c == cluster]\n",
    "            tensor_cluster_features = torch.from_numpy(np.array(cluster_features)).float().unsqueeze(0) # (1, n_patches, n_features)\n",
    "\n",
    "            list_phenotype_tensors.append(tensor_cluster_features.to(device))\n",
    "\n",
    "        return list_phenotype_tensors # [t1,t2,t3,t4,t5]\n",
    "\n",
    "    def clustering(self, patches_features, n_clusters=5):\n",
    "        feature_vectors = list(patches_features.values())\n",
    "        kmeans = KMeans(n_clusters=n_clusters, random_state=0, n_init=50)\n",
    "        cluster_ids = kmeans.fit_predict(feature_vectors)\n",
    "        return cluster_ids\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.case_ids)\n",
    "\n",
    "\n",
    "\n",
    "## Fusion multimodal\n",
    "\n",
    "class MultimodalDataset(Dataset):\n",
    "    \"\"\"\n",
    "    takes three data paths (clinical, rna-seq, histopath images)\n",
    "    build a data out of 'em\n",
    "    \"\"\"\n",
    "    def __init__(self, \n",
    "        clinical_data_path, \n",
    "        rna_seq_data_path, \n",
    "        wsi_data_path\n",
    "    ):\n",
    "        # prepare labels from the clinical data path\n",
    "        self.LABELS_DF = pd.read_csv(clinical_data_path)[[\"submitter_id\", \"event\", \"time\"]]\n",
    "        # then by initializing the clinical_dataset, remove the time and event from the clinical features:\n",
    "        self.clinical_dataset = PatientClinicalDataset(clinical_data_path)\n",
    "\n",
    "        # initialize the datasets for each modality\n",
    "        self.wsi_dataset = PatientWSIDataset(wsi_data_path)\n",
    "        self.rna_dataset = PatientRNASeqDataset(rna_seq_data_path)\n",
    "\n",
    "        # label dictionary with key=submitter_id and value=(event,time) for easy lookup\n",
    "        self.labels_dict = {}\n",
    "        for submitter_id, event, time in zip(self.LABELS_DF[\"submitter_id\"], self.LABELS_DF[\"event\"], self.LABELS_DF[\"time\"]):\n",
    "            self.labels_dict[submitter_id] = {\"event\": event, \"time\": time}\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.clinical_dataset)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        # (1) start from clinical dataset\n",
    "        patient_series = self.clinical_dataset[idx]\n",
    "        case_id = patient_series[\"submitter_id\"]\n",
    "        clinical_features = list(patient_series.drop([\"submitter_id\"]))\n",
    "        tensor_clinical_features = torch.tensor(clinical_features, dtype=torch.float32).unsqueeze(0) \n",
    "        # above: add batch dim (1, 13) instead of (13)\n",
    "\n",
    "        # (2) grab the tensor for 20000 (processed) gene counts for that case id\n",
    "        tensor_rna_genes = self.rna_dataset[case_id] # (1, 19962)\n",
    "\n",
    "        # (2.5) NOTE: to save time for this moment, I will concat the clinical and rna together \n",
    "        # and build one feed-forward for the combined\n",
    "        tensor_clinical_rna = torch.cat((tensor_clinical_features, tensor_rna_genes), dim=1) # (1, 19975)\n",
    "\n",
    "        # (3) collect the list of phenotype tensor for that case id\n",
    "        list_of_phenotype_tensors = self.wsi_dataset[case_id]\n",
    "\n",
    "        # (4) labels\n",
    "        time = self.labels_dict[case_id][\"time\"]\n",
    "        event = self.labels_dict[case_id][\"event\"]\n",
    "\n",
    "        return (\n",
    "            tensor_clinical_rna,\n",
    "            list_of_phenotype_tensors,\n",
    "            time,\n",
    "            event\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 first gene counts:\n",
      "tensor(2.4332)\n",
      "tensor(0.)\n",
      "tensor(3.4071)\n",
      "tensor(2.7216)\n",
      "tensor(1.6839)\n",
      "tensor(1.7558)\n",
      "tensor(3.9939)\n",
      "first 13 in clinical and rna:\n",
      "tensor(0.)\n",
      "tensor(1.1109)\n",
      "tensor(0.)\n",
      "tensor(0.)\n",
      "tensor(0.)\n",
      "tensor(1.)\n",
      "tensor(0.)\n",
      "tensor(0.)\n",
      "tensor(0.)\n",
      "tensor(0.)\n",
      "tensor(0.)\n",
      "tensor(1.)\n",
      "tensor(0.)\n"
     ]
    }
   ],
   "source": [
    "check_data = MultimodalDataset(\n",
    "    config[\"clinical\"][\"cleaned_clinical_json\"],\n",
    "    config[\"rna\"][\"cleaned_rna\"],\n",
    "    config[\"wsi\"][\"wsi_slides\"]\n",
    ")\n",
    "\n",
    "case0 = check_data[5]\n",
    "clin_rna, list_tensors = case0[0], case0[1]\n",
    "\n",
    "print(\"5 first gene counts:\")\n",
    "for i in clin_rna.flatten()[13:20]:\n",
    "    print(i)\n",
    "\n",
    "print(\"first 13 in clinical and rna:\")\n",
    "for i in clin_rna.flatten()[0:13]:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1148, 512])\n",
      "torch.Size([1, 1078, 512])\n",
      "torch.Size([1, 984, 512])\n",
      "torch.Size([1, 966, 512])\n",
      "torch.Size([1, 824, 512])\n",
      "\n",
      "torch.Size([1, 1148, 512])\n",
      "torch.Size([1, 1078, 512])\n",
      "torch.Size([1, 984, 512])\n",
      "torch.Size([1, 966, 512])\n",
      "torch.Size([1, 824, 512])\n"
     ]
    }
   ],
   "source": [
    "for tensor in list_tensors:\n",
    "    print(tensor.shape)\n",
    "\n",
    "print()\n",
    "check_wsi = PatientWSIDataset(config[\"wsi\"][\"wsi_slides\"])[\"TCGA-BP-4352\"]\n",
    "for tensor in check_wsi:\n",
    "    print(tensor.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import random\n",
    "import os\n",
    "import math\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "random.seed(0)\n",
    "np.random.seed(0)\n",
    "torch.manual_seed(0)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "dropout_ratio = 0.5\n",
    "\n",
    "class WSI_FCN(nn.Module):\n",
    "    \"\"\"\n",
    "    https://arxiv.org/abs/2009.11169\n",
    "    fully convolutional network for WSI\n",
    "    takes 1 phenotype tensor/cluster of shape (1, n_patches, 512)\n",
    "    outputs a local representation of that phenotype tensor of shape (1, 64)\n",
    "    why FCN? on the numerical vectors? \n",
    "        - utilize the kernel, and especially kernel_size=1 because we can't have kernel_size>1 for randomly picked patches from the histopathology slides\n",
    "        - so why not a simple fully connected network (MLP)? it's because it requires inputs with fixed dimension and we have varying number of patches for each cluster\n",
    "    also, note that a patch -> FCN -> (1,64) shape. So if we have 300 patches or (300,64) shape, we would use avgpooling and get (1,64) as the final output for that cluster\n",
    "    \"\"\"\n",
    "    def __init__(self, in_features, out_features=64):\n",
    "        super(WSI_FCN, self).__init__()\n",
    "        # conv1d because we only have a tensor of shape (N, C, L) = (1, 512, i.e. 272)\n",
    "        self.conv = nn.Conv1d(in_features, out_features, \n",
    "            kernel_size=1 # kernel size = 1 is extremely important because we only want to the a single patch to be learned, \n",
    "            # doing i.e. 3x3 is no use because the patches are picked randomly, so can't use spatial relationship here\n",
    "        )\n",
    "        self.relu = nn.ReLU()\n",
    "        # adaptive avg pooling to get a local representation of the phenotype tensor\n",
    "        # NOTE: adapative pooling from (64, 300 patches) to (64,1) as the final output of that cluster\n",
    "        self.pool = nn.AdaptiveAvgPool1d(1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: (1, n_patches, n_features)\n",
    "        # permute to (1, n_features, n_patches) so that n_features become channels why? because tensor in pytorch reads () https://stackoverflow.com/questions/51541532/which-part-of-pytorch-tensor-represents-channels\n",
    "        # n_patches is the length of the sequence. why?\n",
    "        # FYI: for a conv2D, input should be in (N, C, H, W) format. N is the number of samples/batch_size. C is the channels. H and W are height and width resp: https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html#torch.nn.Conv2d \n",
    "        # but here we have conv1d: https://pytorch.org/docs/stable/generated/torch.nn.Conv1d.html#torch.nn.Conv1d\n",
    "\n",
    "        x = x.permute(0, 2, 1) # (1, 512, 300 patches)\n",
    "        x = self.conv(x) # (1, 64, 300 patches)\n",
    "        x = self.relu(x) # (1, 64, 300 patches)\n",
    "        x = self.pool(x) # (1, 64, 1)\n",
    "        x = x.view(x.size()[0], -1) # (1, 64)\n",
    "        return x # (1, 64)\n",
    "\n",
    "\n",
    "class WSI_Attention(nn.Module):\n",
    "    \"\"\"\n",
    "    https://arxiv.org/abs/2009.11169 \n",
    "    pooling attention mechanism for WSI\n",
    "    takes a local representation of the phenotype tensor of shape (5, 64) in which 5 is the number of clusters\n",
    "    outputs a global representation of the phenotype tensors of shape (64-dim) which is a weighted sum across 5 clusters for 64 features\n",
    "        each case has a global representation\n",
    "    \"\"\"\n",
    "    def __init__(self, in_features, out_features=64):\n",
    "        super(WSI_Attention, self).__init__()\n",
    "        self.attention = nn.Sequential(\n",
    "            nn.Linear(in_features, out_features),\n",
    "            nn.Tanh(),  # tanh because we want to normalize the weights\n",
    "            # why tanh() >> output values in range (-1,1), allowing both neg and pos values, often used in attention scores\n",
    "            nn.Linear(out_features, 1),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # apply softmax because we have different number of clusters for each case\n",
    "        # x: (5, 64) stack representation of 5 clusters/phenotypes\n",
    "        scores = self.attention(x) # (5, 1)\n",
    "        att_weights = torch.softmax(scores, dim=0).T # (1,5) which is probabilities\n",
    "        # weighted sum across the 5 clusters:\n",
    "        weights_applied = att_weights @ x  # (5, 64) = (1,5) @ (5,64)\n",
    "        # weighted_sum_vector = torch.sum(weights_applied, dim=0) # (1, 64) or (64)\n",
    "        return weights_applied, att_weights\n",
    "\n",
    "\n",
    "class Clinical_RNA_FeedForward(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim=32, dropout_ratio=dropout_ratio):\n",
    "        # https://www.cs.toronto.edu/~hinton/absps/JMLRdropout.pdf\n",
    "        # https://arxiv.org/pdf/1207.0580\n",
    "        # For fully connected layers, dropout in all hidden layers works\n",
    "        # better than dropout in only one hidden layer and more extreme probabilities tend to be worse,\n",
    "        # which is why we have used 0.5 throughout this paper\n",
    "        \n",
    "        super(Clinical_RNA_FeedForward, self).__init__()\n",
    "\n",
    "        # hidden = [512, 256, 256, 64, 64, 32]\n",
    "        # hidden = [1024, 512, 512, 256, 256, 128, 128, 64, 64, 32]\n",
    "\n",
    "        hidden = [1024, 1024, 512, 512, 256, 256, 128, 128, 64, 64, 32] # final: march 2, 2025\n",
    "\n",
    "        self.feedforward = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden[0]), nn.ReLU(), nn.Dropout(dropout_ratio),\n",
    "            nn.Linear(hidden[0], hidden[1]), nn.ReLU(), nn.Dropout(dropout_ratio),\n",
    "            nn.Linear(hidden[1], hidden[2]), nn.ReLU(), nn.Dropout(dropout_ratio),  \n",
    "            nn.Linear(hidden[2], hidden[3]), nn.ReLU(), nn.Dropout(dropout_ratio),\n",
    "            nn.Linear(hidden[3], hidden[4]), nn.ReLU(), nn.Dropout(dropout_ratio),\n",
    "            nn.Linear(hidden[4], hidden[5]), nn.ReLU(), nn.Dropout(dropout_ratio),\n",
    "            nn.Linear(hidden[5], hidden[6]), nn.ReLU(), nn.Dropout(dropout_ratio),\n",
    "            nn.Linear(hidden[6], hidden[7]), nn.ReLU(), nn.Dropout(dropout_ratio),\n",
    "            nn.Linear(hidden[7], hidden[8]), nn.ReLU(), nn.Dropout(dropout_ratio),\n",
    "            nn.Linear(hidden[8], hidden[9]), nn.ReLU(), nn.Dropout(dropout_ratio),\n",
    "            nn.Linear(hidden[9], hidden[10]), nn.ReLU(), nn.Dropout(dropout_ratio),\n",
    "            nn.Linear(hidden[10], output_dim), nn.ReLU(), nn.Dropout(dropout_ratio),    \n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.feedforward(x)\n",
    "        return out\n",
    "\n",
    "\n",
    "# FusionFeedForward\n",
    "class FusionNetwork(nn.Module):\n",
    "    def __init__(self, \n",
    "        input_dim_clinical_rna=19975, \n",
    "        input_dim_wsi_fcn=512, \n",
    "        input_dim_wsi_attention=64, \n",
    "        input_dim_final=96  # as from 32+64 = (out_dim of clinical_RNA) + (out_dim of WSI)\n",
    "    ): \n",
    "        # NOTE: no dropout for now\n",
    "        super(FusionNetwork, self).__init__()\n",
    "\n",
    "        # Clinical+RNA\n",
    "        self.clinical_rna_feedforward = Clinical_RNA_FeedForward(input_dim_clinical_rna, output_dim=32, dropout_ratio=dropout_ratio)\n",
    "        # WSI_FCN and WSI_Attention\n",
    "        self.wsi_fcn = WSI_FCN(input_dim_wsi_fcn, out_features=64)\n",
    "        self.attention = WSI_Attention(input_dim_wsi_attention, out_features=64)\n",
    "\n",
    "        # after fusion:\n",
    "        # TODO: rational -> book: many hidden neurons are good -> with regularization like dropout/weight decay\n",
    "        # for no. layers -> background knowledge and experimentation, for now 4 layers\n",
    "        hidden = [64, 32, 16, 8]\n",
    "\n",
    "        self.baby_feed_forward = nn.Sequential(\n",
    "            nn.Linear(input_dim_final, hidden[0]),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden[0], hidden[1]),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden[1], hidden[2]),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden[2], hidden[3]),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden[3], 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, tensor_clinical_rna, list_of_phenotype_tensors):\n",
    "\n",
    "        # Clinical+RNA:\n",
    "        extracted_clinical_rna = self.clinical_rna_feedforward(tensor_clinical_rna.to(device)) # (1, 32) shape\n",
    "        \n",
    "        # WSI_FCN\n",
    "        local_reps = [] # len=5\n",
    "        # here since tensors have different no. images in each of them\n",
    "        # we use the \"flexiblity\" of the FCN to output 1x64 for each cluster\n",
    "        for tensor in list_of_phenotype_tensors:\n",
    "            tensor = tensor.to(device)\n",
    "            cluster_rep = self.wsi_fcn(tensor) # each of shape (1,64) by pooling from tensors with varying dim\n",
    "            local_reps.append(cluster_rep)\n",
    "        # stack 5 local representation of shape (1,64) >> tensor of shape (5,64)\n",
    "        tensor_local_reps = torch.cat(local_reps)\n",
    "\n",
    "        # WSI_Attention:\n",
    "        wsi_aggregated_vector, att_weights = self.attention(tensor_local_reps) # from (5,64) to weighted vector (1,64)\n",
    "\n",
    "        # concantenate:\n",
    "        concatenated_features = torch.cat((extracted_clinical_rna, wsi_aggregated_vector), dim=1) # shape (1, 96)\n",
    "\n",
    "        risk_score = self.baby_feed_forward(concatenated_features)\n",
    "        return risk_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 64])\n",
      "torch.Size([1, 64])\n",
      "torch.Size([1, 32])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([[0.2094]], device='cuda:0', grad_fn=<AddmmBackward0>),\n",
       " torch.Size([1, 1]))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sanity check\n",
    "\n",
    "x = torch.rand(5, 64)\n",
    "a2 = WSI_Attention(64)(x)\n",
    "print(a2[0].shape)\n",
    "\n",
    "x = torch.rand(1, 300, 512) # (1, n_patches, 512)\n",
    "a1 = WSI_FCN(512)(x)\n",
    "print(a1.shape)\n",
    "\n",
    "x = torch.rand(1, 19975)\n",
    "a3 = Clinical_RNA_FeedForward(19975)(x)\n",
    "print(a3.shape)\n",
    "\n",
    "x1 = torch.rand(1, 19975)\n",
    "x2 = [torch.rand(1, 300, 512), torch.rand(1, 200, 512), torch.rand(1, 50, 512), torch.rand(1, 150, 512), torch.rand(1, 25, 512)]\n",
    "m = FusionNetwork().to(device)\n",
    "a4 = m(x1,x2)\n",
    "a4, a4.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "begin to train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12/12 [16:35<00:00, 82.98s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0, loss: 1.1736237357060115\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12/12 [16:40<00:00, 83.41s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1, loss: 1.106985181570053\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12/12 [16:43<00:00, 83.63s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2, loss: 1.0525387277205784\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12/12 [16:01<00:00, 80.09s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 3, loss: 1.052827815214793\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12/12 [16:31<00:00, 82.58s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 4, loss: 1.04255161434412\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12/12 [16:42<00:00, 83.52s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 5, loss: 1.0202295829852421\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12/12 [11:51<00:00, 59.31s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 6, loss: 1.0018265098333359\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12/12 [15:30<00:00, 77.52s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 7, loss: 0.951243648926417\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12/12 [10:37<00:00, 53.12s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 8, loss: 0.9475130587816238\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12/12 [15:37<00:00, 78.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 9, loss: 0.9347797681887945\n",
      "finished training\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from datetime import datetime, date\n",
    "from lifelines.utils import concordance_index\n",
    "from utils import display_km_curves_fusion\n",
    "\n",
    "# from models import *\n",
    "# from data_utils import *\n",
    "\n",
    "# import configparser\n",
    "# config = configparser.ConfigParser()\n",
    "# config.read(\"config.ini\")\n",
    "\n",
    "random.seed(0)\n",
    "np.random.seed(0)\n",
    "torch.manual_seed(0)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "########################## LOSS ###############################################\n",
    "\n",
    "def negative_partial_log_likelihood(hazard_preds, times, events, device, eps=1e-8):\n",
    "\n",
    "    # This calculation credit to Travers Ching https://github.com/traversc/cox-nnet\n",
    "    # Cox-nnet: An artificial neural network method for prognosis prediction of high-throughput omics data\n",
    "\n",
    "    # flatten predictions\n",
    "    hazard_preds = hazard_preds.view(-1)\n",
    "    times = times.to(device).view(-1)\n",
    "    events = events.to(device).view(-1)\n",
    "\n",
    "    # uncensored patients ~ patients with event observed = 1\n",
    "    # censored patients ~ not yet observed\n",
    "    # if this batch only contains censored/alive patients:\n",
    "    if events.sum() == 0:\n",
    "        return torch.tensor(0.0, device=device)\n",
    "\n",
    "    # compute risk set/matrix: R[i,j] = 1 if times[j] >= times[i]\n",
    "    # https://stackoverflow.com/questions/56646261/can-someone-please-explain-np-less-equal-outerrange1-18-range1-13\n",
    "    risk_matrix = torch.tensor(\n",
    "        np.greater_equal.outer(times.cpu(), times.cpu()).T.astype(np.float32), \n",
    "        device=device\n",
    "    )\n",
    "\n",
    "    # standardize theta/hazard prediction\n",
    "    theta = (hazard_preds - hazard_preds.mean()) / (hazard_preds.std(unbiased=False) + eps)\n",
    "\n",
    "    # compute the log risk set using the correct formula\n",
    "    # NOTE: use theta directly without an extra exp()\n",
    "    # First, mask the non-risk set entries by multiplying exp(theta) with risk_matrix,\n",
    "    # then take the log of the sum\n",
    "    log_risk_set = torch.log(torch.sum(torch.exp(theta) * risk_matrix, dim=1) + eps)\n",
    "\n",
    "    # negative partial likelihood only for events=1\n",
    "    # only take the avg loss for the batch across patients in D=1\n",
    "    loss = -torch.mean((theta - log_risk_set) * events)\n",
    "\n",
    "    return loss\n",
    "\n",
    "# one-batch\n",
    "# hazard_pred = torch.tensor([2.1, 1.8, 3.0, 0.5, 2.5], device=device)\n",
    "# time = torch.tensor([5, 3, 6, 2, 4], device=device)\n",
    "# event = torch.tensor([1, 1, 0, 1, 0], device=device)\n",
    "\n",
    "# one_batch_loss = negative_partial_log_likelihood(hazard_pred, time, event, device)\n",
    "# print(one_batch_loss)\n",
    "\n",
    "################## HYPERPARAMS ################################################\n",
    "\n",
    "# https://arxiv.org/pdf/1206.5533 (guide to choose hyperparams)\n",
    "n_epochs = 10\n",
    "lr = 0.0001\n",
    "batch_size = 32\n",
    "\n",
    "# regularizations:\n",
    "dropout_ratio = 0.5\n",
    "weight_decay = 0.0001\n",
    "\n",
    "# since we have relatively small dataset (~300 for training), high weidght decay may lead to udnerfitting\n",
    "# but we might have many interactions between parameters in the final feedforward, so let's try different ones\n",
    "# https://medium.com/towards-data-science/this-thing-called-weight-decay-a7cd4bcfccab\n",
    "# https://stackoverflow.com/questions/44452571/what-is-the-proper-way-to-weight-decay-for-adam-optimizer\n",
    "\n",
    "################### TRAIN #####################################################\n",
    "\n",
    "def custom_collate(batch):\n",
    "    \"\"\"\n",
    "    https://stackoverflow.com/questions/65279115/how-to-use-collate-fn-with-dataloaders \n",
    "    i.e. 32 batch_size\n",
    "    batch = [\n",
    "        (list_of_phenotype_tensors, time1, event1),    => case 1\n",
    "        (list_of_phenotype_tensors, time2, event2),    => case 2\n",
    "        ...                                            => case 32\n",
    "    ]\n",
    "\n",
    "    TODO: more explanation to come\n",
    "    \"\"\"\n",
    "    # each element in batch is a tuple: \n",
    "    # (clinical_rna_tensor, list_of_phenotype_tensors, time, event)\n",
    "    list_of_clinical_rna_features, list_of_lists_of_5_tensors, times, events = zip(*batch)\n",
    "    # i.e. [patient_1_clinical_rna_t1, patient_2_clinical_rna_t2,..., patient32_clinical_rna_t32]\n",
    "    # i.e. [[t1,t2,t3,t4,t5],[t1,t2,t3,t4,t5],...,[t1,t2,t3,t4,t5]] = [32 lists]\n",
    "    \n",
    "    return (\n",
    "        list(list_of_clinical_rna_features),\n",
    "        list(list_of_lists_of_5_tensors),\n",
    "        torch.tensor(times),\n",
    "        torch.tensor(events)\n",
    "    )\n",
    "\n",
    "# dataset and splitting\n",
    "dataset = MultimodalDataset(\n",
    "    config[\"clinical\"][\"cleaned_clinical_json\"],\n",
    "    config[\"rna\"][\"cleaned_rna\"],\n",
    "    config[\"wsi\"][\"wsi_slides\"]\n",
    ")\n",
    "\n",
    "train_size, val_size = int(0.7 * len(dataset)), int(0.15 * len(dataset))\n",
    "test_size = len(dataset) - train_size - val_size\n",
    "train, val, test = random_split(dataset, [train_size, val_size, test_size])\n",
    "\n",
    "# loading data\n",
    "train_loader = DataLoader(train, batch_size=batch_size, shuffle=True, collate_fn=custom_collate)\n",
    "val_loader = DataLoader(val, batch_size=val_size, shuffle=False, collate_fn=custom_collate)\n",
    "test_loader = DataLoader(test, batch_size=test_size, shuffle=False, collate_fn=custom_collate)\n",
    "\n",
    "# initiate model\n",
    "model = FusionNetwork(\n",
    "    input_dim_clinical_rna=19975,\n",
    "    input_dim_wsi_fcn=512,\n",
    "    input_dim_wsi_attention=64,\n",
    "    input_dim_final=96\n",
    ")\n",
    "model.to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "\n",
    "\n",
    "print(\"begin to train\")\n",
    "# training loops\n",
    "for epoch in range(n_epochs):\n",
    "\n",
    "    model.train()\n",
    "    train_loss = 0.0 \n",
    "\n",
    "    # each batch contains 32 cases!\n",
    "    for batch in tqdm(train_loader):\n",
    "        batch_clinical_rna_features, batch_lists_phenotype_clusters, batch_times, batch_events = batch\n",
    "\n",
    "        risk_scores = [] # list of  32 risk scores\n",
    "        for (clinical_rna_features, list_of_phenotype_tensors) in zip(batch_clinical_rna_features, batch_lists_phenotype_clusters):\n",
    "            # process each sample in the batch of 32\n",
    "            risk_score = model(clinical_rna_features, list_of_phenotype_tensors)\n",
    "            risk_scores.append(risk_score)\n",
    "\n",
    "        # convert to tensor type\n",
    "        risk_scores = torch.stack(risk_scores) # of shape (batch_size, 1) or (32,1) \n",
    "\n",
    "        # TODO: explain in detail: meaning of loss of 32 cases in the batch\n",
    "        optimizer.zero_grad() # zero the parameter gradients\n",
    "        loss = negative_partial_log_likelihood(risk_scores, batch_times.to(device), batch_events.to(device), device)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "\n",
    "    # the lower the better i.e. the negative better better\n",
    "    print(f\"epoch {epoch}, loss: {train_loss / len(train_loader)}\")\n",
    "\n",
    "print(\"finished training\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "begin to validate\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [02:05<00:00, 125.84s/it]\n"
     ]
    }
   ],
   "source": [
    "####################### VALIDATION ############################################\n",
    "\n",
    "print(\"begin to validate\")\n",
    "model.eval()\n",
    "\n",
    "val_risks = []\n",
    "val_times = []\n",
    "val_events = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(val_loader):\n",
    "        # unpack the batch\n",
    "        batch_clinical_rna_features, batch_lists_phenotype_clusters, batch_times, batch_events = batch\n",
    "        \n",
    "        # move times and events to the device\n",
    "        batch_times = batch_times.to(device)\n",
    "        batch_events = batch_events.to(device)\n",
    "        \n",
    "        # tterate over each sample in the batch\n",
    "        for idx, (clinical_rna_features, list_of_phenotype_tensors) in enumerate(zip(batch_clinical_rna_features, batch_lists_phenotype_clusters)):\n",
    "            \n",
    "            risk_score = model(clinical_rna_features, list_of_phenotype_tensors)\n",
    "            \n",
    "            val_risks.append(risk_score.item())\n",
    "            val_times.append(batch_times[idx].item())\n",
    "            val_events.append(batch_events[idx].item())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation c-index: 0.7572533849129593\n",
      "validation c-index custom: 0.7567829457364341\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from lifelines import KaplanMeierFitter\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def display_km_curves_fusion(risks, times, events, title_name, c_index, save_figure=False):\n",
    "    risks = np.array(risks)\n",
    "    times = np.array(times)\n",
    "    events = np.array(events)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(10, 8)) \n",
    "    high_risk_idx = risks > np.median(risks)\n",
    "    low_risk_idx = risks <= np.median(risks)\n",
    "    kmf_high = KaplanMeierFitter()\n",
    "    kmf_low = KaplanMeierFitter()\n",
    "    # fit low risk\n",
    "    kmf_low.fit(times[low_risk_idx], event_observed=events[low_risk_idx], label='Low risk')\n",
    "    kmf_low.plot_survival_function(ax=ax, ci_show=True, ci_alpha=0.15, show_censors=True, color='orange')\n",
    "    # fit high risk\n",
    "    kmf_high.fit(times[high_risk_idx], event_observed=events[high_risk_idx], label='High risk')\n",
    "    kmf_high.plot_survival_function(ax=ax, ci_alpha=0.15, ci_show=True,show_censors=True, color='blue')\n",
    "    ax.set_title(f\"Kaplan-Meier curve for final model on {title_name}\")\n",
    "    ax.set_xlabel(\"Time\")\n",
    "    ax.set_ylabel(\"Survival probability\")\n",
    "    plt.legend()\n",
    "    if save_figure:\n",
    "        current_time = datetime.now().strftime(\"%H-%M-%S\")\n",
    "        plt.savefig(f\"../evaluation-results/fusion_{title_name}_{date.today()}_{c_index:4f}.png\")\n",
    "    else:\n",
    "        plt.show()\n",
    "\n",
    "def concordance_index_custom(hazards, times, events):\n",
    "    \"\"\"\n",
    "    computes the c-index for survival prediction\n",
    "    - hazards: predicted risk scores (higher means higher risk)\n",
    "    - times: observed survival times\n",
    "    - events: event indicators (1 if event occurred, 0 if censored)\n",
    "    \"\"\"\n",
    "    n = len(times)\n",
    "    concordant = 0.0\n",
    "    permissible = 0.0\n",
    "    for i in range(n):\n",
    "        for j in range(n):\n",
    "            # only compare if i had an event and its time is earlier than j\n",
    "            if times[i] < times[j] and events[i] == 1:\n",
    "                permissible += 1\n",
    "                if hazards[i] > hazards[j]:\n",
    "                    concordant += 1\n",
    "                elif hazards[i] == hazards[j]:\n",
    "                    concordant += 0.5\n",
    "    return concordant / permissible if permissible > 0 else 0\n",
    "\n",
    "\n",
    "val_c_index = concordance_index(val_times, -np.array(val_risks), val_events)\n",
    "print(f\"validation c-index: {val_c_index}\")\n",
    "\n",
    "val_c_index_custom = concordance_index_custom(val_risks, val_times, val_events)\n",
    "print(f\"validation c-index custom: {val_c_index_custom}\")\n",
    "\n",
    "display_km_curves_fusion(val_risks, val_times, val_events, \"validation set\", val_c_index, save_figure=False)\n",
    "\n",
    "\n",
    "saved_model = False\n",
    "\n",
    "if saved_model:\n",
    "    current_time = datetime.now().strftime(\"%H-%M-%S\")\n",
    "    checkpoint_path = f\"../checkpoints/trained-model_{date.today()}_{val_c_index:4f}.pth\"\n",
    "    torch.save({\n",
    "        'model_state_dict': model.state_dict(), # all weights all models\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'batch_size': batch_size,\n",
    "        'dropout_ratio': dropout_ratio,\n",
    "        'learning_rate': lr,\n",
    "        'weight_decay': weight_decay,\n",
    "        'n_epochs': n_epochs,\n",
    "        'random_seed': 0,\n",
    "        'val_c_index': val_c_index,\n",
    "        'hidden': [1024, 1024, 512, 512, 256, 256, 128, 128, 64, 64, 32]\n",
    "    }, checkpoint_path)\n",
    "    print(f\"saved model: {checkpoint_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_state_dict OrderedDict([('clinical_rna_feedforward.feedforward.0.weight', tensor([[-1.2345e-03, -4.2677e-03,  2.1296e-05,  ..., -6.9195e-05,\n",
      "          1.6668e-04, -7.3537e-04],\n",
      "        [-5.1345e-03, -3.8178e-03, -5.7655e-03,  ...,  5.6969e-07,\n",
      "          3.6948e-03,  6.0809e-03],\n",
      "        [ 1.1110e-08, -2.8465e-08,  1.4977e-07,  ...,  1.4407e-05,\n",
      "         -2.4255e-08,  3.9335e-06],\n",
      "        ...,\n",
      "        [-5.4654e-03, -1.7705e-03,  8.0576e-07,  ...,  1.8097e-04,\n",
      "         -1.2366e-03,  3.0575e-03],\n",
      "        [ 1.6793e-03, -6.8450e-04,  8.2199e-06,  ...,  4.4877e-08,\n",
      "         -3.7996e-06, -1.6932e-04],\n",
      "        [ 1.1334e-03,  4.7919e-03,  2.8039e-06,  ..., -5.6452e-05,\n",
      "         -7.8428e-04,  1.2821e-03]], device='cuda:0')), ('clinical_rna_feedforward.feedforward.0.bias', tensor([ 5.5707e-04,  6.4389e-03,  4.8782e-06,  ..., -1.1887e-03,\n",
      "         7.3178e-05, -2.8289e-03], device='cuda:0')), ('clinical_rna_feedforward.feedforward.3.weight', tensor([[-1.1577e-05,  4.2631e-03,  3.2045e-06,  ..., -6.6469e-03,\n",
      "          6.6322e-03, -2.0967e-02],\n",
      "        [-2.8982e-02,  3.1869e-02,  3.2645e-06,  ..., -2.6225e-02,\n",
      "         -1.2682e-02,  1.5822e-02],\n",
      "        [ 1.7345e-03,  2.4773e-02,  9.8780e-03,  ..., -2.5114e-02,\n",
      "         -1.2978e-03, -1.1290e-02],\n",
      "        ...,\n",
      "        [ 4.9049e-04, -8.4740e-03,  7.2174e-03,  ..., -1.1271e-02,\n",
      "          6.8059e-06,  1.7055e-03],\n",
      "        [-6.1332e-03, -2.3507e-02,  9.6412e-04,  ..., -2.1500e-02,\n",
      "          1.0600e-03, -6.5858e-03],\n",
      "        [ 7.9609e-03, -8.0085e-03,  2.0562e-05,  ...,  2.2449e-02,\n",
      "         -5.2429e-06, -2.4784e-03]], device='cuda:0')), ('clinical_rna_feedforward.feedforward.3.bias', tensor([ 0.0313, -0.0098, -0.0235,  ...,  0.0258,  0.0270, -0.0160],\n",
      "       device='cuda:0')), ('clinical_rna_feedforward.feedforward.6.weight', tensor([[-0.0288,  0.0002,  0.0260,  ..., -0.0130, -0.0197, -0.0162],\n",
      "        [ 0.0024,  0.0148,  0.0167,  ..., -0.0001, -0.0287, -0.0110],\n",
      "        [ 0.0092,  0.0079, -0.0312,  ...,  0.0257,  0.0046, -0.0217],\n",
      "        ...,\n",
      "        [-0.0077, -0.0303,  0.0262,  ..., -0.0216,  0.0129, -0.0133],\n",
      "        [-0.0296, -0.0179, -0.0047,  ...,  0.0163, -0.0300,  0.0207],\n",
      "        [ 0.0152, -0.0196, -0.0288,  ...,  0.0037,  0.0024, -0.0102]],\n",
      "       device='cuda:0')), ('clinical_rna_feedforward.feedforward.6.bias', tensor([-9.1772e-03, -1.9428e-02,  1.6610e-02, -1.5539e-02, -2.5266e-02,\n",
      "        -3.7242e-03,  4.5728e-03, -2.7521e-03,  1.8689e-02, -6.6866e-03,\n",
      "         1.6080e-03, -1.8504e-02,  1.5926e-02,  2.0741e-02,  1.5715e-02,\n",
      "        -9.9291e-03, -1.2137e-02,  1.9406e-02,  1.2301e-02,  8.8872e-03,\n",
      "         1.0877e-02, -8.0026e-03, -2.2159e-03,  1.0370e-02,  1.7491e-02,\n",
      "        -8.0912e-04,  1.2827e-02,  2.4864e-02,  2.3264e-02,  2.1203e-02,\n",
      "         2.6010e-02,  2.6009e-02,  9.6898e-03, -3.0594e-02, -2.5144e-02,\n",
      "         1.0743e-02,  1.4357e-02, -4.9976e-03, -2.3071e-03, -4.0448e-03,\n",
      "         1.1524e-02,  1.9991e-02,  2.0672e-02, -3.1000e-02,  2.0464e-02,\n",
      "        -1.3495e-03, -1.3113e-02, -1.8833e-02,  8.3741e-03,  5.8479e-03,\n",
      "        -1.6945e-02, -2.4247e-02, -7.1265e-03,  3.0862e-02,  1.7886e-02,\n",
      "        -1.4013e-02,  1.4462e-03, -5.1788e-03,  6.3548e-03,  1.9374e-03,\n",
      "         2.3128e-02, -5.9922e-03,  2.2906e-02, -2.3060e-02, -1.9821e-02,\n",
      "        -2.6932e-02,  1.5594e-02,  2.7635e-02,  2.6746e-03, -1.4084e-02,\n",
      "         8.1593e-03,  3.0591e-02, -2.1785e-02, -2.5480e-02,  2.3558e-03,\n",
      "         1.1923e-02,  9.9673e-03,  1.4895e-02, -8.4893e-04, -3.4571e-05,\n",
      "        -4.2219e-03,  1.2680e-02, -2.7058e-03,  9.2492e-04,  3.0359e-02,\n",
      "         1.9635e-02, -1.6071e-02, -1.3568e-02, -2.0982e-02,  2.4208e-02,\n",
      "         2.4343e-02, -2.3207e-02, -2.0666e-02,  1.1127e-02,  1.5073e-04,\n",
      "         2.5939e-02,  2.3247e-02,  1.6389e-02, -2.7858e-02, -7.2808e-03,\n",
      "        -5.2277e-03, -3.5320e-03, -1.0139e-02,  2.5542e-02, -4.9918e-03,\n",
      "         2.8407e-02, -2.5811e-03,  3.9704e-03, -1.6543e-02, -1.7041e-02,\n",
      "        -3.2327e-02, -2.1848e-02, -1.6159e-02,  2.7140e-02, -2.7475e-02,\n",
      "         2.4770e-02,  1.5731e-02, -8.8296e-03, -3.9173e-03, -6.9022e-03,\n",
      "         5.1156e-03, -7.9415e-03, -1.6810e-02, -3.0578e-02, -1.8130e-02,\n",
      "        -7.6193e-03, -2.2144e-02, -2.7055e-02, -2.3041e-03, -2.8202e-02,\n",
      "        -7.4944e-03, -1.9495e-03, -2.0951e-02,  1.4328e-02, -2.9956e-04,\n",
      "        -2.3599e-02, -2.8752e-02, -2.5932e-02, -2.6017e-02, -2.4000e-03,\n",
      "         1.1066e-02, -3.7990e-03,  7.9212e-03, -3.2367e-02,  1.4094e-03,\n",
      "         1.7808e-02, -1.2136e-02, -2.3835e-02,  3.0103e-02, -1.2368e-02,\n",
      "         5.6431e-03, -2.9792e-02,  6.7978e-03, -7.7381e-03,  1.6167e-02,\n",
      "         2.9620e-02, -1.6504e-02, -2.1548e-02, -2.3208e-04, -1.6639e-02,\n",
      "        -5.2056e-03, -1.3200e-02, -1.4846e-02, -5.4663e-03, -1.1704e-02,\n",
      "         8.4552e-03, -1.2962e-02, -1.3141e-02, -1.9439e-02, -3.3217e-03,\n",
      "        -1.0806e-03, -4.4586e-03, -1.5775e-02,  6.2980e-03, -4.7570e-03,\n",
      "        -1.4781e-02, -3.0207e-02, -2.5249e-02,  8.2210e-03, -9.6665e-03,\n",
      "        -2.1709e-02,  1.0200e-02, -2.0282e-02, -2.4388e-02, -1.6328e-02,\n",
      "        -1.7116e-02, -7.8665e-03,  1.6649e-02, -4.7265e-03, -2.8738e-02,\n",
      "        -2.9338e-02, -9.7383e-03,  1.1948e-02,  1.9008e-02, -4.7672e-03,\n",
      "        -8.7974e-03,  6.5618e-03,  1.8623e-02,  2.9809e-02, -1.7694e-02,\n",
      "         6.8090e-03,  1.6431e-02,  1.6891e-02, -3.5904e-03, -8.3593e-03,\n",
      "         2.5742e-02,  2.6666e-02, -2.6697e-02, -5.4523e-03, -1.9650e-02,\n",
      "         1.6259e-03, -2.7227e-02, -2.4397e-02, -8.7739e-04, -2.4446e-02,\n",
      "        -1.0971e-02, -2.2848e-03,  1.8165e-02, -1.6848e-02,  2.0348e-02,\n",
      "         1.1339e-02, -2.5982e-02,  3.0067e-04,  7.9662e-03,  6.8722e-03,\n",
      "        -1.9554e-02, -1.0006e-02, -1.4402e-02,  5.7194e-03, -2.3930e-02,\n",
      "        -1.8959e-02,  2.5382e-02, -9.4577e-03,  1.1810e-02, -1.6727e-02,\n",
      "         7.5024e-03, -4.6156e-04, -2.1422e-02, -1.6082e-02,  1.8077e-02,\n",
      "         1.5692e-02,  1.1344e-02,  1.6053e-02, -1.8410e-02, -1.3310e-02,\n",
      "         2.2571e-02, -2.1234e-02, -2.4313e-02, -1.6736e-03,  1.5805e-02,\n",
      "        -1.9292e-02, -5.3021e-03,  2.7686e-02, -5.8371e-03,  4.1009e-03,\n",
      "        -1.7694e-03, -9.7871e-03, -2.0281e-02, -1.7670e-02, -2.9158e-02,\n",
      "         1.5956e-02,  3.8302e-03,  2.1074e-02,  2.4062e-02, -1.5757e-02,\n",
      "         1.3846e-02, -3.9629e-03,  1.4209e-03,  2.3504e-02,  5.7536e-03,\n",
      "         1.2300e-02,  8.5112e-03,  2.6257e-02, -1.6211e-02, -5.9647e-03,\n",
      "         2.1442e-02,  8.9557e-03,  1.5665e-02,  2.2722e-02,  8.6469e-03,\n",
      "         1.9870e-02, -3.0935e-02,  7.1539e-03, -2.3184e-02, -2.8040e-02,\n",
      "        -1.3510e-02, -2.5657e-02,  1.2547e-02, -2.7520e-02, -4.8447e-03,\n",
      "         2.3230e-02,  9.0877e-03,  1.3833e-03, -1.6595e-02,  2.0314e-02,\n",
      "        -2.3797e-02, -3.1289e-02,  3.8726e-03,  2.6556e-02, -7.2376e-03,\n",
      "        -8.4550e-03, -1.6983e-02, -2.6657e-02, -1.5768e-02, -1.8979e-02,\n",
      "        -1.9075e-02,  3.6595e-03, -9.9600e-05,  1.2278e-02, -2.4386e-03,\n",
      "        -1.5077e-02,  2.3204e-02, -1.9174e-03,  1.3624e-02, -1.9989e-02,\n",
      "         7.2196e-03,  3.0046e-02,  2.2584e-02,  1.4545e-02, -6.6027e-03,\n",
      "        -1.2028e-02,  1.9991e-02, -2.1835e-02,  1.9873e-02,  3.0485e-03,\n",
      "        -3.8696e-03,  1.9234e-02,  2.7215e-02,  1.7743e-02,  7.2728e-03,\n",
      "        -1.6481e-02, -2.1869e-02, -9.7334e-03, -5.2698e-03,  2.3552e-02,\n",
      "        -2.7526e-02,  2.7995e-02,  7.0394e-04,  4.9626e-03,  1.0161e-02,\n",
      "        -2.9228e-02,  2.2151e-02,  1.4032e-02, -2.7947e-02, -2.1396e-02,\n",
      "        -1.2559e-02, -1.2560e-02, -2.2464e-02,  2.7175e-02,  4.2196e-03,\n",
      "         2.1926e-02,  1.2943e-02,  2.7420e-02, -2.4558e-02, -2.2115e-02,\n",
      "        -2.8568e-02,  2.0243e-02, -1.6288e-02,  1.8103e-02, -2.0492e-02,\n",
      "         7.3502e-03,  2.9493e-02, -2.8266e-02, -1.8748e-02,  5.7485e-03,\n",
      "         4.7502e-03,  7.9331e-03,  7.4369e-03, -1.7783e-02, -2.5659e-02,\n",
      "        -2.8376e-02,  1.3194e-02,  7.5345e-03,  1.8278e-02, -2.1274e-02,\n",
      "         2.3751e-02,  1.1441e-02,  2.4846e-02, -6.3041e-03, -9.1657e-03,\n",
      "        -1.8581e-02, -1.9865e-02,  5.6059e-03,  1.5229e-02, -1.4187e-02,\n",
      "         2.3052e-02,  3.0868e-02,  2.0462e-02,  7.5042e-03, -2.5472e-02,\n",
      "        -1.3921e-02,  1.9400e-02, -6.3040e-03,  2.7265e-02,  1.5023e-02,\n",
      "        -7.2465e-03, -1.7043e-02, -1.3567e-02, -2.4041e-02,  1.7248e-02,\n",
      "         3.5034e-04, -2.0994e-02, -2.3387e-03, -5.0095e-03, -2.5378e-02,\n",
      "        -2.6058e-02,  4.0400e-03, -1.1167e-03,  7.3284e-03,  1.8124e-02,\n",
      "        -3.0346e-02,  2.9198e-02,  1.4955e-02,  3.7301e-03,  7.6423e-03,\n",
      "        -2.6341e-02, -1.6312e-02,  2.6231e-02, -1.8130e-02,  1.3398e-02,\n",
      "        -5.9805e-03, -2.7962e-02, -2.3518e-02, -2.1867e-02,  2.9888e-02,\n",
      "         2.4799e-02, -1.4768e-02,  6.0559e-03, -2.4609e-02, -2.0526e-02,\n",
      "        -1.1310e-03,  2.0032e-02, -3.1227e-02, -7.0228e-03, -1.6503e-02,\n",
      "        -2.8818e-02, -2.3303e-02,  6.7652e-03,  1.5307e-02,  8.5244e-03,\n",
      "        -8.6258e-03,  2.2231e-02,  3.0303e-02, -6.1823e-03, -2.2320e-02,\n",
      "         6.0155e-03,  3.1192e-02, -1.0140e-02,  2.9222e-02,  2.0100e-02,\n",
      "         2.4979e-02,  1.0550e-02, -8.5645e-03, -4.6407e-03, -2.2834e-03,\n",
      "         2.9707e-02,  2.2608e-02, -2.3033e-02,  2.0690e-03,  2.1489e-02,\n",
      "         1.9551e-03,  2.7341e-02,  4.6090e-03,  2.8484e-03,  2.7247e-04,\n",
      "         1.3819e-02,  3.0927e-02,  1.7457e-02,  9.2741e-03, -2.1286e-02,\n",
      "         1.7802e-02,  2.3843e-02, -2.9733e-02, -7.5174e-03, -2.5694e-03,\n",
      "        -5.0712e-04, -1.2360e-02,  9.4557e-03, -2.8475e-03, -1.7715e-02,\n",
      "         2.9832e-02, -6.6939e-03, -1.1700e-02, -2.5773e-02, -1.0148e-02,\n",
      "        -7.6428e-03,  4.1474e-03, -2.8291e-02, -1.1026e-02,  3.0008e-02,\n",
      "        -1.7992e-02,  2.0577e-02, -2.6359e-03,  1.9535e-02, -1.6682e-02,\n",
      "         5.7414e-03,  2.1243e-02, -1.1652e-02, -3.4565e-03, -2.0615e-02,\n",
      "         1.6799e-03,  2.9638e-02, -1.3042e-02,  2.8856e-02, -2.6748e-03,\n",
      "        -1.4667e-04,  1.9808e-02, -1.1420e-02,  2.1088e-02,  1.1416e-02,\n",
      "        -3.1301e-02, -2.9482e-02], device='cuda:0')), ('clinical_rna_feedforward.feedforward.9.weight', tensor([[ 0.0030,  0.0172, -0.0389,  ..., -0.0248, -0.0401,  0.0034],\n",
      "        [-0.0056,  0.0229, -0.0375,  ..., -0.0115, -0.0278,  0.0418],\n",
      "        [-0.0109, -0.0106,  0.0120,  ...,  0.0113, -0.0003, -0.0296],\n",
      "        ...,\n",
      "        [ 0.0352, -0.0020, -0.0366,  ..., -0.0275,  0.0082, -0.0049],\n",
      "        [ 0.0366,  0.0429, -0.0147,  ...,  0.0199, -0.0150, -0.0063],\n",
      "        [-0.0288,  0.0325, -0.0377,  ...,  0.0215,  0.0110,  0.0126]],\n",
      "       device='cuda:0')), ('clinical_rna_feedforward.feedforward.9.bias', tensor([ 1.4828e-02,  1.6854e-02,  4.2669e-02, -4.2617e-03,  3.3298e-02,\n",
      "         2.1518e-02,  3.8774e-02,  2.3076e-03, -2.9341e-02,  1.3388e-02,\n",
      "         1.6615e-02, -2.7186e-02,  3.2945e-02, -1.6107e-02,  2.2373e-03,\n",
      "        -5.6412e-03,  1.9452e-02,  5.1401e-03, -1.2031e-02,  5.7407e-03,\n",
      "        -3.6672e-02,  1.8105e-03,  1.2911e-02, -3.1939e-02, -1.5679e-02,\n",
      "         6.6368e-03,  4.4771e-02, -2.1072e-02,  4.4161e-02, -4.4977e-03,\n",
      "         3.8374e-02, -2.5778e-02,  1.6820e-02, -3.3340e-02, -6.6964e-03,\n",
      "        -4.0274e-03,  5.1214e-03,  1.4510e-02, -1.1011e-02,  2.1831e-02,\n",
      "         2.0952e-02, -1.1353e-02, -9.6020e-03,  1.7607e-02,  1.4320e-02,\n",
      "        -3.9872e-02, -4.5799e-03,  4.1275e-02,  1.1727e-02, -3.9301e-03,\n",
      "        -1.7572e-02,  3.1285e-02, -2.4997e-02,  1.7721e-02, -7.0434e-03,\n",
      "        -1.8046e-02,  4.2528e-02,  1.5482e-02, -4.2827e-02, -1.0908e-02,\n",
      "         1.0187e-02,  3.8808e-02, -8.0284e-03,  2.1035e-02, -3.7995e-02,\n",
      "        -3.0631e-02, -3.0356e-02, -2.9599e-03, -3.6304e-02, -4.2609e-02,\n",
      "         1.9972e-02, -3.3029e-02,  3.8195e-02,  3.3389e-02, -3.5960e-02,\n",
      "        -8.0531e-03,  1.6664e-02, -4.7614e-03, -6.1584e-03,  8.1431e-03,\n",
      "         2.5896e-02,  9.5051e-03,  4.0256e-02, -3.2618e-02,  2.4806e-03,\n",
      "        -3.8946e-02,  9.3338e-03, -2.0548e-02,  2.2110e-02,  3.2245e-02,\n",
      "        -1.3142e-02, -2.6375e-02, -2.3687e-02, -2.5437e-02,  1.7263e-02,\n",
      "        -3.2984e-02, -2.0755e-03, -3.1220e-02, -3.2999e-02,  3.2328e-02,\n",
      "         5.1003e-03, -4.0598e-02, -2.8304e-02, -1.3566e-03, -3.0268e-02,\n",
      "        -2.5459e-02, -3.3985e-02,  2.6304e-02, -2.6688e-02, -6.5346e-03,\n",
      "        -1.2961e-02, -2.7706e-02, -2.2469e-02,  3.7690e-02,  3.8128e-02,\n",
      "         2.5474e-02,  9.8013e-03, -1.6398e-02, -7.1476e-03,  3.9058e-02,\n",
      "        -1.9944e-02,  1.5944e-02, -1.6530e-02, -3.7336e-02, -1.9150e-04,\n",
      "         4.4762e-02, -3.3142e-03, -7.9088e-04,  6.4643e-03,  3.9357e-02,\n",
      "         2.3693e-02, -1.3498e-02,  3.6370e-02,  2.4094e-02,  3.9730e-02,\n",
      "        -1.1512e-03, -1.1824e-03, -4.3515e-02, -1.3403e-02, -4.4049e-02,\n",
      "        -3.9408e-02,  5.3058e-03,  7.3418e-03,  3.6012e-02, -2.1932e-02,\n",
      "         2.8280e-03,  4.1163e-02,  4.6627e-04, -3.8704e-02,  4.2697e-02,\n",
      "        -3.0630e-02, -1.7481e-02,  3.1702e-02,  3.2034e-02, -2.5207e-02,\n",
      "         1.1446e-03,  3.9408e-03,  3.9260e-03,  2.8058e-02, -4.2100e-02,\n",
      "         4.0119e-02,  3.7172e-02, -6.6243e-04,  2.5131e-02, -2.1128e-02,\n",
      "        -1.9494e-02, -3.2067e-02,  3.4816e-02,  1.5410e-02,  3.7154e-02,\n",
      "        -3.4411e-02, -4.1361e-02,  4.1716e-02, -3.3312e-02, -4.0515e-02,\n",
      "        -8.4767e-03,  9.8349e-03, -5.6818e-03, -3.5741e-03, -2.4196e-03,\n",
      "         3.0210e-02, -1.2377e-02, -3.8752e-02, -3.5664e-03, -3.9860e-02,\n",
      "        -2.9383e-02, -3.0057e-02,  3.3810e-02, -9.3425e-04,  2.7357e-02,\n",
      "        -4.5036e-02, -2.9843e-02, -4.1723e-02,  3.2641e-02, -3.3551e-02,\n",
      "         1.5916e-02,  2.7998e-02,  3.5986e-02, -3.3364e-02,  2.6196e-02,\n",
      "        -3.1085e-02,  2.4302e-02,  1.2643e-02, -3.5709e-04,  2.6259e-02,\n",
      "         3.4792e-02,  2.8460e-02, -2.8220e-02, -3.5917e-02,  7.9079e-03,\n",
      "         6.7270e-03,  4.3255e-02, -3.6528e-02, -3.4540e-02, -2.3074e-02,\n",
      "        -4.1841e-03, -3.8413e-02, -3.2069e-02,  1.1363e-04, -2.2433e-02,\n",
      "        -6.9064e-03, -2.4919e-02, -4.1014e-02,  1.8232e-02,  1.4343e-02,\n",
      "         1.0237e-02,  3.5884e-02,  1.8330e-02,  2.0192e-02,  3.4340e-02,\n",
      "         1.3869e-02, -2.5196e-02, -4.2229e-02, -1.0522e-02, -2.0558e-02,\n",
      "         4.2251e-02,  1.4313e-02,  3.9612e-02,  4.0982e-02,  4.0312e-03,\n",
      "         1.2857e-02, -1.0651e-03,  1.0501e-02,  4.4073e-02,  2.8764e-02,\n",
      "         1.8486e-02,  4.3086e-02, -1.8503e-02,  5.4351e-03,  3.1795e-02,\n",
      "        -3.5395e-02,  1.7240e-02, -2.3726e-03, -1.0206e-02,  1.4734e-02,\n",
      "        -1.9274e-02,  2.9954e-02,  2.3764e-02, -2.7346e-02, -2.3996e-02,\n",
      "         4.0190e-02,  2.4386e-02,  1.2525e-02, -3.7621e-02,  2.1802e-02,\n",
      "         1.0882e-04, -2.8361e-02, -1.9796e-02,  2.0401e-02, -1.6625e-02,\n",
      "        -1.4717e-02,  4.4951e-03, -4.3661e-02,  1.2552e-02,  3.8939e-02,\n",
      "         2.5487e-02, -2.4369e-02,  3.7179e-02, -3.9028e-02, -2.7659e-02,\n",
      "        -1.6757e-02, -1.8865e-03, -2.1282e-02, -2.3578e-02, -2.5558e-02,\n",
      "        -1.3131e-02,  2.4481e-02,  5.9085e-03,  1.6594e-02,  2.3417e-02,\n",
      "        -2.6938e-02,  2.4192e-02, -3.4959e-02,  2.8296e-02,  2.8840e-02,\n",
      "        -3.9451e-02,  3.3194e-02,  3.1125e-03, -1.6467e-02,  1.8910e-03,\n",
      "        -2.0728e-02, -9.0408e-03, -3.1726e-02, -1.3173e-02, -2.4029e-02,\n",
      "        -2.5332e-02, -3.0142e-02, -3.8300e-03,  1.0182e-02,  1.9819e-02,\n",
      "        -3.0040e-02, -1.4484e-02, -1.3370e-02, -1.6249e-02,  2.6749e-02,\n",
      "         2.0967e-02,  3.4547e-02, -1.1365e-02,  4.2511e-02, -1.7423e-02,\n",
      "         1.2768e-02, -3.1298e-02, -3.8506e-02, -2.6294e-02,  4.1835e-02,\n",
      "         1.2539e-02,  2.3299e-02,  3.9865e-02,  5.1098e-03,  8.5890e-03,\n",
      "         4.4386e-02,  4.1583e-02,  6.5362e-03,  2.1708e-02,  3.8114e-02,\n",
      "         4.2659e-02,  1.4047e-02, -6.5735e-03, -3.1642e-02, -3.3830e-04,\n",
      "         4.2875e-02, -3.7281e-02,  3.4434e-03, -1.3309e-02,  2.4423e-02,\n",
      "         4.5998e-05,  2.6266e-02,  3.9293e-02, -3.2069e-02,  2.3159e-02,\n",
      "         4.1843e-02,  4.0320e-02,  2.1009e-02,  1.1391e-02,  3.9734e-02,\n",
      "        -3.4137e-02,  2.0603e-02,  2.0797e-02,  2.7760e-02, -2.4365e-02,\n",
      "        -1.3042e-02,  2.9309e-03,  1.7476e-02, -2.8277e-02, -3.4277e-03,\n",
      "         2.1896e-02, -2.7562e-02,  1.3444e-02, -3.6942e-02,  3.1688e-02,\n",
      "         3.2736e-02,  2.0342e-02, -4.2790e-02,  4.2681e-02, -7.7514e-03,\n",
      "         1.8188e-03, -2.4968e-02, -2.8556e-02,  2.6870e-02,  4.2574e-02,\n",
      "         1.7777e-02, -2.5820e-02,  4.9321e-03, -1.6871e-02, -4.3070e-02,\n",
      "        -2.8009e-02, -4.0616e-02,  4.1111e-02, -1.2546e-02, -1.8567e-02,\n",
      "         2.4765e-02, -2.4291e-02,  3.8563e-02, -4.2518e-02, -4.0539e-02,\n",
      "         3.0354e-02,  2.8262e-02, -1.1489e-02, -7.4718e-03,  1.0310e-03,\n",
      "         2.2315e-02,  2.4685e-02, -3.0643e-02, -9.8660e-03,  3.9743e-02,\n",
      "         2.0114e-02, -1.5805e-02, -2.7685e-02,  3.3003e-02,  2.6008e-02,\n",
      "        -3.9625e-02, -5.2705e-03,  3.1695e-02,  1.8152e-03,  6.2066e-03,\n",
      "         3.3127e-02,  1.2979e-02,  1.9365e-03,  2.9576e-02, -5.3636e-03,\n",
      "         3.4947e-02,  3.8646e-02,  8.1713e-03, -1.8396e-02,  1.3056e-02,\n",
      "         2.9909e-02,  3.7744e-02,  1.3143e-02, -3.4468e-02,  4.0321e-02,\n",
      "        -7.6941e-03,  2.4585e-02,  3.3070e-02,  1.1232e-02,  4.2048e-04,\n",
      "        -1.8594e-02,  4.0164e-02,  2.5033e-02, -1.7883e-02,  2.9105e-02,\n",
      "         2.8647e-02, -3.7006e-03, -2.8199e-02,  1.8293e-02, -2.8611e-02,\n",
      "         1.3169e-02, -3.6379e-02, -1.0730e-02,  3.8491e-02,  4.0580e-02,\n",
      "        -2.2358e-03,  1.9360e-02,  4.4192e-02,  3.4210e-02, -4.0898e-02,\n",
      "        -2.6421e-02, -3.3163e-02, -1.5684e-02,  3.3683e-03,  1.5412e-02,\n",
      "         1.3067e-02, -2.2996e-02,  2.6664e-02,  3.0162e-02,  4.2736e-02,\n",
      "         1.2925e-02, -1.9515e-02, -3.2047e-02,  2.2998e-02, -1.4809e-02,\n",
      "         3.7871e-02,  1.2535e-02, -2.6687e-02, -5.3852e-03, -2.6750e-02,\n",
      "        -1.7976e-03,  2.6706e-02, -1.9332e-02,  1.3011e-02,  4.1499e-02,\n",
      "        -1.9100e-02, -5.7636e-04,  1.3861e-02, -2.3387e-02, -9.8295e-03,\n",
      "         2.6593e-04,  3.0776e-02,  1.9377e-02,  1.7994e-02,  1.2701e-02,\n",
      "        -3.7562e-02,  4.1022e-02,  2.9239e-02,  2.9179e-02, -3.9602e-02,\n",
      "         2.1645e-02,  4.0009e-02, -3.3009e-02, -4.5802e-02,  2.1115e-02,\n",
      "         1.9223e-02, -3.9095e-02, -9.7227e-03, -2.4078e-02,  1.5459e-02,\n",
      "        -8.5065e-03, -5.0222e-03,  1.5531e-02, -3.4117e-02, -3.8866e-02,\n",
      "        -2.2250e-02, -2.9054e-02], device='cuda:0')), ('clinical_rna_feedforward.feedforward.12.weight', tensor([[ 0.0344, -0.0035,  0.0404,  ...,  0.0168, -0.0220, -0.0407],\n",
      "        [ 0.0242, -0.0227, -0.0149,  ..., -0.0019,  0.0394,  0.0269],\n",
      "        [ 0.0283,  0.0220,  0.0358,  ..., -0.0377, -0.0048,  0.0221],\n",
      "        ...,\n",
      "        [ 0.0184,  0.0031,  0.0003,  ..., -0.0003, -0.0250,  0.0124],\n",
      "        [ 0.0186, -0.0138,  0.0326,  ..., -0.0397,  0.0138, -0.0199],\n",
      "        [-0.0160, -0.0320, -0.0207,  ..., -0.0146, -0.0091, -0.0114]],\n",
      "       device='cuda:0')), ('clinical_rna_feedforward.feedforward.12.bias', tensor([-0.0383,  0.0224, -0.0229, -0.0368, -0.0054, -0.0201, -0.0274, -0.0403,\n",
      "         0.0295, -0.0367,  0.0260, -0.0444, -0.0185, -0.0416,  0.0198,  0.0347,\n",
      "        -0.0040,  0.0192, -0.0283, -0.0095, -0.0067, -0.0039, -0.0016,  0.0277,\n",
      "        -0.0247,  0.0399, -0.0165, -0.0150,  0.0405,  0.0075, -0.0232, -0.0410,\n",
      "         0.0109, -0.0039,  0.0431,  0.0108, -0.0174,  0.0361,  0.0387, -0.0243,\n",
      "         0.0092, -0.0335,  0.0033, -0.0211, -0.0135,  0.0175,  0.0284,  0.0154,\n",
      "         0.0391, -0.0339,  0.0411,  0.0233, -0.0305,  0.0342, -0.0319, -0.0326,\n",
      "        -0.0263,  0.0338, -0.0089,  0.0035, -0.0067,  0.0192,  0.0159, -0.0266,\n",
      "         0.0018,  0.0122, -0.0285,  0.0400, -0.0037,  0.0418, -0.0040, -0.0240,\n",
      "        -0.0091,  0.0141,  0.0147, -0.0434, -0.0170,  0.0250,  0.0244, -0.0040,\n",
      "         0.0351, -0.0105,  0.0368,  0.0022,  0.0272, -0.0396,  0.0300,  0.0137,\n",
      "         0.0226, -0.0088,  0.0102,  0.0088, -0.0076, -0.0345,  0.0153, -0.0246,\n",
      "        -0.0406,  0.0215, -0.0034, -0.0088,  0.0086,  0.0213,  0.0309,  0.0078,\n",
      "         0.0059,  0.0055, -0.0053,  0.0436, -0.0282, -0.0026, -0.0318, -0.0276,\n",
      "         0.0070, -0.0336, -0.0441, -0.0368, -0.0034, -0.0385, -0.0393,  0.0323,\n",
      "         0.0181, -0.0324, -0.0114,  0.0423, -0.0093, -0.0156,  0.0318, -0.0258,\n",
      "         0.0273,  0.0051, -0.0151,  0.0198, -0.0152,  0.0369,  0.0403, -0.0246,\n",
      "         0.0196, -0.0165, -0.0204, -0.0424, -0.0412,  0.0189,  0.0428,  0.0251,\n",
      "         0.0108, -0.0413,  0.0195, -0.0209, -0.0349,  0.0313,  0.0312, -0.0274,\n",
      "         0.0162,  0.0255, -0.0338,  0.0248, -0.0077, -0.0265, -0.0021,  0.0263,\n",
      "         0.0340,  0.0050, -0.0002, -0.0089,  0.0216,  0.0016,  0.0421,  0.0297,\n",
      "        -0.0214,  0.0070,  0.0080,  0.0135,  0.0227, -0.0229, -0.0096,  0.0185,\n",
      "         0.0277,  0.0247, -0.0073,  0.0385, -0.0121,  0.0080, -0.0005, -0.0211,\n",
      "        -0.0149, -0.0445,  0.0311,  0.0325,  0.0305,  0.0247,  0.0132,  0.0055,\n",
      "        -0.0035,  0.0148,  0.0120, -0.0313, -0.0158,  0.0099,  0.0042,  0.0265,\n",
      "        -0.0085, -0.0141, -0.0279, -0.0203, -0.0254,  0.0304, -0.0078, -0.0312,\n",
      "        -0.0210,  0.0385,  0.0147, -0.0214,  0.0272, -0.0030, -0.0443,  0.0429,\n",
      "         0.0070, -0.0040,  0.0060,  0.0284,  0.0246, -0.0414, -0.0390, -0.0029,\n",
      "         0.0427,  0.0360, -0.0118,  0.0303,  0.0290, -0.0411,  0.0032,  0.0052,\n",
      "         0.0398,  0.0242, -0.0408,  0.0355,  0.0267,  0.0201,  0.0330,  0.0226,\n",
      "        -0.0368, -0.0299, -0.0449,  0.0397, -0.0043,  0.0286, -0.0130,  0.0120,\n",
      "        -0.0311, -0.0311, -0.0261, -0.0435, -0.0360,  0.0244, -0.0261,  0.0113],\n",
      "       device='cuda:0')), ('clinical_rna_feedforward.feedforward.15.weight', tensor([[-0.0395, -0.0613,  0.0592,  ..., -0.0090, -0.0384,  0.0100],\n",
      "        [-0.0082,  0.0101, -0.0223,  ..., -0.0419, -0.0098, -0.0155],\n",
      "        [ 0.0369, -0.0358, -0.0023,  ..., -0.0454, -0.0354,  0.0035],\n",
      "        ...,\n",
      "        [ 0.0305, -0.0622, -0.0005,  ...,  0.0337,  0.0073,  0.0309],\n",
      "        [ 0.0042,  0.0115, -0.0531,  ..., -0.0028,  0.0605, -0.0536],\n",
      "        [-0.0509, -0.0591,  0.0214,  ...,  0.0025,  0.0522,  0.0490]],\n",
      "       device='cuda:0')), ('clinical_rna_feedforward.feedforward.15.bias', tensor([ 0.0495, -0.0206, -0.0603, -0.0089,  0.0064, -0.0334, -0.0443, -0.0017,\n",
      "         0.0050,  0.0158,  0.0480, -0.0225, -0.0458,  0.0276,  0.0266,  0.0160,\n",
      "        -0.0384,  0.0004,  0.0583,  0.0047,  0.0452, -0.0318,  0.0470, -0.0156,\n",
      "         0.0200,  0.0614, -0.0082, -0.0242,  0.0110, -0.0624, -0.0071, -0.0390,\n",
      "         0.0130,  0.0581,  0.0035, -0.0323,  0.0253,  0.0590, -0.0185, -0.0267,\n",
      "        -0.0156, -0.0588, -0.0216, -0.0061,  0.0256,  0.0275, -0.0537, -0.0249,\n",
      "         0.0488,  0.0002,  0.0427,  0.0314, -0.0125, -0.0512,  0.0045,  0.0311,\n",
      "        -0.0424, -0.0045,  0.0200,  0.0485,  0.0331,  0.0070,  0.0207, -0.0485,\n",
      "        -0.0473, -0.0104,  0.0513, -0.0267,  0.0611, -0.0394,  0.0137, -0.0528,\n",
      "         0.0523, -0.0143,  0.0296,  0.0395,  0.0044, -0.0316,  0.0028,  0.0232,\n",
      "         0.0509, -0.0599, -0.0462, -0.0620, -0.0044, -0.0529,  0.0563, -0.0313,\n",
      "        -0.0168,  0.0153,  0.0320,  0.0207, -0.0325, -0.0339,  0.0460, -0.0260,\n",
      "        -0.0608,  0.0085, -0.0581,  0.0123,  0.0380, -0.0239,  0.0018, -0.0273,\n",
      "         0.0303, -0.0358, -0.0503,  0.0371,  0.0537, -0.0448,  0.0345, -0.0066,\n",
      "         0.0405,  0.0502,  0.0528,  0.0300, -0.0366,  0.0369,  0.0618, -0.0209,\n",
      "        -0.0587, -0.0523,  0.0348,  0.0305,  0.0351,  0.0218, -0.0047, -0.0452,\n",
      "        -0.0226, -0.0020,  0.0306,  0.0339,  0.0213, -0.0471,  0.0607,  0.0274,\n",
      "         0.0127,  0.0503, -0.0511, -0.0466,  0.0462,  0.0216,  0.0344,  0.0621,\n",
      "        -0.0412, -0.0519,  0.0341, -0.0615,  0.0149,  0.0529,  0.0418, -0.0497,\n",
      "        -0.0464, -0.0161,  0.0472, -0.0228,  0.0067, -0.0001,  0.0488,  0.0428,\n",
      "         0.0467,  0.0493,  0.0564, -0.0365, -0.0040, -0.0159, -0.0040, -0.0015,\n",
      "        -0.0043, -0.0469, -0.0350,  0.0079, -0.0527, -0.0144,  0.0172,  0.0191,\n",
      "        -0.0168, -0.0067,  0.0197, -0.0356,  0.0305,  0.0437,  0.0475, -0.0485,\n",
      "        -0.0414, -0.0512,  0.0517, -0.0456,  0.0029,  0.0333,  0.0341, -0.0199,\n",
      "         0.0578, -0.0447,  0.0023,  0.0558,  0.0221,  0.0082,  0.0554,  0.0097,\n",
      "        -0.0486, -0.0366, -0.0441,  0.0044, -0.0270, -0.0466,  0.0127, -0.0563,\n",
      "        -0.0355, -0.0424,  0.0375, -0.0275, -0.0119,  0.0591,  0.0291, -0.0611,\n",
      "         0.0112,  0.0234, -0.0628, -0.0520,  0.0305,  0.0526,  0.0325,  0.0134,\n",
      "         0.0049, -0.0224, -0.0407, -0.0546, -0.0116,  0.0196, -0.0407,  0.0566,\n",
      "         0.0506, -0.0433,  0.0173,  0.0170,  0.0208, -0.0301,  0.0481, -0.0146,\n",
      "         0.0312,  0.0377,  0.0024,  0.0184, -0.0485, -0.0177, -0.0228,  0.0388,\n",
      "         0.0346,  0.0530,  0.0043,  0.0546, -0.0572, -0.0389,  0.0100,  0.0577],\n",
      "       device='cuda:0')), ('clinical_rna_feedforward.feedforward.18.weight', tensor([[ 0.0046, -0.0524,  0.0350,  ..., -0.0232, -0.0403,  0.0153],\n",
      "        [-0.0192,  0.0489,  0.0351,  ...,  0.0006, -0.0052,  0.0628],\n",
      "        [-0.0439,  0.0035, -0.0201,  ...,  0.0572, -0.0338, -0.0245],\n",
      "        ...,\n",
      "        [ 0.0435,  0.0623, -0.0300,  ..., -0.0034,  0.0259,  0.0101],\n",
      "        [ 0.0243, -0.0248,  0.0311,  ...,  0.0064,  0.0174, -0.0010],\n",
      "        [ 0.0410, -0.0625,  0.0456,  ..., -0.0560,  0.0280,  0.0436]],\n",
      "       device='cuda:0')), ('clinical_rna_feedforward.feedforward.18.bias', tensor([-0.0202, -0.0439, -0.0167,  0.0164,  0.0142, -0.0488, -0.0363, -0.0575,\n",
      "         0.0315, -0.0044,  0.0096, -0.0500, -0.0172, -0.0042, -0.0566,  0.0439,\n",
      "         0.0503,  0.0447, -0.0054,  0.0212, -0.0011, -0.0033, -0.0248,  0.0067,\n",
      "         0.0286, -0.0055, -0.0320,  0.0062,  0.0465, -0.0044,  0.0317,  0.0052,\n",
      "         0.0502,  0.0090, -0.0175,  0.0509,  0.0473, -0.0042,  0.0035,  0.0300,\n",
      "         0.0386,  0.0068,  0.0565,  0.0364, -0.0256,  0.0439, -0.0246, -0.0379,\n",
      "        -0.0092, -0.0279,  0.0230,  0.0520,  0.0014,  0.0171,  0.0209, -0.0615,\n",
      "         0.0353, -0.0039, -0.0084, -0.0617, -0.0046, -0.0535, -0.0054, -0.0363,\n",
      "         0.0604,  0.0429,  0.0438,  0.0181, -0.0008, -0.0242, -0.0549,  0.0090,\n",
      "         0.0402, -0.0005,  0.0358, -0.0581, -0.0449, -0.0253,  0.0596,  0.0460,\n",
      "        -0.0059,  0.0348,  0.0209,  0.0499, -0.0245,  0.0441, -0.0282,  0.0264,\n",
      "        -0.0309,  0.0281, -0.0388,  0.0078, -0.0209,  0.0038,  0.0352, -0.0434,\n",
      "         0.0295, -0.0606, -0.0031, -0.0542,  0.0073, -0.0052,  0.0084,  0.0046,\n",
      "         0.0320, -0.0543,  0.0377,  0.0129, -0.0134, -0.0403, -0.0489, -0.0139,\n",
      "        -0.0069, -0.0009, -0.0085, -0.0307,  0.0393, -0.0074,  0.0265, -0.0465,\n",
      "         0.0137, -0.0036, -0.0528, -0.0153,  0.0164, -0.0626,  0.0011, -0.0579],\n",
      "       device='cuda:0')), ('clinical_rna_feedforward.feedforward.21.weight', tensor([[ 0.0106,  0.0409,  0.0641,  ...,  0.0812, -0.0063, -0.0803],\n",
      "        [ 0.0408,  0.0094, -0.0303,  ...,  0.0463, -0.0683, -0.0346],\n",
      "        [ 0.0076, -0.0656,  0.0058,  ..., -0.0189,  0.0060,  0.0881],\n",
      "        ...,\n",
      "        [ 0.0177, -0.0740,  0.0670,  ..., -0.0725,  0.0881,  0.0130],\n",
      "        [ 0.0444,  0.0367, -0.0807,  ...,  0.0372, -0.0322, -0.0302],\n",
      "        [-0.0554, -0.0249,  0.0779,  ...,  0.0679, -0.0312, -0.0461]],\n",
      "       device='cuda:0')), ('clinical_rna_feedforward.feedforward.21.bias', tensor([-0.0514, -0.0624,  0.0183,  0.0015,  0.0350, -0.0840,  0.0551,  0.0280,\n",
      "         0.0675,  0.0312, -0.0010, -0.0191, -0.0712, -0.0820, -0.0783,  0.0685,\n",
      "         0.0602,  0.0113, -0.0714, -0.0778, -0.0284, -0.0233,  0.0530, -0.0497,\n",
      "         0.0448, -0.0408, -0.0184, -0.0153,  0.0596,  0.0037,  0.0102,  0.0580,\n",
      "         0.0766,  0.0808, -0.0729, -0.0601, -0.0116,  0.0043,  0.0762,  0.0083,\n",
      "         0.0147,  0.0572, -0.0703, -0.0541,  0.0809,  0.0543, -0.0666,  0.0792,\n",
      "        -0.0034,  0.0521,  0.0723, -0.0560, -0.0507, -0.0504,  0.0782, -0.0221,\n",
      "        -0.0154,  0.0031,  0.0169,  0.0318,  0.0771, -0.0100,  0.0837,  0.0519,\n",
      "        -0.0467, -0.0369, -0.0554,  0.0105,  0.0277,  0.0036, -0.0870,  0.0364,\n",
      "         0.0155,  0.0258, -0.0646,  0.0040, -0.0892,  0.0711, -0.0023,  0.0564,\n",
      "        -0.0593,  0.0290,  0.0710,  0.0693,  0.0228, -0.0196, -0.0307, -0.0021,\n",
      "        -0.0283,  0.0102,  0.0610, -0.0376, -0.0608,  0.0171, -0.0859,  0.0457,\n",
      "        -0.0480,  0.0556,  0.0472, -0.0569, -0.0370,  0.0247, -0.0611, -0.0165,\n",
      "        -0.0522, -0.0540,  0.0642,  0.0059, -0.0326, -0.0793, -0.0305, -0.0195,\n",
      "        -0.0459, -0.0202, -0.0527, -0.0490,  0.0849, -0.0048,  0.0765,  0.0078,\n",
      "         0.0666,  0.0535, -0.0272,  0.0486, -0.0013,  0.0766,  0.0198, -0.0726],\n",
      "       device='cuda:0')), ('clinical_rna_feedforward.feedforward.24.weight', tensor([[ 0.0567,  0.0723, -0.0870,  ...,  0.0853,  0.0080,  0.0209],\n",
      "        [-0.0429,  0.0798, -0.0659,  ..., -0.0886,  0.0762,  0.0197],\n",
      "        [-0.0200,  0.0202,  0.0425,  ...,  0.0017,  0.0442, -0.0379],\n",
      "        ...,\n",
      "        [-0.0634,  0.0513, -0.0848,  ..., -0.0469,  0.0832,  0.0004],\n",
      "        [ 0.0166,  0.0105,  0.0887,  ..., -0.0533,  0.0401,  0.0432],\n",
      "        [ 0.0782,  0.0766, -0.0356,  ...,  0.0021, -0.0588, -0.0827]],\n",
      "       device='cuda:0')), ('clinical_rna_feedforward.feedforward.24.bias', tensor([ 0.0342, -0.0805, -0.0486,  0.0345,  0.0818, -0.0277, -0.0613, -0.0211,\n",
      "         0.0290, -0.0453, -0.0815, -0.0141, -0.0594,  0.0443, -0.0773,  0.0865,\n",
      "        -0.0210, -0.0024, -0.0126, -0.0634, -0.0368, -0.0060,  0.0325,  0.0380,\n",
      "         0.0843, -0.0007, -0.0361, -0.0110, -0.0435, -0.0562, -0.0340, -0.0826,\n",
      "        -0.0838, -0.0603, -0.0743,  0.0381, -0.0110, -0.0086,  0.0225, -0.0464,\n",
      "        -0.0183, -0.0014,  0.0675,  0.0802, -0.0516,  0.0458,  0.0713,  0.0474,\n",
      "        -0.0126,  0.0439,  0.0702,  0.0106, -0.0819, -0.0042, -0.0872,  0.0664,\n",
      "        -0.0797, -0.0349, -0.0700,  0.0760, -0.0660,  0.0441,  0.0879,  0.0594],\n",
      "       device='cuda:0')), ('clinical_rna_feedforward.feedforward.27.weight', tensor([[-0.1004,  0.1162, -0.0299,  ...,  0.0473, -0.0778, -0.1227],\n",
      "        [-0.0366, -0.0608, -0.0603,  ..., -0.0069,  0.0217, -0.0247],\n",
      "        [ 0.0576, -0.0919, -0.0909,  ...,  0.0975, -0.1142,  0.0012],\n",
      "        ...,\n",
      "        [-0.0693,  0.0207, -0.1159,  ...,  0.0805,  0.1228,  0.0682],\n",
      "        [ 0.0599,  0.0814, -0.0505,  ..., -0.0521,  0.1027, -0.0165],\n",
      "        [-0.0966,  0.0484,  0.1055,  ...,  0.0861, -0.0967,  0.0154]],\n",
      "       device='cuda:0')), ('clinical_rna_feedforward.feedforward.27.bias', tensor([-0.0855, -0.0184, -0.0783,  0.0558,  0.1117, -0.0572,  0.0984, -0.1016,\n",
      "        -0.0689, -0.1205,  0.0789, -0.0809, -0.0121,  0.0365,  0.0568, -0.0011,\n",
      "        -0.0764,  0.0283,  0.0114, -0.0019,  0.1044, -0.0090,  0.0584, -0.1056,\n",
      "         0.0918,  0.0269, -0.0846,  0.0455, -0.0765,  0.0535, -0.0602, -0.0889,\n",
      "         0.1103, -0.0392, -0.0052, -0.0942,  0.0575,  0.1100, -0.0438, -0.0460,\n",
      "        -0.1175,  0.0028, -0.0785,  0.0121, -0.1039, -0.0781,  0.0589, -0.1231,\n",
      "         0.0304, -0.1019,  0.1035,  0.0951, -0.0808,  0.0740, -0.0564, -0.1060,\n",
      "         0.0902,  0.0286, -0.0269,  0.0812,  0.0725,  0.0252,  0.0987,  0.0197],\n",
      "       device='cuda:0')), ('clinical_rna_feedforward.feedforward.30.weight', tensor([[ 0.1090, -0.0197,  0.0638,  ..., -0.1040, -0.1108,  0.0828],\n",
      "        [ 0.0892, -0.0350,  0.0103,  ...,  0.0325, -0.0923, -0.0130],\n",
      "        [-0.0872, -0.1143,  0.0739,  ..., -0.0469,  0.1222, -0.0525],\n",
      "        ...,\n",
      "        [ 0.0566, -0.0463,  0.0733,  ...,  0.0572,  0.0168,  0.0636],\n",
      "        [-0.0458,  0.0711, -0.0769,  ..., -0.0562,  0.0103, -0.0405],\n",
      "        [-0.0819, -0.1052, -0.0206,  ...,  0.0255, -0.0291, -0.0797]],\n",
      "       device='cuda:0')), ('clinical_rna_feedforward.feedforward.30.bias', tensor([ 0.0794, -0.1026,  0.0454,  0.1214,  0.0476,  0.1032,  0.0955,  0.0996,\n",
      "        -0.0334, -0.0865, -0.0129, -0.1233,  0.1155,  0.0755,  0.0766,  0.0987,\n",
      "         0.0241, -0.0666,  0.0827, -0.0461,  0.0775, -0.1113, -0.0956,  0.1128,\n",
      "        -0.0411,  0.0555,  0.0505,  0.0691, -0.0429, -0.0628, -0.1021, -0.0803],\n",
      "       device='cuda:0')), ('clinical_rna_feedforward.feedforward.33.weight', tensor([[-0.0027,  0.0430, -0.0957,  ...,  0.1025, -0.0609, -0.1076],\n",
      "        [ 0.1548,  0.1481,  0.1158,  ...,  0.0586,  0.0828,  0.0009],\n",
      "        [ 0.1314, -0.0690, -0.0580,  ..., -0.0901,  0.1418,  0.0782],\n",
      "        ...,\n",
      "        [-0.1105,  0.1505, -0.1571,  ...,  0.0174, -0.1086, -0.1050],\n",
      "        [-0.0402, -0.1637,  0.0911,  ...,  0.0941, -0.1393, -0.1672],\n",
      "        [ 0.1551, -0.0531,  0.0321,  ...,  0.0995,  0.1722,  0.0337]],\n",
      "       device='cuda:0')), ('clinical_rna_feedforward.feedforward.33.bias', tensor([ 0.1424,  0.1417, -0.0130, -0.1173,  0.0165,  0.0589,  0.0942,  0.0369,\n",
      "         0.0028, -0.0452, -0.0840, -0.0293,  0.0752, -0.0914, -0.1141, -0.1628,\n",
      "         0.1381, -0.1446,  0.1152,  0.1258, -0.0031,  0.0578, -0.0460, -0.1432,\n",
      "        -0.0223, -0.0373,  0.0465, -0.0448, -0.0808,  0.1672, -0.0163,  0.0868],\n",
      "       device='cuda:0')), ('wsi_fcn.conv.weight', tensor([[[-0.0144],\n",
      "         [-0.0217],\n",
      "         [-0.0351],\n",
      "         ...,\n",
      "         [-0.0425],\n",
      "         [-0.0021],\n",
      "         [-0.0352]],\n",
      "\n",
      "        [[-0.0044],\n",
      "         [ 0.0066],\n",
      "         [ 0.0141],\n",
      "         ...,\n",
      "         [ 0.0053],\n",
      "         [ 0.0115],\n",
      "         [-0.0200]],\n",
      "\n",
      "        [[ 0.0219],\n",
      "         [-0.0364],\n",
      "         [ 0.0175],\n",
      "         ...,\n",
      "         [-0.0356],\n",
      "         [ 0.0341],\n",
      "         [-0.0404]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0019],\n",
      "         [ 0.0105],\n",
      "         [-0.0329],\n",
      "         ...,\n",
      "         [ 0.0338],\n",
      "         [ 0.0080],\n",
      "         [-0.0359]],\n",
      "\n",
      "        [[ 0.0433],\n",
      "         [ 0.0287],\n",
      "         [-0.0436],\n",
      "         ...,\n",
      "         [-0.0195],\n",
      "         [ 0.0204],\n",
      "         [ 0.0315]],\n",
      "\n",
      "        [[ 0.0287],\n",
      "         [ 0.0075],\n",
      "         [-0.0158],\n",
      "         ...,\n",
      "         [-0.0183],\n",
      "         [-0.0265],\n",
      "         [ 0.0402]]], device='cuda:0')), ('wsi_fcn.conv.bias', tensor([ 0.0383,  0.0337,  0.0159,  0.0107, -0.0200, -0.0323,  0.0259, -0.0249,\n",
      "        -0.0063, -0.0367,  0.0127, -0.0342, -0.0190, -0.0184, -0.0433,  0.0192,\n",
      "        -0.0146,  0.0440, -0.0439,  0.0173,  0.0175,  0.0064, -0.0367,  0.0228,\n",
      "         0.0050,  0.0296,  0.0285,  0.0024,  0.0123,  0.0050,  0.0381, -0.0212,\n",
      "         0.0123,  0.0079,  0.0312, -0.0348, -0.0286, -0.0435, -0.0200,  0.0010,\n",
      "        -0.0108, -0.0292, -0.0006, -0.0177, -0.0271, -0.0243, -0.0031, -0.0338,\n",
      "        -0.0060,  0.0283,  0.0179, -0.0238, -0.0245,  0.0427,  0.0387,  0.0345,\n",
      "        -0.0037, -0.0218,  0.0362, -0.0427,  0.0202,  0.0001, -0.0176,  0.0047],\n",
      "       device='cuda:0')), ('attention.attention.0.weight', tensor([[ 0.0542, -0.0297,  0.0113,  ..., -0.0211, -0.0789, -0.0135],\n",
      "        [ 0.0600,  0.0410,  0.0780,  ...,  0.0130,  0.1163, -0.0278],\n",
      "        [-0.1069, -0.0930,  0.0376,  ...,  0.0101, -0.0301,  0.0829],\n",
      "        ...,\n",
      "        [-0.0809, -0.0338, -0.0499,  ...,  0.0743,  0.0676,  0.0837],\n",
      "        [ 0.1067, -0.0754,  0.0010,  ...,  0.0418, -0.0729,  0.1219],\n",
      "        [-0.0323, -0.0018,  0.0343,  ...,  0.0455, -0.0902,  0.0725]],\n",
      "       device='cuda:0')), ('attention.attention.0.bias', tensor([ 0.0155,  0.0889,  0.0613, -0.0649, -0.1065, -0.0858, -0.0274,  0.0951,\n",
      "         0.0935,  0.0341,  0.0749,  0.0789,  0.0480, -0.0276, -0.0305, -0.0086,\n",
      "        -0.1008,  0.1243,  0.1016,  0.0969, -0.1034, -0.0111,  0.1245,  0.0265,\n",
      "        -0.0523, -0.0314, -0.0973,  0.0906,  0.0863, -0.0149, -0.0785, -0.1167,\n",
      "        -0.0888, -0.0823,  0.0663,  0.0443, -0.0548,  0.0449,  0.1094,  0.0103,\n",
      "         0.0354, -0.0411,  0.0439,  0.0874, -0.0796,  0.0343,  0.1046, -0.0732,\n",
      "        -0.0281,  0.0827,  0.1058, -0.0332,  0.1164, -0.0765,  0.0181,  0.1047,\n",
      "        -0.0513,  0.0433,  0.1025, -0.0851, -0.1093, -0.0420, -0.1176,  0.0013],\n",
      "       device='cuda:0')), ('attention.attention.2.weight', tensor([[-0.0770,  0.0459, -0.0204,  0.0821,  0.0632,  0.1024,  0.0498, -0.1073,\n",
      "          0.0893,  0.0736,  0.0816,  0.0888,  0.0344,  0.0683,  0.0058, -0.0004,\n",
      "         -0.0918, -0.0299, -0.1237,  0.0883,  0.0809,  0.0479, -0.1136,  0.0098,\n",
      "          0.0193, -0.1013, -0.0403, -0.0103, -0.0558,  0.1126,  0.0907,  0.1036,\n",
      "         -0.0704, -0.1099,  0.1153,  0.1215, -0.0288, -0.0803,  0.0374,  0.1210,\n",
      "         -0.0042,  0.0302,  0.0177, -0.0701, -0.0662, -0.0733, -0.1110, -0.0639,\n",
      "         -0.0293, -0.1010, -0.0517, -0.1220, -0.0801, -0.0707,  0.0467,  0.0634,\n",
      "          0.0649,  0.0130,  0.1032, -0.1103, -0.1243,  0.0319, -0.0926, -0.0725]],\n",
      "       device='cuda:0')), ('attention.attention.2.bias', tensor([-0.0713], device='cuda:0')), ('baby_feed_forward.0.weight', tensor([[-0.0016, -0.0179,  0.0710,  ...,  0.0589, -0.0392, -0.0062],\n",
      "        [-0.0700,  0.0184,  0.0417,  ..., -0.0967,  0.0819, -0.0835],\n",
      "        [-0.0835,  0.0423,  0.0128,  ..., -0.0014, -0.0177,  0.0382],\n",
      "        ...,\n",
      "        [ 0.0215, -0.0431, -0.0614,  ..., -0.0901,  0.0224, -0.0833],\n",
      "        [-0.0676,  0.0868,  0.0927,  ...,  0.0789,  0.0305, -0.0085],\n",
      "        [-0.0827, -0.0230, -0.0312,  ..., -0.0751,  0.0896, -0.0882]],\n",
      "       device='cuda:0')), ('baby_feed_forward.0.bias', tensor([ 6.0016e-02, -3.3035e-02,  8.7655e-02, -1.0017e-01, -1.5096e-02,\n",
      "        -7.7603e-02, -6.7904e-02,  7.7002e-02,  1.4510e-02, -6.3682e-02,\n",
      "         4.8034e-02, -5.0411e-02, -6.3090e-02,  1.7112e-06, -6.4653e-02,\n",
      "         2.1158e-02,  4.0585e-02,  8.0243e-03,  7.8483e-03, -3.0089e-02,\n",
      "         4.2563e-02, -4.1304e-02, -6.7679e-02, -2.0703e-02,  4.7222e-02,\n",
      "        -8.9207e-02,  3.3538e-02,  3.8179e-02, -9.8826e-02, -2.3582e-02,\n",
      "        -7.4038e-03, -2.9490e-02,  9.6656e-02, -1.5609e-02,  9.8327e-02,\n",
      "         8.3592e-02, -2.7533e-02,  7.8635e-02,  5.1889e-03,  5.1041e-02,\n",
      "        -9.0503e-02, -9.7781e-02, -9.8819e-02,  4.9850e-02, -6.5948e-02,\n",
      "        -7.7503e-02,  2.1870e-02, -2.4192e-02,  5.2242e-02,  6.9887e-02,\n",
      "        -3.3353e-02,  1.3554e-02,  6.4444e-03,  8.2093e-02,  3.3651e-02,\n",
      "        -1.6312e-02,  5.7039e-02, -2.5767e-02, -2.0896e-02,  4.4032e-02,\n",
      "        -1.9522e-02, -2.1577e-02,  8.4874e-02,  2.1199e-02], device='cuda:0')), ('baby_feed_forward.2.weight', tensor([[ 3.1025e-02,  1.1099e-01, -7.8862e-02,  ..., -1.0573e-01,\n",
      "          6.5878e-05,  3.9599e-02],\n",
      "        [ 7.5267e-02, -8.1519e-02,  5.3735e-02,  ..., -3.3879e-02,\n",
      "          1.0699e-01,  9.8350e-02],\n",
      "        [-8.2498e-02,  1.6799e-02,  9.9452e-02,  ...,  4.3147e-02,\n",
      "          7.3294e-02,  1.8853e-02],\n",
      "        ...,\n",
      "        [ 6.3353e-02, -9.4795e-02,  7.5217e-02,  ...,  9.4055e-02,\n",
      "         -7.3711e-02, -2.1537e-02],\n",
      "        [ 1.5630e-02,  5.7475e-02, -1.9553e-02,  ...,  9.1269e-03,\n",
      "          1.7540e-02, -1.2552e-01],\n",
      "        [ 6.6127e-02, -1.4432e-02,  8.2807e-04,  ..., -3.3289e-02,\n",
      "         -1.8937e-02, -8.3590e-03]], device='cuda:0')), ('baby_feed_forward.2.bias', tensor([-0.0836,  0.1182,  0.0304,  0.0422,  0.0429,  0.1181, -0.0509, -0.0781,\n",
      "         0.0556,  0.0250, -0.0959,  0.0532, -0.0613, -0.0312, -0.0060, -0.0351,\n",
      "        -0.0945,  0.0772,  0.1177,  0.0023,  0.0198, -0.0870,  0.0226, -0.0957,\n",
      "         0.1084, -0.0065,  0.0043, -0.0036, -0.0269,  0.0766,  0.0119, -0.0433],\n",
      "       device='cuda:0')), ('baby_feed_forward.4.weight', tensor([[ 1.1253e-01, -1.0361e-01,  1.3314e-01, -1.1365e-01, -6.9035e-03,\n",
      "          2.9444e-02, -9.9306e-02,  2.9092e-02, -1.2657e-01,  1.2968e-01,\n",
      "          8.4098e-02,  6.3226e-02,  1.1724e-01,  9.9536e-02,  1.1089e-01,\n",
      "         -1.5752e-01, -1.0191e-01,  1.3563e-01,  3.1843e-02, -8.8836e-02,\n",
      "          1.5082e-01, -1.6402e-01, -1.5708e-01, -8.2565e-02, -4.5518e-02,\n",
      "         -1.3323e-01, -1.1096e-01,  1.4023e-01, -1.0741e-01, -1.2627e-01,\n",
      "         -1.1275e-01,  5.9514e-03],\n",
      "        [ 2.6084e-02,  6.9944e-02,  1.5086e-01, -6.5312e-02,  1.9746e-02,\n",
      "          1.1445e-01,  1.0854e-01,  2.4156e-02,  1.1198e-01,  1.5627e-01,\n",
      "          7.5314e-02, -1.4515e-01, -3.2171e-03, -1.0869e-01, -1.1196e-01,\n",
      "          3.1691e-02,  5.5004e-02,  7.0130e-03, -1.0415e-01, -6.4971e-02,\n",
      "          1.4103e-01,  6.3187e-02, -3.9805e-02, -1.5296e-01, -7.1109e-02,\n",
      "          9.5414e-02,  1.0303e-01, -8.7187e-02, -1.3686e-01,  4.0707e-02,\n",
      "         -8.0378e-02,  1.4633e-01],\n",
      "        [-6.6471e-02, -1.1361e-01, -3.5249e-03, -1.5647e-01, -8.0127e-02,\n",
      "         -1.4699e-01,  6.5085e-02, -7.7709e-02, -1.2311e-01, -1.5036e-01,\n",
      "          1.0320e-01, -1.5039e-01, -4.0303e-02, -4.8867e-02, -6.2875e-02,\n",
      "          1.0725e-01, -1.2931e-01, -1.7469e-01,  1.3755e-02, -1.2931e-01,\n",
      "         -1.2901e-01, -1.3501e-01,  2.8980e-02, -1.1230e-03,  6.2316e-04,\n",
      "         -2.2241e-04, -1.3615e-01,  8.2822e-02, -1.4526e-01, -8.1135e-03,\n",
      "          1.6407e-01,  3.3488e-02],\n",
      "        [-1.5339e-01,  1.7377e-01, -1.5211e-01,  1.5752e-01, -1.2234e-01,\n",
      "         -7.7943e-02, -4.2423e-02, -5.2338e-02, -1.5635e-01,  7.4362e-02,\n",
      "          2.1844e-02, -3.4979e-02, -1.0199e-02,  1.8059e-02, -1.1926e-01,\n",
      "          9.2070e-02, -6.9877e-02,  3.7409e-02, -8.1950e-02, -9.9805e-02,\n",
      "          1.5214e-01, -1.2382e-01, -1.4919e-01, -1.0849e-03, -1.4966e-01,\n",
      "          7.8054e-02, -7.7245e-04,  1.2380e-02,  1.4104e-01, -1.9076e-02,\n",
      "         -1.6465e-01,  1.0939e-01],\n",
      "        [ 2.4873e-02,  6.6942e-02,  1.6992e-01, -3.6263e-02, -1.7007e-01,\n",
      "         -1.5541e-01, -3.3388e-02,  7.2728e-02,  2.2371e-02,  4.1802e-02,\n",
      "          9.9116e-02, -1.2094e-01,  9.4390e-02, -5.8024e-02, -1.5090e-01,\n",
      "          1.7128e-01,  1.4306e-01, -1.1697e-01,  7.2065e-02,  1.5267e-02,\n",
      "          1.2059e-02,  1.0795e-02,  8.4905e-02, -4.5340e-02, -1.7576e-01,\n",
      "          5.1803e-02,  1.6553e-01, -2.1272e-03,  1.0271e-01,  1.1745e-01,\n",
      "         -1.0111e-03,  1.7201e-01],\n",
      "        [-7.2726e-02,  4.4461e-02, -4.1402e-02,  6.5758e-03, -1.2396e-01,\n",
      "          7.3559e-02,  1.4622e-01, -9.6881e-02, -3.9187e-02, -7.7356e-02,\n",
      "          1.3547e-01, -8.8700e-02,  1.1756e-01,  8.4641e-02, -5.9521e-02,\n",
      "         -1.1348e-01, -4.0452e-04, -1.5373e-01, -1.3114e-01,  6.5362e-02,\n",
      "         -1.5048e-01,  6.0209e-02,  5.7442e-02,  7.4419e-02, -1.3423e-02,\n",
      "          3.3322e-02,  6.6129e-02, -8.6791e-02,  8.7843e-02, -2.0170e-02,\n",
      "          7.7725e-02, -5.9077e-02],\n",
      "        [-1.8579e-02,  1.1082e-02, -7.1732e-02, -1.3014e-01,  5.9161e-02,\n",
      "          4.9442e-02, -7.2676e-02, -5.4436e-02, -5.7666e-02,  2.4044e-02,\n",
      "          9.7042e-02, -1.3623e-01, -1.3177e-01,  2.8110e-02,  3.8131e-02,\n",
      "          7.7151e-03, -1.4573e-01,  1.2590e-01, -9.0146e-02, -1.1124e-01,\n",
      "          1.5704e-01,  1.3763e-01, -1.0753e-01, -8.5185e-02, -1.2157e-01,\n",
      "         -1.4247e-01,  2.3176e-02,  1.4061e-01,  8.2120e-02,  3.2953e-02,\n",
      "         -1.3511e-01, -3.4501e-03],\n",
      "        [ 6.5155e-07,  1.2758e-01,  1.4349e-01,  1.2434e-01, -1.2246e-01,\n",
      "          1.5375e-01, -8.0154e-02, -1.1140e-01, -1.2993e-01, -1.1218e-01,\n",
      "          1.5758e-01,  1.6221e-01, -1.4878e-01,  1.3627e-01,  1.1435e-01,\n",
      "          4.8191e-02,  1.3694e-01,  4.1044e-03, -1.6465e-01,  6.0266e-02,\n",
      "          2.2740e-02, -8.3730e-02,  7.5008e-02,  8.2342e-02,  2.9860e-02,\n",
      "         -1.5771e-01, -1.1904e-02,  5.1796e-02,  1.5511e-01, -6.4320e-02,\n",
      "         -2.4712e-02, -8.4362e-02],\n",
      "        [ 7.4228e-02, -1.5664e-01, -7.2872e-02,  1.1200e-01,  1.4686e-01,\n",
      "          1.2190e-01, -7.4203e-03, -1.2647e-01,  7.9713e-02,  8.0426e-02,\n",
      "          1.3986e-01, -4.5199e-02, -4.9345e-02,  3.9749e-02, -6.2705e-04,\n",
      "          1.3152e-01, -2.2035e-08, -1.1960e-01,  1.1780e-01,  5.8041e-04,\n",
      "         -7.0317e-02, -9.1532e-03, -1.5709e-02,  1.1030e-03,  3.9994e-02,\n",
      "         -1.0987e-02,  8.2790e-02, -8.3912e-02,  4.7827e-02, -2.5827e-02,\n",
      "         -5.5545e-02,  1.5039e-01],\n",
      "        [-8.7238e-02,  1.1590e-01,  1.0040e-01,  4.4576e-02,  4.0726e-02,\n",
      "          1.2700e-01, -1.2182e-01,  9.2667e-02,  1.3624e-01,  3.5703e-02,\n",
      "          1.3148e-01,  1.5101e-01,  1.2749e-01, -1.5055e-01, -9.3953e-02,\n",
      "         -2.2272e-02, -6.4048e-02,  1.6808e-05, -8.7954e-02,  1.0164e-01,\n",
      "         -1.0392e-01, -8.3365e-02, -1.8906e-02, -9.9389e-02,  6.6964e-02,\n",
      "          7.9030e-02, -9.1707e-02,  8.0507e-02, -1.2259e-01, -8.5427e-02,\n",
      "         -4.9455e-02,  6.4875e-02],\n",
      "        [-1.7900e-02, -1.7407e-01, -1.0279e-01,  1.6063e-01, -1.6283e-01,\n",
      "         -1.0674e-01, -5.3821e-02, -1.4261e-01, -7.6761e-02, -8.9366e-02,\n",
      "         -6.2864e-02,  4.9764e-02, -1.3611e-02,  1.3774e-01, -2.3199e-02,\n",
      "         -7.2149e-03, -3.4113e-02, -2.1461e-02, -1.1882e-01, -8.7517e-02,\n",
      "         -1.6362e-01,  1.2613e-01, -6.7257e-02, -6.3344e-03, -1.3692e-01,\n",
      "          1.5131e-01,  1.5788e-01, -4.9053e-02, -1.6809e-01,  1.7071e-01,\n",
      "         -1.6235e-01,  1.1422e-01],\n",
      "        [-1.5200e-01, -1.1452e-01, -1.0369e-02,  6.2546e-03, -4.5511e-02,\n",
      "          8.2318e-02, -1.1571e-07, -3.4958e-02,  1.6060e-01,  2.1825e-03,\n",
      "         -1.0536e-01, -1.4243e-01,  5.6398e-02, -1.1078e-01, -1.2612e-01,\n",
      "          2.9533e-02,  1.0027e-01, -4.9507e-03,  1.7735e-01,  2.8395e-02,\n",
      "         -2.4475e-03,  1.5958e-01, -5.4867e-02,  1.2657e-01, -1.0504e-01,\n",
      "         -5.7456e-03, -2.0017e-02,  1.6011e-02, -9.1814e-02,  5.2568e-02,\n",
      "          5.2508e-02,  1.5391e-01],\n",
      "        [ 1.2726e-01,  9.4819e-02,  7.6678e-02, -7.4604e-02, -5.7127e-02,\n",
      "          1.7213e-01,  8.7437e-02,  1.3154e-01,  6.2880e-02, -5.3718e-02,\n",
      "          6.0731e-02,  1.3038e-01,  1.7824e-02,  1.3587e-02,  7.5223e-02,\n",
      "          1.3179e-02,  3.8149e-02,  1.3105e-01, -4.4012e-02,  1.7513e-01,\n",
      "          9.5543e-02, -7.4998e-02,  4.1240e-02,  1.7074e-01, -3.2249e-02,\n",
      "          1.1475e-01,  9.3980e-02, -2.6734e-02,  1.1640e-01, -1.5454e-02,\n",
      "          8.6092e-03, -4.2929e-03],\n",
      "        [-1.4837e-01, -1.3168e-01, -1.2298e-01, -2.0759e-02,  8.2222e-02,\n",
      "         -8.1013e-02,  1.3847e-01, -6.2276e-02,  4.2374e-02,  7.2966e-02,\n",
      "         -8.4401e-02,  1.1976e-01,  1.0109e-01, -2.5254e-03,  1.4888e-01,\n",
      "          1.8259e-02, -1.0102e-01, -1.2086e-01, -4.5820e-02,  5.8661e-02,\n",
      "          1.2217e-01, -1.0887e-01, -9.3459e-02,  1.3812e-01,  3.3822e-02,\n",
      "         -1.3445e-01, -8.8002e-02,  4.8430e-02, -4.1506e-02, -1.5385e-01,\n",
      "         -1.5767e-01, -9.9679e-03],\n",
      "        [-4.4852e-04,  4.1006e-02,  8.1942e-02,  3.5352e-02, -2.5615e-02,\n",
      "          1.6432e-01, -9.2838e-02,  9.6055e-02, -1.7156e-01, -1.2171e-01,\n",
      "          1.0505e-01, -9.5729e-02,  1.6939e-01, -1.4802e-01,  7.6230e-02,\n",
      "          1.2906e-01, -3.2007e-02,  6.9676e-02,  1.6788e-01, -6.7675e-02,\n",
      "         -1.0625e-01, -5.6127e-02,  6.0371e-02, -1.8809e-02,  1.0846e-01,\n",
      "         -9.5027e-02,  3.2011e-02, -1.4987e-01,  1.1200e-01, -3.2275e-02,\n",
      "         -1.3986e-01,  2.1303e-02],\n",
      "        [-1.0199e-01,  9.4789e-02,  9.2285e-02, -5.7300e-02, -7.5326e-02,\n",
      "          3.7851e-02,  1.5453e-02,  1.1425e-01,  1.0874e-01, -1.2020e-01,\n",
      "          3.9665e-03, -8.0189e-02,  4.0638e-02,  1.3005e-01,  1.1287e-01,\n",
      "         -5.1499e-02,  9.0966e-02, -1.1209e-01, -2.2689e-02,  1.6573e-01,\n",
      "         -4.1981e-02,  2.3630e-02, -1.1340e-01, -1.1795e-01,  1.3499e-01,\n",
      "         -1.5724e-01,  2.7567e-02,  1.7516e-01,  1.5925e-01, -9.0618e-02,\n",
      "          6.1732e-02, -1.0143e-01]], device='cuda:0')), ('baby_feed_forward.4.bias', tensor([-0.0896, -0.0921,  0.1527,  0.1571,  0.1281, -0.0139,  0.1351,  0.1348,\n",
      "        -0.1280, -0.1091,  0.1261,  0.0784,  0.0512,  0.0134,  0.1358,  0.1423],\n",
      "       device='cuda:0')), ('baby_feed_forward.6.weight', tensor([[ 1.7692e-01,  3.0020e-02,  4.3174e-06, -1.9921e-01, -1.7580e-01,\n",
      "          4.2003e-02, -1.2527e-01,  2.0773e-03,  9.6851e-02, -4.3354e-02,\n",
      "          1.8855e-01, -5.1094e-02, -2.2088e-01,  4.5181e-02, -1.7468e-01,\n",
      "         -1.1275e-01],\n",
      "        [ 2.2621e-01, -6.3241e-02,  1.9768e-01,  1.6265e-01, -1.8494e-01,\n",
      "          2.2035e-01, -1.1713e-01, -1.4898e-01, -1.9841e-01,  5.5567e-02,\n",
      "          4.3026e-02,  1.4082e-01,  6.6573e-02,  1.4551e-01,  1.8150e-01,\n",
      "         -9.0955e-02],\n",
      "        [ 1.4937e-01,  3.9446e-02,  7.5650e-04,  2.0567e-02,  9.0508e-02,\n",
      "         -1.7259e-01, -1.3604e-01,  9.2993e-03, -4.5516e-02, -5.7994e-02,\n",
      "          1.5718e-01, -5.5382e-02,  1.6013e-01,  1.1548e-01, -1.1455e-01,\n",
      "         -6.2460e-02],\n",
      "        [-2.2970e-03, -1.1514e-01,  1.0513e-01,  4.9694e-02, -2.2910e-01,\n",
      "          1.6618e-01,  1.4987e-01,  1.2077e-01,  2.1776e-02, -1.5520e-01,\n",
      "          3.5992e-02, -4.1849e-02, -6.6077e-02,  1.5482e-01, -8.3858e-02,\n",
      "         -2.1341e-01],\n",
      "        [-1.4725e-01,  5.4267e-02, -2.6658e-02,  1.3040e-01, -1.3392e-01,\n",
      "         -1.3587e-01, -2.1352e-02, -1.6421e-01,  4.0202e-02, -8.7158e-02,\n",
      "          1.4967e-01,  1.2002e-01,  2.0240e-02, -2.2176e-01,  4.3976e-02,\n",
      "         -5.9687e-02],\n",
      "        [-1.8997e-01, -1.2878e-01,  7.6839e-02,  1.6062e-01,  4.6794e-02,\n",
      "          1.3345e-01, -9.9619e-02, -1.4153e-01, -1.3107e-01,  1.0690e-01,\n",
      "          6.3837e-02,  2.2198e-02, -1.6479e-01,  1.4200e-01,  2.2330e-08,\n",
      "         -2.1962e-01],\n",
      "        [-1.9305e-01,  2.0752e-01, -2.4849e-01, -6.5035e-02, -1.6202e-01,\n",
      "         -5.5958e-02,  1.4277e-01, -2.3968e-01,  5.7789e-02, -1.7932e-01,\n",
      "          1.6430e-01, -7.3198e-02, -1.9110e-01,  1.3842e-01, -3.2607e-02,\n",
      "          1.0411e-01],\n",
      "        [ 2.1926e-01, -1.1859e-02, -2.3293e-01, -1.4226e-01,  1.9475e-01,\n",
      "         -1.7668e-01, -3.1514e-02,  2.3405e-01,  1.7093e-01,  7.9228e-02,\n",
      "          3.9171e-02, -1.6803e-01,  9.4341e-02, -9.0032e-02, -2.1125e-01,\n",
      "         -2.2348e-01]], device='cuda:0')), ('baby_feed_forward.6.bias', tensor([ 0.1229,  0.1327, -0.1071, -0.1392,  0.0094, -0.1185,  0.0974, -0.0377],\n",
      "       device='cuda:0')), ('baby_feed_forward.8.weight', tensor([[ 0.1167, -0.2544, -0.1444, -0.0986,  0.0946,  0.2997,  0.1566, -0.2967]],\n",
      "       device='cuda:0')), ('baby_feed_forward.8.bias', tensor([-0.2033], device='cuda:0'))])\n",
      "optimizer_state_dict {'state': {0: {'step': tensor(120., device='cuda:0'), 'exp_avg': tensor([[-1.4745e-07, -4.3655e-07, -1.6511e-10,  ..., -1.6829e-08,\n",
      "          2.6450e-08, -1.0113e-07],\n",
      "        [-3.3381e-06, -2.9343e-06, -2.1429e-06,  ...,  1.2061e-10,\n",
      "         -4.7569e-07, -5.3501e-06],\n",
      "        [ 2.6789e-11,  3.2843e-10, -5.1746e-12,  ...,  2.4923e-09,\n",
      "          2.7973e-13,  1.8240e-09],\n",
      "        ...,\n",
      "        [-5.5966e-07, -2.0873e-07, -1.3323e-09,  ...,  3.2855e-08,\n",
      "         -1.5646e-07,  3.3526e-07],\n",
      "        [ 1.9539e-07, -8.0136e-08,  2.1684e-09,  ...,  7.0133e-11,\n",
      "         -1.7876e-09, -3.1240e-08],\n",
      "        [ 1.1552e-07,  4.8328e-07, -1.0823e-09,  ..., -1.4855e-08,\n",
      "         -9.0007e-08,  1.3121e-07]], device='cuda:0'), 'exp_avg_sq': tensor([[5.0966e-14, 2.1484e-12, 5.3077e-15,  ..., 8.9895e-15, 1.4497e-14,\n",
      "         2.2207e-14],\n",
      "        [3.1167e-10, 7.7950e-10, 4.7601e-12,  ..., 6.7988e-17, 1.1856e-11,\n",
      "         6.8836e-11],\n",
      "        [6.4653e-18, 3.3696e-16, 8.5736e-19,  ..., 3.2612e-15, 1.6595e-20,\n",
      "         2.6245e-15],\n",
      "        ...,\n",
      "        [1.9510e-12, 5.7749e-14, 2.3514e-15,  ..., 1.1598e-14, 3.3537e-14,\n",
      "         1.5446e-13],\n",
      "        [6.5880e-14, 6.1474e-14, 2.8710e-15,  ..., 2.9593e-17, 2.6226e-15,\n",
      "         1.1359e-14],\n",
      "        [3.0682e-12, 1.4397e-11, 2.2295e-15,  ..., 8.6386e-15, 7.6578e-14,\n",
      "         2.0858e-12]], device='cuda:0')}, 1: {'step': tensor(120., device='cuda:0'), 'exp_avg': tensor([ 5.7846e-08, -7.3053e-06,  2.7896e-10,  ..., -1.2242e-07,\n",
      "         1.6164e-08, -2.8995e-07], device='cuda:0'), 'exp_avg_sq': tensor([8.1305e-13, 5.2583e-10, 4.9949e-16,  ..., 1.2780e-12, 9.5352e-15,\n",
      "        1.8100e-12], device='cuda:0')}, 2: {'step': tensor(120., device='cuda:0'), 'exp_avg': tensor([[ 2.4402e-12,  8.4938e-04,  1.2115e-10,  ..., -6.7541e-07,\n",
      "          7.1850e-07, -2.1694e-06],\n",
      "        [-2.9264e-06, -7.5519e-05, -1.8531e-11,  ..., -2.6321e-06,\n",
      "         -1.3446e-06,  1.5999e-06],\n",
      "        [ 1.7923e-07, -4.1386e-06,  1.0606e-06,  ..., -2.5424e-06,\n",
      "         -1.6645e-07, -1.1565e-06],\n",
      "        ...,\n",
      "        [ 6.5301e-08,  1.6129e-05,  7.8914e-07,  ..., -1.1383e-06,\n",
      "          6.4873e-09,  1.7927e-07],\n",
      "        [-6.6479e-07,  5.4860e-06,  1.2840e-07,  ..., -2.1611e-06,\n",
      "          1.3950e-07, -6.6652e-07],\n",
      "        [ 8.0223e-07,  5.6785e-04,  2.4881e-09,  ...,  2.2754e-06,\n",
      "         -1.7888e-10, -2.5529e-07]], device='cuda:0'), 'exp_avg_sq': tensor([[5.2546e-15, 5.0187e-07, 2.0500e-16,  ..., 4.2483e-12, 2.0222e-13,\n",
      "         1.0161e-12],\n",
      "        [1.1432e-11, 2.2239e-07, 2.4128e-16,  ..., 7.7266e-11, 3.6764e-13,\n",
      "         8.6438e-12],\n",
      "        [1.0518e-12, 2.0806e-07, 2.5571e-13,  ..., 7.1520e-12, 3.1089e-14,\n",
      "         1.9054e-12],\n",
      "        ...,\n",
      "        [2.5362e-14, 4.7454e-08, 1.6867e-13,  ..., 1.0924e-11, 6.9914e-15,\n",
      "         4.7033e-13],\n",
      "        [1.9922e-13, 3.8603e-08, 2.5562e-14,  ..., 3.8899e-11, 2.7071e-14,\n",
      "         7.3743e-12],\n",
      "        [1.8234e-11, 2.5330e-07, 3.7742e-15,  ..., 5.9229e-12, 5.4415e-16,\n",
      "         1.2704e-12]], device='cuda:0')}, 3: {'step': tensor(120., device='cuda:0'), 'exp_avg': tensor([ 2.8076e-05,  9.2645e-06, -6.5545e-06,  ...,  4.2407e-06,\n",
      "         1.0539e-06,  3.6373e-05], device='cuda:0'), 'exp_avg_sq': tensor([1.5710e-09, 6.7489e-10, 9.9387e-10,  ..., 4.7140e-10, 2.3809e-10,\n",
      "        9.6794e-10], device='cuda:0')}, 4: {'step': tensor(120., device='cuda:0'), 'exp_avg': tensor([[-1.0062e-04, -1.0876e-05, -8.8894e-05,  ..., -9.7393e-07,\n",
      "         -2.2808e-06,  1.1755e-04],\n",
      "        [-1.6585e-04,  3.3345e-05, -4.7025e-04,  ...,  4.2678e-06,\n",
      "         -6.8070e-05, -7.5788e-04],\n",
      "        [ 1.1980e-03,  1.4300e-03, -1.2193e-04,  ...,  3.5270e-05,\n",
      "          3.9275e-06, -1.9487e-04],\n",
      "        ...,\n",
      "        [ 4.9596e-04,  8.7351e-05, -1.2778e-04,  ..., -2.6973e-05,\n",
      "         -1.4842e-04,  1.2673e-06],\n",
      "        [-6.2944e-04, -4.0735e-05, -3.7606e-04,  ...,  2.6869e-05,\n",
      "          1.8777e-05, -8.3865e-04],\n",
      "        [ 5.1071e-04, -5.9076e-04, -1.0201e-03,  ...,  4.3169e-05,\n",
      "         -3.4448e-05,  6.9409e-05]], device='cuda:0'), 'exp_avg_sq': tensor([[6.0560e-07, 3.7516e-07, 2.0816e-07,  ..., 2.8523e-08, 4.0971e-08,\n",
      "         2.0998e-06],\n",
      "        [2.2688e-06, 6.9361e-07, 7.5809e-07,  ..., 3.0433e-07, 4.9910e-08,\n",
      "         6.9803e-07],\n",
      "        [1.2857e-06, 3.3217e-07, 2.8289e-07,  ..., 2.0889e-08, 4.9541e-08,\n",
      "         7.3989e-07],\n",
      "        ...,\n",
      "        [2.6060e-06, 3.4182e-07, 2.9450e-07,  ..., 6.1899e-08, 1.0239e-07,\n",
      "         4.8472e-07],\n",
      "        [1.6775e-06, 3.8153e-07, 7.0397e-07,  ..., 3.6295e-07, 2.8420e-08,\n",
      "         6.3227e-07],\n",
      "        [1.6078e-06, 6.7137e-07, 9.0966e-07,  ..., 1.6601e-07, 2.2676e-08,\n",
      "         8.6494e-07]], device='cuda:0')}, 5: {'step': tensor(120., device='cuda:0'), 'exp_avg': tensor([-1.4572e-05, -3.6370e-05,  2.2146e-05, -3.8509e-05,  6.7303e-06,\n",
      "         3.4518e-07,  2.9155e-05, -4.2494e-05,  2.6522e-05, -1.1672e-05,\n",
      "         5.0134e-06,  5.2111e-05, -2.2248e-05,  5.3470e-05, -1.5931e-05,\n",
      "         1.3370e-05, -2.3366e-05,  4.2656e-06,  5.1342e-05,  6.5307e-06,\n",
      "        -2.7688e-05, -6.5450e-05,  6.3924e-05,  1.0079e-07,  1.7085e-05,\n",
      "         1.8837e-05,  2.0414e-05, -2.0220e-05,  8.4326e-06,  1.7235e-05,\n",
      "        -2.8530e-05,  3.5658e-05,  6.0718e-05,  4.7014e-05,  2.0514e-05,\n",
      "         8.7355e-06, -2.9882e-06,  2.1903e-06, -4.0663e-05,  2.4650e-07,\n",
      "         3.1574e-05, -1.1037e-05,  9.7069e-06, -5.7099e-06, -1.3158e-05,\n",
      "         8.6283e-06,  5.0226e-05,  1.9473e-06,  2.9934e-05, -3.6581e-05,\n",
      "         1.4829e-05, -6.3042e-06, -3.0764e-05,  1.0964e-05,  1.1453e-05,\n",
      "        -8.8930e-06, -9.2123e-06,  4.3539e-05,  3.5190e-05,  6.6136e-05,\n",
      "         1.3570e-05, -5.8076e-05, -5.1600e-06, -1.5121e-05, -1.2272e-06,\n",
      "        -1.7962e-06,  2.9743e-05,  3.2121e-05, -4.1885e-05, -7.9494e-06,\n",
      "         1.7467e-05,  4.0577e-05, -1.8944e-05, -4.7849e-05, -2.5817e-05,\n",
      "         3.0460e-05,  9.9608e-06, -5.5169e-05, -9.8379e-06,  1.2833e-05,\n",
      "        -1.2376e-05, -8.0696e-06,  1.9460e-05,  7.1268e-07, -3.2066e-05,\n",
      "        -2.5468e-05, -3.8434e-05, -9.0675e-06,  6.1190e-05,  5.4090e-05,\n",
      "         3.4618e-05, -9.8461e-06,  3.6376e-05,  8.7588e-06,  4.8600e-05,\n",
      "         3.5815e-05,  6.6689e-06,  5.2961e-05,  4.0582e-06, -5.3381e-05,\n",
      "         7.7691e-06, -1.0451e-05, -3.5210e-05,  1.4387e-05,  7.3389e-05,\n",
      "         4.8848e-05,  1.8538e-05, -3.9473e-05,  1.9363e-05, -6.0222e-05,\n",
      "        -3.2302e-06,  1.1004e-05, -2.6861e-05, -6.6136e-06,  4.0382e-05,\n",
      "        -9.3887e-06,  1.0533e-05,  2.8219e-05, -5.9010e-05, -1.4565e-05,\n",
      "        -6.2734e-06,  1.4691e-05, -5.9747e-05, -4.4302e-05,  9.2839e-06,\n",
      "        -1.1311e-05,  1.4458e-05,  2.4409e-05, -5.2503e-06,  3.3158e-05,\n",
      "         1.1973e-05, -4.2031e-05,  2.4690e-05, -1.5759e-05,  1.7964e-05,\n",
      "        -2.2613e-05, -3.0894e-05, -1.6167e-05,  8.6102e-05, -2.0914e-05,\n",
      "        -3.4042e-05, -1.7711e-05, -1.0714e-05, -1.5524e-05,  6.5195e-05,\n",
      "        -5.0785e-05,  4.0320e-06, -1.4414e-05, -2.0583e-05, -6.8684e-06,\n",
      "         1.6543e-05,  2.2222e-05,  7.0226e-05,  5.2486e-05,  5.1315e-06,\n",
      "         6.4441e-07, -9.8215e-06, -3.0355e-05,  5.1011e-05, -2.5490e-05,\n",
      "        -1.6390e-06,  2.1304e-05, -3.1883e-06,  3.6993e-05, -5.0444e-05,\n",
      "        -1.9409e-05, -3.3895e-05,  9.0972e-06, -1.4228e-05, -1.6093e-05,\n",
      "         2.0758e-05, -1.5241e-05, -5.9685e-05, -1.9293e-05,  1.3511e-05,\n",
      "         2.8784e-05,  2.5769e-05,  1.6315e-05,  5.8500e-07,  3.3250e-05,\n",
      "         3.6438e-06,  9.6137e-06, -2.6262e-05, -6.4063e-07,  2.6258e-05,\n",
      "         4.1727e-06,  1.0011e-05, -8.0997e-05, -1.3245e-06,  2.1409e-05,\n",
      "        -5.7772e-06, -2.1933e-05,  3.0277e-05, -7.5543e-06,  1.3316e-06,\n",
      "        -2.1460e-06, -5.9154e-05, -2.5122e-08, -1.1822e-05,  3.8170e-05,\n",
      "         3.8267e-05,  1.1583e-05,  8.6758e-06,  8.8283e-06, -1.5915e-05,\n",
      "        -2.2236e-05,  3.3104e-05, -1.9364e-06, -1.5857e-05, -1.5715e-05,\n",
      "         3.1225e-06, -1.7401e-05, -4.4634e-05, -4.7333e-05,  1.1210e-05,\n",
      "        -2.1113e-05, -7.4438e-06, -4.8827e-05, -2.3563e-05, -3.6438e-05,\n",
      "         1.0683e-05, -2.7699e-05, -1.4979e-07,  6.8902e-05,  2.8276e-06,\n",
      "        -2.0562e-05,  1.2446e-05,  5.0089e-06,  6.2020e-05,  6.1888e-06,\n",
      "        -1.3501e-06, -8.6158e-06,  7.0310e-06, -1.9412e-05, -2.3996e-05,\n",
      "        -5.1999e-05,  7.2928e-07,  4.4676e-06,  2.3048e-05,  2.4523e-05,\n",
      "        -2.5351e-05,  1.1595e-05, -8.1240e-06,  2.6968e-05,  6.8927e-05,\n",
      "         3.1470e-05,  7.4990e-05,  3.0182e-05, -6.1903e-05,  4.9568e-06,\n",
      "         3.0552e-05, -1.8756e-05,  7.9147e-06,  3.1873e-05,  4.7032e-05,\n",
      "        -3.6819e-05, -1.0428e-05, -7.0858e-06, -2.3877e-05,  5.2628e-06,\n",
      "         1.5489e-05,  2.3165e-06,  1.5963e-05,  3.6199e-05, -4.3038e-05,\n",
      "         1.0509e-05, -1.7189e-05, -1.2312e-05,  3.0138e-05, -1.5670e-06,\n",
      "         2.6054e-05, -2.1784e-05,  5.4937e-05,  5.4380e-05,  7.9822e-05,\n",
      "         1.7659e-05,  5.4097e-05, -4.3670e-05, -1.2232e-05,  1.3793e-05,\n",
      "        -2.0306e-05,  1.8291e-05, -1.5206e-05, -3.0539e-05, -4.4360e-05,\n",
      "        -1.8521e-05, -1.2701e-05, -2.5496e-05, -2.4045e-05,  1.0339e-05,\n",
      "        -3.6925e-05,  4.3797e-06,  1.2185e-05,  1.4582e-05,  5.6007e-06,\n",
      "         2.4951e-06,  1.2983e-05,  8.6974e-06, -5.3220e-06, -4.8321e-05,\n",
      "         8.0105e-05, -1.3714e-07, -1.5881e-05, -1.9047e-05, -2.1589e-05,\n",
      "        -1.0138e-05,  3.0712e-06, -3.1872e-05,  3.9675e-05, -4.0062e-05,\n",
      "         2.1851e-05,  1.0393e-06, -4.7661e-05, -9.1599e-06, -2.0342e-05,\n",
      "         8.0002e-06,  1.7986e-05, -4.4849e-06,  4.6834e-05,  1.2676e-05,\n",
      "        -2.1555e-06,  2.3187e-05,  1.2969e-05,  5.5621e-05, -2.4271e-05,\n",
      "         3.5701e-05,  5.3871e-05, -1.9107e-05,  2.3528e-06, -4.0481e-05,\n",
      "         2.2192e-05, -1.3070e-05,  2.2689e-06,  5.5653e-05, -1.6182e-05,\n",
      "        -2.4236e-05, -6.3086e-06, -1.1982e-04,  3.9637e-06,  1.2136e-05,\n",
      "        -3.3071e-05,  1.0232e-05, -7.6759e-05,  3.9801e-05, -2.2164e-06,\n",
      "         1.6259e-05,  1.2959e-05, -1.9751e-05, -2.1075e-05,  3.9465e-05,\n",
      "        -3.2192e-05, -1.3143e-05,  4.6875e-07, -2.9061e-06, -5.3395e-06,\n",
      "        -6.4736e-05, -5.6023e-05, -1.0785e-05, -1.5156e-06,  4.8810e-05,\n",
      "        -1.1021e-05,  4.9887e-05, -6.5243e-05,  1.8245e-05, -2.1999e-05,\n",
      "         4.1910e-07,  2.7840e-05, -2.2772e-05,  4.8965e-06,  1.3478e-06,\n",
      "        -1.9908e-05,  5.2304e-06,  2.1415e-06,  2.2943e-05,  2.6863e-05,\n",
      "         4.1621e-06, -3.5065e-06,  1.4255e-05,  1.2727e-05,  6.8814e-06,\n",
      "        -3.5208e-05,  4.1278e-05,  2.5821e-06, -1.0921e-05, -2.4746e-05,\n",
      "        -3.8231e-05,  4.1213e-05, -4.1028e-06, -1.0507e-05, -2.2153e-05,\n",
      "        -7.8474e-05, -2.1842e-05,  1.4877e-05, -4.2432e-05, -1.8083e-05,\n",
      "        -1.6628e-06, -5.9131e-05,  5.2457e-05,  3.4639e-05,  1.7945e-05,\n",
      "        -2.2155e-05,  7.3561e-06, -1.2760e-05, -7.1944e-05,  1.0767e-05,\n",
      "         5.4449e-06, -7.4649e-05, -8.1177e-06, -1.9544e-05,  9.2539e-06,\n",
      "         3.8966e-05,  1.7080e-05, -7.7510e-07, -3.0224e-05,  1.3162e-05,\n",
      "        -2.9638e-05, -2.7987e-06,  1.7536e-06, -9.2631e-05,  1.2770e-07,\n",
      "         2.9738e-06, -4.6439e-05,  3.4416e-06,  6.5684e-06,  5.0190e-05,\n",
      "        -1.1960e-05, -1.2156e-06,  3.2582e-05,  1.9486e-05, -1.5190e-05,\n",
      "        -3.7561e-05,  5.2106e-05,  4.3312e-05,  3.3092e-05, -1.2658e-05,\n",
      "        -2.4561e-05,  3.1504e-05, -4.3445e-05,  8.3047e-06, -8.0970e-06,\n",
      "        -8.6165e-06, -2.1191e-05, -1.7206e-05, -3.8997e-05,  4.8152e-05,\n",
      "         2.1034e-05, -3.5101e-05, -7.3319e-06,  7.2508e-07,  1.6914e-05,\n",
      "        -9.7777e-06, -1.5011e-05,  1.5796e-05,  2.2423e-05,  3.7157e-05,\n",
      "         1.5537e-05, -6.6609e-05, -7.3049e-06, -1.4621e-05, -6.3418e-06,\n",
      "        -2.9213e-05,  1.2538e-05,  2.3158e-05,  1.6370e-05,  4.3064e-05,\n",
      "        -3.6829e-05, -1.6736e-05, -2.9276e-06, -2.2502e-06,  1.4152e-05,\n",
      "         1.6343e-05,  1.9078e-05, -2.7717e-05,  1.9371e-05, -1.7634e-05,\n",
      "         1.1005e-05,  1.6435e-05,  1.0462e-05,  6.9780e-07, -4.1047e-05,\n",
      "         2.5181e-05,  1.7460e-06,  1.8209e-05,  5.4741e-05, -2.7955e-05,\n",
      "         2.5915e-07,  1.8489e-05, -6.4261e-05,  2.1632e-05,  1.5732e-06,\n",
      "         1.6819e-06,  5.6156e-05,  3.3711e-05, -6.6810e-06,  1.5160e-06,\n",
      "         3.9614e-05,  2.9972e-06, -5.3756e-05, -4.5599e-06, -3.2722e-05,\n",
      "         2.0538e-05,  7.8267e-06,  2.4014e-05, -2.7163e-05,  3.4104e-05,\n",
      "        -1.6421e-06,  4.9075e-05, -9.5511e-06,  1.3571e-05,  6.2630e-05,\n",
      "        -3.7702e-05,  2.3458e-05], device='cuda:0'), 'exp_avg_sq': tensor([3.8514e-09, 5.0933e-09, 1.7540e-09, 1.6677e-09, 5.9355e-10, 3.1578e-09,\n",
      "        5.8428e-09, 6.6237e-09, 1.4095e-09, 2.6247e-09, 3.7100e-09, 6.4292e-09,\n",
      "        8.3590e-09, 6.9485e-09, 3.6544e-09, 3.4273e-09, 3.4265e-09, 5.0751e-09,\n",
      "        3.1223e-09, 2.3455e-09, 4.7618e-09, 2.0512e-09, 4.0057e-09, 4.0571e-09,\n",
      "        6.0681e-09, 3.1716e-09, 1.3289e-09, 6.2010e-09, 2.2843e-10, 3.0450e-09,\n",
      "        2.9227e-09, 1.2263e-08, 6.5711e-09, 1.8340e-09, 8.5240e-09, 3.2335e-09,\n",
      "        5.2086e-10, 4.1410e-09, 6.2829e-09, 3.6780e-09, 6.1668e-09, 3.0138e-09,\n",
      "        3.6171e-09, 4.3434e-09, 8.8201e-09, 3.5812e-09, 5.3521e-09, 3.8948e-09,\n",
      "        2.1999e-09, 6.0680e-09, 8.2645e-09, 4.8972e-09, 5.7943e-09, 8.1117e-09,\n",
      "        1.2969e-09, 4.9662e-09, 6.2249e-09, 4.7904e-09, 7.0477e-10, 6.3013e-09,\n",
      "        4.0002e-10, 3.6948e-09, 8.7854e-09, 3.6424e-09, 3.7317e-10, 1.0389e-09,\n",
      "        5.7570e-09, 5.4113e-09, 5.4895e-09, 4.4343e-09, 3.8563e-09, 1.7415e-09,\n",
      "        7.4713e-09, 4.9823e-09, 3.2956e-09, 9.8100e-09, 4.9943e-09, 6.6334e-09,\n",
      "        1.8429e-09, 6.3389e-09, 4.5921e-09, 8.7404e-09, 3.2561e-09, 3.7449e-09,\n",
      "        3.7785e-09, 5.2130e-09, 7.3139e-09, 3.5292e-09, 4.9675e-09, 7.4464e-09,\n",
      "        8.4951e-09, 3.6025e-10, 4.5506e-09, 7.1173e-09, 5.9524e-09, 8.1459e-09,\n",
      "        8.7925e-10, 5.1583e-09, 1.2231e-08, 3.9609e-09, 4.4941e-09, 4.3932e-09,\n",
      "        4.9952e-09, 7.5787e-09, 1.0507e-08, 4.8657e-09, 8.6116e-10, 5.3683e-09,\n",
      "        6.9666e-09, 5.2454e-09, 2.4422e-09, 2.7762e-09, 4.4760e-09, 1.3497e-09,\n",
      "        4.5584e-09, 4.9869e-09, 1.9061e-09, 3.8125e-09, 8.8075e-09, 2.3266e-09,\n",
      "        3.2908e-09, 8.8604e-09, 7.0087e-09, 3.4309e-09, 2.1496e-09, 4.3020e-09,\n",
      "        4.4332e-09, 4.3215e-09, 2.4249e-09, 7.4211e-09, 5.2293e-09, 1.9693e-09,\n",
      "        1.0223e-08, 4.9629e-09, 1.0074e-09, 4.9421e-09, 5.2842e-09, 4.1139e-09,\n",
      "        6.6803e-09, 9.0121e-10, 3.3962e-09, 2.6895e-09, 4.0804e-09, 9.1275e-10,\n",
      "        4.5858e-09, 6.5674e-09, 1.9308e-09, 3.0207e-09, 5.6341e-09, 5.7538e-10,\n",
      "        1.6056e-09, 6.9372e-09, 6.5212e-09, 4.3023e-09, 1.4647e-09, 1.1574e-09,\n",
      "        3.4063e-09, 3.3430e-09, 6.5808e-09, 2.4339e-09, 3.7844e-10, 2.6156e-09,\n",
      "        6.1325e-09, 5.2676e-09, 5.1641e-09, 4.5222e-09, 3.1055e-09, 3.2569e-09,\n",
      "        7.0698e-09, 3.9534e-09, 3.8447e-09, 4.6774e-09, 2.3307e-09, 4.2246e-09,\n",
      "        3.6128e-09, 3.9507e-09, 5.6033e-09, 1.7399e-09, 6.3091e-09, 5.8338e-09,\n",
      "        2.2538e-09, 3.7299e-09, 3.9051e-09, 9.6671e-09, 3.0235e-09, 5.1167e-09,\n",
      "        1.7648e-09, 2.2106e-09, 4.1355e-09, 4.1320e-09, 7.4782e-09, 2.5990e-09,\n",
      "        6.4495e-09, 5.8825e-09, 2.4862e-10, 3.2538e-09, 3.3588e-09, 1.7289e-09,\n",
      "        6.3534e-09, 1.4380e-09, 8.4811e-09, 1.7326e-09, 3.1655e-09, 3.3824e-09,\n",
      "        6.1488e-09, 8.7958e-09, 2.2931e-09, 2.1268e-09, 5.3692e-09, 4.5899e-09,\n",
      "        2.7361e-09, 4.5951e-09, 8.8055e-09, 5.8224e-09, 8.2901e-10, 7.7743e-11,\n",
      "        5.3415e-09, 2.2600e-09, 6.2941e-09, 3.7004e-09, 3.9273e-09, 3.2247e-09,\n",
      "        5.2213e-09, 1.3515e-08, 4.7066e-09, 1.0002e-08, 4.9309e-09, 1.4618e-09,\n",
      "        8.3018e-09, 3.9611e-09, 4.1304e-09, 7.4915e-09, 7.3302e-09, 8.1762e-09,\n",
      "        3.9466e-09, 6.5495e-09, 2.5910e-10, 2.5319e-09, 8.2347e-09, 2.5780e-09,\n",
      "        5.2303e-09, 8.1095e-09, 3.4248e-09, 2.3707e-09, 4.0607e-09, 5.9062e-09,\n",
      "        3.3668e-09, 7.4855e-09, 4.4349e-09, 1.9181e-09, 5.9892e-09, 8.6224e-09,\n",
      "        5.9513e-09, 4.2541e-09, 6.5948e-09, 9.4535e-09, 4.6841e-09, 2.2532e-09,\n",
      "        4.3821e-09, 3.6009e-09, 1.1352e-09, 5.3633e-09, 2.6379e-09, 2.6042e-09,\n",
      "        1.9495e-09, 3.5535e-09, 1.4103e-09, 8.1795e-10, 5.7601e-09, 5.6975e-09,\n",
      "        7.5752e-09, 9.9788e-10, 4.2830e-09, 6.4825e-09, 6.2525e-09, 3.3089e-09,\n",
      "        6.0768e-09, 3.9775e-09, 3.2943e-09, 8.1523e-09, 1.4660e-09, 5.0210e-09,\n",
      "        7.7439e-09, 4.2541e-09, 5.2248e-09, 1.5819e-09, 3.2843e-09, 4.2357e-09,\n",
      "        6.0706e-09, 1.2716e-08, 2.2024e-09, 3.6252e-09, 4.3904e-09, 3.2910e-09,\n",
      "        2.0576e-09, 5.9910e-09, 5.3497e-09, 2.1997e-09, 4.6318e-09, 6.9132e-09,\n",
      "        7.6621e-09, 8.0829e-09, 1.8162e-09, 6.0102e-09, 5.4765e-09, 1.2640e-09,\n",
      "        3.4847e-09, 3.0786e-09, 3.8227e-09, 5.2122e-09, 1.0487e-08, 6.9351e-09,\n",
      "        3.8038e-09, 2.4213e-09, 1.0229e-08, 7.7113e-09, 6.1720e-09, 1.5844e-09,\n",
      "        9.2391e-09, 3.0546e-09, 3.0563e-09, 2.2720e-09, 1.6525e-09, 5.8548e-09,\n",
      "        3.1630e-09, 5.7615e-09, 4.4455e-09, 4.9193e-09, 8.0005e-10, 8.3030e-09,\n",
      "        4.6809e-09, 4.3635e-09, 1.5568e-09, 4.9201e-09, 3.1640e-09, 2.6514e-09,\n",
      "        6.1621e-09, 5.9909e-09, 4.3114e-09, 2.8637e-09, 5.0703e-09, 2.1008e-09,\n",
      "        5.2323e-09, 2.8219e-09, 2.7801e-09, 4.3494e-09, 3.5009e-09, 2.1728e-09,\n",
      "        8.3931e-09, 3.1009e-09, 6.8282e-09, 2.2991e-09, 2.9153e-09, 3.9404e-09,\n",
      "        7.4116e-09, 3.0398e-09, 7.2185e-09, 7.2176e-09, 9.1494e-09, 1.2229e-09,\n",
      "        3.8645e-09, 8.9985e-09, 7.5432e-09, 6.5856e-09, 3.7310e-09, 2.3102e-09,\n",
      "        1.9428e-09, 3.9682e-09, 1.1098e-09, 6.4233e-09, 5.4689e-09, 1.1556e-09,\n",
      "        2.9903e-09, 2.2571e-09, 1.6988e-09, 1.7244e-09, 4.8901e-09, 3.3221e-09,\n",
      "        1.3341e-09, 4.0222e-09, 4.0128e-09, 4.5470e-09, 3.2652e-09, 1.0401e-08,\n",
      "        3.5316e-09, 9.4135e-09, 4.0610e-09, 9.2794e-09, 6.1809e-09, 2.7424e-09,\n",
      "        1.5844e-09, 6.7787e-09, 6.9103e-09, 9.3365e-09, 5.2397e-09, 2.8583e-09,\n",
      "        4.5468e-09, 6.1629e-09, 9.5044e-09, 3.2674e-09, 4.4367e-09, 5.9613e-09,\n",
      "        3.4221e-09, 5.0085e-09, 2.7804e-09, 2.6371e-09, 9.4003e-09, 9.1125e-09,\n",
      "        3.7765e-09, 2.7369e-09, 7.5767e-09, 6.9259e-09, 3.8121e-10, 5.7186e-09,\n",
      "        3.4111e-09, 1.9710e-08, 1.3873e-09, 7.8230e-09, 6.1156e-09, 1.7074e-09,\n",
      "        1.4046e-09, 7.7327e-09, 7.1716e-09, 6.8896e-09, 7.3601e-09, 2.8897e-09,\n",
      "        7.7821e-09, 4.5109e-09, 4.9519e-09, 2.5152e-09, 3.5180e-09, 4.8703e-09,\n",
      "        4.3398e-09, 3.9535e-09, 2.4795e-09, 5.9456e-09, 5.8290e-09, 8.2149e-09,\n",
      "        3.2422e-09, 3.6263e-09, 5.8132e-09, 6.3430e-09, 3.7315e-09, 4.8311e-09,\n",
      "        6.7287e-09, 8.7050e-09, 4.1889e-09, 1.1465e-09, 2.7191e-09, 4.2712e-09,\n",
      "        2.9734e-09, 5.4363e-09, 3.8519e-09, 8.8316e-09, 4.4891e-09, 2.3857e-09,\n",
      "        6.7369e-09, 2.5918e-09, 2.3403e-09, 2.9393e-09, 3.2417e-09, 6.0043e-09,\n",
      "        6.5645e-09, 6.8033e-09, 2.2403e-09, 2.8470e-09, 7.5758e-09, 6.0305e-09,\n",
      "        3.0890e-09, 4.0171e-09, 6.6915e-09, 6.1811e-09, 2.2917e-09, 1.9264e-09,\n",
      "        1.4635e-09, 7.8858e-09, 1.6324e-09, 6.0686e-09, 2.8549e-09, 3.9634e-09,\n",
      "        5.5739e-09, 1.3639e-09, 8.9522e-09, 6.6070e-09, 6.0728e-09, 1.0827e-09,\n",
      "        1.3675e-09, 7.0445e-09, 2.7052e-09, 2.0228e-09, 2.1834e-09, 6.9234e-09,\n",
      "        7.6059e-09, 1.7770e-09, 8.5317e-09, 2.4490e-09, 8.6829e-09, 7.2741e-09,\n",
      "        2.0419e-09, 3.4722e-09, 3.1998e-09, 1.3992e-09, 7.7048e-09, 5.2696e-09,\n",
      "        1.9214e-09, 9.1012e-10, 6.7116e-09, 5.5027e-09, 8.3785e-09, 4.2574e-09,\n",
      "        3.2315e-09, 4.5518e-09], device='cuda:0')}, 6: {'step': tensor(120., device='cuda:0'), 'exp_avg': tensor([[-7.7992e-05,  1.1285e-04,  1.0931e-04,  ..., -1.2705e-05,\n",
      "         -8.6096e-05,  4.0529e-05],\n",
      "        [ 1.3491e-04, -5.1397e-04,  1.8528e-04,  ...,  1.2009e-04,\n",
      "         -1.6308e-04, -5.0058e-06],\n",
      "        [ 7.0207e-05,  3.8386e-04,  2.6743e-04,  ...,  8.1814e-05,\n",
      "          1.6058e-04,  8.5312e-04],\n",
      "        ...,\n",
      "        [ 1.3197e-04, -2.4547e-04, -4.3605e-04,  ..., -3.5156e-04,\n",
      "         -1.1747e-04,  2.7266e-04],\n",
      "        [-2.4562e-04,  2.5642e-04, -6.9022e-04,  ..., -1.0040e-04,\n",
      "         -2.6128e-04, -2.8527e-05],\n",
      "        [ 6.8670e-06,  1.5085e-04, -4.4638e-05,  ...,  2.9063e-04,\n",
      "          2.7224e-04,  4.4251e-04]], device='cuda:0'), 'exp_avg_sq': tensor([[4.2162e-07, 7.3699e-07, 1.6812e-07,  ..., 1.8943e-07, 3.8644e-07,\n",
      "         1.1080e-06],\n",
      "        [2.2967e-07, 3.9898e-07, 5.6256e-08,  ..., 1.7893e-07, 1.6052e-07,\n",
      "         4.3679e-07],\n",
      "        [8.9472e-07, 7.4382e-07, 2.8513e-07,  ..., 3.3789e-07, 2.4795e-07,\n",
      "         1.0189e-06],\n",
      "        ...,\n",
      "        [3.6314e-07, 3.3212e-07, 2.8511e-07,  ..., 5.3127e-07, 3.7296e-07,\n",
      "         1.2046e-06],\n",
      "        [5.3422e-07, 4.1095e-07, 3.3403e-07,  ..., 4.3715e-07, 2.9702e-07,\n",
      "         6.2787e-07],\n",
      "        [3.9457e-07, 6.0899e-07, 2.2619e-07,  ..., 5.7654e-07, 4.2131e-07,\n",
      "         8.0502e-07]], device='cuda:0')}, 7: {'step': tensor(120., device='cuda:0'), 'exp_avg': tensor([ 2.7204e-06,  6.2562e-05,  1.5668e-04,  5.4274e-06, -1.4826e-05,\n",
      "        -1.0350e-04, -4.5694e-05,  1.0066e-05,  1.8583e-05, -8.4266e-06,\n",
      "         1.0666e-05,  9.6645e-06, -1.7271e-05, -2.6672e-05,  7.5843e-05,\n",
      "        -1.7117e-05, -8.6119e-05,  3.8043e-05,  1.2611e-06, -3.0040e-05,\n",
      "         1.3653e-05,  2.2333e-05,  4.7918e-05,  2.2425e-05,  8.9119e-05,\n",
      "         6.8064e-05,  7.3514e-05,  5.4924e-05,  2.1573e-05, -4.4144e-05,\n",
      "         6.0683e-05,  5.7116e-06, -1.7146e-05,  4.0167e-05,  3.0854e-05,\n",
      "        -6.5380e-05, -3.8482e-05, -1.5866e-06, -6.7892e-06, -3.6512e-05,\n",
      "         1.7505e-05, -7.3475e-06,  1.2790e-04,  2.8974e-06,  1.0796e-04,\n",
      "         2.2567e-05, -6.1156e-06, -1.8088e-05, -8.8031e-05,  3.5894e-05,\n",
      "        -7.3431e-05, -6.3334e-06,  2.5818e-05,  3.8654e-06, -1.4627e-05,\n",
      "        -5.8164e-05,  2.9673e-05, -1.2673e-05, -7.3607e-05,  2.1979e-05,\n",
      "        -4.8502e-06,  2.7921e-05,  1.7235e-05,  1.4987e-05,  5.9366e-06,\n",
      "        -1.8038e-05,  3.3762e-05, -7.5556e-06,  7.1373e-05, -7.9223e-05,\n",
      "         2.5723e-06,  3.0218e-05,  3.8953e-05, -3.1798e-05,  7.1695e-08,\n",
      "         3.9056e-05,  8.2269e-05,  2.4729e-05, -1.1946e-04, -2.1441e-05,\n",
      "        -4.3910e-05,  2.7227e-05,  3.2239e-05, -4.5523e-05,  5.5938e-05,\n",
      "         6.4506e-05, -1.5835e-06, -9.4818e-05,  8.5192e-06, -2.2052e-05,\n",
      "         2.5488e-06, -2.2404e-05, -8.0229e-05, -2.2604e-05,  9.9876e-06,\n",
      "         7.7448e-06, -1.9547e-05,  3.1184e-05,  3.1997e-05,  3.4974e-06,\n",
      "         3.2253e-06,  2.7843e-05, -2.9228e-06,  1.5185e-05, -1.8119e-06,\n",
      "        -7.0119e-05, -4.0025e-05,  1.4424e-04, -2.2087e-05,  2.2998e-05,\n",
      "         2.1740e-05,  4.0779e-05, -1.8958e-05, -6.6807e-05,  2.3431e-05,\n",
      "         6.2743e-05, -1.0280e-04,  2.6216e-05, -8.4193e-06,  5.6312e-05,\n",
      "         8.6915e-05, -1.9916e-05,  3.7482e-05,  4.8280e-07,  4.7540e-05,\n",
      "         5.8440e-05, -1.4612e-05,  1.1533e-04, -5.2830e-05, -1.9134e-05,\n",
      "        -3.1032e-05,  2.1999e-05, -7.0055e-05,  2.8870e-05,  3.3287e-05,\n",
      "        -6.5186e-05,  3.0326e-05,  3.1185e-05,  1.6620e-05,  9.5158e-05,\n",
      "        -7.9136e-06, -4.5659e-06, -4.4954e-05,  1.0355e-04, -3.0310e-05,\n",
      "         6.6325e-06, -2.6027e-05, -3.3720e-05,  1.5053e-06, -3.7704e-05,\n",
      "         3.0562e-06, -2.7871e-05,  3.3595e-06, -5.1434e-05,  2.4595e-05,\n",
      "        -2.0633e-05, -2.9686e-06,  1.4985e-05,  7.0752e-05, -3.2236e-05,\n",
      "         4.1229e-05,  1.5554e-06,  9.6321e-06, -8.4870e-06, -2.6244e-05,\n",
      "        -1.2420e-05, -4.8948e-05, -6.6273e-06,  1.9740e-06, -1.8220e-05,\n",
      "        -5.1622e-05, -1.5291e-04,  2.9890e-05,  1.6400e-05,  3.8894e-05,\n",
      "        -1.6543e-05, -2.8943e-05,  2.3850e-05,  7.3119e-06, -1.1737e-05,\n",
      "         6.7846e-06, -2.1796e-05, -4.6982e-05,  3.0033e-05,  1.3353e-05,\n",
      "         4.4052e-05,  5.2416e-05,  2.6289e-05,  4.0208e-05, -8.7087e-05,\n",
      "        -2.6313e-05,  5.0362e-05,  1.3439e-05,  2.5887e-05, -2.8640e-05,\n",
      "         1.0040e-04, -1.7684e-06,  1.6582e-04,  1.4210e-05, -1.2844e-04,\n",
      "        -3.7330e-05,  2.1066e-05, -1.0996e-06, -3.4537e-05, -1.4947e-05,\n",
      "        -2.2864e-05,  2.7829e-05,  4.9510e-05,  3.9358e-05,  1.6010e-05,\n",
      "         6.9479e-05,  1.0034e-04, -1.0985e-05, -9.9637e-06, -6.2889e-05,\n",
      "        -4.4610e-05, -5.2354e-05,  1.3840e-05,  3.4609e-05,  9.2852e-05,\n",
      "        -3.9836e-06,  8.1277e-05,  2.7372e-05, -7.5067e-05, -1.9232e-06,\n",
      "        -4.9243e-08, -3.2099e-05,  6.4593e-05, -5.5718e-05, -6.3001e-05,\n",
      "         1.3056e-04,  1.0207e-04,  1.5987e-05, -1.4928e-04, -3.9012e-05,\n",
      "        -1.3134e-05,  1.2871e-04, -2.6620e-05, -1.0638e-04,  4.8381e-05,\n",
      "        -6.5424e-05,  5.0362e-06, -1.9762e-05,  6.8968e-05, -2.3923e-05,\n",
      "        -8.0691e-05,  2.3109e-05, -8.1851e-05, -8.8712e-05, -7.9981e-05,\n",
      "        -5.2369e-05, -1.0805e-04,  1.3026e-05,  3.8544e-06, -1.2535e-04,\n",
      "        -3.6600e-06, -2.6129e-05,  1.6219e-06,  7.0071e-05, -5.6755e-05,\n",
      "        -8.5331e-05, -3.1916e-05, -2.6754e-05, -4.5739e-06,  2.1036e-05,\n",
      "         2.6125e-05, -3.3320e-05,  8.9131e-05,  4.1534e-06, -3.3279e-05,\n",
      "         1.7369e-05,  1.2179e-05,  5.2933e-06, -5.3325e-06, -1.9150e-05,\n",
      "        -3.1282e-05,  6.1600e-06,  1.0957e-05, -8.4725e-06,  4.6821e-05,\n",
      "         4.7858e-05,  5.5311e-05, -7.6582e-06,  1.9144e-06,  5.5834e-05,\n",
      "        -3.7681e-05,  1.5390e-06,  1.4366e-05, -3.1661e-05, -1.6620e-06,\n",
      "        -6.2809e-06, -2.6532e-05,  4.7174e-05, -1.0240e-04, -1.0417e-04,\n",
      "        -1.0577e-04,  4.4464e-05, -1.4907e-04,  2.7477e-05, -1.9514e-05,\n",
      "         7.7328e-05,  1.4601e-05, -5.0856e-06, -5.0695e-07, -6.2861e-06,\n",
      "        -4.5133e-05,  3.2622e-05,  8.8268e-06,  2.6563e-05,  6.7836e-05,\n",
      "         1.2288e-05, -8.5811e-06, -9.3626e-06,  2.2328e-05,  9.5024e-06,\n",
      "        -4.1031e-05,  1.4805e-05,  1.9281e-05,  7.0528e-05,  3.8551e-05,\n",
      "         5.9142e-05,  1.0409e-04, -1.1377e-05, -4.3894e-06,  6.3106e-05,\n",
      "         3.5062e-05, -5.2740e-05,  3.2829e-05, -2.7170e-05, -1.0546e-04,\n",
      "        -1.2535e-04, -9.8233e-06,  1.0604e-04, -6.8410e-06, -6.5475e-07,\n",
      "        -9.6854e-06, -9.5861e-06,  3.0034e-05,  1.3862e-05, -3.2135e-05,\n",
      "         8.4407e-06, -1.2195e-05,  4.2340e-05,  3.7928e-06,  2.1084e-05,\n",
      "        -8.4404e-05, -3.5058e-05, -3.8316e-06, -1.0952e-04, -3.0841e-06,\n",
      "         1.5152e-05,  6.0709e-05,  4.6193e-05,  6.6076e-05,  1.6522e-05,\n",
      "        -4.9546e-05, -6.2964e-05,  1.5466e-05, -1.8723e-05, -4.4745e-05,\n",
      "         1.3529e-05, -5.8564e-05,  6.7334e-05,  8.1406e-06,  1.7020e-05,\n",
      "         2.3237e-05, -3.8774e-05,  3.8517e-06,  5.2320e-06, -3.4197e-05,\n",
      "         1.0915e-05, -1.1397e-05, -3.1882e-05,  1.0772e-05, -1.1804e-04,\n",
      "        -6.5380e-05,  1.3565e-04,  1.3174e-05, -1.2975e-04,  5.2354e-05,\n",
      "         4.3906e-05,  8.7071e-06,  4.5335e-05,  3.5954e-05, -1.8418e-05,\n",
      "         7.3624e-05, -8.9037e-05, -1.1640e-05, -1.2174e-05,  4.3746e-05,\n",
      "         1.7587e-06, -5.1240e-05,  2.2498e-05,  1.9315e-06,  1.3308e-04,\n",
      "         5.8371e-05,  6.7387e-06, -3.8442e-06, -3.8563e-05, -6.6766e-05,\n",
      "         1.5358e-05,  3.0469e-05, -5.2165e-05,  1.1759e-05, -2.2436e-05,\n",
      "        -8.4435e-05,  1.6235e-05,  2.1010e-05, -1.7716e-05, -2.0088e-06,\n",
      "         2.3417e-05, -2.3493e-05,  6.4405e-05,  3.9555e-05, -1.7089e-05,\n",
      "        -6.8661e-05,  7.4565e-05, -4.7599e-06, -1.0218e-06,  2.0961e-04,\n",
      "         3.0422e-05, -4.1709e-05, -9.0385e-06, -2.2195e-05, -2.1097e-05,\n",
      "         3.2799e-06,  3.7359e-05, -6.3737e-05, -5.7699e-05,  6.5308e-07,\n",
      "         1.0848e-04,  5.2251e-05,  3.7685e-05,  1.9976e-05, -9.5033e-06,\n",
      "         5.2010e-05,  1.0041e-04,  8.1470e-06, -2.6319e-05,  1.1898e-04,\n",
      "         4.8152e-05,  2.0623e-05,  3.0460e-05,  5.2553e-05, -1.1946e-04,\n",
      "         2.9021e-05,  4.5021e-06,  5.3695e-05,  8.4135e-05, -4.0144e-06,\n",
      "         6.9471e-05, -1.1246e-04, -8.4068e-05, -6.5090e-05, -7.7473e-05,\n",
      "         3.7347e-05,  4.6650e-05,  8.0651e-05,  1.2192e-04, -1.4365e-05,\n",
      "        -3.3737e-07, -1.6139e-05, -7.9842e-06, -1.5047e-05,  8.1747e-05,\n",
      "        -4.1583e-05, -6.2254e-05, -3.7374e-05, -1.3619e-05, -3.5416e-05,\n",
      "        -5.9948e-06,  1.1212e-05, -2.2259e-05,  4.9333e-05,  9.0876e-06,\n",
      "        -5.0311e-05,  7.3485e-08, -4.6995e-05,  4.2277e-05,  9.6702e-05,\n",
      "        -4.1261e-05, -4.5922e-05, -5.6149e-05, -2.2464e-05, -9.5290e-06,\n",
      "        -4.0236e-05, -1.3283e-04, -4.4389e-05,  1.6602e-05,  9.3581e-06,\n",
      "         1.4823e-05, -1.1821e-05,  2.6652e-05, -6.9187e-05,  5.2229e-05,\n",
      "        -8.3307e-05, -9.3797e-06,  1.5491e-05, -8.5794e-06,  5.0478e-06,\n",
      "         6.7926e-05,  3.0226e-05,  3.7118e-06, -4.4409e-05, -4.8809e-05,\n",
      "         9.5655e-05,  4.6312e-05,  1.3226e-04, -2.7111e-06, -2.9169e-05,\n",
      "         4.2078e-06,  3.4656e-05], device='cuda:0'), 'exp_avg_sq': tensor([1.5242e-08, 7.5543e-09, 2.8309e-08, 1.7285e-08, 1.2569e-08, 1.1486e-08,\n",
      "        1.7618e-08, 1.7350e-08, 7.1811e-09, 1.8177e-08, 9.2888e-09, 8.1247e-09,\n",
      "        1.2363e-08, 1.0716e-08, 1.7844e-08, 1.3619e-08, 1.5387e-08, 1.6257e-08,\n",
      "        3.3994e-09, 5.3752e-09, 1.7808e-08, 8.1236e-09, 7.2540e-09, 2.5090e-08,\n",
      "        7.4834e-09, 2.7828e-09, 2.9466e-08, 1.3865e-08, 6.5581e-09, 1.2089e-08,\n",
      "        1.1792e-08, 2.0382e-08, 1.6778e-08, 1.2401e-08, 7.1009e-09, 1.8291e-08,\n",
      "        1.1387e-08, 1.5556e-08, 1.9985e-08, 7.0836e-09, 1.6863e-08, 9.9647e-09,\n",
      "        8.5522e-09, 2.7309e-08, 9.9306e-09, 1.1402e-08, 5.5445e-09, 1.5793e-08,\n",
      "        1.6154e-08, 2.2137e-08, 9.4216e-09, 6.9205e-09, 2.7822e-09, 1.0407e-08,\n",
      "        2.5398e-08, 1.7368e-08, 1.6824e-08, 8.3335e-09, 1.7819e-08, 1.6243e-08,\n",
      "        1.3246e-09, 1.7546e-08, 1.0799e-08, 3.8067e-09, 2.3565e-08, 7.0524e-09,\n",
      "        9.4893e-09, 1.2916e-08, 1.0797e-08, 2.4199e-08, 9.5729e-09, 7.6272e-09,\n",
      "        6.5792e-09, 1.4403e-08, 1.9514e-08, 1.4496e-08, 2.0690e-08, 6.8991e-09,\n",
      "        1.0373e-08, 1.5591e-08, 1.1501e-08, 1.4040e-08, 1.7022e-08, 1.9510e-08,\n",
      "        1.1741e-08, 2.3234e-08, 1.4949e-08, 1.8411e-08, 1.6885e-08, 1.2754e-08,\n",
      "        1.7969e-09, 1.7749e-08, 1.4900e-08, 1.6991e-08, 2.9171e-09, 1.7366e-08,\n",
      "        4.7620e-09, 1.7988e-08, 2.2175e-08, 3.4672e-09, 3.9202e-09, 4.7914e-09,\n",
      "        1.5479e-08, 1.2365e-08, 1.3183e-08, 2.5834e-08, 1.1023e-08, 3.6684e-09,\n",
      "        1.3442e-08, 2.8361e-09, 1.2931e-08, 1.3148e-08, 8.2444e-09, 1.7075e-08,\n",
      "        9.0468e-09, 1.1503e-08, 1.7726e-08, 1.5390e-08, 7.0747e-09, 1.8996e-08,\n",
      "        2.0912e-08, 1.4601e-08, 1.0207e-08, 5.4381e-09, 1.6940e-08, 1.3607e-08,\n",
      "        9.9219e-09, 2.5095e-08, 1.1222e-08, 1.7478e-08, 1.8542e-08, 1.7017e-08,\n",
      "        1.2511e-08, 1.2437e-08, 8.5035e-09, 6.2342e-09, 1.7459e-09, 1.2761e-08,\n",
      "        1.5243e-08, 2.1798e-08, 1.0558e-08, 1.6210e-08, 1.2284e-08, 5.6237e-09,\n",
      "        3.5986e-09, 1.9422e-08, 1.7189e-08, 1.3879e-08, 6.1793e-09, 1.4715e-08,\n",
      "        1.0268e-08, 2.6214e-08, 1.0114e-11, 1.0131e-08, 3.0845e-08, 1.9196e-08,\n",
      "        4.3681e-09, 1.6264e-08, 2.0473e-08, 1.2302e-08, 2.1576e-08, 3.5943e-08,\n",
      "        3.7362e-09, 3.4737e-09, 8.3408e-09, 1.8511e-08, 1.1578e-08, 6.7352e-09,\n",
      "        8.1069e-09, 5.6508e-09, 9.5299e-09, 1.2816e-08, 1.3835e-08, 9.2710e-09,\n",
      "        1.0240e-08, 8.7288e-09, 1.3831e-08, 1.1551e-08, 1.2152e-08, 1.2625e-08,\n",
      "        2.7289e-09, 1.3827e-08, 8.1904e-09, 1.0653e-08, 1.6631e-08, 5.8700e-09,\n",
      "        1.1747e-08, 1.5346e-08, 2.4140e-08, 1.1001e-08, 1.1479e-08, 1.8429e-08,\n",
      "        2.9191e-08, 1.3256e-08, 6.1674e-09, 2.6837e-08, 1.6998e-08, 2.6756e-08,\n",
      "        1.5026e-08, 1.3997e-08, 1.4036e-08, 1.3424e-08, 7.4849e-09, 6.4910e-09,\n",
      "        1.1285e-08, 8.6956e-09, 8.3441e-09, 2.8055e-08, 1.6297e-08, 2.1997e-08,\n",
      "        7.1089e-09, 2.3207e-08, 2.6288e-08, 1.1774e-09, 8.6970e-09, 1.5103e-08,\n",
      "        1.0293e-08, 3.1831e-08, 6.9937e-09, 1.8699e-08, 2.0987e-08, 1.2760e-08,\n",
      "        2.2397e-08, 1.4299e-08, 9.5493e-09, 1.9365e-08, 1.5054e-08, 1.4537e-08,\n",
      "        1.8100e-08, 9.4765e-09, 1.5073e-08, 1.4481e-08, 3.0586e-09, 1.3163e-08,\n",
      "        1.4518e-08, 1.1820e-08, 1.5123e-08, 2.9784e-08, 3.2894e-08, 1.0363e-08,\n",
      "        1.6657e-08, 1.8332e-08, 9.2632e-09, 1.2577e-08, 1.3948e-08, 1.6396e-08,\n",
      "        1.0368e-08, 2.0095e-09, 3.5966e-08, 1.0387e-08, 1.2889e-08, 1.8239e-08,\n",
      "        5.4013e-09, 2.4204e-08, 1.8636e-08, 8.3580e-10, 1.6440e-08, 7.2010e-09,\n",
      "        1.0981e-08, 1.0221e-08, 1.8499e-08, 6.0520e-09, 2.9627e-08, 2.5490e-08,\n",
      "        7.7034e-09, 1.0931e-08, 7.3318e-09, 1.9005e-08, 1.7044e-08, 1.2711e-08,\n",
      "        2.2570e-08, 2.3137e-08, 3.7690e-09, 9.0565e-09, 1.4859e-08, 7.0897e-09,\n",
      "        1.8313e-08, 5.4755e-09, 4.3055e-08, 2.0582e-08, 9.3323e-09, 1.2872e-08,\n",
      "        1.3636e-08, 2.8595e-08, 2.2470e-08, 2.5161e-08, 1.8021e-08, 1.2808e-08,\n",
      "        2.2072e-08, 2.2633e-08, 4.2632e-09, 8.5178e-09, 2.1358e-08, 1.5724e-08,\n",
      "        9.5518e-09, 2.1982e-08, 1.1027e-08, 7.4293e-09, 9.5316e-09, 7.9150e-09,\n",
      "        2.0768e-08, 5.3443e-09, 2.8667e-08, 1.1427e-08, 1.5369e-08, 1.1623e-08,\n",
      "        1.2284e-08, 1.6592e-08, 8.4389e-09, 6.2880e-09, 1.1717e-08, 8.2781e-09,\n",
      "        1.7627e-08, 1.4392e-08, 8.2889e-09, 1.4945e-08, 1.0170e-08, 1.3305e-08,\n",
      "        1.6963e-08, 9.9024e-09, 1.7981e-08, 1.6710e-08, 1.3019e-08, 1.4999e-09,\n",
      "        1.5609e-08, 1.5251e-08, 5.2870e-09, 2.4933e-08, 8.9189e-09, 1.3735e-08,\n",
      "        3.3446e-08, 1.2171e-08, 1.9732e-08, 1.5988e-08, 7.9250e-09, 2.2622e-08,\n",
      "        9.5589e-09, 1.6203e-08, 4.9141e-09, 1.2746e-08, 1.9144e-08, 1.6359e-08,\n",
      "        1.4593e-08, 1.6453e-08, 1.1076e-08, 4.1083e-09, 2.0385e-08, 1.8494e-08,\n",
      "        2.3715e-08, 2.3421e-08, 7.1052e-09, 1.8412e-08, 1.4177e-08, 7.5108e-09,\n",
      "        2.3468e-08, 1.2174e-08, 2.1589e-08, 1.2348e-08, 2.4138e-08, 8.3269e-09,\n",
      "        1.2921e-08, 1.7302e-08, 1.2544e-08, 6.7582e-09, 9.5995e-09, 1.8277e-08,\n",
      "        1.8352e-08, 6.1717e-09, 4.4587e-09, 1.3939e-08, 6.5287e-09, 8.6830e-09,\n",
      "        1.4343e-08, 2.6588e-09, 2.2229e-08, 1.4569e-08, 1.7027e-08, 1.3018e-08,\n",
      "        2.0218e-08, 1.3045e-08, 5.8030e-09, 1.0868e-08, 9.2364e-09, 9.9031e-09,\n",
      "        1.5203e-08, 2.2650e-08, 2.6385e-08, 4.3229e-09, 4.0532e-09, 4.6970e-09,\n",
      "        8.6517e-09, 2.6154e-08, 1.9446e-08, 1.0811e-08, 2.6888e-08, 2.6253e-08,\n",
      "        5.5444e-09, 3.0349e-09, 1.1298e-08, 1.4880e-08, 1.5966e-08, 1.5134e-08,\n",
      "        2.6305e-08, 9.6970e-09, 1.2606e-08, 1.4570e-08, 9.4757e-09, 1.1180e-08,\n",
      "        1.6809e-08, 1.3292e-08, 1.6317e-08, 1.9468e-08, 1.3851e-08, 1.2162e-08,\n",
      "        6.8449e-09, 1.0719e-08, 9.8460e-09, 3.6096e-09, 1.8882e-08, 4.0590e-08,\n",
      "        1.1675e-08, 1.2135e-08, 1.3572e-08, 8.4682e-09, 1.0020e-08, 7.2258e-09,\n",
      "        1.0545e-08, 1.5803e-08, 2.2692e-08, 1.2801e-08, 3.6309e-08, 1.1881e-08,\n",
      "        1.7236e-08, 1.4999e-08, 1.4950e-08, 1.7623e-08, 1.3396e-08, 1.3893e-08,\n",
      "        1.1382e-08, 3.2832e-08, 1.1783e-08, 6.1334e-09, 1.1578e-08, 1.8141e-08,\n",
      "        1.5663e-08, 3.5252e-09, 2.0730e-08, 1.3941e-08, 8.8917e-09, 1.0529e-08,\n",
      "        3.5405e-08, 7.0380e-09, 2.1552e-08, 6.0090e-09, 1.1694e-08, 1.9778e-09,\n",
      "        1.0886e-08, 1.2344e-08, 1.5324e-08, 1.3723e-08, 1.7623e-08, 1.8460e-09,\n",
      "        2.5197e-08, 2.6811e-08, 1.5987e-08, 1.1363e-08, 1.3337e-08, 1.1712e-08,\n",
      "        9.5031e-09, 1.4895e-08, 1.4361e-08, 3.7028e-09, 1.7940e-08, 1.8696e-08,\n",
      "        5.0978e-09, 2.7158e-08, 9.4764e-09, 2.1107e-08, 1.3938e-08, 2.2954e-08,\n",
      "        2.2437e-08, 2.0353e-08, 1.2792e-08, 7.4026e-09, 1.1019e-08, 1.8211e-08,\n",
      "        1.7370e-08, 7.5780e-09, 1.7293e-08, 1.5900e-08, 1.3046e-08, 1.1851e-09,\n",
      "        5.8356e-09, 1.1179e-08, 2.0678e-08, 2.0570e-08, 4.9183e-09, 8.3351e-09,\n",
      "        3.3620e-09, 7.4693e-09, 1.9296e-08, 1.0739e-08, 2.5704e-10, 1.7910e-08,\n",
      "        4.1967e-09, 1.9941e-08, 2.8182e-09, 2.7395e-08, 9.5993e-09, 1.4508e-08,\n",
      "        1.6572e-08, 1.8385e-08], device='cuda:0')}, 8: {'step': tensor(120., device='cuda:0'), 'exp_avg': tensor([[-1.5313e-05,  3.2314e-05, -1.3052e-04,  ..., -9.1286e-05,\n",
      "         -9.7453e-05,  2.2129e-04],\n",
      "        [ 1.3570e-04,  1.0466e-04, -1.3316e-03,  ..., -7.5493e-04,\n",
      "          1.0418e-04,  2.3254e-04],\n",
      "        [ 7.1486e-05, -7.6567e-04,  9.2126e-04,  ...,  9.3521e-05,\n",
      "          1.2511e-04,  8.7469e-04],\n",
      "        ...,\n",
      "        [ 1.6577e-05, -9.6428e-04, -2.9938e-04,  ..., -1.7178e-04,\n",
      "         -1.1452e-04, -2.3627e-03],\n",
      "        [-2.1602e-04,  1.3692e-04, -3.1219e-04,  ...,  8.5379e-05,\n",
      "         -8.8064e-05, -8.4633e-04],\n",
      "        [ 1.4426e-05, -5.4737e-04,  1.0318e-03,  ...,  6.3966e-04,\n",
      "         -1.0857e-04,  6.0914e-04]], device='cuda:0'), 'exp_avg_sq': tensor([[2.7616e-07, 2.7392e-07, 1.1785e-06,  ..., 4.7099e-07, 2.1428e-07,\n",
      "         7.5600e-07],\n",
      "        [1.7803e-06, 5.0804e-07, 1.2418e-06,  ..., 1.9880e-06, 8.0530e-07,\n",
      "         1.8839e-06],\n",
      "        [5.2269e-07, 5.7946e-07, 2.7790e-06,  ..., 7.3277e-07, 1.2867e-06,\n",
      "         1.9486e-06],\n",
      "        ...,\n",
      "        [9.1109e-07, 9.1938e-07, 2.3204e-06,  ..., 1.2981e-06, 1.7222e-06,\n",
      "         5.7894e-06],\n",
      "        [2.4848e-07, 1.0906e-07, 2.5747e-07,  ..., 5.6614e-07, 3.1574e-07,\n",
      "         9.1496e-07],\n",
      "        [3.6948e-07, 4.3011e-07, 1.1505e-06,  ..., 9.0507e-07, 4.5405e-07,\n",
      "         1.3639e-06]], device='cuda:0')}, 9: {'step': tensor(120., device='cuda:0'), 'exp_avg': tensor([-1.5978e-04, -1.1418e-04, -2.0463e-05, -7.7537e-05, -2.8913e-04,\n",
      "         6.3850e-05,  3.6897e-05, -1.5994e-05, -1.4055e-04, -1.1621e-04,\n",
      "         1.8360e-04,  7.3987e-05, -1.2741e-05,  8.8551e-05,  7.9698e-05,\n",
      "         1.1804e-04,  2.0166e-04,  2.9637e-05, -2.4159e-06, -2.3013e-04,\n",
      "        -1.9367e-05, -6.7713e-06, -4.9488e-05,  1.6455e-04, -1.3482e-04,\n",
      "        -8.4607e-05, -3.1169e-05,  3.9383e-05, -7.4982e-06,  2.2527e-05,\n",
      "         1.4278e-04,  3.2657e-05, -1.7831e-04,  2.5531e-05, -3.3739e-04,\n",
      "        -2.2231e-05,  3.4811e-04,  8.6205e-05, -9.7178e-05,  4.0325e-05,\n",
      "        -1.3817e-04, -2.6632e-04, -2.5926e-04,  8.7211e-05,  9.3681e-05,\n",
      "        -1.0052e-04,  8.4830e-05, -3.9887e-05, -1.2098e-04,  3.9583e-05,\n",
      "        -1.8690e-04,  1.1618e-04,  1.4904e-05, -3.4285e-04, -3.5542e-05,\n",
      "         3.9847e-05, -8.2590e-06, -8.9249e-05, -6.6796e-05, -1.1532e-04,\n",
      "        -4.6669e-04, -8.8791e-05,  2.4439e-04, -7.3027e-05,  7.6979e-05,\n",
      "        -4.0150e-05, -2.5883e-05, -3.0623e-04, -2.0542e-04, -2.9751e-04,\n",
      "         1.9628e-04, -1.1042e-04, -1.1138e-04,  1.0684e-07,  1.5254e-06,\n",
      "        -7.8768e-05,  1.9538e-04,  1.0328e-04,  5.9363e-05, -2.1915e-04,\n",
      "         1.6556e-04, -1.4144e-05, -2.8691e-06, -8.8479e-05,  8.8072e-06,\n",
      "         1.0898e-06,  1.5926e-04, -3.8930e-04, -2.1114e-05, -1.2435e-04,\n",
      "        -8.8354e-05, -1.4151e-04,  1.2214e-04, -3.1179e-05, -1.6603e-04,\n",
      "         2.1223e-05,  3.2820e-05,  5.1760e-05,  3.6254e-04, -7.7236e-06,\n",
      "        -2.5777e-04,  1.7443e-05,  1.8159e-04,  3.5320e-05, -3.8168e-05,\n",
      "         2.2258e-05,  1.8460e-04, -3.6471e-04,  2.6414e-04, -1.4145e-04,\n",
      "        -2.1760e-04,  1.7825e-04,  3.3061e-04, -5.9141e-05,  1.0187e-04,\n",
      "         1.1452e-04,  2.2591e-04, -1.1606e-04,  2.2689e-06, -5.8648e-05,\n",
      "         4.6820e-05, -2.1275e-04, -4.3034e-05, -1.3970e-05,  4.0950e-05,\n",
      "        -1.4159e-05, -9.9717e-05,  3.9114e-05,  2.5674e-04, -5.8090e-05,\n",
      "         1.0379e-04,  6.5951e-05,  9.0479e-05,  2.6246e-06, -1.7675e-05,\n",
      "         1.2415e-04,  3.2697e-05,  1.1540e-04,  1.1616e-04, -9.8197e-05,\n",
      "         1.6830e-04,  1.0721e-04,  7.9900e-05,  3.6788e-05, -1.1296e-04,\n",
      "        -1.5914e-05,  3.4998e-04,  1.9559e-04, -1.2805e-04, -4.0515e-05,\n",
      "         1.0465e-04,  5.0741e-05,  2.5866e-05, -2.7953e-06, -8.1983e-05,\n",
      "        -7.1640e-05,  1.1033e-04, -3.3415e-05,  2.6418e-04, -1.6750e-04,\n",
      "        -1.4727e-04, -2.2510e-05,  9.4869e-05,  8.6053e-05,  3.0055e-05,\n",
      "         1.3287e-04,  1.4875e-04, -1.4812e-05,  1.0014e-04,  2.2168e-06,\n",
      "        -7.3933e-05,  1.0597e-04,  2.8721e-06,  2.2598e-04, -7.0558e-05,\n",
      "        -4.0302e-05,  3.8044e-05, -8.7352e-05,  2.2979e-05, -2.2495e-04,\n",
      "         3.2309e-05, -5.2747e-07,  2.0902e-04,  4.1952e-05, -8.5244e-05,\n",
      "         6.7740e-05,  1.8527e-04,  5.5525e-05, -2.5834e-04, -7.9510e-05,\n",
      "         1.2933e-04, -4.4097e-05,  1.0832e-04, -8.6125e-05, -7.4256e-05,\n",
      "         8.0765e-05, -2.4434e-05,  5.7587e-05, -5.8431e-05, -3.1804e-06,\n",
      "        -1.0025e-04,  1.0035e-04,  5.8743e-05,  2.0279e-04,  1.2557e-04,\n",
      "        -1.2278e-05,  2.9038e-04, -1.5338e-04, -1.8409e-04, -1.4653e-04,\n",
      "         1.3627e-04,  1.5805e-04,  9.9200e-05, -8.6590e-05,  6.2253e-05,\n",
      "         7.8960e-05, -3.1449e-05,  9.0128e-05, -7.6909e-05, -1.5273e-05,\n",
      "         7.8538e-05,  7.6365e-05,  1.4575e-04,  1.1300e-04,  2.2889e-05,\n",
      "        -1.7011e-05,  3.9710e-05,  1.6392e-04,  6.6917e-05,  2.0608e-04,\n",
      "         3.5411e-04,  6.2631e-06, -4.2202e-04, -3.3405e-05,  1.7427e-05,\n",
      "         1.6090e-04,  8.3041e-05, -2.5735e-04,  8.5565e-05,  4.8231e-05,\n",
      "        -5.0611e-05, -2.5236e-04,  4.9085e-05, -3.3649e-04,  1.5474e-05,\n",
      "         9.1068e-05, -1.3599e-04,  1.8837e-04,  5.1766e-05,  2.2217e-04,\n",
      "         3.1457e-05, -1.1378e-04, -3.8606e-05, -2.1203e-05,  1.5247e-04,\n",
      "         1.5942e-04], device='cuda:0'), 'exp_avg_sq': tensor([3.6838e-08, 7.6636e-08, 7.9881e-08, 7.6236e-08, 1.4279e-07, 1.6964e-07,\n",
      "        6.2607e-08, 1.2502e-07, 6.4064e-08, 1.2777e-07, 2.7376e-08, 6.3106e-08,\n",
      "        1.3890e-07, 6.2574e-08, 8.1379e-08, 9.1252e-08, 8.7861e-08, 3.7012e-08,\n",
      "        1.4223e-08, 1.3433e-07, 2.1755e-08, 3.2191e-08, 6.3803e-08, 9.3789e-08,\n",
      "        4.3561e-08, 2.9553e-08, 8.5377e-08, 1.1613e-07, 2.2819e-08, 9.6116e-08,\n",
      "        5.6703e-08, 2.5834e-08, 8.7040e-08, 9.5419e-08, 6.4993e-08, 6.3327e-08,\n",
      "        1.1030e-07, 1.1144e-07, 6.9822e-08, 1.1519e-07, 9.7238e-08, 7.5565e-08,\n",
      "        6.3698e-08, 1.0687e-07, 5.6384e-08, 7.1298e-08, 7.9101e-08, 1.2718e-07,\n",
      "        8.9600e-08, 6.7623e-08, 1.4185e-07, 9.0864e-08, 5.9315e-08, 8.0686e-08,\n",
      "        1.2479e-07, 2.6872e-08, 7.1318e-08, 1.0724e-07, 5.1458e-08, 1.8961e-07,\n",
      "        1.6298e-07, 7.3644e-08, 1.4077e-07, 7.4844e-08, 9.6522e-08, 4.5805e-08,\n",
      "        1.1265e-07, 4.8998e-08, 1.1747e-07, 7.7782e-08, 1.4065e-07, 1.2986e-08,\n",
      "        6.3636e-08, 5.4914e-08, 4.5256e-08, 5.1751e-08, 1.0022e-07, 4.1612e-08,\n",
      "        7.3857e-08, 5.4418e-08, 8.2695e-08, 3.8628e-08, 1.0887e-07, 7.7433e-08,\n",
      "        1.4742e-07, 1.2340e-07, 1.2638e-07, 1.3506e-07, 9.2676e-08, 6.6784e-08,\n",
      "        4.3189e-08, 7.8916e-08, 2.3121e-08, 1.8015e-07, 6.8982e-08, 8.5950e-08,\n",
      "        9.6301e-08, 4.7808e-08, 1.4633e-07, 1.0601e-07, 1.1408e-07, 1.1274e-07,\n",
      "        1.5459e-07, 2.8960e-08, 1.4605e-07, 4.3568e-08, 7.1942e-08, 6.8780e-08,\n",
      "        7.9637e-08, 7.9366e-08, 7.9041e-08, 6.1866e-08, 9.5084e-08, 4.7601e-08,\n",
      "        4.7830e-08, 7.7705e-08, 1.1477e-07, 7.2156e-08, 5.5759e-08, 1.2656e-07,\n",
      "        3.8741e-08, 7.7763e-08, 7.5607e-08, 4.6459e-08, 1.0012e-07, 5.2283e-08,\n",
      "        7.9863e-08, 1.7236e-07, 1.2415e-07, 2.4618e-08, 9.5451e-08, 8.1124e-09,\n",
      "        5.8505e-08, 1.7122e-07, 6.7831e-08, 4.5385e-08, 7.6637e-08, 4.1939e-08,\n",
      "        4.1539e-08, 1.5525e-08, 9.1121e-08, 1.2940e-07, 7.4325e-08, 2.4856e-08,\n",
      "        9.1984e-08, 1.6655e-07, 9.1250e-08, 1.0731e-07, 4.8245e-08, 6.0486e-08,\n",
      "        4.6663e-08, 2.4055e-08, 5.2036e-08, 5.1338e-08, 1.9790e-08, 4.2519e-08,\n",
      "        8.1954e-08, 9.0992e-08, 7.2037e-08, 8.7967e-08, 2.4180e-08, 1.1035e-07,\n",
      "        4.2767e-08, 1.0266e-07, 9.2920e-09, 6.6236e-08, 9.2692e-08, 5.8444e-08,\n",
      "        8.0891e-08, 7.3658e-09, 5.4416e-08, 1.1554e-07, 4.6117e-08, 3.4152e-08,\n",
      "        6.0876e-08, 7.6234e-08, 8.7999e-08, 5.0021e-08, 6.8125e-08, 6.6166e-08,\n",
      "        1.4382e-08, 5.2850e-08, 1.0454e-07, 2.9669e-08, 7.4819e-08, 8.1462e-08,\n",
      "        3.2507e-07, 9.9978e-08, 1.1144e-07, 1.3621e-07, 9.0921e-08, 4.5879e-08,\n",
      "        5.2727e-08, 7.7249e-08, 8.7177e-08, 8.6653e-08, 1.3962e-08, 9.9659e-08,\n",
      "        1.3850e-07, 4.7305e-08, 8.5683e-08, 1.0645e-07, 3.2053e-08, 1.4018e-07,\n",
      "        8.1972e-08, 2.8610e-08, 1.1084e-07, 1.3488e-07, 4.8228e-08, 1.4091e-07,\n",
      "        5.7089e-08, 8.1201e-08, 8.4830e-08, 1.1435e-07, 8.6208e-08, 3.6889e-08,\n",
      "        4.4705e-08, 8.7804e-08, 1.6453e-07, 9.5528e-09, 1.2061e-07, 6.7233e-08,\n",
      "        3.2054e-08, 1.0989e-07, 2.7382e-08, 2.9813e-08, 4.3376e-08, 1.7400e-07,\n",
      "        5.0440e-08, 6.6479e-08, 1.2368e-07, 6.3325e-08, 1.5035e-07, 4.0016e-08,\n",
      "        5.9242e-08, 1.8057e-07, 5.3503e-08, 1.1186e-07, 4.3240e-08, 1.1120e-07,\n",
      "        5.6848e-08, 7.6173e-08, 7.3744e-08, 4.6241e-08, 4.8622e-08, 4.3212e-08,\n",
      "        1.2141e-07, 8.7827e-08, 8.0252e-08, 1.2533e-07, 1.7635e-07, 9.6736e-08,\n",
      "        6.6371e-08, 1.2688e-07, 3.5152e-08, 5.0449e-08], device='cuda:0')}, 10: {'step': tensor(120., device='cuda:0'), 'exp_avg': tensor([[-2.5424e-05,  4.4413e-05,  3.8325e-05,  ...,  6.7514e-04,\n",
      "         -2.1808e-04, -4.7038e-06],\n",
      "        [-2.5760e-04, -3.2881e-04,  2.0549e-03,  ..., -1.3460e-04,\n",
      "         -3.3368e-04, -6.0813e-04],\n",
      "        [ 6.9076e-05, -1.3792e-04,  1.6844e-03,  ...,  2.9989e-03,\n",
      "          3.9077e-04,  1.7009e-03],\n",
      "        ...,\n",
      "        [-2.0163e-04, -3.4684e-04,  2.1396e-04,  ...,  7.9804e-05,\n",
      "          3.4065e-05,  3.0144e-03],\n",
      "        [ 1.1239e-04,  5.1563e-05,  1.5419e-03,  ..., -7.6072e-04,\n",
      "         -6.5175e-04,  6.2580e-04],\n",
      "        [ 2.4780e-04,  8.8288e-05, -9.5863e-04,  ...,  7.6768e-04,\n",
      "          1.9458e-04, -8.0524e-04]], device='cuda:0'), 'exp_avg_sq': tensor([[1.5246e-07, 1.4156e-07, 1.5410e-06,  ..., 6.0966e-07, 2.5792e-07,\n",
      "         3.2124e-07],\n",
      "        [8.4727e-07, 7.1219e-07, 4.5557e-06,  ..., 4.6673e-06, 3.1329e-07,\n",
      "         9.2154e-07],\n",
      "        [8.9671e-07, 8.9027e-07, 2.4305e-06,  ..., 5.5660e-06, 4.9520e-07,\n",
      "         1.6970e-06],\n",
      "        ...,\n",
      "        [1.9598e-06, 5.4952e-07, 2.8591e-06,  ..., 5.3871e-06, 5.6301e-07,\n",
      "         2.8272e-06],\n",
      "        [1.5610e-07, 3.3241e-07, 1.3467e-06,  ..., 2.2824e-06, 3.9427e-07,\n",
      "         7.0736e-07],\n",
      "        [1.1032e-06, 8.3395e-07, 1.4853e-06,  ..., 3.6932e-06, 8.9859e-07,\n",
      "         2.0238e-06]], device='cuda:0')}, 11: {'step': tensor(120., device='cuda:0'), 'exp_avg': tensor([ 2.1119e-04,  1.0620e-05,  2.8397e-04,  1.8085e-04,  1.5423e-04,\n",
      "        -1.2402e-04, -3.1316e-04,  2.0676e-04,  4.2141e-04, -9.3498e-05,\n",
      "         1.9686e-05,  1.9267e-04, -3.7587e-04,  2.7891e-04, -1.6074e-04,\n",
      "         4.5240e-06,  3.9096e-04, -1.2182e-04,  4.3479e-04, -1.4268e-04,\n",
      "        -5.5005e-05, -1.0108e-05, -1.9798e-04,  1.7008e-04,  1.8853e-04,\n",
      "         4.1839e-04, -3.6542e-04,  2.1808e-04, -1.6296e-04, -4.6807e-04,\n",
      "        -1.7676e-04, -4.1152e-04,  1.2837e-04,  7.6908e-05, -1.5148e-04,\n",
      "        -8.0744e-05, -1.5504e-05,  1.4797e-05,  2.0200e-04,  9.1010e-05,\n",
      "         2.1365e-04,  8.6425e-05,  4.0096e-05,  3.6697e-04,  1.8873e-05,\n",
      "         5.1022e-04,  5.9736e-05,  2.7233e-04, -6.2349e-05, -8.9427e-05,\n",
      "         5.5026e-04, -4.8443e-04, -4.3560e-04, -6.4839e-05, -1.9283e-04,\n",
      "        -3.4658e-04,  6.7517e-05, -1.8407e-04,  6.0923e-05,  1.2992e-05,\n",
      "        -6.3352e-05, -3.9958e-05,  3.8445e-05,  2.6892e-05, -1.9034e-04,\n",
      "        -5.6269e-06, -5.9142e-05,  1.0228e-04,  2.2958e-04, -2.3641e-04,\n",
      "        -3.5082e-04, -3.1797e-05,  2.3142e-05,  5.9646e-06,  1.1586e-04,\n",
      "         1.8434e-04,  3.9236e-05, -2.1269e-04, -4.1825e-05, -1.2398e-04,\n",
      "        -1.2514e-04, -3.2890e-04,  4.1039e-04,  2.5415e-05, -1.4483e-05,\n",
      "        -2.2946e-04, -5.0169e-05,  8.3039e-05, -1.2400e-04,  3.8456e-05,\n",
      "        -3.0991e-04,  5.8450e-05, -1.0113e-04, -1.1140e-04,  2.9057e-04,\n",
      "         2.3646e-05, -2.1749e-04,  4.2105e-04, -5.6610e-06, -6.3597e-05,\n",
      "         5.3189e-04,  7.0460e-05,  2.5390e-04, -8.9224e-05, -3.8019e-04,\n",
      "         3.3516e-04,  7.4201e-05, -4.6641e-05,  1.1513e-04, -2.2331e-04,\n",
      "        -1.3277e-04, -7.0107e-05,  2.2177e-04,  1.8748e-05,  7.7830e-05,\n",
      "         3.4718e-04, -3.4845e-04, -1.4905e-05,  4.1450e-05, -1.8185e-04,\n",
      "         4.5829e-05,  1.1929e-04, -2.2644e-04,  2.0972e-04, -3.5848e-04,\n",
      "         7.8089e-04, -1.3507e-04,  3.8683e-05, -8.9292e-05,  3.9383e-04,\n",
      "        -1.5996e-04, -8.0539e-05, -2.4960e-05, -4.0847e-04, -2.3400e-04,\n",
      "        -2.6587e-04,  7.6662e-04,  4.6143e-04,  3.0239e-04, -1.1278e-04,\n",
      "         7.6997e-05, -2.8810e-04,  5.5115e-04, -5.0430e-05,  1.4063e-04,\n",
      "        -1.5649e-04,  5.3431e-04,  4.1940e-04,  1.4658e-04, -1.1680e-05,\n",
      "         3.3935e-05, -4.7934e-05,  6.8187e-04, -1.7595e-04,  7.1780e-05,\n",
      "         2.1191e-05, -3.8099e-04,  4.0980e-04,  3.9832e-05,  3.3570e-04,\n",
      "        -3.6840e-05, -6.9989e-05, -6.3091e-04,  1.9947e-04,  1.2684e-04,\n",
      "        -1.7877e-04, -2.9237e-04,  1.4379e-04,  5.4531e-05, -3.2933e-05,\n",
      "        -2.9457e-04, -3.1403e-04,  2.5830e-04,  6.8735e-06, -4.8397e-05,\n",
      "        -4.8209e-05, -1.0382e-04,  1.2710e-04, -2.5844e-04, -1.3281e-04,\n",
      "         2.1547e-04, -3.2553e-04,  6.4225e-04,  1.4886e-04, -3.4075e-04,\n",
      "         6.6780e-05,  6.2923e-05,  1.8584e-04, -3.8158e-04, -4.2185e-04,\n",
      "        -6.4781e-06,  3.9715e-04,  2.0508e-04,  2.1307e-04, -2.8654e-04,\n",
      "         3.8178e-04,  2.4745e-04,  1.0234e-04,  7.7545e-05,  8.3662e-05,\n",
      "         2.6230e-04,  2.6980e-04, -3.2003e-04,  5.5032e-04,  3.4415e-06,\n",
      "         6.2253e-05,  2.0367e-04, -6.6724e-06, -2.5302e-04, -8.1792e-05,\n",
      "        -1.7587e-04,  1.5746e-04,  1.7405e-05,  1.0111e-04, -1.0706e-04,\n",
      "         8.7739e-05, -1.1080e-04, -2.0786e-04,  5.4867e-06, -1.5735e-05,\n",
      "         2.0798e-05, -1.5706e-04, -5.6997e-05,  5.7955e-05, -2.7101e-04,\n",
      "        -2.9234e-04,  2.7080e-04, -1.8807e-04,  6.9581e-05, -7.8843e-05,\n",
      "         1.3733e-05, -4.8102e-05, -4.0308e-05, -1.0527e-04,  2.6833e-04,\n",
      "        -5.1005e-05, -9.5626e-05,  2.4897e-04,  3.5382e-05,  1.9911e-04,\n",
      "         1.2301e-04, -6.4500e-05,  5.9307e-05,  3.9790e-04,  5.7281e-05,\n",
      "         2.9773e-05, -3.4015e-04,  5.7742e-05,  1.6467e-04, -3.0417e-04,\n",
      "         2.5297e-05, -1.5313e-04,  6.3976e-05,  1.6407e-04,  1.0711e-05,\n",
      "         1.3446e-04], device='cuda:0'), 'exp_avg_sq': tensor([7.7664e-08, 3.4768e-07, 2.6583e-07, 3.5617e-07, 8.9206e-08, 2.1407e-07,\n",
      "        4.5486e-07, 2.2881e-07, 3.3921e-07, 1.8788e-07, 1.7503e-07, 4.3756e-07,\n",
      "        2.2637e-07, 2.4321e-07, 2.5675e-07, 9.6171e-08, 2.4690e-07, 2.4148e-07,\n",
      "        1.7624e-07, 6.2341e-08, 2.7335e-07, 8.2521e-08, 1.9653e-07, 1.0996e-07,\n",
      "        2.0006e-07, 2.1456e-07, 4.3341e-07, 3.0278e-07, 1.1141e-07, 2.4664e-07,\n",
      "        2.0731e-07, 2.5001e-07, 3.0650e-07, 2.8024e-07, 3.1947e-07, 1.3632e-07,\n",
      "        4.5870e-07, 1.3034e-07, 1.3082e-07, 2.7780e-07, 1.1773e-07, 8.8497e-08,\n",
      "        1.5768e-07, 2.5715e-07, 2.2259e-07, 8.8420e-08, 3.1056e-07, 2.1023e-07,\n",
      "        2.6118e-07, 4.7752e-07, 2.8924e-07, 2.0863e-07, 1.4874e-07, 2.3070e-07,\n",
      "        2.2212e-07, 1.2986e-07, 2.3683e-07, 2.5820e-07, 2.4361e-07, 5.7142e-08,\n",
      "        1.4620e-07, 2.3576e-07, 1.5633e-07, 1.9437e-07, 1.1235e-07, 1.9863e-07,\n",
      "        2.0344e-07, 1.2177e-07, 3.4378e-07, 3.1138e-07, 4.2731e-07, 5.8454e-07,\n",
      "        1.0402e-07, 1.0163e-07, 1.2427e-07, 3.4686e-07, 2.4627e-07, 2.7115e-07,\n",
      "        6.1590e-08, 3.5422e-07, 2.4170e-07, 3.7229e-07, 2.5481e-07, 4.1542e-07,\n",
      "        2.8738e-07, 3.0394e-07, 3.2475e-07, 3.2631e-07, 1.2594e-07, 1.9050e-07,\n",
      "        7.2572e-07, 2.4306e-07, 2.2511e-07, 7.4250e-08, 1.1981e-07, 2.9446e-07,\n",
      "        3.4566e-07, 2.2984e-07, 2.4324e-07, 2.1253e-07, 3.0261e-07, 8.5611e-08,\n",
      "        2.8190e-07, 1.5260e-07, 2.3696e-07, 2.1107e-07, 2.0666e-07, 1.5566e-07,\n",
      "        5.4791e-08, 3.2403e-07, 2.1345e-07, 2.1518e-07, 1.3868e-07, 4.0908e-07,\n",
      "        2.3299e-07, 1.5452e-07, 3.7172e-07, 1.9620e-07, 1.8402e-07, 3.8885e-07,\n",
      "        2.7003e-07, 2.2677e-07, 1.8203e-07, 1.2846e-07, 2.4284e-07, 4.2656e-07,\n",
      "        1.7539e-07, 3.1222e-07, 2.0792e-07, 5.0978e-07, 2.7187e-07, 3.1003e-07,\n",
      "        1.4518e-07, 3.3300e-07, 1.9472e-07, 2.3488e-07, 3.6566e-07, 1.4416e-07,\n",
      "        1.6950e-07, 2.3704e-07, 2.8266e-07, 2.6299e-07, 4.5488e-07, 2.6879e-07,\n",
      "        2.1669e-07, 2.7182e-07, 3.0546e-07, 3.0650e-07, 1.8192e-07, 1.6374e-07,\n",
      "        1.4225e-07, 6.2072e-08, 3.8058e-07, 4.9521e-07, 1.5227e-07, 2.0520e-07,\n",
      "        2.0158e-07, 4.5147e-07, 2.7452e-07, 1.8253e-07, 3.7526e-07, 3.4542e-07,\n",
      "        3.2822e-07, 2.9644e-07, 1.0071e-07, 1.4449e-07, 1.0800e-07, 1.6808e-07,\n",
      "        9.2210e-08, 2.6169e-07, 7.9942e-08, 2.2486e-07, 4.3508e-07, 1.4169e-07,\n",
      "        1.8698e-07, 3.2240e-07, 3.9714e-07, 5.0163e-07, 1.7685e-07, 1.0867e-07,\n",
      "        2.1289e-07, 2.4071e-07, 3.1117e-07, 7.2137e-08, 2.5750e-07, 1.8357e-07,\n",
      "        3.8921e-07, 4.0924e-08, 3.2791e-07, 2.4235e-07, 1.8029e-07, 2.1065e-07,\n",
      "        2.8139e-07, 3.5711e-07, 3.1796e-07, 2.0144e-07, 3.1871e-07, 2.9516e-07,\n",
      "        4.4498e-07, 1.2660e-07, 1.7192e-07, 1.8111e-07, 2.9394e-07, 3.9905e-07,\n",
      "        1.2514e-07, 1.7959e-07, 3.8588e-07, 4.3187e-07, 1.0474e-07, 1.4385e-07,\n",
      "        2.0709e-07, 2.9570e-07, 2.4674e-07, 3.2751e-07, 2.0057e-07, 4.0390e-07,\n",
      "        1.1235e-07, 2.7272e-07, 2.1270e-07, 1.1245e-07, 3.7212e-07, 3.6782e-07,\n",
      "        4.3578e-07, 1.4553e-07, 2.3761e-07, 1.8027e-07, 2.2783e-07, 6.5999e-07,\n",
      "        3.2979e-07, 3.5375e-07, 9.7386e-08, 5.0615e-07, 2.2660e-07, 1.5046e-07,\n",
      "        2.0486e-07, 1.6008e-07, 3.4992e-07, 2.5794e-07, 3.5576e-07, 1.5316e-07,\n",
      "        2.4831e-07, 2.7508e-07, 9.1920e-08, 2.2683e-07, 2.5211e-07, 4.1127e-07,\n",
      "        2.0564e-07, 8.7191e-08, 1.8685e-07, 4.9565e-07, 4.4245e-07, 2.7403e-07,\n",
      "        3.1440e-07, 4.0359e-07, 1.8704e-07, 2.0062e-07], device='cuda:0')}, 12: {'step': tensor(120., device='cuda:0'), 'exp_avg': tensor([[ 2.7940e-04,  4.9836e-04,  5.5300e-04,  ...,  2.0054e-03,\n",
      "         -7.2399e-05,  2.9600e-04],\n",
      "        [ 3.9575e-05,  3.3318e-03,  1.5011e-03,  ...,  1.3926e-03,\n",
      "          5.0670e-04,  1.3241e-04],\n",
      "        [ 3.7859e-04,  7.3260e-04,  3.6432e-04,  ...,  1.8718e-03,\n",
      "          3.5104e-05,  1.4816e-03],\n",
      "        ...,\n",
      "        [-2.1970e-04, -2.8515e-03, -8.5448e-04,  ..., -6.0481e-04,\n",
      "         -2.7708e-04,  3.2307e-05],\n",
      "        [ 3.3413e-04, -7.3596e-04,  6.0351e-04,  ...,  1.1487e-03,\n",
      "         -1.9194e-04,  4.5912e-04],\n",
      "        [-4.0631e-04, -5.3217e-04, -6.9436e-04,  ..., -2.2971e-04,\n",
      "         -6.0166e-05,  4.9527e-05]], device='cuda:0'), 'exp_avg_sq': tensor([[1.0853e-06, 3.3157e-06, 1.0888e-05,  ..., 7.7859e-06, 1.8123e-06,\n",
      "         4.3399e-06],\n",
      "        [6.4255e-07, 1.2818e-05, 1.2310e-05,  ..., 6.2241e-06, 1.7772e-06,\n",
      "         6.3332e-06],\n",
      "        [1.0728e-06, 4.6578e-06, 4.4601e-06,  ..., 7.0062e-06, 9.6858e-07,\n",
      "         3.9927e-06],\n",
      "        ...,\n",
      "        [1.5339e-07, 4.7638e-06, 2.4734e-06,  ..., 1.5059e-06, 3.1715e-07,\n",
      "         1.0436e-06],\n",
      "        [1.1500e-06, 1.2290e-05, 1.8720e-05,  ..., 1.4391e-05, 3.0685e-06,\n",
      "         2.8977e-05],\n",
      "        [1.4893e-06, 2.7568e-06, 1.6517e-05,  ..., 6.0064e-06, 1.1043e-06,\n",
      "         3.0564e-06]], device='cuda:0')}, 13: {'step': tensor(120., device='cuda:0'), 'exp_avg': tensor([ 3.2241e-04,  1.3235e-03,  8.0590e-04,  2.8998e-04, -5.3034e-04,\n",
      "        -2.6166e-04, -5.2717e-04,  9.2513e-05,  8.2768e-05, -1.8925e-04,\n",
      "        -2.2329e-04, -5.1589e-04,  5.6224e-04, -3.9852e-04, -1.1442e-04,\n",
      "         4.1704e-04,  6.7865e-04, -2.3023e-04,  1.5143e-04,  1.5470e-04,\n",
      "         2.7705e-04,  5.6570e-04, -1.3449e-04, -6.2491e-04,  1.7584e-05,\n",
      "        -8.3267e-04,  5.1877e-05,  1.2434e-05, -1.3653e-04,  7.7332e-05,\n",
      "         1.0949e-04, -8.1343e-04, -6.5732e-04, -2.7895e-04, -8.5353e-04,\n",
      "        -2.6187e-04,  2.1051e-05,  1.7843e-04,  4.1412e-05, -1.3203e-03,\n",
      "         5.0633e-04,  3.3650e-04,  2.8578e-05, -3.8406e-04, -2.9889e-04,\n",
      "        -4.0911e-04,  1.8997e-03,  4.7909e-04, -1.4081e-03,  7.3663e-06,\n",
      "         7.6681e-04, -6.4197e-04, -2.7596e-04,  2.4710e-04, -6.0025e-04,\n",
      "        -3.3869e-04, -3.2088e-05, -3.1561e-04, -7.1665e-05,  5.5722e-05,\n",
      "         1.4709e-03, -1.6117e-04, -1.1159e-03, -1.3209e-04, -8.8037e-04,\n",
      "        -3.1096e-04, -6.8601e-04,  3.9494e-04, -7.1589e-04, -7.1480e-05,\n",
      "        -2.9587e-04,  1.4315e-04,  1.5238e-04, -3.9938e-04, -3.9772e-05,\n",
      "        -3.2827e-04, -7.4302e-04, -7.7004e-04,  2.7943e-04, -4.0512e-04,\n",
      "        -1.3018e-04, -1.2185e-04, -1.7771e-05,  7.5318e-05,  1.9074e-04,\n",
      "        -6.4748e-05,  1.4531e-04,  6.8021e-04,  8.9330e-05, -2.4444e-04,\n",
      "        -1.1224e-04,  3.6309e-04,  4.8976e-04,  1.3224e-04, -2.5935e-04,\n",
      "        -4.2301e-04, -8.6654e-04,  3.5540e-04, -9.6607e-05, -3.8246e-04,\n",
      "         7.5982e-04,  2.4499e-04,  2.2919e-04,  1.4103e-03,  6.0038e-04,\n",
      "         1.1647e-04,  2.1549e-04, -8.4236e-04, -4.8415e-04, -2.3214e-05,\n",
      "        -2.1098e-04,  1.5901e-04,  1.3033e-03,  2.3239e-04,  4.9004e-04,\n",
      "         1.6522e-04, -4.0789e-04, -1.8907e-04,  2.8808e-04,  4.8372e-04,\n",
      "         7.6699e-04, -3.6368e-04, -5.5450e-04,  1.3536e-04,  5.0639e-04,\n",
      "        -3.2667e-04, -9.3510e-05, -9.5216e-04], device='cuda:0'), 'exp_avg_sq': tensor([1.4472e-06, 1.8024e-06, 1.9042e-06, 1.0655e-06, 5.3780e-07, 6.7972e-07,\n",
      "        1.0662e-06, 2.0407e-06, 4.6068e-07, 6.2487e-07, 7.9989e-07, 2.4409e-06,\n",
      "        2.8100e-06, 8.9933e-07, 2.3918e-06, 1.4371e-06, 2.1216e-06, 1.3213e-06,\n",
      "        8.6157e-07, 8.0038e-07, 3.1126e-06, 1.9801e-06, 1.2722e-06, 3.4056e-07,\n",
      "        5.0197e-07, 1.9746e-06, 5.2245e-07, 1.0486e-06, 2.3256e-06, 3.0802e-06,\n",
      "        8.1266e-07, 1.7427e-06, 1.1087e-06, 1.6485e-06, 1.5220e-06, 1.7383e-06,\n",
      "        1.5635e-06, 1.4592e-06, 6.3940e-07, 1.4029e-06, 1.5406e-06, 1.1265e-06,\n",
      "        1.3864e-06, 1.8985e-06, 2.0411e-06, 9.1335e-07, 1.9605e-06, 2.4317e-06,\n",
      "        1.2672e-06, 1.6213e-06, 2.4239e-06, 6.4669e-07, 9.2333e-07, 5.6607e-07,\n",
      "        1.2747e-06, 4.5876e-07, 2.2210e-06, 2.3263e-06, 2.1168e-07, 1.7872e-06,\n",
      "        1.9350e-06, 1.3300e-06, 1.3597e-06, 1.4970e-06, 1.1559e-06, 1.4804e-06,\n",
      "        2.1190e-06, 2.6851e-06, 1.0052e-06, 5.7907e-07, 1.6774e-06, 1.2101e-06,\n",
      "        2.1364e-06, 2.0675e-06, 9.9906e-07, 1.3689e-06, 1.3439e-06, 1.4785e-06,\n",
      "        1.7599e-06, 1.6153e-06, 1.1636e-06, 4.1449e-06, 4.6317e-07, 1.3722e-06,\n",
      "        2.0613e-06, 1.4141e-07, 1.3686e-06, 3.4490e-06, 1.1884e-06, 5.8370e-07,\n",
      "        1.1884e-06, 2.7225e-06, 9.5803e-07, 1.4424e-06, 9.0265e-07, 8.3811e-07,\n",
      "        8.8433e-07, 2.2937e-06, 1.0742e-06, 1.2933e-06, 1.2143e-06, 1.1372e-06,\n",
      "        2.6138e-06, 2.6905e-06, 9.6304e-07, 6.4727e-07, 1.6145e-06, 1.3577e-06,\n",
      "        1.7972e-06, 2.0809e-06, 9.3166e-07, 1.4035e-06, 1.0916e-06, 1.0585e-06,\n",
      "        1.3707e-06, 1.6375e-06, 2.0471e-06, 1.5578e-06, 1.9121e-06, 1.3572e-06,\n",
      "        2.0935e-06, 1.5164e-06, 2.0078e-06, 9.6246e-07, 1.9233e-06, 3.3668e-07,\n",
      "        3.8325e-06, 1.3321e-06], device='cuda:0')}, 14: {'step': tensor(120., device='cuda:0'), 'exp_avg': tensor([[-1.3641e-03, -2.2732e-04, -3.4494e-04,  ..., -2.8193e-04,\n",
      "         -1.5284e-04,  1.8452e-04],\n",
      "        [-1.3020e-03, -3.4630e-03, -6.0495e-04,  ...,  1.6584e-05,\n",
      "         -3.9028e-03, -5.5332e-04],\n",
      "        [ 8.9391e-05,  3.6173e-03, -1.9902e-04,  ..., -1.6433e-04,\n",
      "         -9.6383e-04, -8.1938e-04],\n",
      "        ...,\n",
      "        [ 1.6515e-04, -7.7642e-04,  4.1571e-04,  ...,  1.3710e-04,\n",
      "         -1.6866e-03, -9.2012e-04],\n",
      "        [-5.9239e-04,  1.4130e-04,  5.4948e-05,  ..., -1.3753e-03,\n",
      "         -1.3907e-03, -1.5648e-03],\n",
      "        [-6.0852e-04, -1.0685e-03, -2.6449e-04,  ..., -9.5019e-04,\n",
      "          3.1638e-04,  2.2733e-04]], device='cuda:0'), 'exp_avg_sq': tensor([[3.7931e-06, 1.4722e-05, 2.2910e-06,  ..., 3.7001e-07, 1.5861e-05,\n",
      "         2.7188e-06],\n",
      "        [2.2174e-05, 9.8106e-06, 1.4681e-06,  ..., 1.3795e-06, 1.1167e-05,\n",
      "         5.3086e-06],\n",
      "        [4.7589e-06, 3.0293e-06, 1.1030e-06,  ..., 1.5358e-07, 1.1791e-05,\n",
      "         4.4799e-06],\n",
      "        ...,\n",
      "        [3.1599e-06, 1.2558e-06, 7.3174e-07,  ..., 6.1204e-07, 1.3131e-05,\n",
      "         1.0472e-06],\n",
      "        [7.0884e-07, 3.1275e-06, 3.0249e-07,  ..., 2.4869e-07, 1.4606e-06,\n",
      "         3.5464e-07],\n",
      "        [7.3777e-06, 2.5532e-06, 1.4872e-06,  ..., 2.7647e-07, 3.2501e-06,\n",
      "         8.3991e-07]], device='cuda:0')}, 15: {'step': tensor(120., device='cuda:0'), 'exp_avg': tensor([-1.6963e-04, -1.9174e-03, -1.2694e-04,  4.2722e-04,  7.4859e-04,\n",
      "        -1.0642e-03, -5.8923e-04,  8.4969e-04, -1.7838e-04,  5.8692e-04,\n",
      "        -4.9973e-05, -2.1756e-03, -1.3534e-04,  7.6973e-04, -4.4738e-04,\n",
      "         2.3868e-03, -7.5040e-04, -1.7465e-03,  2.2193e-04, -7.4823e-04,\n",
      "         1.0807e-03, -3.4414e-04,  1.0245e-03,  6.1990e-05, -6.2790e-04,\n",
      "         3.0823e-04,  5.9406e-05,  1.2252e-04, -8.1230e-04,  2.5943e-04,\n",
      "        -3.9884e-05, -9.9864e-04, -1.9534e-04,  1.2432e-03,  1.0329e-03,\n",
      "        -3.4437e-04,  1.4015e-03,  7.3148e-04, -3.1856e-06,  4.4879e-04,\n",
      "         4.8652e-05,  4.7354e-04, -2.0705e-04, -2.4935e-03, -2.1441e-03,\n",
      "         1.9812e-03, -2.4226e-04,  5.0905e-04,  2.9724e-03,  1.3823e-03,\n",
      "        -9.6851e-04, -7.6207e-04,  5.9761e-04,  1.3372e-04, -9.5569e-04,\n",
      "         1.4887e-04, -7.1179e-04, -6.9455e-04, -1.2648e-03,  2.6353e-03,\n",
      "         7.2717e-04, -2.5480e-03,  7.0473e-04, -6.0563e-04, -1.3174e-03,\n",
      "        -5.4995e-04,  2.3369e-03, -9.0123e-04,  4.0659e-04,  7.4052e-04,\n",
      "         9.4715e-04, -6.5804e-04, -1.1282e-03,  3.3276e-03,  1.2813e-04,\n",
      "         1.7606e-04, -2.2105e-03,  2.2978e-03,  1.9237e-03,  5.7977e-07,\n",
      "         6.9738e-04,  4.9476e-05,  5.8712e-04, -6.2360e-04,  2.7123e-04,\n",
      "         1.9682e-05,  2.6634e-04, -6.8122e-04, -1.4817e-03,  4.5346e-04,\n",
      "         7.8843e-04, -5.2490e-04,  1.0505e-03,  2.1991e-03,  1.4287e-04,\n",
      "         5.6085e-04,  8.6172e-04, -8.4025e-04,  1.1752e-03, -3.2078e-05,\n",
      "        -6.0990e-04,  4.8413e-04, -6.5584e-04, -4.2236e-04, -1.6360e-03,\n",
      "        -6.9845e-04,  3.1523e-04, -4.8912e-04, -1.5242e-03,  1.2409e-03,\n",
      "         2.0594e-03,  6.7990e-04,  4.6588e-04,  2.5289e-03,  6.3345e-04,\n",
      "         1.5348e-03,  6.0508e-04, -1.5179e-04,  6.6545e-04, -4.6152e-05,\n",
      "         6.7209e-04,  1.6276e-04, -1.6269e-03, -1.3805e-03, -1.6850e-03,\n",
      "        -4.9458e-05, -7.2362e-04, -3.6830e-04], device='cuda:0'), 'exp_avg_sq': tensor([4.7666e-06, 5.5400e-06, 4.1838e-06, 2.9534e-06, 3.5037e-06, 5.9775e-06,\n",
      "        4.3396e-06, 4.5623e-06, 4.4141e-06, 2.7630e-06, 7.6645e-06, 4.4129e-06,\n",
      "        7.9696e-06, 5.2193e-06, 4.8067e-06, 7.3383e-06, 4.6918e-06, 8.3693e-06,\n",
      "        4.6159e-06, 9.3126e-07, 4.2227e-06, 2.4909e-06, 6.4090e-06, 1.7767e-06,\n",
      "        2.8511e-06, 3.8365e-06, 5.4378e-06, 1.8374e-06, 5.2944e-06, 6.0364e-06,\n",
      "        5.0528e-06, 6.0998e-06, 2.8449e-06, 5.9024e-06, 1.6264e-06, 4.4807e-06,\n",
      "        5.1816e-06, 8.3352e-06, 6.6545e-06, 4.2714e-06, 4.9020e-06, 3.6645e-06,\n",
      "        3.8533e-06, 3.0371e-06, 5.1227e-06, 5.8778e-06, 3.1355e-06, 5.3755e-06,\n",
      "        6.3047e-06, 3.8934e-06, 3.1007e-06, 2.7947e-06, 4.6093e-06, 1.2451e-06,\n",
      "        2.2667e-06, 8.5736e-07, 3.6478e-06, 6.2582e-06, 5.0429e-06, 4.3478e-06,\n",
      "        7.0542e-06, 6.1613e-06, 5.7221e-06, 1.3312e-06, 2.3435e-06, 2.9235e-06,\n",
      "        8.4819e-06, 2.5142e-06, 1.1548e-06, 5.1750e-06, 8.5602e-06, 6.8026e-06,\n",
      "        3.8947e-06, 3.8370e-06, 2.9103e-06, 4.9298e-06, 3.2079e-06, 7.1309e-06,\n",
      "        4.7219e-06, 3.9182e-06, 8.2412e-06, 2.6024e-06, 9.8815e-06, 7.3207e-06,\n",
      "        1.1914e-06, 8.2729e-06, 2.1030e-06, 3.6101e-06, 9.4571e-06, 1.7756e-06,\n",
      "        4.4359e-06, 2.6088e-06, 1.0064e-06, 5.2084e-06, 5.7878e-07, 4.1015e-06,\n",
      "        5.0190e-06, 7.2174e-06, 7.1337e-06, 1.6693e-06, 2.3131e-06, 3.8501e-06,\n",
      "        3.0036e-06, 4.5937e-06, 8.9746e-06, 3.9146e-06, 5.2388e-06, 7.7281e-06,\n",
      "        4.9452e-06, 2.9864e-06, 4.6297e-06, 1.0916e-06, 4.5629e-06, 9.4603e-06,\n",
      "        1.6101e-06, 3.4498e-06, 5.5087e-06, 2.4062e-06, 5.7166e-06, 2.1886e-06,\n",
      "        5.3710e-06, 4.6673e-06, 4.8229e-06, 8.6417e-06, 3.5037e-06, 1.6094e-06,\n",
      "        1.1152e-06, 2.1146e-06], device='cuda:0')}, 16: {'step': tensor(120., device='cuda:0'), 'exp_avg': tensor([[ 2.3720e-03,  1.2322e-04, -5.0483e-04,  ..., -1.3281e-04,\n",
      "         -1.7196e-04,  6.7542e-04],\n",
      "        [-3.7562e-03,  2.7670e-03,  6.2870e-04,  ...,  1.2201e-04,\n",
      "         -3.1620e-04, -1.3165e-04],\n",
      "        [ 4.5453e-04,  9.7366e-04,  1.1401e-03,  ...,  1.1438e-04,\n",
      "         -1.9085e-04, -4.3390e-05],\n",
      "        ...,\n",
      "        [-3.3948e-04, -1.7030e-03, -9.0923e-04,  ..., -4.0805e-04,\n",
      "         -5.2104e-04, -4.4305e-04],\n",
      "        [-2.0746e-03, -2.4817e-03, -1.8034e-03,  ..., -4.9984e-04,\n",
      "         -1.6211e-03, -3.4571e-04],\n",
      "        [ 4.9868e-03,  2.3583e-03,  9.0633e-04,  ...,  4.4066e-04,\n",
      "          9.0663e-04,  2.7183e-04]], device='cuda:0'), 'exp_avg_sq': tensor([[6.6531e-06, 1.2092e-05, 2.2676e-06,  ..., 1.3437e-06, 4.9319e-07,\n",
      "         1.4805e-06],\n",
      "        [1.7521e-05, 1.8002e-05, 5.5586e-06,  ..., 1.4085e-06, 1.8060e-06,\n",
      "         2.8308e-06],\n",
      "        [4.2770e-06, 1.9622e-05, 1.5198e-06,  ..., 4.6527e-07, 1.0775e-07,\n",
      "         6.7666e-07],\n",
      "        ...,\n",
      "        [7.2257e-06, 1.1330e-05, 3.7333e-06,  ..., 2.0256e-06, 9.7582e-07,\n",
      "         1.0264e-06],\n",
      "        [9.6562e-06, 1.3123e-05, 5.0109e-06,  ..., 2.1674e-06, 1.9894e-06,\n",
      "         9.5975e-07],\n",
      "        [8.2393e-06, 1.3730e-05, 9.4513e-06,  ..., 1.3616e-06, 1.2776e-06,\n",
      "         1.7766e-06]], device='cuda:0')}, 17: {'step': tensor(120., device='cuda:0'), 'exp_avg': tensor([ 2.7806e-03, -1.6789e-03,  3.3875e-03, -9.0062e-04,  3.0634e-03,\n",
      "         1.6432e-03, -1.0935e-03,  5.1450e-03, -2.8377e-03, -6.1070e-04,\n",
      "        -2.8189e-03,  2.7574e-04, -2.2137e-03,  4.6440e-03,  3.2316e-03,\n",
      "         3.8905e-03,  4.6789e-04,  2.7240e-03, -4.4638e-04, -1.4629e-03,\n",
      "        -4.2016e-03, -3.2955e-03, -4.1829e-03,  1.1490e-03, -1.0908e-03,\n",
      "         3.1472e-03, -9.1664e-04,  2.5806e-03, -3.4818e-03,  3.1855e-03,\n",
      "         3.2578e-03, -5.8222e-04, -1.0286e-03,  9.5284e-04,  1.7954e-03,\n",
      "        -2.7654e-04,  4.0090e-03,  1.3199e-03, -1.8276e-03,  3.1637e-03,\n",
      "        -5.6704e-04,  1.2921e-03, -2.3265e-03,  5.9504e-05,  1.5439e-03,\n",
      "        -9.9378e-03, -2.3419e-03,  7.8808e-03,  7.7128e-03,  1.8969e-03,\n",
      "        -2.1972e-03, -2.8306e-03,  3.8578e-04, -2.8151e-03,  4.5893e-03,\n",
      "        -6.2829e-03,  2.6445e-04, -1.3760e-03, -2.9953e-03, -4.3242e-04,\n",
      "        -2.0753e-03, -6.2081e-03, -3.4837e-03,  6.0660e-03], device='cuda:0'), 'exp_avg_sq': tensor([4.0455e-05, 4.3743e-05, 1.6584e-05, 2.9478e-05, 1.6924e-05, 1.8125e-05,\n",
      "        2.3077e-05, 3.7175e-05, 2.3213e-05, 1.3956e-05, 1.4119e-05, 5.7558e-05,\n",
      "        1.2328e-05, 4.9444e-05, 3.4299e-05, 3.5277e-05, 4.7438e-05, 1.6330e-05,\n",
      "        4.1930e-05, 1.3385e-05, 2.0211e-05, 3.8851e-05, 1.7988e-05, 2.1036e-05,\n",
      "        4.1878e-05, 1.9733e-05, 5.0197e-05, 1.1246e-05, 2.8892e-05, 4.9889e-06,\n",
      "        3.7165e-05, 1.0465e-05, 9.8833e-06, 3.4360e-05, 2.3114e-05, 3.5871e-05,\n",
      "        1.5946e-05, 2.5368e-05, 5.3530e-05, 1.8363e-05, 2.7954e-05, 5.8564e-05,\n",
      "        4.4462e-05, 3.7223e-05, 1.0951e-05, 2.5535e-05, 1.8991e-05, 5.3545e-05,\n",
      "        3.4152e-05, 3.6127e-05, 4.2399e-05, 1.5200e-05, 1.6795e-05, 2.3971e-05,\n",
      "        1.0522e-05, 5.2945e-05, 7.9663e-06, 1.6409e-05, 5.1881e-05, 8.1559e-06,\n",
      "        6.2790e-06, 2.5795e-05, 2.4840e-05, 3.8569e-05], device='cuda:0')}, 18: {'step': tensor(120., device='cuda:0'), 'exp_avg': tensor([[ 7.3816e-04, -2.1864e-03,  1.1384e-03,  ..., -3.6349e-04,\n",
      "          6.3867e-04, -1.0394e-03],\n",
      "        [ 1.2191e-04, -4.0337e-04,  3.0652e-04,  ..., -1.1470e-03,\n",
      "         -1.4679e-03, -1.1185e-03],\n",
      "        [-1.1566e-03, -1.7465e-03, -2.3899e-04,  ...,  5.7155e-04,\n",
      "         -3.3240e-04, -2.1695e-03],\n",
      "        ...,\n",
      "        [-8.2490e-03,  5.1378e-03, -1.3772e-03,  ...,  2.8819e-03,\n",
      "         -2.0518e-03, -6.3785e-03],\n",
      "        [-3.9751e-04, -2.6734e-03, -4.6139e-04,  ..., -4.7719e-05,\n",
      "         -1.6984e-04, -3.4011e-03],\n",
      "        [ 3.0217e-04,  2.9447e-03,  1.0083e-03,  ...,  1.4310e-03,\n",
      "          1.9316e-03,  4.1583e-03]], device='cuda:0'), 'exp_avg_sq': tensor([[2.8649e-06, 1.8091e-05, 7.0604e-06,  ..., 3.0023e-06, 1.0791e-05,\n",
      "         1.7172e-05],\n",
      "        [1.0025e-05, 8.0845e-06, 3.4637e-06,  ..., 5.0761e-06, 6.2736e-06,\n",
      "         1.7124e-05],\n",
      "        [5.7119e-06, 4.3909e-06, 3.4161e-06,  ..., 3.7975e-06, 1.6986e-06,\n",
      "         7.7981e-06],\n",
      "        ...,\n",
      "        [2.0190e-05, 3.3788e-05, 4.1839e-06,  ..., 1.2857e-05, 2.4642e-05,\n",
      "         3.5808e-05],\n",
      "        [1.4145e-05, 3.3014e-05, 4.0501e-06,  ..., 9.4645e-06, 9.2701e-06,\n",
      "         2.5965e-05],\n",
      "        [1.0045e-05, 1.7096e-05, 5.6244e-06,  ..., 6.5121e-06, 6.0548e-06,\n",
      "         1.3294e-05]], device='cuda:0')}, 19: {'step': tensor(120., device='cuda:0'), 'exp_avg': tensor([-3.5155e-06, -2.4290e-03, -4.6794e-04, -1.1157e-03,  1.9373e-03,\n",
      "         2.4296e-03, -6.3334e-04, -2.7246e-03,  2.7620e-03, -3.4392e-03,\n",
      "         1.8842e-03,  1.4431e-03,  6.3793e-03, -5.2827e-03,  2.1196e-03,\n",
      "         4.4349e-03,  2.0788e-03, -1.9903e-03,  4.2592e-03,  1.8636e-03,\n",
      "        -5.9239e-03, -2.9520e-03, -7.1850e-03, -1.4147e-03, -1.7174e-03,\n",
      "         5.7288e-03, -1.7227e-03, -8.5611e-03,  4.2661e-03, -5.6979e-03,\n",
      "        -4.8863e-03, -3.9610e-03,  1.8918e-03, -2.4249e-03, -3.8996e-03,\n",
      "         4.2529e-03,  3.0465e-04,  1.1550e-02, -1.0286e-03, -8.9068e-03,\n",
      "        -8.5492e-04, -2.1497e-03,  8.8130e-03, -2.7418e-03,  3.5702e-03,\n",
      "        -4.9001e-03,  1.5628e-03,  5.9450e-03, -6.1301e-03,  1.5656e-03,\n",
      "         2.2745e-03, -8.3837e-03, -6.2276e-04,  8.1109e-03, -1.8649e-03,\n",
      "        -8.8780e-04, -2.9975e-03, -1.3996e-03,  1.3236e-02,  5.4919e-04,\n",
      "        -5.8295e-03, -5.7660e-03,  4.6383e-04,  7.5794e-03], device='cuda:0'), 'exp_avg_sq': tensor([6.0174e-05, 1.2162e-04, 4.3632e-05, 1.0791e-04, 1.0880e-04, 3.1005e-05,\n",
      "        1.0506e-04, 3.6929e-05, 3.8119e-05, 1.9745e-05, 1.3833e-04, 2.4024e-05,\n",
      "        5.1114e-05, 1.5630e-04, 9.7562e-05, 3.9815e-05, 1.4746e-05, 8.6183e-05,\n",
      "        9.0312e-05, 8.6956e-05, 1.4109e-04, 1.3298e-04, 1.4108e-04, 1.5942e-05,\n",
      "        8.1344e-05, 1.1374e-04, 1.4796e-05, 1.7113e-04, 8.0604e-05, 5.6871e-05,\n",
      "        3.1952e-05, 7.6954e-05, 1.3203e-04, 3.0847e-05, 1.9273e-04, 5.1835e-05,\n",
      "        1.6851e-04, 1.6895e-04, 9.3703e-06, 5.3164e-05, 3.0040e-05, 3.2004e-05,\n",
      "        5.6567e-05, 3.4605e-05, 3.9996e-05, 3.3127e-05, 7.6005e-05, 7.8292e-05,\n",
      "        9.3848e-05, 4.4941e-05, 7.8714e-05, 1.3032e-04, 6.1804e-05, 1.3683e-04,\n",
      "        1.5857e-05, 1.1673e-05, 1.4160e-04, 5.5642e-05, 7.5493e-05, 8.4779e-05,\n",
      "        7.4604e-05, 1.5659e-04, 9.5446e-05, 8.4960e-05], device='cuda:0')}, 20: {'step': tensor(120., device='cuda:0'), 'exp_avg': tensor([[ 2.1851e-04,  3.5899e-03,  2.9872e-03,  ...,  5.4336e-03,\n",
      "          1.8315e-03,  4.1116e-03],\n",
      "        [-1.1740e-03,  9.8345e-05, -4.7945e-05,  ...,  7.3002e-04,\n",
      "         -3.8442e-05, -1.0745e-04],\n",
      "        [ 4.1151e-04,  7.8042e-04,  3.9460e-04,  ...,  4.1378e-03,\n",
      "         -3.8109e-03, -2.6809e-03],\n",
      "        ...,\n",
      "        [ 1.7643e-04,  5.4961e-04, -3.5349e-04,  ...,  2.3147e-03,\n",
      "          7.7704e-04,  2.2428e-03],\n",
      "        [ 6.6039e-05, -4.3542e-03, -4.6852e-06,  ..., -7.4852e-05,\n",
      "         -4.8917e-03, -2.6417e-04],\n",
      "        [-1.9792e-04, -1.6980e-03, -2.1113e-03,  ..., -3.5066e-05,\n",
      "          1.5909e-03, -6.2814e-04]], device='cuda:0'), 'exp_avg_sq': tensor([[5.4678e-06, 7.8593e-06, 4.9192e-06,  ..., 1.6477e-05, 1.2337e-05,\n",
      "         7.0459e-05],\n",
      "        [1.1698e-05, 1.5437e-06, 2.5614e-06,  ..., 2.8675e-05, 3.1857e-06,\n",
      "         4.3159e-05],\n",
      "        [4.0907e-06, 9.3228e-06, 1.1022e-05,  ..., 3.4149e-05, 5.7936e-05,\n",
      "         6.0365e-05],\n",
      "        ...,\n",
      "        [6.6801e-06, 8.6637e-06, 1.0740e-05,  ..., 2.3360e-05, 1.0212e-05,\n",
      "         1.1131e-04],\n",
      "        [1.4196e-06, 7.4973e-06, 6.1581e-07,  ..., 1.6067e-06, 9.3189e-06,\n",
      "         2.0718e-05],\n",
      "        [1.6567e-06, 3.1725e-06, 5.5599e-06,  ..., 1.4903e-05, 4.6297e-06,\n",
      "         8.7225e-06]], device='cuda:0')}, 21: {'step': tensor(120., device='cuda:0'), 'exp_avg': tensor([ 0.0304, -0.0006,  0.0082,  0.0140, -0.0226,  0.0011, -0.0142,  0.0123,\n",
      "        -0.0136, -0.0066, -0.0184,  0.0099,  0.0100, -0.0079,  0.0150,  0.0024,\n",
      "         0.0164,  0.0005,  0.0145,  0.0050,  0.0070,  0.0043, -0.0021,  0.0137,\n",
      "        -0.0095,  0.0172,  0.0048,  0.0234,  0.0072,  0.0093, -0.0055, -0.0048],\n",
      "       device='cuda:0'), 'exp_avg_sq': tensor([6.7310e-04, 2.2447e-04, 6.8642e-04, 5.3174e-04, 3.3258e-04, 5.6692e-04,\n",
      "        6.6268e-04, 1.1469e-03, 2.8167e-04, 1.1314e-04, 4.2861e-04, 5.5635e-05,\n",
      "        1.3139e-03, 4.7890e-04, 8.2034e-04, 7.2889e-04, 3.5494e-04, 1.0702e-04,\n",
      "        4.1282e-04, 2.1831e-04, 6.5949e-04, 1.1973e-04, 1.0280e-04, 6.5916e-04,\n",
      "        1.1739e-04, 9.6631e-04, 1.3788e-03, 7.0022e-04, 1.7069e-04, 2.3476e-04,\n",
      "        6.0080e-05, 1.7289e-04], device='cuda:0')}, 22: {'step': tensor(120., device='cuda:0'), 'exp_avg': tensor([[ 1.4449e-03,  5.4277e-04,  7.7072e-04,  ..., -9.0636e-04,\n",
      "          2.0200e-04, -3.5583e-04],\n",
      "        [-3.1410e-03, -7.2719e-04,  1.5609e-02,  ..., -2.5784e-04,\n",
      "         -1.0668e-03,  2.5938e-04],\n",
      "        [ 2.0124e-03,  3.0763e-04,  5.8460e-04,  ..., -2.6085e-03,\n",
      "          1.7357e-04, -1.0308e-03],\n",
      "        ...,\n",
      "        [-5.9489e-03,  1.2914e-03,  4.8279e-03,  ...,  1.8611e-03,\n",
      "         -8.2735e-04,  6.6102e-05],\n",
      "        [-3.5922e-04, -1.8745e-05,  1.0897e-02,  ..., -1.3127e-03,\n",
      "         -2.7181e-05, -1.0884e-04],\n",
      "        [ 5.6606e-05, -2.4278e-04, -3.6133e-05,  ...,  7.8543e-04,\n",
      "         -9.4420e-05,  5.7692e-04]], device='cuda:0'), 'exp_avg_sq': tensor([[1.3278e-05, 4.4471e-06, 2.6598e-05,  ..., 6.0650e-06, 9.5495e-07,\n",
      "         5.3800e-07],\n",
      "        [3.5014e-05, 8.3476e-06, 1.0082e-04,  ..., 2.8454e-05, 2.3762e-06,\n",
      "         2.5794e-06],\n",
      "        [1.8618e-05, 1.0172e-05, 4.3135e-05,  ..., 1.1400e-05, 3.7473e-07,\n",
      "         3.4357e-06],\n",
      "        ...,\n",
      "        [1.7919e-05, 2.2328e-06, 4.5566e-05,  ..., 8.2865e-06, 1.0905e-06,\n",
      "         7.0827e-07],\n",
      "        [3.4138e-06, 3.9398e-07, 9.0700e-05,  ..., 1.0276e-05, 1.0404e-07,\n",
      "         2.4687e-07],\n",
      "        [1.8738e-05, 3.3207e-06, 4.4225e-05,  ..., 8.1667e-06, 1.5224e-06,\n",
      "         8.4422e-07]], device='cuda:0')}, 23: {'step': tensor(120., device='cuda:0'), 'exp_avg': tensor([ 0.0142,  0.0567,  0.0157,  0.0012,  0.0029,  0.0115,  0.0770,  0.0069,\n",
      "        -0.0234, -0.0149, -0.0002,  0.0770,  0.0714, -0.0035, -0.0021,  0.0035,\n",
      "         0.0101, -0.0004,  0.0245,  0.0091,  0.0167, -0.0002,  0.0080, -0.0004,\n",
      "        -0.0003,  0.0254,  0.0004, -0.0017,  0.0024,  0.0050,  0.0076,  0.0190],\n",
      "       device='cuda:0'), 'exp_avg_sq': tensor([8.3802e-04, 2.3588e-03, 1.7078e-03, 2.1289e-04, 1.3470e-03, 2.0787e-03,\n",
      "        5.6590e-03, 9.2905e-04, 7.4900e-04, 7.2270e-04, 1.2036e-04, 1.0040e-03,\n",
      "        6.2592e-03, 9.3242e-06, 4.0654e-05, 3.1256e-04, 1.2726e-03, 5.4321e-06,\n",
      "        4.1744e-03, 1.4506e-03, 2.3072e-03, 1.3885e-03, 5.3877e-04, 1.4608e-05,\n",
      "        4.2822e-04, 4.6187e-03, 1.9301e-03, 5.9587e-05, 2.5040e-04, 9.2987e-04,\n",
      "        1.0476e-03, 1.8969e-03], device='cuda:0')}, 24: {'step': tensor(120., device='cuda:0'), 'exp_avg': tensor([[[-7.0439e-03],\n",
      "         [-2.1382e-03],\n",
      "         [-3.0037e-03],\n",
      "         ...,\n",
      "         [ 3.6589e-03],\n",
      "         [-9.6157e-04],\n",
      "         [ 1.1149e-03]],\n",
      "\n",
      "        [[-6.9211e-03],\n",
      "         [-1.0820e-03],\n",
      "         [-1.4336e-03],\n",
      "         ...,\n",
      "         [ 4.3163e-03],\n",
      "         [-3.9653e-04],\n",
      "         [ 9.1589e-04]],\n",
      "\n",
      "        [[ 2.1862e-02],\n",
      "         [ 4.4032e-03],\n",
      "         [ 6.1013e-03],\n",
      "         ...,\n",
      "         [ 7.9562e-03],\n",
      "         [ 4.0414e-03],\n",
      "         [ 6.0957e-03]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 2.5656e-05],\n",
      "         [ 1.2402e-05],\n",
      "         [ 8.7432e-06],\n",
      "         ...,\n",
      "         [ 4.1298e-05],\n",
      "         [ 7.5443e-05],\n",
      "         [ 3.1939e-06]],\n",
      "\n",
      "        [[ 4.0265e-03],\n",
      "         [ 2.5958e-03],\n",
      "         [ 1.1914e-03],\n",
      "         ...,\n",
      "         [-3.3150e-04],\n",
      "         [ 5.7549e-04],\n",
      "         [ 1.7298e-04]],\n",
      "\n",
      "        [[-3.8602e-02],\n",
      "         [-6.2682e-03],\n",
      "         [-8.3391e-03],\n",
      "         ...,\n",
      "         [-1.1081e-02],\n",
      "         [-6.4996e-03],\n",
      "         [-8.1717e-03]]], device='cuda:0'), 'exp_avg_sq': tensor([[[4.1093e-04],\n",
      "         [2.1478e-05],\n",
      "         [3.4332e-05],\n",
      "         ...,\n",
      "         [2.6107e-04],\n",
      "         [2.6201e-05],\n",
      "         [1.6140e-05]],\n",
      "\n",
      "        [[6.1934e-04],\n",
      "         [3.3117e-05],\n",
      "         [4.2508e-05],\n",
      "         ...,\n",
      "         [3.3512e-04],\n",
      "         [3.4744e-05],\n",
      "         [5.5826e-05]],\n",
      "\n",
      "        [[8.8840e-04],\n",
      "         [4.1973e-05],\n",
      "         [6.5465e-05],\n",
      "         ...,\n",
      "         [4.6086e-04],\n",
      "         [4.2538e-05],\n",
      "         [5.9459e-05]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[2.6754e-09],\n",
      "         [6.1253e-11],\n",
      "         [9.4427e-10],\n",
      "         ...,\n",
      "         [7.0574e-09],\n",
      "         [2.3311e-08],\n",
      "         [1.1544e-10]],\n",
      "\n",
      "        [[8.6045e-06],\n",
      "         [1.0201e-06],\n",
      "         [1.5399e-06],\n",
      "         ...,\n",
      "         [3.6399e-06],\n",
      "         [8.6116e-07],\n",
      "         [7.6748e-07]],\n",
      "\n",
      "        [[5.1374e-04],\n",
      "         [2.3105e-05],\n",
      "         [4.0703e-05],\n",
      "         ...,\n",
      "         [2.1627e-04],\n",
      "         [1.4601e-05],\n",
      "         [6.3878e-05]]], device='cuda:0')}, 25: {'step': tensor(120., device='cuda:0'), 'exp_avg': tensor([ 1.0230e-02,  5.5275e-03,  8.3075e-03, -7.5874e-03,  3.0699e-04,\n",
      "         2.1452e-04,  3.3554e-03, -1.3191e-02, -3.2129e-04, -4.3665e-03,\n",
      "        -1.7359e-04, -1.2505e-02,  4.8562e-04, -1.9734e-04, -4.5273e-04,\n",
      "        -4.0368e-03,  1.5194e-03,  6.5415e-03,  1.8998e-03, -6.4922e-05,\n",
      "        -4.9788e-03,  2.2092e-03,  4.1296e-03, -1.2146e-03, -1.1318e-02,\n",
      "         1.0463e-02, -6.2988e-03,  4.3291e-03,  7.6471e-04, -1.4734e-03,\n",
      "         6.9144e-03,  2.5822e-03, -1.2478e-02,  4.0917e-03, -1.1756e-05,\n",
      "         5.9766e-03,  4.2889e-03, -1.2699e-04, -1.9490e-06,  2.3959e-03,\n",
      "         2.7310e-04,  1.3503e-02, -5.8050e-03,  2.2665e-05, -1.6668e-02,\n",
      "        -8.5917e-03, -1.3291e-03, -9.6786e-03,  1.5055e-03, -1.3327e-02,\n",
      "        -5.4796e-03, -4.0751e-03,  1.3110e-02, -3.5170e-03,  3.1984e-04,\n",
      "        -3.0261e-04,  1.5774e-02,  2.5056e-04, -8.8401e-03,  6.3432e-04,\n",
      "         2.1226e-03,  2.6803e-04, -2.5645e-03, -1.1910e-02], device='cuda:0'), 'exp_avg_sq': tensor([2.2618e-04, 2.7398e-04, 4.8725e-04, 7.1539e-05, 2.1247e-06, 1.8099e-06,\n",
      "        2.6061e-04, 4.6779e-05, 1.8092e-04, 2.9730e-04, 1.7758e-06, 3.8305e-04,\n",
      "        2.6997e-05, 2.1834e-07, 5.1308e-05, 3.4601e-04, 8.5008e-06, 4.2391e-04,\n",
      "        2.7859e-04, 7.9719e-08, 3.4159e-04, 2.0084e-04, 3.1048e-04, 3.6834e-06,\n",
      "        2.4680e-04, 5.5019e-04, 3.3033e-04, 1.2273e-04, 4.7137e-05, 8.7819e-05,\n",
      "        7.5298e-05, 5.6273e-04, 3.9669e-04, 2.8485e-05, 6.1451e-06, 4.2771e-04,\n",
      "        7.0852e-05, 3.0203e-05, 3.1315e-11, 2.7976e-04, 1.9016e-06, 3.8214e-04,\n",
      "        2.2202e-04, 9.5051e-08, 2.8599e-04, 2.1906e-04, 1.0983e-04, 2.1184e-04,\n",
      "        1.1845e-04, 1.3899e-04, 1.0278e-04, 1.8217e-04, 2.4209e-04, 6.4233e-04,\n",
      "        7.6699e-06, 4.6936e-06, 1.1080e-03, 1.3942e-06, 5.4183e-04, 4.1896e-06,\n",
      "        3.3731e-04, 2.1400e-07, 2.4189e-06, 2.8397e-04], device='cuda:0')}, 26: {'step': tensor(120., device='cuda:0'), 'exp_avg': tensor([[ 1.2721e-04, -1.1031e-04, -4.4139e-04,  ..., -2.7580e-06,\n",
      "          7.1345e-05,  8.3180e-06],\n",
      "        [-4.3954e-05,  1.1451e-04,  3.8547e-04,  ...,  1.7303e-06,\n",
      "         -3.6583e-05,  5.6319e-05],\n",
      "        [ 1.2717e-05, -5.5845e-05, -1.5941e-04,  ...,  8.9673e-07,\n",
      "          1.8414e-05, -1.1344e-05],\n",
      "        ...,\n",
      "        [-2.9929e-05,  7.7152e-05,  2.5748e-04,  ...,  7.7811e-06,\n",
      "         -2.3102e-05,  6.7469e-05],\n",
      "        [ 1.0582e-04, -2.0689e-04, -6.9517e-04,  ...,  3.4679e-06,\n",
      "          8.1209e-05, -8.2064e-05],\n",
      "        [ 9.1306e-05, -1.4679e-04, -5.2213e-04,  ...,  4.0067e-06,\n",
      "          6.4331e-05, -5.2383e-05]], device='cuda:0'), 'exp_avg_sq': tensor([[5.4838e-08, 4.4927e-08, 2.4215e-07,  ..., 4.5902e-12, 5.8781e-10,\n",
      "         7.7225e-08],\n",
      "        [3.6669e-08, 2.9309e-08, 1.8087e-07,  ..., 1.9714e-12, 2.2860e-10,\n",
      "         3.7079e-08],\n",
      "        [5.9766e-09, 4.9460e-09, 2.9193e-08,  ..., 3.0736e-13, 4.4876e-11,\n",
      "         6.1502e-09],\n",
      "        ...,\n",
      "        [1.5848e-08, 1.2382e-08, 7.9997e-08,  ..., 8.8933e-12, 9.4319e-11,\n",
      "         1.6336e-08],\n",
      "        [1.2840e-07, 1.0418e-07, 6.4850e-07,  ..., 5.7650e-12, 8.0797e-10,\n",
      "         1.2125e-07],\n",
      "        [7.3082e-08, 6.1710e-08, 3.5425e-07,  ..., 4.4553e-12, 5.3887e-10,\n",
      "         9.2784e-08]], device='cuda:0')}, 27: {'step': tensor(120., device='cuda:0'), 'exp_avg': tensor([ 1.7119e-04,  2.5948e-05,  7.0261e-06, -1.6752e-05, -9.9125e-06,\n",
      "         5.1622e-06,  6.0155e-06, -3.9237e-05,  2.0825e-05, -4.3375e-05,\n",
      "         6.6385e-05, -2.2022e-05,  3.3631e-06,  5.4380e-06, -9.4296e-06,\n",
      "        -9.5555e-07, -3.3511e-05, -3.0942e-06,  1.8833e-05,  6.7121e-05,\n",
      "        -9.0792e-05, -4.1508e-06,  4.1854e-05, -4.7395e-07, -3.9360e-06,\n",
      "        -1.1594e-05, -1.2116e-05,  8.4733e-06,  4.0900e-05, -2.6712e-06,\n",
      "         2.6946e-05, -1.5198e-04, -1.0405e-05, -2.0280e-05,  5.1748e-05,\n",
      "        -9.2184e-05, -1.1137e-05,  5.0953e-05,  2.6948e-05, -2.1449e-05,\n",
      "         5.1023e-06, -2.1560e-05,  8.6720e-06, -1.3123e-05, -1.1261e-05,\n",
      "         9.0846e-05, -1.2307e-06,  5.2503e-05,  6.0809e-07,  1.7617e-04,\n",
      "         2.4768e-05, -3.8972e-05,  2.9573e-05, -5.4438e-05, -5.3784e-05,\n",
      "         6.8758e-05,  6.9953e-07,  7.2527e-06,  3.4977e-05, -2.2189e-05,\n",
      "        -4.0525e-05,  3.9950e-05, -1.5579e-05,  4.5469e-05], device='cuda:0'), 'exp_avg_sq': tensor([1.7171e-08, 9.0077e-11, 2.1321e-11, 2.1839e-10, 2.7807e-10, 1.5258e-08,\n",
      "        3.5699e-10, 2.4810e-09, 3.9523e-10, 7.2209e-10, 7.8234e-09, 1.9040e-09,\n",
      "        1.2564e-10, 1.9454e-10, 1.7796e-11, 1.8347e-12, 9.5741e-10, 7.0598e-10,\n",
      "        3.0133e-10, 1.1813e-08, 2.3964e-09, 3.2093e-11, 6.6311e-09, 1.7552e-11,\n",
      "        4.7896e-11, 4.9472e-09, 4.3106e-10, 1.7443e-11, 4.5820e-10, 1.9334e-08,\n",
      "        5.9933e-10, 3.5181e-08, 2.6011e-09, 2.9352e-09, 1.0389e-09, 7.1163e-09,\n",
      "        2.6344e-10, 1.7640e-08, 1.1790e-09, 5.7694e-09, 5.2888e-12, 9.4448e-10,\n",
      "        5.9670e-11, 1.4350e-09, 1.8853e-10, 1.4874e-08, 3.1899e-10, 7.7343e-09,\n",
      "        1.0368e-09, 1.7083e-08, 1.2853e-09, 3.1864e-09, 4.5460e-10, 2.3756e-09,\n",
      "        1.7036e-09, 3.3149e-09, 3.8987e-10, 1.0217e-11, 6.5127e-09, 3.8608e-10,\n",
      "        1.2231e-09, 4.2700e-10, 5.2982e-09, 4.6898e-09], device='cuda:0')}, 28: {'step': tensor(120., device='cuda:0'), 'exp_avg': tensor([[ 2.9979e-03,  1.3189e-03,  1.6569e-03,  6.8144e-04,  3.3814e-03,\n",
      "         -2.1910e-04, -4.1498e-04, -1.7849e-03, -4.0070e-04,  2.7093e-03,\n",
      "          9.7456e-04,  7.2191e-04, -1.1709e-04,  2.9819e-03, -2.5981e-03,\n",
      "          5.9186e-04, -1.1881e-03, -6.9446e-04,  1.7509e-03, -6.4414e-04,\n",
      "          2.3960e-03, -9.9944e-04,  6.7478e-04,  1.8247e-03, -1.7687e-04,\n",
      "         -1.0402e-04, -1.5917e-04,  2.4708e-04, -2.1331e-03, -1.5745e-04,\n",
      "          3.6969e-04, -1.6239e-03,  8.0320e-04, -1.0226e-04, -2.0759e-03,\n",
      "          2.4499e-03, -4.8571e-04, -1.1893e-03, -6.1635e-04, -1.8792e-03,\n",
      "         -1.1418e-03,  1.0299e-03, -1.1362e-03, -5.3578e-04, -1.4508e-03,\n",
      "         -1.4482e-03,  3.2083e-04, -1.0523e-03,  8.7705e-05,  2.1275e-03,\n",
      "          7.7761e-04,  1.3145e-03,  2.3502e-03,  1.4240e-03, -2.1980e-03,\n",
      "         -1.4740e-03, -3.9097e-04,  1.5768e-03, -2.1898e-04, -2.5728e-04,\n",
      "          1.3930e-03, -2.4163e-03, -1.0358e-04, -1.0028e-03]], device='cuda:0'), 'exp_avg_sq': tensor([[4.9326e-06, 2.1373e-06, 2.5969e-06, 2.4317e-06, 4.7521e-06, 3.8385e-06,\n",
      "         1.9661e-06, 3.4610e-06, 2.5199e-06, 2.3354e-06, 6.1780e-06, 9.4084e-07,\n",
      "         2.5106e-06, 3.0121e-06, 2.8655e-06, 8.9059e-06, 3.7293e-06, 3.0234e-06,\n",
      "         2.4985e-06, 4.5512e-06, 2.5803e-06, 1.2688e-06, 1.8054e-06, 6.9945e-06,\n",
      "         1.5389e-06, 1.9374e-06, 3.1698e-06, 2.2436e-06, 4.0319e-06, 3.0590e-06,\n",
      "         1.8085e-06, 5.1547e-06, 5.5300e-06, 2.4158e-06, 3.7828e-06, 3.2317e-06,\n",
      "         4.4762e-06, 6.4758e-06, 2.9448e-06, 5.0983e-06, 2.1495e-06, 5.5567e-06,\n",
      "         3.7857e-06, 1.5837e-06, 2.2733e-06, 6.3233e-06, 1.6340e-06, 2.2984e-06,\n",
      "         2.7475e-06, 2.9657e-06, 5.0373e-06, 7.4018e-06, 4.2612e-06, 3.3410e-06,\n",
      "         4.2664e-06, 3.3521e-06, 2.9940e-06, 1.6892e-06, 1.9308e-06, 1.5831e-06,\n",
      "         1.8647e-06, 3.6308e-06, 3.0995e-06, 7.9672e-06]], device='cuda:0')}, 29: {'step': tensor(120., device='cuda:0'), 'exp_avg': tensor([-7.2165e-06], device='cuda:0'), 'exp_avg_sq': tensor([6.7198e-12], device='cuda:0')}, 30: {'step': tensor(120., device='cuda:0'), 'exp_avg': tensor([[-1.0546e-03, -3.1494e-04,  9.6067e-03,  ...,  1.8387e-05,\n",
      "         -1.6126e-03,  7.4269e-03],\n",
      "        [-1.9192e-03,  1.4275e-04,  4.6666e-03,  ..., -9.2666e-06,\n",
      "         -1.8702e-04,  7.9754e-03],\n",
      "        [-6.2012e-03,  8.1348e-03,  1.7509e-02,  ...,  1.0560e-05,\n",
      "         -2.3855e-03, -4.1517e-03],\n",
      "        ...,\n",
      "        [ 1.2125e-04, -4.4043e-06,  1.9872e-06,  ..., -9.1060e-06,\n",
      "          4.9624e-06,  1.0289e-04],\n",
      "        [ 3.9313e-03,  2.3824e-03,  1.6607e-02,  ...,  2.1627e-05,\n",
      "         -1.8735e-03, -4.3396e-03],\n",
      "        [ 4.0284e-03,  3.0455e-03,  4.0204e-04,  ..., -7.8291e-06,\n",
      "         -1.3410e-05,  5.9654e-03]], device='cuda:0'), 'exp_avg_sq': tensor([[4.4581e-04, 2.9821e-04, 8.8623e-05,  ..., 2.4383e-09, 1.4306e-07,\n",
      "         3.4234e-04],\n",
      "        [9.2685e-05, 1.1948e-04, 5.1331e-05,  ..., 1.8545e-10, 7.5193e-08,\n",
      "         2.7457e-04],\n",
      "        [5.0016e-04, 4.1555e-04, 1.3024e-04,  ..., 4.3571e-09, 6.5111e-07,\n",
      "         7.8719e-04],\n",
      "        ...,\n",
      "        [3.3104e-07, 2.6955e-12, 1.5291e-09,  ..., 1.0406e-11, 1.7204e-10,\n",
      "         1.0336e-06],\n",
      "        [5.5444e-04, 3.8307e-04, 1.3511e-04,  ..., 4.4279e-09, 2.6287e-07,\n",
      "         4.2675e-04],\n",
      "        [1.5207e-04, 1.6758e-04, 2.6862e-05,  ..., 2.8524e-09, 4.6196e-08,\n",
      "         3.2098e-04]], device='cuda:0')}, 31: {'step': tensor(120., device='cuda:0'), 'exp_avg': tensor([ 2.2461e-04,  1.5303e-02, -1.8080e-02,  4.5101e-03, -1.5890e-06,\n",
      "        -7.8549e-06, -6.8843e-06,  3.8799e-04, -3.3398e-02, -1.0683e-02,\n",
      "        -5.6976e-04, -6.3668e-05,  4.9771e-03, -2.2414e-10,  1.7324e-02,\n",
      "         1.0918e-02, -2.4120e-02,  1.9779e-03,  7.6054e-03,  4.0637e-02,\n",
      "        -6.4602e-03, -1.9815e-02, -6.8617e-06, -9.5563e-04,  6.6809e-03,\n",
      "        -1.1257e-05,  9.7047e-04,  3.9078e-06, -8.8035e-03, -2.4433e-06,\n",
      "         1.7819e-02, -5.3286e-03, -4.5674e-04,  2.5377e-03,  1.2509e-03,\n",
      "         4.5307e-03,  8.5563e-03,  7.9581e-06, -6.4158e-03,  2.1748e-03,\n",
      "         4.7450e-02, -3.1885e-02,  2.2469e-03,  9.1632e-04, -7.1085e-06,\n",
      "        -7.8449e-06, -5.6937e-02,  1.1994e-01,  9.6348e-03, -3.2326e-02,\n",
      "        -3.2941e-06,  1.6620e-06, -1.7039e-02, -7.9805e-03,  7.8779e-05,\n",
      "        -1.7117e-06,  2.2726e-02,  9.0004e-03, -5.2037e-04,  5.3764e-03,\n",
      "        -2.4134e-03,  2.1359e-04, -2.3329e-02,  9.0552e-03], device='cuda:0'), 'exp_avg_sq': tensor([3.1507e-03, 2.3238e-03, 4.6368e-03, 1.9166e-04, 4.7288e-13, 7.8659e-12,\n",
      "        6.1393e-12, 1.3318e-05, 2.0328e-03, 1.9577e-03, 1.5711e-03, 8.8511e-06,\n",
      "        2.3451e-03, 2.9621e-16, 1.8689e-04, 1.7558e-02, 4.1275e-03, 2.7898e-06,\n",
      "        2.6019e-03, 2.5898e-03, 3.3358e-03, 2.0282e-03, 6.1016e-12, 3.3122e-03,\n",
      "        1.3461e-03, 7.0999e-05, 2.0473e-03, 2.1733e-12, 3.9710e-03, 9.5776e-13,\n",
      "        1.1565e-03, 4.0660e-03, 6.5300e-03, 7.8334e-03, 1.5746e-04, 1.5656e-03,\n",
      "        1.8126e-03, 8.0621e-12, 7.2890e-03, 2.8350e-03, 4.6460e-03, 3.3818e-04,\n",
      "        1.8715e-03, 6.3365e-05, 4.7481e-07, 7.8470e-12, 1.0572e-02, 5.0979e-03,\n",
      "        1.6663e-03, 5.7995e-03, 9.5820e-06, 1.0532e-04, 2.2649e-03, 2.2651e-03,\n",
      "        1.3736e-03, 5.3238e-13, 2.1663e-03, 1.8321e-03, 1.7374e-03, 2.2327e-03,\n",
      "        2.6170e-03, 5.4759e-06, 3.8202e-03, 3.0356e-03], device='cuda:0')}, 32: {'step': tensor(120., device='cuda:0'), 'exp_avg': tensor([[ 3.1905e-06,  1.1195e-05, -7.9809e-06,  ..., -1.0669e-05,\n",
      "          1.6319e-08,  4.0501e-06],\n",
      "        [-1.1966e-03,  1.7622e-03,  3.2175e-03,  ..., -3.8248e-06,\n",
      "          1.3367e-03, -7.4182e-05],\n",
      "        [-2.0413e-03,  2.3006e-03, -1.7741e-03,  ...,  4.3898e-06,\n",
      "         -1.4906e-03,  1.1579e-03],\n",
      "        ...,\n",
      "        [-2.7086e-03,  8.6577e-04,  7.6471e-03,  ...,  1.2843e-05,\n",
      "          1.0269e-02, -3.1908e-03],\n",
      "        [-1.6756e-05, -1.4412e-05, -1.7296e-05,  ...,  9.8420e-07,\n",
      "         -8.3318e-05, -1.2190e-05],\n",
      "        [ 3.5648e-03, -2.4719e-04, -1.9485e-02,  ..., -3.5989e-06,\n",
      "         -9.7085e-03,  7.5778e-03]], device='cuda:0'), 'exp_avg_sq': tensor([[1.5173e-12, 1.5437e-11, 8.1056e-12,  ..., 1.4077e-11, 8.8999e-15,\n",
      "         2.3172e-12],\n",
      "        [4.1598e-05, 4.4523e-05, 5.9255e-05,  ..., 1.0845e-10, 2.9076e-04,\n",
      "         4.4770e-05],\n",
      "        [7.3499e-05, 7.5915e-05, 1.0581e-04,  ..., 8.6421e-11, 7.1219e-04,\n",
      "         1.1280e-04],\n",
      "        ...,\n",
      "        [6.2693e-05, 3.0222e-05, 6.6257e-05,  ..., 4.5095e-10, 2.7691e-04,\n",
      "         4.5791e-05],\n",
      "        [8.8104e-05, 2.3994e-05, 3.1749e-04,  ..., 2.2952e-13, 1.1398e-03,\n",
      "         1.3270e-05],\n",
      "        [4.3394e-04, 2.3352e-04, 5.8154e-04,  ..., 1.6849e-09, 4.9972e-03,\n",
      "         3.5865e-04]], device='cuda:0')}, 33: {'step': tensor(120., device='cuda:0'), 'exp_avg': tensor([-8.4532e-06, -4.3675e-03, -1.4731e-02,  4.5880e-03,  1.7925e-03,\n",
      "        -5.3577e-04, -5.1864e-06, -1.5273e-06, -1.0260e-03,  1.0233e-04,\n",
      "         5.6033e-04, -1.5808e-03,  4.9907e-03, -6.7238e-04,  1.1232e-03,\n",
      "         6.0613e-04, -9.5446e-06,  3.1381e-03,  2.7469e-03, -8.0297e-03,\n",
      "         5.6253e-02,  1.2969e-01, -4.3838e-03,  3.2992e-04, -4.5513e-03,\n",
      "        -7.1796e-07, -7.7154e-02, -4.8218e-02,  1.5044e-05,  4.4952e-03,\n",
      "        -3.8564e-04, -3.0623e-02], device='cuda:0'), 'exp_avg_sq': tensor([9.0366e-12, 5.1555e-03, 1.4481e-02, 4.0002e-03, 2.6198e-02, 3.1189e-04,\n",
      "        3.6312e-12, 4.1266e-05, 1.3343e-03, 2.8477e-03, 1.1529e-05, 5.8397e-04,\n",
      "        2.7569e-02, 6.0385e-02, 1.8808e-03, 1.0495e-01, 1.1381e-11, 3.2345e-03,\n",
      "        8.5615e-04, 4.8659e-03, 1.2565e-02, 9.4005e-03, 6.9567e-03, 1.6343e-03,\n",
      "        2.8300e-03, 1.4860e-13, 6.3470e-02, 8.8862e-02, 3.9132e-04, 3.3655e-03,\n",
      "        2.2843e-02, 1.0202e-01], device='cuda:0')}, 34: {'step': tensor(120., device='cuda:0'), 'exp_avg': tensor([[ 1.1350e-05, -1.0457e-05,  1.3410e-05, -1.1461e-05, -7.5695e-07,\n",
      "          3.0320e-06, -1.0026e-05,  2.9966e-06, -1.2754e-05,  1.3064e-05,\n",
      "          8.5047e-06,  6.4161e-06,  1.1820e-05,  1.0049e-05,  1.1186e-05,\n",
      "         -1.5850e-05, -1.0287e-05,  1.3660e-05,  3.2727e-06, -8.9788e-06,\n",
      "          1.5179e-05, -1.6499e-05, -1.5805e-05, -8.3513e-06, -4.6432e-06,\n",
      "         -1.3420e-05, -1.1192e-05,  1.4120e-05, -1.0837e-05, -1.2724e-05,\n",
      "         -1.1371e-05,  6.5903e-07],\n",
      "        [ 2.6947e-06,  7.0885e-06,  1.5183e-05, -6.6249e-06,  2.0576e-06,\n",
      "          1.1541e-05,  1.0950e-05,  2.5010e-06,  1.1294e-05,  1.5724e-05,\n",
      "          7.6259e-06, -1.4612e-05, -3.7406e-07, -1.0965e-05, -1.1292e-05,\n",
      "          3.2573e-06,  5.5930e-06,  7.6819e-07, -1.0511e-05, -6.5907e-06,\n",
      "          1.4200e-05,  6.4122e-06, -4.0708e-06, -1.5393e-05, -7.2050e-06,\n",
      "          9.6369e-06,  1.0399e-05, -8.8138e-06, -1.3783e-05,  4.1611e-06,\n",
      "         -8.1326e-06,  1.4730e-05],\n",
      "        [-6.7409e-06, -4.6879e-02, -2.5797e-02, -2.5842e-02,  1.0543e-03,\n",
      "          2.8209e-02,  6.6022e-06, -7.6211e-06,  3.1187e-02,  1.3333e-02,\n",
      "          1.5921e-05, -2.1060e-02, -3.2105e-02, -2.8623e-05, -6.1020e-05,\n",
      "         -1.4554e-02, -1.3027e-05,  1.9888e-02, -2.0828e-02, -6.9835e-02,\n",
      "         -6.3411e-03, -4.8200e-04, -1.6859e-02,  4.5025e-06, -1.2061e-03,\n",
      "         -3.8443e-08, -3.5764e-03, -2.3329e-02, -1.6013e-05, -2.1606e-02,\n",
      "         -1.1077e-05, -1.2471e-02],\n",
      "        [-1.5436e-05, -2.0842e-02, -1.3030e-02, -1.2020e-02,  4.9418e-05,\n",
      "          5.9579e-03, -4.3331e-06, -3.5606e-06,  1.9155e-02,  1.0563e-02,\n",
      "          4.5688e-06, -1.0158e-02, -2.6228e-02, -1.0588e-05, -3.5941e-05,\n",
      "         -1.2280e-02, -7.0817e-06,  9.8106e-03, -4.5271e-03, -3.8398e-02,\n",
      "         -3.2944e-03, -2.8315e-04, -1.5492e-02,  2.7071e-06, -1.1135e-03,\n",
      "          7.9000e-06, -4.9471e-03, -1.8048e-02,  1.3350e-05, -1.5881e-02,\n",
      "         -3.2492e-05, -1.4277e-03],\n",
      "        [ 2.5730e-06,  6.4083e-03,  4.5741e-03,  3.8956e-03,  3.8754e-04,\n",
      "          3.4934e-03, -3.4275e-06,  5.4022e-06, -8.5970e-03, -5.7968e-03,\n",
      "          9.4229e-06,  3.4257e-03,  1.5606e-02, -5.5702e-07, -8.8685e-06,\n",
      "          7.7323e-03,  1.4403e-05, -3.0115e-03, -1.6395e-03,  1.5340e-02,\n",
      "          1.2519e-03,  1.1510e-04,  9.8934e-03, -5.8419e-06,  9.3088e-04,\n",
      "          5.2726e-06,  3.8167e-03,  1.0224e-02,  1.0552e-05,  8.6881e-03,\n",
      "          7.2088e-06, -2.3776e-03],\n",
      "        [-7.3669e-06,  4.5372e-06, -4.2308e-06,  7.2330e-07, -1.2493e-05,\n",
      "          7.4503e-06,  1.4719e-05, -9.7837e-06, -4.0089e-06, -7.8302e-06,\n",
      "          1.3644e-05, -8.9652e-06,  1.1852e-05,  8.5591e-06, -6.0452e-06,\n",
      "         -1.1444e-05, -6.1851e-08, -1.5470e-05, -1.3210e-05,  6.6299e-06,\n",
      "         -1.5145e-05,  6.1141e-06,  5.8371e-06,  7.5363e-06, -1.4200e-06,\n",
      "          3.4209e-06,  6.7067e-06, -8.7743e-06,  8.8794e-06, -2.1003e-06,\n",
      "          7.8671e-06, -6.0008e-06],\n",
      "        [-1.9402e-06,  2.5803e-02,  1.4564e-02,  1.4347e-02, -4.9473e-04,\n",
      "         -1.3897e-02, -7.3619e-06, -6.6656e-06, -1.8529e-02, -8.4761e-03,\n",
      "          6.6775e-06,  1.1757e-02,  2.0661e-02,  1.5350e-05,  3.3845e-05,\n",
      "          9.4735e-03, -1.4670e-05, -1.1157e-02,  1.0241e-02,  4.0250e-02,\n",
      "          3.6170e-03,  2.8756e-04,  1.1254e-02, -1.1233e-05,  7.7256e-04,\n",
      "         -1.4344e-05,  2.8002e-03,  1.4788e-02,  9.0446e-06,  1.3479e-02,\n",
      "          2.4618e-06,  5.8214e-03],\n",
      "        [-2.9669e-10, -5.8004e-03, -1.9008e-03, -2.7345e-03,  7.7609e-04,\n",
      "          1.2050e-02, -8.1102e-06, -1.2598e-05, -1.3120e-03, -3.1399e-03,\n",
      "          1.6780e-05, -1.8944e-03,  9.1353e-03,  1.3495e-05,  3.0971e-06,\n",
      "          4.8771e-03,  1.3791e-05,  2.0305e-03, -7.8948e-03, -1.6766e-03,\n",
      "         -3.2670e-04, -6.3594e-06,  6.8346e-03,  8.0575e-06,  7.5122e-04,\n",
      "         -1.5868e-05,  3.4312e-03,  5.3980e-03,  1.5421e-05,  4.0419e-03,\n",
      "         -1.8709e-06, -6.3361e-03],\n",
      "        [ 7.5171e-06, -1.5761e-05, -7.3814e-06,  1.1297e-05,  1.4783e-05,\n",
      "          1.2286e-05, -8.0993e-07, -1.2743e-05,  8.0660e-06,  8.1373e-06,\n",
      "          1.4083e-05, -4.6112e-06, -5.0264e-06,  4.0652e-06, -8.8973e-08,\n",
      "          1.3249e-05,  9.6986e-14, -1.2057e-05,  1.1876e-05,  8.3381e-08,\n",
      "         -7.1258e-06, -9.8687e-07, -1.6509e-06,  1.4426e-07,  4.0898e-06,\n",
      "         -1.1733e-06,  8.3739e-06, -8.4861e-06,  4.8744e-06, -2.6689e-06,\n",
      "         -5.6472e-06,  1.5136e-05],\n",
      "        [-8.8189e-06,  1.1686e-05,  1.0136e-05,  4.5488e-06,  4.1630e-06,\n",
      "          1.2796e-05, -1.2278e-05,  9.3621e-06,  1.3720e-05,  3.6596e-06,\n",
      "          1.3244e-05,  1.5198e-05,  1.2845e-05, -1.5152e-05, -9.4908e-06,\n",
      "         -2.3117e-06, -6.4983e-06, -1.4817e-09, -8.8906e-06,  1.0260e-05,\n",
      "         -1.0488e-05, -8.4314e-06, -1.9731e-06, -1.0035e-05,  6.7902e-06,\n",
      "          7.9977e-06, -9.2660e-06,  8.1455e-06, -1.2355e-05, -8.6377e-06,\n",
      "         -5.0374e-06,  6.5812e-06],\n",
      "        [-1.8717e-06,  1.3702e-02,  6.1092e-03,  7.0756e-03, -7.7544e-04,\n",
      "         -1.5108e-02, -5.4746e-06, -1.4287e-05, -4.0617e-03,  5.8365e-04,\n",
      "         -8.0948e-06,  5.4132e-03, -2.4386e-03,  1.6920e-05,  1.4272e-05,\n",
      "         -1.5603e-03, -3.5003e-06, -5.0244e-03,  1.0787e-02,  1.3440e-02,\n",
      "          1.3491e-03,  9.0220e-05, -3.0118e-03, -1.2208e-06, -2.8720e-04,\n",
      "          1.5228e-05, -2.3164e-03, -7.2376e-04, -1.6477e-05,  1.8741e-04,\n",
      "         -1.2036e-05,  7.7956e-03],\n",
      "        [-1.5297e-05, -1.9055e-02, -1.1911e-02, -1.1014e-02,  9.3797e-05,\n",
      "          5.5241e-03, -3.3478e-10, -2.0325e-06,  1.7648e-02,  9.6601e-03,\n",
      "         -8.3829e-06, -9.3023e-03, -2.4055e-02, -2.2497e-05, -3.4680e-05,\n",
      "         -1.1251e-02,  1.0123e-05,  8.9969e-03, -4.0663e-03, -3.5171e-02,\n",
      "         -3.0416e-03, -2.3240e-04, -1.4170e-02,  1.5245e-05, -9.7376e-04,\n",
      "         -6.3780e-07, -4.5371e-03, -1.6557e-02, -9.8779e-06, -1.4561e-02,\n",
      "         -9.4330e-06, -1.2804e-03],\n",
      "        [ 1.2822e-05, -2.2649e-02, -1.3024e-02, -1.2714e-02,  5.4180e-04,\n",
      "          1.2705e-02,  8.8388e-06,  1.3881e-05,  1.6744e-02,  7.6819e-03,\n",
      "          8.8342e-06, -1.0431e-02, -1.8479e-02, -1.0008e-05, -1.9499e-05,\n",
      "         -8.3371e-03,  3.9049e-06,  1.0148e-02, -8.9342e-03, -3.6053e-02,\n",
      "         -3.2228e-03, -2.5351e-04, -1.0012e-02,  1.9526e-05, -5.6245e-04,\n",
      "          1.1572e-05, -2.4514e-03, -1.3247e-02,  1.0890e-05, -1.2075e-02,\n",
      "         -1.3428e-05, -5.1438e-03],\n",
      "        [-1.4935e-05, -1.3265e-05, -1.2394e-05, -2.1596e-06,  8.3171e-06,\n",
      "         -8.1961e-06,  1.3944e-05, -6.3210e-06,  4.3282e-06,  7.3909e-06,\n",
      "         -8.5351e-06,  1.2073e-05,  1.0205e-05, -3.0041e-07,  1.4985e-05,\n",
      "          1.9079e-06, -1.0197e-05, -1.2182e-05, -4.6734e-06,  5.9592e-06,\n",
      "          1.2314e-05, -1.0983e-05, -9.4413e-06,  1.3909e-05,  3.4710e-06,\n",
      "         -1.3542e-05, -8.8954e-06,  4.9348e-06, -4.2412e-06, -1.5482e-05,\n",
      "         -1.5864e-05, -1.0698e-06],\n",
      "        [-6.7314e-08, -2.4821e-02, -1.4089e-02, -1.3836e-02,  3.1674e-04,\n",
      "          1.1841e-02, -9.3792e-06,  1.1472e-05,  1.8328e-02,  8.7569e-03,\n",
      "          1.3400e-05, -1.1394e-02, -2.1713e-02, -2.7186e-05, -2.0784e-05,\n",
      "         -1.0131e-02, -3.2890e-06,  1.0674e-02, -9.1110e-03, -3.9434e-02,\n",
      "         -3.5139e-03, -2.7487e-04, -1.2123e-02,  8.3405e-07, -9.6912e-04,\n",
      "         -9.5982e-06, -3.2763e-03, -1.5339e-02,  1.0386e-05, -1.3838e-02,\n",
      "         -3.0014e-05, -4.8828e-03],\n",
      "        [-1.0295e-05,  1.7600e-02,  1.0472e-02,  9.9609e-03, -2.2834e-04,\n",
      "         -7.4718e-03,  1.6250e-06,  1.0461e-05, -1.4358e-02, -7.2899e-03,\n",
      "         -1.6571e-06,  8.2845e-03,  1.7924e-02,  2.2587e-05,  3.1772e-05,\n",
      "          8.2795e-03,  9.1919e-06, -7.9790e-03,  5.4804e-03,  2.9901e-02,\n",
      "          2.6196e-03,  2.0954e-04,  1.0214e-02, -1.3916e-05,  7.1172e-04,\n",
      "         -1.5821e-05,  2.9709e-03,  1.2561e-02,  1.6535e-05,  1.1215e-02,\n",
      "          1.8349e-05,  2.6611e-03]], device='cuda:0'), 'exp_avg_sq': tensor([[1.5848e-11, 1.3547e-11, 2.1851e-11, 1.6149e-11, 1.5945e-13, 1.3880e-12,\n",
      "         1.2501e-11, 1.3599e-12, 1.9835e-11, 2.0776e-11, 9.1411e-12, 5.3825e-12,\n",
      "         1.7135e-11, 1.2556e-11, 1.5412e-11, 3.0198e-11, 1.3129e-11, 2.2643e-11,\n",
      "         1.5865e-12, 1.0132e-11, 2.7770e-11, 3.2646e-11, 3.0035e-11, 8.8315e-12,\n",
      "         2.9666e-12, 2.1881e-11, 1.5429e-11, 2.4141e-11, 1.4504e-11, 1.9744e-11,\n",
      "         1.5906e-11, 1.3285e-13],\n",
      "        [1.1319e-12, 6.4847e-12, 2.7784e-11, 5.7139e-12, 7.1841e-13, 1.6365e-11,\n",
      "         1.4795e-11, 9.9647e-13, 1.5700e-11, 2.9737e-11, 7.4393e-12, 2.5795e-11,\n",
      "         6.7676e-14, 1.4834e-11, 1.5695e-11, 1.5734e-12, 4.1724e-12, 1.6264e-13,\n",
      "         1.3680e-11, 5.6589e-12, 2.4404e-11, 5.3764e-12, 2.3385e-12, 2.8534e-11,\n",
      "         6.6862e-12, 1.1591e-11, 1.3403e-11, 9.7812e-12, 2.3039e-11, 2.4327e-12,\n",
      "         8.3991e-12, 2.6200e-11],\n",
      "        [5.9022e-12, 8.4869e-03, 5.0982e-03, 3.1547e-03, 2.9025e-03, 6.1111e-03,\n",
      "         5.6773e-12, 1.3778e-06, 3.9067e-03, 6.8593e-03, 1.1369e-09, 2.9962e-03,\n",
      "         4.9197e-03, 6.4444e-05, 1.0915e-07, 2.2139e-03, 2.0663e-11, 3.7487e-03,\n",
      "         4.5157e-03, 5.2352e-03, 3.6774e-03, 1.4681e-06, 5.4183e-03, 2.9385e-07,\n",
      "         5.2479e-03, 1.2450e-14, 4.3026e-03, 2.1231e-03, 3.2749e-06, 5.2947e-03,\n",
      "         1.1714e-04, 1.0547e-03],\n",
      "        [2.8688e-11, 4.4419e-03, 1.8912e-03, 9.4462e-04, 9.2442e-04, 2.0754e-03,\n",
      "         2.6171e-12, 2.5556e-06, 1.4729e-03, 1.8289e-03, 2.0053e-10, 1.1607e-03,\n",
      "         1.6707e-03, 2.0244e-05, 3.1088e-08, 7.7751e-04, 6.4732e-12, 1.2053e-03,\n",
      "         2.3702e-03, 1.8282e-03, 1.3331e-03, 4.8735e-07, 2.0575e-03, 9.6570e-08,\n",
      "         2.0555e-03, 7.9513e-12, 1.4319e-03, 6.6546e-04, 1.0764e-06, 1.7157e-03,\n",
      "         3.8065e-05, 3.4530e-04],\n",
      "        [1.0458e-12, 3.8069e-03, 6.4677e-04, 5.8492e-04, 2.0334e-04, 9.4594e-04,\n",
      "         1.7211e-12, 2.8949e-06, 4.3133e-04, 3.9064e-04, 2.0887e-11, 6.3889e-04,\n",
      "         3.9208e-04, 6.0614e-06, 4.9531e-09, 3.1632e-04, 2.5086e-11, 5.6420e-04,\n",
      "         1.9354e-03, 5.7410e-04, 5.2549e-04, 9.3470e-08, 7.6073e-04, 1.8251e-08,\n",
      "         7.6262e-04, 3.7428e-12, 3.3210e-04, 1.4475e-04, 2.1410e-07, 4.1562e-04,\n",
      "         8.1434e-06, 9.2504e-05],\n",
      "        [6.9711e-12, 2.8447e-12, 2.5066e-12, 1.5007e-13, 1.9059e-11, 7.1202e-12,\n",
      "         2.6161e-11, 1.1930e-11, 2.2750e-12, 7.8194e-12, 2.2592e-11, 1.0103e-11,\n",
      "         1.7224e-11, 9.2521e-12, 4.8183e-12, 1.6102e-11, 1.5893e-14, 2.8812e-11,\n",
      "         2.1226e-11, 5.7219e-12, 2.7649e-11, 4.9207e-12, 4.5153e-12, 7.2756e-12,\n",
      "         3.9655e-13, 1.7152e-12, 5.8463e-12, 9.6980e-12, 9.9198e-12, 7.4324e-13,\n",
      "         7.8890e-12, 4.7528e-12],\n",
      "        [6.5221e-13, 2.1950e-03, 1.7650e-03, 9.3756e-04, 9.5270e-04, 1.9582e-03,\n",
      "         6.9622e-12, 1.5381e-06, 1.3299e-03, 2.1081e-03, 3.2694e-10, 9.4211e-04,\n",
      "         1.6484e-03, 2.0661e-05, 3.5169e-08, 7.2234e-04, 2.5993e-11, 1.0829e-03,\n",
      "         1.3817e-03, 1.7441e-03, 1.2903e-03, 4.9152e-07, 1.8591e-03, 9.8553e-08,\n",
      "         1.7307e-03, 2.4885e-11, 1.4575e-03, 6.9896e-04, 1.0883e-06, 1.7404e-03,\n",
      "         3.9401e-05, 3.6017e-04],\n",
      "        [3.2225e-16, 5.4054e-03, 2.8423e-04, 7.4082e-04, 9.4711e-05, 1.0322e-03,\n",
      "         8.3555e-12, 1.7730e-06, 2.0499e-04, 3.7141e-04, 6.7457e-11, 6.1019e-04,\n",
      "         1.8777e-04, 2.3446e-06, 9.8372e-10, 3.1019e-04, 2.3063e-11, 8.5908e-04,\n",
      "         2.2885e-03, 2.6731e-04, 2.5785e-04, 5.8398e-11, 4.6417e-04, 1.9643e-10,\n",
      "         5.1380e-04, 3.0266e-11, 7.3564e-05, 5.0899e-05, 1.2521e-09, 2.5221e-04,\n",
      "         3.7047e-07, 3.5668e-05],\n",
      "        [7.2408e-12, 2.9872e-11, 6.9970e-12, 1.5707e-11, 2.6383e-11, 1.8457e-11,\n",
      "         1.7474e-13, 1.9803e-11, 8.2696e-12, 8.4085e-12, 2.4019e-11, 2.9295e-12,\n",
      "         3.4285e-12, 2.3327e-12, 1.9803e-14, 2.1346e-11, 1.2570e-20, 1.7800e-11,\n",
      "         1.7291e-11, 1.8997e-14, 6.5489e-12, 2.3041e-13, 5.0249e-13, 2.7935e-14,\n",
      "         2.3581e-12, 2.9671e-13, 8.8767e-12, 9.1033e-12, 3.2413e-12, 1.1133e-12,\n",
      "         4.2474e-12, 2.7616e-11],\n",
      "        [9.7920e-12, 1.6764e-11, 1.2764e-11, 2.8579e-12, 2.4347e-12, 1.9961e-11,\n",
      "         1.8434e-11, 1.0970e-11, 2.2837e-11, 1.9331e-12, 2.1332e-11, 2.7836e-11,\n",
      "         2.0109e-11, 2.7674e-11, 1.1259e-11, 8.7231e-13, 5.5118e-12, 5.7324e-15,\n",
      "         9.9435e-12, 1.3064e-11, 1.3623e-11, 8.9925e-12, 6.7045e-13, 1.2520e-11,\n",
      "         5.9832e-12, 8.1380e-12, 1.0757e-11, 8.4243e-12, 1.8657e-11, 9.4139e-12,\n",
      "         3.4423e-12, 5.6436e-12],\n",
      "        [6.1507e-13, 3.5930e-03, 1.6555e-04, 5.6415e-04, 1.7515e-04, 8.8579e-04,\n",
      "         4.0109e-12, 3.3453e-08, 2.0482e-04, 6.4747e-04, 1.2076e-10, 3.3830e-04,\n",
      "         2.8566e-04, 1.9028e-06, 5.3447e-09, 2.8605e-04, 1.7862e-12, 8.4028e-04,\n",
      "         1.3617e-03, 2.6092e-04, 1.4100e-04, 3.6913e-08, 3.2346e-04, 7.9913e-09,\n",
      "         3.4688e-04, 2.7943e-11, 1.5812e-04, 1.0896e-04, 8.0915e-08, 3.9888e-04,\n",
      "         2.9289e-06, 5.1490e-05],\n",
      "        [2.8190e-11, 3.8160e-03, 1.6158e-03, 8.0371e-04, 7.9290e-04, 1.7703e-03,\n",
      "         3.4036e-16, 1.9907e-06, 1.2594e-03, 1.5727e-03, 1.7164e-10, 9.8942e-04,\n",
      "         1.4208e-03, 1.7334e-05, 2.6389e-08, 6.6189e-04, 1.2731e-11, 1.0403e-03,\n",
      "         2.0065e-03, 1.5591e-03, 1.1325e-03, 4.1325e-07, 1.7501e-03, 8.2000e-08,\n",
      "         1.7505e-03, 1.2737e-13, 1.2126e-03, 5.7013e-04, 9.2027e-07, 1.4705e-03,\n",
      "         3.3824e-05, 2.9130e-04],\n",
      "        [2.0041e-11, 2.3198e-03, 1.4288e-03, 8.0507e-04, 7.7818e-04, 1.6498e-03,\n",
      "         9.8339e-12, 7.2544e-07, 1.0842e-03, 1.7381e-03, 2.7571e-10, 8.1007e-04,\n",
      "         1.3614e-03, 1.6649e-05, 2.8373e-08, 5.9894e-04, 2.1703e-12, 9.6391e-04,\n",
      "         1.2397e-03, 1.3889e-03, 1.0153e-03, 4.0031e-07, 1.5154e-03, 8.0476e-08,\n",
      "         1.4421e-03, 1.6449e-11, 1.1722e-03, 5.6607e-04, 8.8196e-07, 1.4234e-03,\n",
      "         3.1597e-05, 2.8582e-04],\n",
      "        [2.6908e-11, 2.1397e-11, 1.8772e-11, 7.7839e-13, 8.7631e-12, 8.5235e-12,\n",
      "         2.3562e-11, 5.2348e-12, 2.6117e-12, 7.0138e-12, 9.2031e-12, 1.7846e-11,\n",
      "         1.2929e-11, 5.3749e-14, 2.7084e-11, 6.3456e-13, 1.2911e-11, 1.8159e-11,\n",
      "         3.0018e-12, 4.6918e-12, 1.8537e-11, 1.4882e-11, 1.1147e-11, 2.3447e-11,\n",
      "         1.7599e-12, 2.2267e-11, 9.9537e-12, 3.3151e-12, 2.5177e-12, 2.8853e-11,\n",
      "         3.0252e-11, 2.5893e-13],\n",
      "        [1.6682e-14, 2.0242e-03, 1.8469e-03, 9.2846e-04, 9.1818e-04, 1.9205e-03,\n",
      "         1.1008e-11, 3.1053e-06, 1.3408e-03, 1.9556e-03, 3.1473e-10, 9.8199e-04,\n",
      "         1.5922e-03, 2.1274e-05, 3.3484e-08, 7.1602e-04, 1.6005e-12, 9.4572e-04,\n",
      "         1.5591e-03, 1.8068e-03, 1.4033e-03, 4.8570e-07, 1.9348e-03, 9.6628e-08,\n",
      "         1.7656e-03, 1.1502e-11, 1.4638e-03, 6.8247e-04, 1.0826e-06, 1.6793e-03,\n",
      "         3.9065e-05, 3.6547e-04],\n",
      "        [1.3148e-11, 1.8191e-03, 1.0618e-03, 5.2458e-04, 5.4682e-04, 1.1451e-03,\n",
      "         4.9000e-13, 9.4364e-07, 8.1178e-04, 1.1419e-03, 1.4786e-10, 6.0008e-04,\n",
      "         9.6829e-04, 1.1941e-05, 1.9397e-08, 4.2646e-04, 1.0594e-11, 6.4818e-04,\n",
      "         1.0124e-03, 1.0271e-03, 7.5024e-04, 2.8779e-07, 1.1294e-03, 5.7377e-08,\n",
      "         1.0955e-03, 3.0092e-11, 8.3999e-04, 3.9760e-04, 6.4222e-07, 1.0017e-03,\n",
      "         2.2947e-05, 2.0187e-04]], device='cuda:0')}, 35: {'step': tensor(120., device='cuda:0'), 'exp_avg': tensor([-9.0536e-06, -9.3100e-06,  1.6664e-03,  1.7262e-02, -1.2867e-02,\n",
      "        -1.4665e-06, -5.0218e-03, -1.5081e-02, -1.2893e-05, -1.1005e-05,\n",
      "         1.5240e-02,  1.6139e-02,  6.2801e-03,  1.4225e-06,  6.2105e-03,\n",
      "        -8.9255e-03], device='cuda:0'), 'exp_avg_sq': tensor([1.0293e-11, 1.0854e-11, 5.3507e-02, 3.8487e-02, 4.7741e-02, 4.1693e-13,\n",
      "        8.3168e-03, 7.8617e-02, 2.0255e-11, 1.4938e-11, 5.5538e-02, 3.3299e-02,\n",
      "        1.4237e-02, 3.9762e-13, 4.6282e-03, 1.1632e-02], device='cuda:0')}, 36: {'step': tensor(120., device='cuda:0'), 'exp_avg': tensor([[ 1.7790e-05,  3.0897e-06, -1.7362e-10, -2.0019e-05, -1.7677e-05,\n",
      "          4.2910e-06, -1.2623e-05,  2.5210e-07,  9.7807e-06, -4.4263e-06,\n",
      "          1.8953e-05, -5.2015e-06, -2.2186e-05,  4.6093e-06, -1.7566e-05,\n",
      "         -1.1371e-05],\n",
      "        [ 2.2719e-05, -6.4176e-06,  1.9421e-02, -1.2077e-02, -6.9217e-02,\n",
      "          2.2133e-05,  5.8527e-02, -4.2466e-02, -1.9939e-05,  5.6494e-06,\n",
      "          1.5864e-02,  1.5922e-02, -3.3527e-02,  1.4648e-05, -2.0953e-02,\n",
      "         -4.0124e-02],\n",
      "        [ 1.5034e-05,  4.0348e-06,  1.0430e-07,  2.1403e-06,  9.1461e-06,\n",
      "         -1.7357e-05, -1.3701e-05,  1.0018e-06, -4.6429e-06, -5.8924e-06,\n",
      "          1.5816e-05, -5.6309e-06,  1.6110e-05,  1.1644e-05, -1.1552e-05,\n",
      "         -6.3394e-06],\n",
      "        [-2.7586e-07, -1.1610e-05,  1.0609e-05,  5.0614e-06, -2.3008e-05,\n",
      "          1.6715e-05,  1.5084e-05,  1.2173e-05,  2.2619e-06, -1.5618e-05,\n",
      "          3.6886e-06, -4.2756e-06, -6.7014e-06,  1.5579e-05, -8.4808e-06,\n",
      "         -2.1438e-05],\n",
      "        [-1.4822e-05,  5.5193e-06,  1.4604e-02,  3.6612e-02,  2.4339e-02,\n",
      "         -1.3684e-05,  5.2969e-03,  7.3593e-03,  4.1105e-06, -8.8109e-06,\n",
      "          1.1090e-02,  1.1665e-02, -4.9814e-03, -2.2274e-05,  1.8608e-03,\n",
      "          1.4041e-02],\n",
      "        [-1.9094e-05, -1.2975e-05,  7.7785e-06,  1.6159e-05,  4.7710e-06,\n",
      "          1.3442e-05, -1.0058e-05, -1.4250e-05, -1.3204e-05,  1.0786e-05,\n",
      "          6.4772e-06,  2.3043e-06, -1.6577e-05,  1.4297e-05, -1.1497e-13,\n",
      "         -2.2060e-05],\n",
      "        [-1.9403e-05,  2.0850e-05, -1.2750e-02,  4.3509e-03,  3.9613e-02,\n",
      "         -5.6885e-06, -3.7443e-02,  2.2507e-02,  5.8718e-06, -1.8030e-05,\n",
      "         -1.0204e-02, -1.1336e-02,  1.8120e-02,  1.3939e-05,  8.4939e-03,\n",
      "          2.1512e-02],\n",
      "        [ 2.2024e-05, -1.2617e-06, -2.3391e-05, -1.4323e-05,  1.9572e-05,\n",
      "         -1.7765e-05, -3.2396e-06,  2.3503e-05,  1.7191e-05,  8.0175e-06,\n",
      "          4.0073e-06, -1.6901e-05,  9.5296e-06, -9.0985e-06, -2.1223e-05,\n",
      "         -2.2446e-05]], device='cuda:0'), 'exp_avg_sq': tensor([[3.7798e-11, 1.4344e-12, 6.7401e-16, 4.7583e-11, 3.7334e-11, 2.5714e-12,\n",
      "         1.9445e-11, 4.5242e-14, 1.1923e-11, 2.7199e-12, 4.2763e-11, 3.6507e-12,\n",
      "         5.8171e-11, 2.9274e-12, 3.6876e-11, 1.5906e-11],\n",
      "        [6.0938e-11, 5.3848e-12, 5.4404e-03, 1.2822e-02, 9.2258e-03, 5.7897e-11,\n",
      "         7.8938e-03, 1.1826e-02, 4.7211e-11, 4.2505e-12, 1.0088e-02, 4.1054e-03,\n",
      "         8.7422e-03, 2.5918e-11, 5.0685e-03, 7.8057e-03],\n",
      "        [2.7257e-11, 2.3015e-12, 2.2023e-14, 7.6686e-13, 1.0493e-11, 3.6027e-11,\n",
      "         2.2775e-11, 2.3541e-13, 2.9663e-12, 4.5948e-12, 3.0072e-11, 4.2247e-12,\n",
      "         3.1169e-11, 1.6647e-11, 1.6395e-11, 5.2633e-12],\n",
      "        [4.9365e-14, 1.6555e-11, 1.3927e-11, 3.4723e-12, 6.2465e-11, 3.3482e-11,\n",
      "         2.7434e-11, 1.8132e-11, 8.4096e-13, 2.9346e-11, 1.9604e-12, 2.5548e-12,\n",
      "         5.8378e-12, 2.9206e-11, 9.0924e-12, 5.4398e-11],\n",
      "        [2.6516e-11, 4.0715e-12, 4.7039e-03, 6.2474e-02, 3.8951e-02, 2.2719e-11,\n",
      "         2.4910e-02, 5.8507e-02, 2.3797e-12, 9.7751e-12, 3.9627e-03, 1.4097e-02,\n",
      "         2.6558e-02, 5.8622e-11, 7.8559e-02, 4.5878e-02],\n",
      "        [4.3388e-11, 2.0503e-11, 7.7222e-12, 3.1354e-11, 3.1169e-12, 2.1950e-11,\n",
      "         1.2575e-11, 2.4572e-11, 2.1205e-11, 1.4373e-11, 5.4785e-12, 8.6759e-13,\n",
      "         3.2946e-11, 2.4729e-11, 1.2978e-20, 5.7524e-11],\n",
      "        [4.4764e-11, 5.1515e-11, 2.3692e-03, 1.6225e-02, 9.4724e-03, 4.3050e-12,\n",
      "         6.7659e-03, 1.5376e-02, 4.5652e-12, 3.8798e-11, 4.1192e-03, 3.0368e-03,\n",
      "         7.3103e-03, 2.3545e-11, 1.5563e-02, 9.4765e-03],\n",
      "        [5.7342e-11, 3.3090e-13, 6.4518e-11, 2.4815e-11, 4.5532e-11, 3.7697e-11,\n",
      "         1.5584e-12, 6.5127e-11, 3.5360e-11, 8.1760e-12, 2.2734e-12, 3.4209e-11,\n",
      "         1.1346e-11, 1.0390e-11, 5.3335e-11, 5.9510e-11]], device='cuda:0')}, 37: {'step': tensor(120., device='cuda:0'), 'exp_avg': tensor([ 1.2391e-05,  1.3856e-04, -1.0803e-05, -1.4017e-05,  1.2072e-01,\n",
      "        -1.1941e-05, -1.8828e-02, -3.8600e-06], device='cuda:0'), 'exp_avg_sq': tensor([1.8760e-11, 2.5130e-07, 1.4417e-11, 2.3802e-11, 2.1573e+00, 1.7474e-11,\n",
      "        3.6440e-01, 2.1259e-12], device='cuda:0')}, 38: {'step': tensor(120., device='cuda:0'), 'exp_avg': tensor([[ 1.1765e-05, -5.8096e-02, -1.4536e-05, -9.9544e-06,  3.8453e-02,\n",
      "          3.0067e-05, -1.1781e-01, -2.9773e-05]], device='cuda:0'), 'exp_avg_sq': tensor([[1.6981e-11, 1.1903e-02, 2.5536e-11, 1.2330e-11, 2.0327e-03, 1.0564e-10,\n",
      "         2.8286e-02, 1.0361e-10]], device='cuda:0')}, 39: {'step': tensor(120., device='cuda:0'), 'exp_avg': tensor([-0.0005], device='cuda:0'), 'exp_avg_sq': tensor([3.8514e-06], device='cuda:0')}}, 'param_groups': [{'lr': 0.0001, 'betas': (0.9, 0.999), 'eps': 1e-08, 'weight_decay': 0.0001, 'amsgrad': False, 'maximize': False, 'foreach': None, 'capturable': False, 'differentiable': False, 'fused': None, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39]}]}\n",
      "batch_size 32\n",
      "dropout_ratio 0.5\n",
      "learning_rate 0.0001\n",
      "weight_decay 0.0001\n",
      "n_epochs 10\n",
      "random_seed 0\n",
      "val_c_index 0.7572533849129593\n",
      "hidden [1024, 1024, 512, 512, 256, 256, 128, 128, 64, 64, 32]\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning) # ignore the loading security warning\n",
    "\n",
    "model_chkpt = FusionNetwork()\n",
    "model_chkpt.to(device)\n",
    "optimizer = optim.Adam(model_chkpt.parameters())\n",
    "\n",
    "# load from last check point\n",
    "checkpoint_path = r\"..\\checkpoints\\trained-model_2025-03-02_0.757253.pth\"\n",
    "checkpoint = torch.load(checkpoint_path, map_location=device)\n",
    "model_chkpt.load_state_dict(checkpoint['model_state_dict'])\n",
    "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "val_c_index = checkpoint['val_c_index']\n",
    "\n",
    "for k, v in checkpoint.items():\n",
    "    print(k, v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clinical_rna_feedforward.feedforward.0.weight: torch.Size([1024, 19975])\n",
      "clinical_rna_feedforward.feedforward.0.bias: torch.Size([1024])\n",
      "clinical_rna_feedforward.feedforward.3.weight: torch.Size([1024, 1024])\n",
      "clinical_rna_feedforward.feedforward.3.bias: torch.Size([1024])\n",
      "clinical_rna_feedforward.feedforward.6.weight: torch.Size([512, 1024])\n",
      "clinical_rna_feedforward.feedforward.6.bias: torch.Size([512])\n",
      "clinical_rna_feedforward.feedforward.9.weight: torch.Size([512, 512])\n",
      "clinical_rna_feedforward.feedforward.9.bias: torch.Size([512])\n",
      "clinical_rna_feedforward.feedforward.12.weight: torch.Size([256, 512])\n",
      "clinical_rna_feedforward.feedforward.12.bias: torch.Size([256])\n",
      "clinical_rna_feedforward.feedforward.15.weight: torch.Size([256, 256])\n",
      "clinical_rna_feedforward.feedforward.15.bias: torch.Size([256])\n",
      "clinical_rna_feedforward.feedforward.18.weight: torch.Size([128, 256])\n",
      "clinical_rna_feedforward.feedforward.18.bias: torch.Size([128])\n",
      "clinical_rna_feedforward.feedforward.21.weight: torch.Size([128, 128])\n",
      "clinical_rna_feedforward.feedforward.21.bias: torch.Size([128])\n",
      "clinical_rna_feedforward.feedforward.24.weight: torch.Size([64, 128])\n",
      "clinical_rna_feedforward.feedforward.24.bias: torch.Size([64])\n",
      "clinical_rna_feedforward.feedforward.27.weight: torch.Size([64, 64])\n",
      "clinical_rna_feedforward.feedforward.27.bias: torch.Size([64])\n",
      "clinical_rna_feedforward.feedforward.30.weight: torch.Size([32, 64])\n",
      "clinical_rna_feedforward.feedforward.30.bias: torch.Size([32])\n",
      "clinical_rna_feedforward.feedforward.33.weight: torch.Size([32, 32])\n",
      "clinical_rna_feedforward.feedforward.33.bias: torch.Size([32])\n",
      "wsi_fcn.conv.weight: torch.Size([64, 512, 1])\n",
      "wsi_fcn.conv.bias: torch.Size([64])\n",
      "attention.attention.0.weight: torch.Size([64, 64])\n",
      "attention.attention.0.bias: torch.Size([64])\n",
      "attention.attention.2.weight: torch.Size([1, 64])\n",
      "attention.attention.2.bias: torch.Size([1])\n",
      "baby_feed_forward.0.weight: torch.Size([64, 96])\n",
      "baby_feed_forward.0.bias: torch.Size([64])\n",
      "baby_feed_forward.2.weight: torch.Size([32, 64])\n",
      "baby_feed_forward.2.bias: torch.Size([32])\n",
      "baby_feed_forward.4.weight: torch.Size([16, 32])\n",
      "baby_feed_forward.4.bias: torch.Size([16])\n",
      "baby_feed_forward.6.weight: torch.Size([8, 16])\n",
      "baby_feed_forward.6.bias: torch.Size([8])\n",
      "baby_feed_forward.8.weight: torch.Size([1, 8])\n",
      "baby_feed_forward.8.bias: torch.Size([1])\n"
     ]
    }
   ],
   "source": [
    "for name, param in checkpoint['model_state_dict'].items():\n",
    "    print(f\"{name}: {param.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [02:05<00:00, 125.94s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test c-index: 0.7354965585054081\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA04AAAK9CAYAAAAT0TyCAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAbkFJREFUeJzt3Ql4VNX5x/FfEkhCQLawK6IiQkAWcUGwijuKS6m1UrCKqFgX0GprBWvZrILVWiygtrZ2+0tFW7WtWpci7rsRrQq4obiwyiZkJbn/5z3jhEmYyc0kM5nt+3meYTJ37tx77jLDfe855z1Znud5AgAAAABElB35LQAAAACAIXACAAAAAB8ETgAAAADgg8AJAAAAAHwQOAEAAACADwInAAAAAPBB4AQAAAAAPgicAAAAAMAHgRMAAAAA+CBwApBwn3zyibKysvSnP/1J6ci2y7bPthPRe+yxxzRkyBDl5+e7/bhly5a4ru+1117TiBEj1Lp1a7e+ZcuWaebMme7veHr66afdOuw5Xb+vqbKNABAOgROAWhf3r7/+eq3pW7du1WGHHeYuWu0CNh3ZdtvjwgsvDPv+z372s5p5Nm7c2Ozly2RfffWVzjrrLLVq1UoLFy7UX//6VxfQxEtlZaW+973vadOmTfr1r3/t1terV6+4rQ+J9eijj7qgOJ5KSkrcOhIRLL733ntu3dy0AWKDwAlARNu2bdOJJ56ot99+Ww8++KBOOukkpSsLDP/xj3+ooqJit/f+9re/ufcb65xzzlFpaSkX4I2s/fn66691/fXX64ILLtAPfvADtWzZMm7r++ijj/Tpp5/qJz/5iS666CK3vg4dOui6665zxxDpFzjNmjUr7oGTrSNRgZOtm8AJiA0CJwBh2cXqqFGjXDMlCyhOPvlkpTMLCi1Q/M9//lNr+osvvqhVq1bplFNOafSyc3JyapqZxcKOHTuUKJ7nNWsAsX79evfcvn37mC2zvv0XaX0tWrRoUvAMAEh9BE4AdrN9+3YXSBQXF7ugqW7Q8M9//tNN69Gjh/Ly8tS7d29XI1BVVVVrvqOPPloHHnig3njjDddnxJpb7bvvvrrzzjt9y2C1XOedd572228/d8HarVs3nX/++a7pVqhg35MPP/zQzW8XvO3atdPEiRPdnd6G2nPPPXXUUUdp0aJFtabfc889GjhwoNuOcF555RW3r2ydBQUFGjlypF544YUG9XGyIO3II490Tc/22GMPt0/ffffdWvPYNrVp08bVhIwePdrNd/bZZ9e7LV988YWrnQkeH9vnl1xySU1tWqT+OuHKuc8+++jUU0/V448/rkMOOcQdw9/+9rdufxxzzDG7LaO6utrtyzPPPLPWtHnz5mnAgAHuWHbt2lU//OEPtXnz5nq3w86fCRMmuL8PPfRQVzbbH0H333+/Dj74YFemTp06udoh2/bG7j+b146fseZ6tj4rQ6R9Zq8nT56shx56yO0P29e2jXWbtFoN1qWXXqq+ffu6shYWFrrlN7YWIFiW999/322znXudO3fWz3/+cxfYfvbZZ/r2t7+ttm3buu/Nr371q7ABop0jdizsmAwePFh//vOfd5vP+pPZfrF12HfLjkekPmYrVqxwx71jx45umXa+/Otf/1Jjvfnmm+6GjW2HHcPjjjtOL7/8cthz1r5zV111ldsP9n36zne+ow0bNtS7fNsua/5pgk1xQ49xQ89ba95sN5nsHAz+xtlvlbFjbGUyVvMTXEd9zQOtuajN26dPH7deO1++9a1v6cknn4xqf9u+sfPM2Hc1uG76lwGN16IJnwWQhuxuvF2sWBOpv//97+6iuS77D9kuZOxCxZ6feuopTZ8+3dXY3HzzzbXmtYsMu2C1firjxo3Tfffd5y7ic3Nzay4uwrGLhI8//tgFQHbxZwHF7373O/dsF091L2Jt+XbBMmfOHBfw/f73v1eXLl100003NXjbx48fryuuuMIFjrZdO3fudBfntp1lZWW7zW/bbfvKLt5nzJih7Oxs/fGPf9Sxxx6r5557zvUNi8T6zthFqF1wWRktyLvjjjvcBZJdMFrAEmTlsPnsvVtuucUFaJF8+eWXbr12cWtNzfr16+eCCTuWtg7b79FauXKlO3Z20Thp0iQXAIwdO9Zd/K1du9Ydn6Dnn3/eleH73/9+zTT7nJ0zdiwvv/xyV4O3YMECt512wRup6Z31LbN12XGfPXu2O74WpJvg8iygsmO+bt063XbbbW55ttzQGqOG7j8rpwV9N954oyunLdsulutj2/vAAw+4wMiCst/85jf67ne/q9WrV7sLXmPfJau5tH2y1157uYtpO9YWlFlTqvqOZ33sGBQVFWnu3Ll65JFH9Itf/MJdRFtga+egnVcW+FuzQ9sWuzFgrMbQ1m03Gyzws/1q57kFEnbe2HfAWBBmAZht48UXX+zWZU12g8FsKPteHnHEEW7/TZ061QUv9l0fM2aMu/ligUw0bHl2U8GCpp/+9KfuHLHtsnI/88wzGjZsWK35p0yZ4ppU2vfQ9q8FPLZtixcvjrgOO952rtpvjX0fw73vd95aAGrNmS04su22887Wb+eEsel2rO03z/bBGWec4aYPGjQoYrnse2XntPW5tO+y/a5acGa/ayeccEKD97cdbyu3nZPXXnutO34m+AygETwA8Dzvj3/8o2c/Cb169fJatmzpPfTQQxHnLSkp2W3aD3/4Q6+goMArKyurmTZy5Ei3zF/96lc108rLy70hQ4Z4Xbp08SoqKty0VatWufmsDPWt429/+5ub79lnn62ZNmPGDDft/PPPrzXvd77zHa+wsLBB226fv+yyy7xNmzZ5ubm53l//+lc3/ZFHHvGysrK8Tz75pGY9GzZscO9VV1d7ffr08UaNGuX+Di33vvvu651wwgm77VvbTvP111977du39yZNmlSrHGvXrvXatWtXa/qECRPcZ6dOndqgbTn33HO97Oxs77XXXtvtvWA5g9tSV91yGjsfbNpjjz1Wa96VK1e66fPnz681/dJLL/XatGlTc/yee+45N98999xTaz5bXrjpkcoUuj123tj5c+CBB3qlpaU10x9++GE37/Tp0xu9/5YuXermv//++2tND7fP7LWdLx9++GHNtLfeemu3/RLuXH7ppZfcfH/5y192W7c91ydYlosuuqhm2s6dO7299trLna9z586tmb5582avVatWbj8EzZs3z33+//7v/2rt0+HDh7tjt23bNjfNfgNsvl/+8pe11nPkkUfu9n097rjjvIEDB9b6/tv5NmLECPc9iXYbx4wZ4/btRx99VDPtyy+/9PbYYw/vqKOO2u38OP7442t9D6+88kovJyfH27JlS73rse99uO9CQ8/bBx98cLfzsy77zbB57Lg1xODBg71TTjml3nkaur/tPG7I/gbQMDTVA1CL3bm3Zh89e/aMOI81RwntC2WZ5uzusNVoWPORun1D7M5tkNV42Gu7U2tN+BqyDqvtsXUcfvjh7rXdea3L7oiHsvJYsz67W9tQdsfamt1ZMghjzfasiWG4pA7W9+uDDz5wtVS2HiufPazGzpoUPfvss66pTzh2h9vu7FstTvBz9rC+UHYnfenSpbt9xu5Y+7H1WbOx0047zTXbqauxfaysRsJqbEIdcMABLkV46B19a6ppNVu2/uDxs5oMa+Zld8pDt9Vq6axWL9y2+rG773b+WC1PaL8ja+poNWxW+9KY/dcYxx9/fE0tWLAmwWpJrLY03LlszbDsfNl///1d7US4c7mhQrNA2rljx9ziOWuCF2TrsFq70PJYQgSrJbTzL8hqT6x2wmpbrUYnOJ99f0P3na3HandCWQZCq321Wt/g74E9bDvtvLHvSd0mlPWx8+iJJ55wtSfWVDeoe/fu7vtmNWB1v9dWuxp6ftv335ZjzSQbo6HnbbBm8+GHH3bHNhZsmVajZPstnFjvbwANR+AEoBZrDmPBjQUQ1kQrHPtP3ZqC2IWFXSRacxTraxFMXx7K+tnUTR9tF92mvj4ednFgTYasqZRdeNo67AI+3DrM3nvvvVsQZIL9EWx51qws+Ai3DGMXZhbYWFMrC0LsdTjBixprtmRlC31YM8Hy8vKI6wh+1ppT1f2sXTAGExQE2cWrNfHyY3067IIyUn+sxgru93BNxazJUvAizfpOWNlteui22n6wZpN1t9Uu0utua0MEL4YtIKjLAqe6F8sN3X+NUfe8C557of1grGmcNWW1mxHWD8r6wtj2W/Ac6RxpzLrt+2iBpC2/7vTQ8tj+sf4z1rQ0VLAJV3D/2bMFKxYohKq7363JnwVs1seq7jG2pnMmmuNs57HdhAl3fK2MdoPA+nFF8/2PVkPPW+sTZ00zrU+S7Xdr2mjNde3731jWLNXODfudtP6VV199tevzGa/9DaDh6OMEoJb+/fu7O81Wa2J3W+3COLT2yf5Dt4sFC5jsP3i7224Xa3bn/JprrolYyxItu5tq/ULsosFqNuzizZZtAV24ddid8HACLark+hYE76QHA55wA3iefvrp7uLW3reLHytHOMEyWJ8uK184dS84637W+lWE9g8KvdAPZeWpe5HbFJFqnuom9whXYxLKAqRp06a5u/M/+tGPXB8Lu0gPTVtv22oXn9bXJpxgx/l4ivX+i+a8M1ZDYxfTto+GDx/u9pEdA+vz1JTvS7h1N6Q8sRbcButLVbdmMshq2OIp1tvd0PPWjqPVslq/y3//+98uiYr13bSEHDYt0m9AfaxvkiUzsSQ8diPFbsTYmGKWVMdqGZNhfwOZisAJwG6sQ7LVtljTJwueLNFB8ELBahWsSYh1fg52NjfWcToc63xtzddCa50sG5gJTYAQyu4SL1myxN3FtTv1QZGarjSEXciE3n22mrBIQYI1Efq///s/l/ih7t37oGDzLAsgrblWNIKftQuzaD9bHztGVp533nmn3vmCd+MtCA5NohBtsyaribJzxZrrWUd8Oyds31mgErqt//3vf11H9kgBWLSCTSetRtRq7ULZtGQbL8surC0QD81uZ81PI2WnizfbP1aDYRfgoQFlsJltcP/Zs30Pg8lSgurWRAeb01lzv1icz3YeW8KMcDXeVkYrc31NiWNxEyHa89aaEdvjhhtucE18LXPjvffe6wKdxjSRtSQflpTCHrb/7bfWkkbY8qLZ37EaAgFAAE31AIRlNU7W18eahQTHOAq9sxt6J9fSXN9+++1hl2MZzaz5X+i89toujqy/QDjh1mEsU1Zj2brsIiP4sJq1SOxOrjV5saYw9S3PLq4sS5td2NRVXypku0tsAY5lbwvXL8IvjXIkdkFpgYvd+bZ+QHUF92cwcLN+WEEW3IZLR+3Hap3szvrdd9/t+lmENtMzVmNnNVmWrj7cudGY4MH68ljQaXfgQ5tEWXr35cuXN2nMrXiw87nuuTx//vyINXzxZlkurblqaP80OxZWJguQginZbT6bblnhgqzMNl8oOxaW7c6+12vWrGny+Wz7yzLVWY1LaHNe639pQYllR7TvTywEb+jUPQ8bet7azZi6xzZYAx08N4NZExt6rtcdcsGOidUgBZcXzf6OtH0AGocaJwARWT+mu+66yzU9sSZsNj6NJUuwGgu7g26dye2OpjU5i9Qkxmp2LC2yXQBZm327WLPECpZiOlIaarsosjusv/zlL11gYSl3rclKpFqtWLMxbezhF6RYExqrlbJxXuzOsJXT+vtYx3HbBgtgwrH37GL0nHPO0dChQ12TLQskrV+VJTawu9yW9rgxLBizfWUXv9Zh3vqE2MWVNaezTvVWw2QXpdYnxJIIWFNIu1C1wCdYhmjYBaYFmvawu+R174BbOSwZiKVXtuNu67bjbrWHViZLIR465lND2OftnLJ9bsu3JAfBdORWi3nllVcqmVhKf/uOWBM9C9hfeuklV5sRTFfe3Oy8sItuSz9uCVpsn1mtmDXLtZsTllbdWJIPOxct3bV9f63sVqsYrl+WjYdkAY31ybGU9VYrYsfEtvXzzz/XW2+9FVUZLbW69TW0ZVoSEGu+amW24MF+F2IlePPGfsvshoZ9F+z72NDz1m422E0j+620GxKWrMF+M+07boGnsRor23f222e/gfY9sX6Ikfoi2rwWGFnZbF67CWLHx2p1o93fFsTZNtn3xY6b1QZbLa0FXwAaoYHZ9wCkuXBpn4NuueUW996pp57qVVZWei+88IJ3+OGHuzTHPXr08H760596jz/++G5pby0d+YABA7zXX3/dpTrOz8936a0XLFhQa/nh0pF//vnnLqW4pe22FN3f+973XDriuml966YJry+1tl868vpEWs+bb77pnXHGGS71eV5entu+s846y1uyZIlvWWxfWTpz2z7bN7179/bOO+88t7+CLI1069atvWh8+umnLi15586dXZn2228/t32WCj7ojTfe8IYNG+ZSPu+9997erbfeGjEduV9q5COOOMJ97sILL4w4z+9+9zvv4IMPdueMpZS2VMp23tgxbex5uXjxYu+ggw5y29ixY0fv7LPPdudNqGj3X7TpyMOdN7bPQtN/W0rwiRMnep06dXLpvu2Yr1ixYrf5ok1HXvdcjLStwe9hqHXr1tWUyc4BOx6h37+gr776yjvnnHO8tm3buvPU/rZzvu731VjqcDvvunXr5oY02HPPPd1vxt///veot9EUFxe7fWX7zIY6OOaYY7wXX3yxQedHQ9dj6dWnTJniviuWyr3uMfY7b62M48aNc98hOw8tTb5tc+h32Fi5bTm2r/1Sk//iF7/wDjvsMPfbZ+vt16+fd8MNN9QM3xDN/jZ33XWX+w2w9OykJgeaJsv+aUzABQB+7K6pNd/y63MDAACQ7OjjBAAAAAA+CJwAAAAAwAeBEwAAAAD4oI8TAAAAAPigxgkAAAAAfBA4AQAAAICPjBsAt7q6Wl9++aUb4M8G7gQAAACQmTzPc4NX9+jRww1uX5+MC5wsaOrZs2eiiwEAAAAgSXz22Wfaa6+96p0n4wInq2kK7py2bdsmujgAAAAAEmTbtm2uUiUYI9Qn4wKnYPM8C5oInAAAAABkNaALD8khAAAAAMAHgRMAAAAA+CBwAgAAAAAfGdfHCQAAAGhK+uqdO3eqqqoq0UVBA7Vs2VI5OTlqKgInAAAAoAEqKiq0Zs0alZSUJLooiDLxg6Uab9OmjZqCwAkAAADwUV1drVWrVrmaCxssNTc3t0GZ2JD4GsINGzbo888/V58+fZpU80TgBAAAADSgtsmCJxvzp6CgINHFQRQ6d+6sTz75RJWVlU0KnEgOAQAAADRQdjaXz6kmVjWDHHkAAAAA8EHgBAAAAAA+CJwAAAAANKunn37aNaHbsmVLTOeNJwInAAAAII2dd955GjNmjJLJiBEjXGr3du3aKVWQVQ8AAABAs6msrHTp3Lt166ZUQo0TAAAA0BieJ+3ckZiHrTtGnnnmGR122GHKy8tT9+7dNXXqVO3cudO99/DDD6t9+/aqqqpyr5ctW+aazdk8QRdeeKF+8IMfRFy+zX/HHXfo9NNPV+vWrXXDDTfs1vzu008/1WmnnaYOHTq4eQYMGKBHH3007PJsAOKTTz5ZRxxxRLM236PGCQAAAGiMqhLpvjaJWfdZ26UWrZu8mC+++EKjR492zfn+8pe/aMWKFZo0aZLy8/M1c+ZMHXnkkfr666/15ptv6pBDDnFBVqdOnVzgE2TTrrnmmnrXY8uaO3eu5s2bpxYtWujjjz+u9f5ll13mxsp69tlnXeD03nvvqU2b3fetBUqnnHKKe+/JJ59s1jG1CJwAAACADHX77be7QX0XLFjgaoD69eunL7/80gVC06dPd32QhgwZ4gIlC5zs+corr9SsWbO0fft2bd26VR9++KFGjhxZ73rGjx+viRMn1ryuGzitXr1a3/3udzVw4ED3er/99tttGWvXrtXYsWPVp08fLVq0yDX3a04ETgAAAEBj5BQEan4Ste4YWL58uYYPH15rkFhrAmdB0eeff669997bBUVPP/20fvzjH+u5557TnDlzdN999+n555/Xpk2b1KNHDxfM1MeCrvpcfvnluuSSS/TEE0/o+OOPd0HUoEGDas1zwgknuCaFixcvVk5OjpobfZwSrXSN9MaPpeIfB/6WtGaNVWdKTz4pHX20tSX9Zr63Z9bM0+h1RVpGU5Yfi7I1x3IjLS9e5QcAAOnNgg1rLpeIR0igE29HH320C5LeeusttWzZ0tVK2TQLpqyZnl9tk7Hmd/WxflJWC3XOOefof//7nwu05s+fX2sea6JnTfmsGV8iEDglml2sr7xVWnFrrcBp1izplVeszaj07rvfzPfOrKYHTpGW0ZTlx6JszbHcSMuLV/kBAACSXFFRkV566SV5IckmXnjhBe2xxx7aa6+93OtgP6df//rXNUFSMHCyh/0dC9Zk8OKLL9YDDzzgarfuuuuuWu9bH6kJEybouOOOS0jwRFM9AAAAIM1ZXyTLiBeqsLBQl156qUvYMGXKFE2ePFkrV67UjBkzdNVVVyk7O1DHYpnuBg0apHvuucf1hTJHHXWUzjrrLJdavCE1Tn5+9KMfuUx5BxxwgDZv3qylS5e6oK6uW265xWX4O/bYY13QZrVfzYXACQAAAEhzFmQcdNBBtaZdcMEF+v3vf+/Sfl999dUaPHiwOnbs6KZfd911teYdOXKkC7yCtUs2X//+/bVu3Tr17du3yeWzYMgy61m/qrZt2+qkk05yNVzh2PTQ4MmCrbRvqmdtFC1fu3Uosw5pDz30kO9nbOcMHTrU5Znff//99ac//alZygoAAACkIrtetqZ4dR8WNAWDoldffVXl5eVas2aNaxJnKcNDzZs3z30mtIbHAimb3499bsyYMbWmWQBm022MKGP9mSw7X1lZmdavX+9So1uNWLh5zW9+8xuX/a+5gqaEB047duxwke3ChQsbNP+qVatcp7BjjjnGHSir0rOOZI8//njcywoAAAAgcyW0qZ61Y7RHQ915553ad9999atf/cq9tnaPluHDqutGjRqlVONVeyrZWi6VfZNO0v7O2aHSry2ebaWKsnJJeSorKdOO4HzfzBNkY341OKnKztJdzzbidEPfa8pymyLWy420vMasx1KANmM2GwAAACRWSvVxsowfltc9lAVMVvMUiVU52iNo27ZtanaWrW3z21L5xppJa9bn6+NPcvWt759mdW9hP3b9DXnu+cKL8nWhhoedb0ivN1V8w9DoruH/+63GvdeU5TZFrJcbaXnRrKfTcOmEFwieAAAAMkRKBU42WnDXrl1rTbPXFgyVlpaqVatWu33GBuiykY0T6oPfBtJdh/jtP2Zo1gMzm7zoZZ8epJLyArXOL2nyshCFjS9J5Ruk/C6JLgkAAACaQUoFTo0xbdo0l04xyIIsyxHfrPr8MFBDEVLj9MPe+Trt3Ef11ptb9cnbK9y0nW0OkloU6NO1HbToP4fq4P6f6o33eun4wz/QoUWr1WLLs6osPEHVuV3VKr9Ks24NdM7bPPCfatl5p7z8rrL6j9zqdeHLsfFF6Z3rpb5XSK33r/3e9g+k938jDfi51HnE7p8t3xR4zuu4+3tb3pGWXS0NuVlqf2D4ded1lVrVDnqd0nVSeYTyNma5kZZn5d/0qrTytt23P7jtB1wuFQ4Lv43B9ewskR7+ZmRs+7tqV21m88mScnITsF4AAIDMlVKBU7du3VzKw1D22lIWhqttMpZ9zx4J1ap74BGi+76STTn4yGLpsfGBiSe9IXUcquJiadF/pDHjeumNn0vnTe6js0/+WnpstnTSt6WOfbRjhzTr1sDHPtxxvL6oDvydn299v6TccNfVVjtigdO+57r11LKpOBA89Byz+3t+grUu3Y6N/rMFPWK73PqW165fIHCqu/3Bbd9vgv96QvtAbf9EKosQ9MVTTr7UtojgCQAAoBmlVOA0fPhwl2c+1JNPPummZzLLFtm6tVRRIZWVWcrHRJcoQ2S1kHJaN+86qyukqjJLLdK86wUAAMhwCQ2ctm/f7vK1h6YbtzTjNqDW3nvv7ZrZffHFFy6Pu7n44ovdaMU//elPdf755+upp57Sfffdp0ceeUSZzGqXgjVMlZWJLk0Gyc5NTK1PFQcZAACguSV0HKfXX3/djWAcHMXY+iLZ39OnT3evbUCt1atX18xvqcgtSLJaJhv/ydKS28BdqZiKHAAAAEDqSGiNU3AU4PpGOQ73mTfffDPOJUttln3dsmSH7ecEAAAARLj2tmF+tmzZ0uDPnHfeeW7+hx56qMnrt+v8IUOGaN68eTGdNy1qnBB71sdp+fLAw/o8AQAAILNZcDNmzJjdpj/99NPKysqqCZTGjh2r999/X4nywAMP6Prrr1eySqnkEGnJsu31vcplmA5m3uveXZoxQxo2TBo5Uhow4Jv3DpyxW3a+UFbDVFhYT5KI+pbRgOXXuw2N/WxzLjfS8uJV/niqDqZBJzU5AACIDctSHSlTdTxVVFQoNzfX5TlIZtQ4JZpdrB/8K2nor2oFTjNnSiecYHcCpCFDvplv0Ezfi/vQRBFh1xVpGQ1cftTLbYpYLzfS8uJV/oYqWy+tnB94rjv93bmBR/A9C7Atq97W5dLmZdK25VIVVYsAACSC3aS2IWIS8YhHFmVrqte+ffta037xi1+oS5cu2mOPPXThhRdq6tSprolcXbfccou6d++uwsJCXXbZZaqsJ2PZzJkz3TIsV4HlMMi38XS+aX5nTQWDbr/9dvXp08e937VrV5155pkRl2l5ENq1a6d77rlH8UKNE5Bo5RukDxYExqsKjl0VnL7qj4G/9zot8J5l8ssrDGQjJzU5AAAJVVIitWmTmHVv3x4YjiaeLAi54YYbXABzxBFH6N5773XJ2SzYCbV06VIXNNmzZcy2Jn8WGE2aNCnism2+f/zjH655Xk5OTtgkcpdffrn++te/asSIEdq0aZOee+65sMtatGiRy75tz6eeeqrihcAJSDUWPAWRmhwAADTAww8/rDZ1oryqqqp6PzN//nxdcMEFmjhxonttma+feOIJN6RQqA4dOrghgywA6tevn0455RQtWbKk3sDJmufZkEOdO3cO+75l1m7durULhKy2q1evXjWZuEMtXLhQP/vZz/Tvf/9bI62PSxwROAEAAACNUFAQqPlJ1Lqjccwxx+iOO+6oNe2VV17RD37wg4ifWblypS699NJa0w477DA3lmqoAQMG1Ko1stqn//3vf/WWxwKhSEGTOeGEE9w8++23n0466ST3+M53vqOCkA3/+9//rvXr1+uFF17QoYceqngjcEoDpaW7+jUloD8fAABARrLhX+LdXC5WrPZm//33rzXt888/j8myW7ZsWeu1Zeqrrq72LU99rJapuLjYZf6zWi6r7bK+Ua+99lpNPyyrgbJ57r77bh1yyCFuvfFEcog0cPTRduIEHuPH7+osaOM5+T1IWQ4AAIBw+vbt6wKVUK/VeR1PLVq00PHHH69f/vKXevvtt/XJJ5/Uqu3q3bu361f1z3/+U1OmTIl/eeK+BsSF1VIOHy699FLt6cXFgRqo4HhOfiyJSVERg+U2SlWptDMGO84lePjmeWfJ7tPrvpfTKnCLCwAAII4sGLF+SlabM2LECC1evNgFMNZ8rjn6ZH388cc66qijXB+qRx991NViWTAX6oADDnDBk2Xks0ArngPiEjilKLtutoD75ZcDQZT17RsxIvCeBUENafcacbwnNMxTR8d2eS+Ob9h7rfeR+lwqVVdJLVpJ+V2lNvvEtiwAACDjnX322S54+clPfqKysjKdddZZbjDdV199Ne7rtuZ4lnHPmufZui0t+d/+9jfXn6ouC6asJsqCJ+trZZn/4iHL8zLrsnnbtm0ux/vWrVvVtm1bpTJrardsWaBt7c6dgaZ65s03Gx442TgAloo/Ly/uxU0P9nV58ghpY52qvkTqP1UaODPRpUgiDAoMAIg9u3hftWpVrXGHMtEJJ5ygbt26uTTh6XDsookNqHECoq3qO/YpaePLUk5Bwy/QbUym8o27T6/YLK1/QVq9SOrxHal1yCC8JV9KXzwU+HvvcVLbA6R3ZgVeD7pBysqWslpI7YoCg+EiICdfaltE8AQAQBOVlJTozjvv1KhRo1xNjtX4/Pe//9WTTz6pTETgBDQmeLImctEETi16Sa17hX+vVfdA4NT7HKldSPXz1nd3BU69vie13ndX4NRjtNSiIDAIbkbVGftgUGAAAGLGstRZ3yIbBLesrMw1ibNBay1hQyYicALSZTBcBDAoMAAAMdGqVStXw4QA0pEDAAAAgA9qnOCSTDR3SzfSnwMAgFSUYXnV0oIXo2NG4JThGjreUywxdhQAAEg1LVu2rEmYYE3YkDoqLJW05Y/KyWnScgicMpgFLoWFzbtOxo4CAACpyC66bWyh9evXu9cFBQUueQKSmw2au2HDBne8bIDcpiBwynCJqPWppO9+bXmdpT6TA891p+87cdffAAAgoWz8IhMMnpAasrOztffeezc50CVwAhItv4vUd0r46QOm7nq9s6RZiwUAAGqzC+/u3burS5cuquROcMrIzc11wVNTETgBAAAAUTbba2p/GaQe0pGnodJS+hABAAAAsUSNUxoaMUIaOlRatCiQ+hvIONXNnGMfQIrJknJI7QogOgROacKyYlqwVFwceG3PVvNUUJDokgHNyG4UVJVJW5s5xz6A1JKTL7UtIngCEBUCpzRhNUtWw7RpU6DGCchI2blSXqFEU1UAkVRXBG6w8EMBIEoETmkWPKXKeGzl5fHdDwyum+HBEwDUp4psaACiR+CEZmcD4C6PY0uq/HypqIjgCQAAALFD4IRmZcFMYWH8ll9REQjMyCoIAACAWCJwQrOLd01QRoxHV1UaeM5pRepEAACAZkDgBKSiJ7/JANJhqDSCvPMAAADxxgC4QKqw2iULlEJtLt5V+wQAAIC4ocYJSBVWq2S1SxYo2SNY6wQAAIC4I3ACUi14asGoxgAAAM2NpnoAAAAA4IPACQAAAAB80FQPaam8PH4t5XJz4rNsAAAAJC8CpzRW2oBka63ScBggGwB3+fL4LDs/Xyo6QIrzUFQAAABIMgROaWxEA5KuDR0qLUqjYYBscN3Cwvgsu6IiEJR5XnyWDwAAgORF4JRmrAbJgqHi4obNb/NZzVRBGiVqs+ApXior47dsAAAAJC8CpzRjNUdWg+TXTM/eb0iNFAAAAAACp7QNntKpBgkAAABINNKRAwivbL20cn7gORPWCwAAUA9qnACEV75B+mCB1O1YKb9L+q8XQGapjtO4FUDGypJy0jvvMIETAADIHJZFtqpM2hqncSuATJWTL7UtSuvgicAJAABkjuxcKa9QYmgJIHaqKwI3JNL8i0XghIjWr5cWL5bGjpW60GIKAJBOwROA2KpK/zFbSA6BiDZskBYsCDwDAAAAmYwaJyBK5dafuNw6QAYeWVleXAfd9VVVGqfllu163lkSn3XEY705rQI5+QEAAGKIwAmIQlmZtHxFlrStINAJMruF8vM8FfWtSFzw9GScRzJ+cXx8lx/r9XYYKo1YRPAEAABiiqZ6QANZYFRYKLUusEe1WreqVssWnsrKs+R5zXyRbrUqFiBgd5uL41cLBwAAMhY1TkAUXK1Slf3hSdmeVOWpcmcCajasNsVqVZoaINiYSeUbw7+3bYX0zmzpwOlS237h58nrJOV1To712r6Id+0bAADIWAROUGlp5GZpweeSGHZxaUUXlNiwndiioGnLaNFLat0r/HvWFNF0GCK1G9C09STLegEAABqJwAka4XOTfnyMu7gMHSotogsKAAAAUgh9nDKU1fpYAJMIxcWRa7kAAACAZESNU4ay2h6r9Vm9WtoYoavJihXS7NnS9OlSvwhdTTp1kjo3sIuLBUt+tVsAAABAMiJwyvDgqVevwCOc/G+6mgwZIg2gqwkAAAAyGE31AAAAAMAHgROA8Czdd5/JjUs3norrBQAAqAdN9QCEl99F6jslc9YLAABQDwInIAbKy1M7t3pWlhcY3BcAAABhETgBTZFlAwRna/n7LZXK8vM8FfWtIHgCAACIgMAJEVma8cmTG55uPNbee0+68Ubp2mul/v2VlHJbSoWFOyVPKauiIktl5VnyPKs1S+ENAQAAiCOSQyCiLl2kKVMCz4nw4YfSa68FnpOZBU9WU5O6jzQMlso31H5dtl5aOT/wHPp3pHnibet70os/CDw3RazKHKk8sd4nzbmPkVjJcKyToQwA0gqBE4D0U75x90DqgwWB59C/I80Tb9s/lDa9FnhuiliVOVJ5Yr1PmnMfI7GS4VgnQxkApBUCJwAAAADwQeAEAAAAAD4InAAAAADAB1n1kBClpf7zVFTsei4pafiyW7WycYkaXzYAAACgLgInJMSIEQ2f92c/CzwaauhQadEigqeMVlUm7Syp/Tr02W+e0OlxKV/FruemrCtWZY5Unljvk+bcx0isZDjW9ZUhhztsAKKX5XleGuYijmzbtm1q166dtm7dqrZt2yqVlZdLy5ZJrVsH0konOzvTxo+Xiovjv64335QKCuK0cLu43LZcym4l5aT2wLfBGr0dJdkaMrBCeXkp8HNgqYXDZckqXSO9flkiSgQg1bTtJw26QcrvEngAaPq1UdUOqcMQKSdP6RobUOOEZmM396wmKLSZ3ooV0scfh5//pZekhx+WTj1VGj48/Dz77Sf16xf425YbTU0WUtSniwMphgGgsbatkJ7/rtRnstR3SqJLAyBFEDih2YOn0Joga1Znj3CsFs0Cp5EjpdNPb7YiItn1Git1O3b36RWbpI1vSB/dIe09Xsprv+u9ki+lLx6Suo2SrFJt3ePSnmOkgh675infLK3+m9T7Qqn9QVJeh93XkddJyuvc8Auz7RHuCmx4SVrzsNT9VKlzhLsCbfYL3BV3Y09tjLyOd2ZLB04PzBtOsMyRyrNzm7T+RWnjc1KnI6UOA3ffb7avCg+V2uwbeflBsSovkl8yHOtoy2DN9l45P/D3iEVSQc+mrR9ARiFwAuCUl8envX9WlhfbpqT1Na3J7RgInHqdKbUbsGv61ncDAUCfHwZeW+C037m7z2OBU4/Rtac3VsehgUc4ObmBwKnbSGlPn7sCLXpJrXtFWE5+4NmaRviVub7y2AWsBU49T69dnuB+q7uvmqO8SH7JcKyjLUNoX6e2RVKLeLXpBpCOCJyATJcllZVla/n78emvlZ/nqahvRUr0wwMAAIiEwAnIcLktpcLCnYEmbDFWUZGlsvIseZ7VZqVA4gkAAIAICJwAuOApPjxV7iTlLwAASH3ZiS4AAAAAACQ7Aickrf33lw49NPAMAAAAJBJN9ZC0+veX/u//El0KpBRLbWzjstRNcVx3ekPmiac2+0sdLb13E+8KxKrMkcoT633SnPsYiZUMxzoZygAgrWR5npdRPbajGR042ZWXS8uWSa1bB8Y8ynQlJdJBBwX+fvPN2uNFxXx07G3LpexWUk7cOgelhYoKaUdJtoYMrFBeXkb91ABIRpaO/LFv/qM46U3SkQOxvDaq2hFI/5+Tp3SNDWiqBwAAAAA+CJwAAAAAwAeBEwAAAAD4IHACAAAAAB9k1UNaKi2Nz3JbtZIYzhUAACDzEDghLY0YEZ/lDh0qLforwVO0KiulvNRKsgMAAFALTfWQNqw2yAKbeCoujl9tVlrKksrKsvXRqpYuNTkAAECqosYJaSMrS1q0KD6BjS0zXrVY6Sy3pdS2bZXKyrPkeVZPx1hOAAAgNRE4Ie2Cp7gNfItGadnCU0UFjRsBAEBqo6keAAAAAPggcAIAAAAAHzTVSwN1O93n5iaqJAAAAEB6InBK8f48+fmWtSyQ7tnY34WFBE8AAABALBE4pTALjoqKJO+bRGXl5dLy5YkuFQAAAJB+CJxSHDVLAAAAQPyRHAIAAAAAfBA4AQAAAIAPAicAAAAA8EHgBAAAAAA+SA4BoFmUl2c1+rNZWR6JUAAAQEIROAFRKi2VtDNbys6ScrLUKt9zY2ohgiwbXyxby99v2ehF5Od5KupbQfAEAEAyqy6PYma7jkqt/9gTHjgtXLhQN998s9auXavBgwdr/vz5OuywwyLOP2/ePN1xxx1avXq1OnXqpDPPPFNz5sxRvo0ECzSDEUfal3xgzeuhg8u06A9rCJ4iyG1pgzLvlL4ZbyxaFRVZKivPkufZDm7kQgAAQPxkSaoqk7ZGMaBoTr7UtiilgqeEBk6LFy/WVVddpTvvvFPDhg1zQdGoUaO0cuVKdenSZbf5Fy1apKlTp+ruu+/WiBEj9P777+u8885TVlaWbr311oRsAzJDq1bS0KFScfHu7xW/la/SsiwVtOKivr7gqfE8Ve4kKgUAIGll50p5hQ2/v1ldEQi0UuyGaEIDJwt2Jk2apIkTJ7rXFkA98sgjLjCyAKmuF198UUcccYTGjx/vXu+zzz4aN26cXnnllWYvezKrqAg806wpdqw2adGib5rpVVVIX69UaXmBRpzUO9FFAwAASI7gKRpVlUo1CcuqV1FRoTfeeEPHH3/8rsJkZ7vXL730UtjPWC2TfebVV191rz/++GM9+uijGj16dMT1lJeXa9u2bbUe6Xxxby0WKyulr77aFUAhdvu3oOCbR6tqtWpVnegiAQAAIN1rnDZu3Kiqqip17dq11nR7vWLFirCfsZom+9y3vvUteZ6nnTt36uKLL9a1114bcT3W/2nWrFnKBFbDVFRkHfGl5VE0MUUjVVfWvmtS1UzVzdZqLbtJbd8AAACQzuM4Pf3007rxxht1++23q7i4WA888IBr2nf99ddH/My0adO0devWmsdnn32mdA+e8vISXYpMqY6u2vW6ukyqLm2eR8WW2kEbAAAA0rfGyTLi5eTkaN26dbWm2+tu3bqF/czPf/5znXPOObrwwgvd64EDB2rHjh266KKL9LOf/cw19asrLy/PPYCYsewvbXrXvu2wR1+poBnWbZ0pt3+Uan0pAQAAUl7Capxyc3N18MEHa8mSJTXTqqur3evhw4eH/UxJScluwZEFX8aa7gHNGjyFps8Mvo73I9qOlwAAAEj9rHqWinzChAk65JBD3NhNlo7capCCWfbOPfdc7bnnnq6fkjnttNNcJr6DDjrIpS//8MMPXS2UTQ8GUAAAAACQVoHT2LFjtWHDBk2fPt0NgDtkyBA99thjNQkjbJDb0Bqm6667zo3ZZM9ffPGFOnfu7IKmG264IYFbAQAA0k7ZeunTxVKvsVJ+l9QqSzKVPR7itX3RLDfV9nGqlTdJJTw5xOTJk/Xpp5+6tOE2HpPVJIUmg/jTn/5U87pFixaaMWOGq2kqLS11gdXChQvVvn37BJUeaJj166X58wPPzbreDTma/9v27hkAEIXyDdIHCwLPqVaWZCp7PMRr+6JZbqrt41Qrb5JKeOAEZIING6QFCwLPzbrejTla8LsO7hkAAACNR+AEAAAAAMncxwkAGqq83Eb+RTLKyvLcGHIAAKQzAicAyS1LKivL1vL3Wya6JIggP89TUd8KgicAQFojcAKQ1HJbSoWFOxn0N0lVVGSprDxLnmc1ghwkpJCqUp/3y3Y97yxpliLFrCzJVPZ4iNf2RbPcVNvHzVHenFbWBEHpjMAJiIFSn/9/y8p2PZc05feqylaWLWVnSTn+P05lZVk1zyWlkedvle8l9W+dBU9IVp4qdybxyQNE8uSIhs334ngljWjLkkxlj4d4bV80y021fRzP8nYYKo1YlNbBE4ETEAMjGvj/7/gm/15ZW6iBUX9q/IU96n1/6OAyLfrDmnT+rQOAwB1xu7jbXJzokgDpZ3NxoCa3RYHSFYET0EitWklDh0rFafD/b/Fb+Soty1JBK5paAUhjdnfI7ogHm+nZmDblG8PPu22F9M5s6cDpUtt+4efJ6yTldY5N2aItS8VmqWLLrnlatpfyOiSm7PEQr2MTzXLr7uPQ/ZyM+zhR53NVacNrcFMcgRPQhP9/Fy3a1UzPxmjaGOH3asUKafZsafp0qV+E36tOnaTOfr9XVRXS1yul7HwpJ9B+zcZo2hhhnKYV77fU7F921vSfblC/Ayp3e9/6ppx/WXeflQJAmv14B++It+glte4Vfr6c/MBzhyFSuwHxL1csy9LcZY+HeB2bWC03GfdxMp3PaYrAKY1VVDRsPjJhNe3/34Jv/v/t1SvwCCf/m9+rIUOkAQOa2MdpZ7WU7Uk5gdqhXj13ukf49QbmGTKoQgOKdj8h6uv3BAAAgF0InNL0Yt4u1C0RQeXulQy12DyFhQRPAAAAQH0InNKQBUFFRZLn012lvFxavry5SgUAAACkLgKnNEUNEgAAABA72TFcFgAAAACkJWqcgFRU/U3nNcvtkM3osAAQc5aWuc/k5EjZHW1Zkqns8RCv7Ytmuam2j1OtvEmKwAloBpZmfPLkBqQbb4jsXKm6QqreKVWVS7ntIwZPnTtVafJFm90zACAK+V2kvlOUkmVJprLHQ7y2L5rlpto+TrXyJikCJ6AZdOkiTYnF71VOrtSmd+BvC562fyTVkwSkS+cqTflhncH7AAAAEDUCJyDVWPAEAACAZkVyCAAAAADwQeAEAAAAAD5oqgcAaLLyckvxGF5WlsfYcgCAlEfgBABovCyprCxby9+PnBY/P89TUd8KgicAQEojcAIANFpuS6mwcGfE7I4VFVkqK8+S51mNVD0pIAEASHIETgCc0tLITa2aolW+p6z4LBpJFDxF5qlyJycAACD1ETgBcEac0Csuyx06uEyL/rCG4AkAAKQ0suoBGcxqgyywiafit/JVWkbUBAAAUhs1TkAGs1ogqw2KR2BjTf/iVYsFAADQ3AicoIqK5l8n2bWSK3gqaEWnfQAAgPoQOGX4BXN+vqUSliorm2+9tr7CQoInAAAApA4CpwxmgUtRkeQ1Y2VDebm0fHnzrQ8AAACIBQKnDEetDwAAAOCPrHoAAAAA4IPACQAAAAB8EDgBAAAAgA8CJwAAAADwQeAEAAAAAD4InAAAAADAB+nIgVRX3YyjF0ejKivk70qpqpkGDLPVZrdsnnUBAICMQeAEpLLsXKm6QqreqaRTHVKhXV0mVVc3z3qryqXc9gRPAAAgpgicgFSVkyu16a2U+HXZo69U0AzrtCBy+0dSM1VuAQCAzEHgBKR68JSsckL/zq39GhmnvDyk6WYay8rylJvEX0sAQOMROAGIO48aoMyVJZWVZWv5+5nRdDI/z1NR3wqCJwBIQwROAOLu7LOlBx+0u/GJLgmaW25LqbBwZ0Y0n6yoyFJZeZY8z070DNhgAMgwBE4A4qJVK6moSFq+PPAoLZUKmqOfE5IyeMoMnip3cncAANIV4zgBiAurXbrnnkSXAgAAIDYInADEDU3zAABAuqCpHhKioiK+y6djNgAAAGKJwAnNXgORn29ZtqTKyvisw5ZdWEjwBAAAgNghcEKzsmDGEgbEKz11eXkgEQEAAAAQSwROaHbUBAEAACDVkBwCAAAAAHwQOAEAAACADwInAAAAAPBB4ASgWWzYIM2fL61fn+iSAAAARI/ACUCz2LhRWrAgEEABAACkGgInAAAAAPBB4AQAAAAAPgicAAAAAMAHgRMAAAAA+GjhNwMAxEJZ2a7nkpLoPtuqlZSVFZdiAQAANAiBE4CYsVTjoVnzgsGSOf/8wPP48dEvd+hQadEigicAAJA4BE4AYmbx4kDK8VgrLpZKS6WCgtgvGwAAoCEInADEzNix0rHH1p7meVJ5ubRihTR7tjR9utSvX/jPd+okde6867UFSyNGxLfMAAAADUHgBCBmunQJPMLJzw88DxkiDRgQ54JUV8Z5BUAYVVlSdbZUVSFVeYkuDepjzX6zcxNdCgAphsAJQHqxi6HqCql6Z6JLgkxTnSVVWeBUQuCU7KrKpLxCgicAUSFwApA+cnKlNr0TXQpkqopv/lft4El5iS4MIqoul7Yul4htAUSJwAlpqcIuYOIklxuUyR88AYmQ883oiDnfPAAAaYXACWnF0lVbXxpLg10Zh24uttzCQoInAACATEPghLRiAU1RUSCTW6xZZrjly2O/XAAAACQ/AiekHWqDkpOlGZ88uXa6cSAd2U2WaGvK+d0CgORH4ASgWVia8ilTEl0KIL6sOW+0NdPWvNhqygmeACC5ETgBABADFvhYH8hoE9lYsBWP5sUAgNiy/D8AgG+sXy/Nnx94TrftiNW2pcs+ilfwFO0DAJAaCJwAIMSGDdKCBYHndNuOWG1buuwjAACiQeAEAAAAAD4InAAAAADAB4ETAAAAAPggcAIAAAAAH6QjB5ASSkubZz2WGjr4XFKilBVuO2K1bXWX06pVYBBXAADSGYETgJQwYkTzrm/8eKWFcNsRq20LLqdfP+mGG2oHT507BwY9BgAgXRA4AUhaVpMxdKhUXJzokqA+K1ZI3/1u7WmTJ0tTpiSqRAAAxB6BE4CkZTUYixbFvpmejT+0cWPkIGD2bGn69EBNSjidOgVqVBIt3HZs3ixt2SJ98ol0113SpEnSPvsE3lu1Svr976ULL5T23Vdq317q0CH8tjVkH02dKs2dG5hmxyk/f9c8ybB/AACIJQInAEkfPBUUxHaZvXoFHuEEL/6HDJEGDFBSq2873n03EDidfPKu7bBpFjiNHu2/bQ3ZR4MG7ZpWVBT74wQAQDIhqx4AAAAA+CBwAgAAAAAfBE4AAAAA4IM+TkCUKip2n5abm4iSAAAAoLkQOAFRJCmwTvE26Gdl5a7p9rqwkOAJAAAgnRE4AQ1kgZFlDvO8XdPKy6XlyxNZKsSapdG2MYhSPZ12uO2I1bYFl2OpywEAyBQETkAUqFVKf126pMfAreG2I1bbFlxOSUnTlwUAQKogOQQAAAAA+CBwAgAAAAAfBE4AAAAA4IPACQAAAAB8EDgBAAAAQKwDpxkzZujTTz+N9mMAAAAAkDmB0z//+U/17t1bxx13nBYtWqRyG8gGAIA61q+X5s8PPAMAkHGB07Jly/Taa69pwIABuuKKK9StWzddcsklbhoAAEEbNkgLFgSeAQDIyD5OBx10kH7zm9/oyy+/1B/+8Ad9/vnnOuKIIzRo0CDddttt2rp1a+xLCgAAAACpmBzC8zxVVlaqoqLC/d2hQwctWLBAPXv21OLFi2NXSgAAAABItcDpjTfe0OTJk9W9e3ddeeWVrgZq+fLleuaZZ/TBBx/ohhtu0OWXXx770gIAAABAKgROAwcO1OGHH65Vq1a5ZnqfffaZ5s6dq/33379mnnHjxmlDAxu1L1y4UPvss4/y8/M1bNgwvfrqq/XOv2XLFl122WUuaMvLy9MBBxygRx99NNrNAAAAAIAGa6EonXXWWTr//PO15557RpynU6dOqq6u9l2WNee76qqrdOedd7qgad68eRo1apRWrlypLl267Da/NQk84YQT3Ht///vfXRksNXr79u2j3QwAQAyVlu4+raws8Ox5zV4cAAASHzgF+zLVVVpaqptvvlnTp09v8LJuvfVWTZo0SRMnTnSvLYB65JFHdPfdd2vq1Km7zW/TN23apBdffFEtW7Z006y2CgCQWCNGRH7vyiulX/9aysra/b3OnaUw98kAAEg6WZ5FQlHIycnRmjVrdqsR+uqrr9y0qqqqBi3Hao8KCgpczdGYMWNqpk+YMME1x7PxouoaPXq0Onbs6D5n73fu3Fnjx4/XNddc48oVjo0zFTrW1LZt21zyCsv817Zt2yi2HNidnVrLlkkWx+fmKqWlevnR/Ox/j2OOkdasafwyJk+WpkxRxqqokHbskIYMkfLyEl2aDFFVLm1eJuW0lnL44QOabGeJ9NhBgb9PelNqUeD/maoKqWqH1GGIlJPYHz+LDdq1a9eg2KBRNU5ZYW4bvvXWWy6oaaiNGze6IKtr1661ptvrFStWhP3Mxx9/rKeeekpnn32269f04Ycf6tJLL3WZ/WbMmBH2M3PmzNGsWbMaXC4gGvZVyM8PNEmqrFTKsvIXFhI8Ifrz3xKofv55+PfffluaOzfw96JFge9KuBonAABSQYMDJ2ueZwGTPSwhQ2jwZAHQ9u3bdfHFFyuerN+U1Wr97ne/czVMBx98sL744gvXRDBS4DRt2jTXj6pujRMQCxZoFBWldh8OqzVbvjzRpUCqsntfde5/hWXfk4IG3IQEACDlAydL3GC1TZYYwmpwrEorKDc31/U1Gj58eINXbAkkLPhZt25dren2ulu3bmE/Y5n0rG9TaLO8oqIirV271jX9s3LUZZn37AHEC7U0AAAA6a/BgZP1PTL77ruvRowYUZOcobEsyLEaoyVLltT0cbIaJXttY0SFc8QRR2jRokVuvuzsQCb1999/3wVU4YImAABSQUhXXMSbdcUuz5JyvnkgKllZHjcMkbEaFDhZ87ZgZykb7NYy6NkjnGgSLlgTOgvIDjnkEB122GGuVmvHjh01WfbOPfdcl3Lc+imZSy65RAsWLNAVV1yhKVOmuMF2b7zxRgbbBQCkdB9Dmss2o+osaVuBlJMvZUfd1Tvj5ed5KuprrXwSXRKg+bVoaP+mYCY9GzMpXHKIYNKIhmbVM2PHjnUD5VoKc2tuN2TIED322GM1CSNWr15dU7NkrG/S448/riuvvFKDBg1yQZUFUZZVDwCAVGMXn5aYBc3ILlN2VkvZ1VKO/5iT2KWiIktl5VnyPLsOTOHOvUA8AyfLZBfMmLd06VLFkjXLi9Q07+mnn95tmvWjevnll2NaBgAAEoU79wkInHI9KduTwo9kgog8Ve6keSMyV4MCp5EjR4b9GwCASDp1SnQJAABo5sDpbRuMo4GsCR0AAIzRBADIuMDJ+h5Z/yXrx1SfaPs4AQAAAEDaBE6rVq2Kf0kAAAAAIJUDp169esW/JAAAAACQyoHTv/71L5188slu0Fv7uz6nn356rMoGAAAAAKkTOI0ZM8aNs2TjONnfkdDHCQAAAEDGBk7V1dVh/wYAAACATJCd6AIAAAAAQFoGTkuWLNGpp56q3r17u4f9/d///jf2pQMAAACAVAycbr/9dp100knaY489dMUVV7hH27ZtNXr0aC1cuDA+pQQAZIT166X58wPPiVxGpOXZY+7cwOO992K7HgBAGvRxCnXjjTfq17/+tSZPnlwz7fLLL9cRRxzh3rvssstiXUYAQIbYsEFasEA69lipS5fELSPS8swf/xh47t8/tusBAKRZjdOWLVtcjVNdJ554orZu3RqrcgEAAABA6gZONk7Tgw8+uNv0f/7zn66vE4DUVFERvwcAAEBGNNX7zW9+U/N3//79dcMNN+jpp5/W8OHD3bSXX35ZL7zwgn784x/Hr6QA4iIrS8rPl8rKpMrK2C/flltYKOXmxn7ZAAAASRU4WZ+mUB06dNB7773nHkHt27fX3Xffreuuuy72pQQQNxbQFBVJnhf7ZZeXS8uXx365AAAASRk4rVq1Kv4lAZAw1AYh3kpLG15DGXwuKWncumKxjEjLCxVshhq6nlatArW4AID0E3VWPQAAojViRHTzjx/f9HXGYhn1Le9nP9t9evfu0gUXSPvsI3XsKHXuTMY9AMjowOnzzz/Xv/71L61evVoVdXp+33rrrbEqGwAghVnty9ChUnGxMsaaNdIvfrHrtY3cMWVKIksEAEhY4LRkyRKXWW+//fbTihUrdOCBB+qTTz6R53kaav9DAgDwTeKRRYt2b6Zn4yJt3Bj+MytWSLNnS9OnS/36hZ+nU6fAc1OXYbVB4cq0ebO0erX09dfSjh2Bv5culY45JtAX8OmnA/MNGSItWyYdfbS0557SPfcEpl9zjdSnz64aJwBAhgZO06ZN009+8hPNmjVLe+yxh/7xj3+oS5cuOvvss8OO7wQAyOzgqaCg9rRevQKPcCzDYzAoGTCg/mXHYhkNKdO77wYCp2DNUTBwOvvsQOB0+eXSvvvuCpy+//3dtxkAkIHjOC1fvlznnnuu+7tFixYqLS1VmzZtNHv2bN10003xKCMAAAAApFbg1Lp165p+Td27d9dHH31U897GSO0mAAAAACCTmuodfvjhev7551VUVKTRo0e7QW//97//6YEHHnDvAQAAAIAyPXCyrHnbt293f1s/J/t78eLF6tOnDxn1AAAAAKSlqAMny6YX2mzvzjvvjHWZAAAAACA9BsB9/fXXXaII079/fx188MGxLBcAIANZ+m4b+6gpabxjsYz6ljdxYuB5//1jux4AQJoFTjb47bhx4/TCCy+offv2btqWLVs0YsQI3Xvvvdprr73iUU4AQAbo0qXpA8bGYhn1LW/q1F1/9+8feC4pid36AABpklXvwgsvVGVlpatt2rRpk3vY39XV1e49AAAAAFCm1zg988wzevHFF9W3b9+aafb3/PnzdeSRR8a6fAAAAACQejVOPXv2dDVOdVVVValHjx6xKhcAAAAApG7gdPPNN2vKlCkuOUSQ/X3FFVfolltuiXX5AAAAACA1mup16NBBWVlZNa937NihYcOGqUWLwMd37tzp/j7//PM1ZsyY+JUWAAAAAJI1cJo3b178SwIgbVnr3tzcRJcCAAAgzoHThAkTmrAKAJnKKqrz823IAqllS4InAACQYQPgWiKIhx56qGYA3AEDBuj0009XTk5OrMsHIIVZoNS7t/Tuu4kuCQAAQDMHTh9++KFGjx6tL774oiYl+Zw5c1y2vUceeUS97SoJAL5hNU0AAAAZl1Xv8ssvd8HRZ599puLiYvdYvXq19t13X/ceAAAAAKSbRg2A+/LLL6tjx4410woLCzV37lwdccQRsS4fAAAAAKRejVNeXp6+/vrr3aZv375dufT8BgAAAJCGog6cTj31VF100UV65ZVX5Hmee1gN1MUXX+wSRAAAAACAMj1w+s1vfuP6OA0fPlz5+fnuYU309t9/f912223xKSUAAAAApEofJ6td2rZtm+69916XVS+YjryoqMgFTgAAAACQjqIOnCxAevfdd9WnTx+CJQAAAAAZIaqmetnZ2S5g+uqrr+JXIgAAAABI9T5Olnb86quv1jvvvBOfEgEAAABAqo/jdO6556qkpESDBw926cdbtWpV6/1NmzbFsnwAAACxV12Z6BKknqosqTpbqqqQqrxElwbJoqpCmSLqwGnevHnxKQkAAEBzyM6Vqiuk6p2JLklqqc6SqixwKiFwwi5Vpbv+tu+VCpSuog6cJkyYEJ+SAAAAxFtOrtSmd6JLkZoqvrly7OBJeYkuDJLGzh27/k7zeDrqwMlUVVXpwQcfrElH3r9/f337299WixaNWhwAAEDzBk+IXs43veNzvnkAxsucmtuoIx1LRX766adr7dq16tu3r5t20003qXPnzvr3v/+tAw88MB7lBAAAAIDUyap34YUXasCAAfr8889VXFzsHp999pkGDRqkiy66KD6lBAAAAIBUqnFatmyZXn/9dXXo0KFmmv19ww036NBDD411+QCkiYomJt3JpWUNAABIpcDpgAMO0Lp161ytU6j169dr//33j2XZAKSBrCwpP18qK5MqG5n91z5bWEjwBAAAUihwmjNnji6//HLNnDlThx9+uJv28ssva/bs2a6v07Zt22rmbdu2bWxLCyDlWLBTVCR5jcy0U14ufZOHBgAAIHUCp1NPPdU9n3XWWcqyW8mWTOObK6LTTjut5rW9Z9n3AICaIgAAkHGB09KlS+NTEgAAAABIl8Bp5MiR8SkJAAAAAKRLOnIAAAAAyDQETgAAAADgg8AJAAAAAHwQOAEAAACADwInAACayfr10vz5gWcAQBpm1TvooINqxmzyU1xc3NQyAQCQljZskBYskI49VurSJdGlAQDEPHAaM2ZMVAsFAAAAgIwLnGbMmBH/kgAAAABAkqKPEwAAAADEosYpVFVVlX7961/rvvvu0+rVq1VRUVHr/U2bNkW7SAAAAABIrxqnWbNm6dZbb9XYsWO1detWXXXVVTrjjDOUnZ2tmTNnxqeUAACkiNJSqaQk/KOsLDCPPQeneV6iSwwAiEuN0z333KO77rpLp5xyiguUxo0bp969e2vQoEF6+eWXdfnll0e7SAAA0saIEf7zjB+/6+9+/aQbbpCCyWs7dybjHgCkRY3T2rVrNXDgQPd3mzZtXK2TOfXUU/XII4/EvoQAACS5Vq2koUMb99kVK6Tvflc644zAY/HiWJcOAJCQGqe99tpLa9as0d577+1qmp544gkNHTpUr732mvLy8mJSKAAAUonVFi1aFGimZ2M1bdwYOUiaPVuaPl3aZx/p/PMD0+2z+fm7apwAAGkQOH3nO9/RkiVLNGzYME2ZMkU/+MEP9Ic//MElirjyyivjU0oAGa9OHhokmdzcRJcgOYKnggKpV6/AI5xgcDRkiLTvvrumFxUFPgsASKPAae7cuTV/W4KIXr166cUXX1SfPn102mmnxbp8ADKcXYzaxaZ1pq+sTHRpEI4dm8JCgicAQHqLOnAqKytTfvCWmaTDDz/cPQAgHuxi3O7Gk3ksOZWXS8uXJ7oUAAAkYeDUpUsX11zPmugdd9xxLg05AMQTNRkAACDRoo56/vznP6ukpETf/va3teeee+pHP/qRXn/99fiUDgAAAABSMXCy2qb7779f69at04033qj33nvPNdU74IADNNtSBQEAAABAmml0O7s99thDEydOdOnI3377bbVu3VqzZs2KbekAAEgjlmp88mRSjgNARgVOliTivvvu05gxY9w4Tps2bdLVV18d29IBAJBGunSRpkwJPAMA0jw5xOOPP65FixbpoYceUosWLXTmmWe6WqejjjoqPiUEAAAAgFQcAPfUU0/VX/7yF40ePVotW7aMT8kAAAAAIFUDJ0sKYf2bAAAAACBTNChw2rZtm9q2bev+9jzPvY4kOB8AAAAAZFTg1KFDB61Zs8YNftu+fXtlZWXtNo8FVDa9qqoqHuUEAAAAgOQOnJ566il17Nix5u9wgRMAAAAAZHTgNHLkyJq/jz766HiWBwAAAABSfxynPn36aObMmfrggw/iUyIAAAAASPXA6dJLL9Ujjzyifv366dBDD9Vtt92mtWvXxqd0AAAAAJCKgdOVV16p1157TcuXL3fjOC1cuFA9e/bUiSee6MZ2AgAAAABleuAUdMABB2jWrFl6//339dxzz2nDhg2aOHFibEsHAAAAAKk4AG6oV199VYsWLdLixYvd2E7f+973YlcyAAAAAEjVwMlqmO655x797W9/06pVq3Tsscfqpptu0hlnnKE2bdrEp5QAAAAAkEqBUzApxGWXXabvf//76tq1a3xKBgAAAACpGDhVVVXpt7/9rc4880x16NAhfqUCAAAAgFRNDpGTk6MpU6Zoy5Yt8SsRAAAAAKR6Vr0DDzxQH3/8cXxKAwAAAADpEDj94he/0E9+8hM9/PDDWrNmjcumF/oAAAAAAGV6cggb9NacfvrpysrKqpnueZ57bf2gAAAAACCjA6elS5fGpyQAgJRVUVH/+7m5zVUSAACSJHAaOXJkfEoCAEg51vAgP18qK5MqK8PPY+8VFhI8AQAyLHB69tln633/qKOOiroQCxcu1M0336y1a9dq8ODBmj9/vg477DDfz917770aN26cvv3tb+uhhx6Ker0AgKaxYKioyJprh3+/vFxavry5SwUAQBIETkcfffRu00L7OkXbx2nx4sW66qqrdOedd2rYsGGaN2+eRo0apZUrV6pLly4RP/fJJ5+4JBVHHnlklFsAAIglapIAAJkg6qx6mzdvrvVYv369HnvsMR166KF64oknoi7ArbfeqkmTJmnixInq37+/C6AKCgp09913R/yMBWdnn322Zs2apf322y/qdQIAAABAXGuc2rVrt9u0E044Qbm5ua7m6I033mjwsioqKtz806ZNq5mWnZ2t448/Xi+99FLEz82ePdvVRl1wwQV67rnn6l1HeXm5ewSRMh0AAABA3GucIunatatrXheNjRs3utoj+2zdZVl/p3Cef/55/eEPf9Bdd93VoHXMmTPHBXvBR8+ePaMqIwAAAABEXeP09ttv13pt4zfZQLhz587VkCFDFE9ff/21zjnnHBc0derUqUGfsdosqwkLrXEieAIAAAAQ18DJgiNLBmEBU6jDDz+83n5J4Vjwk5OTo3Xr1tWabq+7deu22/wfffSRSwpx2mmn1Uyrrq52zy1atHA1Xr179671mby8PPcAAAAAgGYLnFatWlXrtfVJ6ty5s/JtII8oWb+ogw8+WEuWLNGYMWNqAiF7PXny5N3m79evn/73v//Vmnbddde5mqjbbruNmiQAAAAAyRE49erVK6YFsGZ0EyZM0CGHHOLGbrJ05Dt27HBZ9sy5556rPffc0/VVsuDswAMPrPX59u3bu+e60wEAAAA0o6pSaWcDxqioqrAOP0rbwMmy3H311Vc69dRTa6b95S9/0YwZM1ygYzVGNnBttM3ixo4dqw0bNmj69OkuIYQ1BbT05sGEEatXr3a1WgAAAACS2FO7j/caUftB0omvKJVkeXU7K0Vw8sknu8Fvr7nmGvfamswNHTpU5513noqKinTzzTfrhz/8oWbOnKlkZskhLLve1q1b1bZt20QXBwDSmo0GsWyZ1Lo1A+XWVVIiHXRQ4O8335QKChJdIqB+FRXSjh3W3936kCe6NEganic9eYS0MfJQQhF99yspr6NSJTZocI3TsmXLdP3119e8vvfeezVs2LCatODWv8hqn5I9cAIAAAAQI1lZ0rFPSRtflnIKpJxc/+Z8T45QKmpw4LR58+Za4y0988wzrhYq6NBDD9Vnn30W+xICAAAASO7gqUWrhgVOKazBnYcsaApm1KuoqFBxcbFLQR5kme1atmwZn1ICAAAAQCoETqNHj9bUqVP13HPPuUFlCwoKdOSRR9YaGLfuGEoAAAAAkA4a3FTP+jedccYZGjlypNq0aaM///nPbhymIBv89sQTT4xXOQEAAAAg+QOnTp066dlnn3UZJyxwysnJqfX+/fff76YDAAAAgDJ9AFxL1xdOx46JTSUIAAAAAPHCyLIAAAAA4IPACQAAAAB8EDgBAAAAgA8CJwAAAADwQeAEAAAAAD4InAAAAADAB4ETAAAAAPggcAIAAACAWA+ACwBAtCoqlDFycxNdgsy2fr20eLE0dqzUpYtSTjKXf8MG6Z57pOuuk/bZJ9GlAZofgRMAIG6ysqT8fKmsTKqsVNqz7SwsJHhK9MX9ggXSsccmX+CR6uW3sv3hD9KFFxI4ITMROAEA4sYCiKIiyfOU9srLpeXLE10KAEC8EDgBAOKK2hcAQDogOQQAAAAA+CBwAgAAAAAfNNUDACDBSksTXYL0StARfC4pUcpJ5vIHy5YJfRaBcAicAABIsBEjEl2C9DN+vFJaMpf/lVekvLzw73XvHngA6YjACQCABGjVSho6VCouTnRJgOhceWXk92bMkGbObM7SAM2HwAkAgASNcbVoEc30Gjue0MaN4d9bsUKaPVuaPl3q1y/8PJ06SZ07K2GSufz1le2dd6Qbb5QWLpQOPzz8PNQ2IZ0ROAEAkMDgqaAg0aVIPb16BR7h2IDLZsgQacAAJaVkLn99ZcvJCTxbTak9gExDVj0AAAAA8EHgBAAAAAA+CJwAAAAAwAeBEwAAAAD4IHACAAAAAB8ETgAAIG1Ymu7JkxObbjxdy29luuACqVu3RJcESAzSkQMAgLTRpYs0ZYpSVjKX3wKnSZMYqwmZixonAAAAAPBB4AQAAAAAPgicAAAAAMAHgRMAAAAA+CBwAgAAAAAfBE4AAAAA4IPACQAAAAB8EDgBAAAAgA8CJwAAAADwQeAEAAAAAD4InAAAAADAB4ETAAAAAPggcAIAAAAAHwROAAAAAOCDwAkAAAAAfBA4AQAAAIAPAicAAAAA8EHgBAAAAAA+CJwAAAAAwAeBEwAAAAD4IHACAAAAAB8ETgAAAADgg8AJAAAAAHwQOAEAAACADwInAAAAAPBB4AQAAAAAPgicAAAAAMAHgRMAAAAA+CBwAgAAAAAfBE4AAAAA4IPACQAAAAB8EDgBAAAAgA8CJwAAAADwQeAEAAAAAD4InAAAAADAB4ETAAAAAPggcAIAAAAAHwROAAAAAOCDwAkAAAAAfBA4AQAAAIAPAicAAAAA8EHgBAAAAAA+CJwAAAAAwAeBEwAAAAD4IHACAAAAAB8ETgAAAADgg8AJAAAAAHwQOAEAAACADwInAAAAAPBB4AQAAAAAPgicAAAAAMBHC78ZAABAw1VURP+Z3Nx4lAQAEEsETgAAxEBWlpSfL5WVSZWVDf+czV9YSPAEAMmOwAkAgBiwwKeoSPK8hn+mvFxavjyepQIAxAqBEwAAMUKtEQCkL5JDAAAAAIAPAicAAAAA8EHgBAAAAAA+CJwAAAAAwAeBEwAAAAD4IHACAAAAAB8ETgAAAADgg8AJAAAAAHwQOAEAAACADwInAAAAAPBB4AQAAAAAPgicAAAAAMAHgRMAAAAApELgtHDhQu2zzz7Kz8/XsGHD9Oqrr0ac96677tKRRx6pDh06uMfxxx9f7/wAAAAAkPKB0+LFi3XVVVdpxowZKi4u1uDBgzVq1CitX78+7PxPP/20xo0bp6VLl+qll15Sz549deKJJ+qLL75o9rIDAAAAyAwJD5xuvfVWTZo0SRMnTlT//v115513qqCgQHfffXfY+e+55x5deumlGjJkiPr166ff//73qq6u1pIlS5q97AAAAAAyQ0IDp4qKCr3xxhuuuV1NgbKz3WurTWqIkpISVVZWqmPHjmHfLy8v17Zt22o9AAAAACBlAqeNGzeqqqpKXbt2rTXdXq9du7ZBy7jmmmvUo0ePWsFXqDlz5qhdu3Y1D2vaBwAAAAAp1VSvKebOnat7771XDz74oEssEc60adO0devWmsdnn33W7OUEAAAAkNpaJHLlnTp1Uk5OjtatW1drur3u1q1bvZ+95ZZbXOD03//+V4MGDYo4X15ennsAAAAAQErWOOXm5urggw+uldghmOhh+PDhET/3y1/+Utdff70ee+wxHXLIIc1UWgAAAACZKqE1TsZSkU+YMMEFQIcddpjmzZunHTt2uCx75txzz9Wee+7p+iqZm266SdOnT9eiRYvc2E/BvlBt2rRxDwAAAACItYQHTmPHjtWGDRtcMGRBkKUZt5qkYMKI1atXu0x7QXfccYfLxnfmmWfWWo6NAzVz5sxmLz8AAACA9JfwwMlMnjzZPSINeBvqk08+aaZSAQAAAEAaZNUDAAAAgOZA4AQAAAAAPgicAAAAAMAHgRMAAAAA+CBwAgAAAAAfBE4AAAAA4IPACQAAAAB8EDgBAAAAgA8CJwAAAADwQeAEAAAAAD4InAAAAADAB4ETAAAAAPggcAIAAAAAHwROAAAAAOCDwAkAAAAAfBA4AQAAAIAPAicAAAAA8EHgBAAAAAA+CJwAAAAAwAeBEwAAAAD4IHACAAAAAB8ETgAAAADgg8AJAAAAAHwQOAEAAACADwInAAAAAPBB4AQAAAAAPgicAAAAAMAHgRMAAAAA+CBwAgAAAAAfBE4AAAAA4IPACQAAAAB8EDgBAAAAgA8CJwAAAADwQeAEAAAAAD4InAAAAADAB4ETAAAAAPggcAIAAAAAHwROAAAAAOCjhd8MAAAgvioqEl0CwB/nKTIdgRMAAAmSlSXl50tlZVJlZaJLA/iz89XOWyATETgBAJAgublSUZHkeYkuCdAwFjTZeQtkIgInAAASiItQAEgNJIcAAAAAAB8ETgAAAADgg8AJAAAAAHwQOAEAAACADwInAAAAAPBB4AQAAAAAPgicAAAAAMAHgRMAAAAA+CBwAgAAAAAfBE4AAAAA4IPACQAAAAB8EDgBAAAAgA8CJwAAAADwQeAEAAAAAD4InAAAAADAB4ETAAAAAPggcAIAAAAAHwROAAAAAOCDwAkAAAAAfBA4AQAAAIAPAicAAAAA8EHgBAAAAAA+CJwAAAAAwAeBEwAAAAD4IHACAAAAAB8ETgAAAADgg8AJAAAAAHwQOAEAAACADwInAAAAAPBB4AQAAAAAPgicAAAAAMAHgRMAAAAA+CBwAgAAAAAfBE4AAAAA4IPACQAAAAB8EDgBAAAAgA8CJwAAAADwQeAEAAAAAD4InAAAAADAB4ETAAAAAPggcAIAAAAAHwROAAAAAOCDwAkAAAAAfBA4AQAAAIAPAicAAAAA8EHgBAAAAAA+CJwAAAAAwAeBEwAAAAD4IHACAAAAAB8ETgAAAADgg8AJAAAAAHwQOAEAAACADwInAAAAAPDRwm8GAAAAAPBVXeE/T1UD5klSBE4AAAAAmiBLysmXqsqkqsr6Z60qjS7QSiIETgAAAAAaLydXalskyfOfd+eOXX971UolBE4AAAAAmh48NYS3U6mK5BAAAAAA4IPACQAAAABSIXBauHCh9tlnH+Xn52vYsGF69dVX653//vvvV79+/dz8AwcO1KOPPtpsZQUAAACQeRIeOC1evFhXXXWVZsyYoeLiYg0ePFijRo3S+vXrw87/4osvaty4cbrgggv05ptvasyYMe7xzjvvNHvZAQAAAGSGLM/zGpD+In6shunQQw/VggUL3Ovq6mr17NlTU6ZM0dSpU3ebf+zYsdqxY4cefvjhmmmHH364hgwZojvvvNN3fdu2bVO7du20detWtW3bNsZbAwAAAKDerHr3tQn8PeYLqaCHEima2CChNU4VFRV64403dPzxx+8qUHa2e/3SSy+F/YxND53fWA1VpPnLy8vdDgl9AAAAAEA0Eho4bdy4UVVVVeratWut6fZ67dq1YT9j06OZf86cOS6KDD6sNgsAAABAgmW3VCpJeB+neJs2bZqregs+Pvvss0QXCQAAAMhMOQXSWdul726S8joplSR0ANxOnTopJydH69atqzXdXnfr1i3sZ2x6NPPn5eW5BwAAAIAEy8qSWrQOPFJMQmuccnNzdfDBB2vJkiU10yw5hL0ePnx42M/Y9ND5zZNPPhlxfgAAAABI6RonY6nIJ0yYoEMOOUSHHXaY5s2b57LmTZw40b1/7rnnas8993R9lcwVV1yhkSNH6le/+pVOOeUU3XvvvXr99df1u9/9LsFbAgAAACBdJTxwsvTiGzZs0PTp012CB0sr/thjj9UkgFi9erXLtBc0YsQILVq0SNddd52uvfZa9enTRw899JAOPPDABG4FAAAAgHSW8HGcmhvjOAEAAABIqXGcAAAAACAVEDgBAAAAgA8CJwAAAADwQeAEAAAAAD4InAAAAADAB4ETAAAAAPggcAIAAAAAHwROAAAAAOCDwAkAAAAAfBA4AQAAAIAPAicAAAAA8EHgBAAAAAA+CJwAAAAAwAeBEwAAAAD4IHACAAAAAB8ETgAAAADgg8AJAAAAAHwQOAEAAACADwInAAAAAPBB4AQAAAAAPloow3ie5563bduW6KIAAAAASKBgTBCMEeqTcYHT119/7Z579uyZ6KIAAAAASJIYoV27dvXOk+U1JLxKI9XV1fryyy+1xx57KCsrKymiXAviPvvsM7Vt2zbRxclIHIPE4xgkB45D4nEMkgPHIfE4BskhE46D53kuaOrRo4eys+vvxZRxNU62Q/baay8lGzsZ0/WETBUcg8TjGCQHjkPicQySA8ch8TgGySHdj0M7n5qmIJJDAAAAAIAPAicAAAAA8EHglGB5eXmaMWOGe0ZicAwSj2OQHDgOiccxSA4ch8TjGCQHjkOGJ4cAAAAAgGhR4wQAAAAAPgicAAAAAMAHgRMAAAAA+CBwAgAAAAAfBE4JtHDhQu2zzz7Kz8/XsGHD9Oqrrya6SGlj5syZysrKqvXo169fzftlZWW67LLLVFhYqDZt2ui73/2u1q1bV2sZq1ev1imnnKKCggJ16dJFV199tXbu3JmArUkNzz77rE477TQ38rbt74ceeqjW+5aHZvr06erevbtatWql448/Xh988EGteTZt2qSzzz7bDbLXvn17XXDBBdq+fXuted5++20deeSR7ntjo5n/8pe/bJbtS5fjcN555+323TjppJNqzcNxaJo5c+bo0EMP1R577OF+O8aMGaOVK1fWmidWv0FPP/20hg4d6jJe7b///vrTn/7ULNuYDsfg6KOP3u27cPHFF9eah2PQNHfccYcGDRpUM3jq8OHD9Z///Kfmfb4HiT8GfA+iZFn10PzuvfdeLzc317v77ru9d99915s0aZLXvn17b926dYkuWlqYMWOGN2DAAG/NmjU1jw0bNtS8f/HFF3s9e/b0lixZ4r3++uve4Ycf7o0YMaLm/Z07d3oHHnigd/zxx3tvvvmm9+ijj3qdOnXypk2blqAtSn62j372s595DzzwgGXq9B588MFa78+dO9dr166d99BDD3lvvfWWd/rpp3v77ruvV1paWjPPSSed5A0ePNh7+eWXveeee87bf//9vXHjxtW8v3XrVq9r167e2Wef7b3zzjve3/72N69Vq1beb3/722bd1lQ+DhMmTHD7OfS7sWnTplrzcByaZtSoUd4f//hHt2+WLVvmjR492tt777297du3x/Q36OOPP/YKCgq8q666ynvvvfe8+fPnezk5Od5jjz3mZbqGHIORI0e6/3tDvwt2bgdxDJruX//6l/fII49477//vrdy5Urv2muv9Vq2bOmOi+F7kPhjwPcgOgROCXLYYYd5l112Wc3rqqoqr0ePHt6cOXMSWq50Cpzswi+cLVu2uB+N+++/v2ba8uXL3UXmSy+95F7bD0N2dra3du3amnnuuOMOr23btl55eXkzbEFqq3vBXl1d7XXr1s27+eabax2HvLw8d9Ft7MfWPvfaa6/VzPOf//zHy8rK8r744gv3+vbbb/c6dOhQ6xhcc801Xt++fZtpy1JLpMDp29/+dsTPcBxib/369W6fPvPMMzH9DfrpT3/qbhCFGjt2rAsaUP8xCF4wXnHFFRE/wzGID/vt+P3vf8/3IAmOgeF7EB2a6iVARUWF3njjDddUKSg7O9u9fumllxJatnRizcCsudJ+++3nmh1ZVbOxfV9ZWVlr/1szvr333rtm/9vzwIED1bVr15p5Ro0apW3btundd99NwNaktlWrVmnt2rW19nm7du1cE9XQfW7Nwg455JCaeWx++2688sorNfMcddRRys3NrXVcrAnO5s2bm3WbUpk1qbDmFn379tUll1yir776quY9jkPsbd261T137Ngxpr9BNk/oMoLz8P+I/zEIuueee9SpUycdeOCBmjZtmkpKSmre4xjEVlVVle69917t2LHDNRfje5D4YxDE96DhWkQxL2Jk48aN7uQNPQmNvV6xYkXCypVO7ILc2tfaheGaNWs0a9Ys1x/jnXfecRfwdsFnF4d197+9Z+w53PEJvofoBPdZuH0aus/tYj5UixYt3IVO6Dz77rvvbssIvtehQ4e4bkc6sP5MZ5xxhtuPH330ka699lqdfPLJ7j+4nJwcjkOMVVdX60c/+pGOOOIId1FiYvUbFGkeu6ApLS11fQkR/hiY8ePHq1evXu4Gm/XZu+aaa1zw/8ADD7j3OQax8b///c9dpFt/JuvH9OCDD6p///5atmwZ34MEHwPD9yA6BE5IS3YhGGSdIi2Qsh+G++67L62+wEC0vv/979f8bXcR7fvRu3dvVwt13HHHJbRs6cg6vtsNm+effz7RRclYkY7BRRddVOu7YIlr7DtgNxTsO4HYsBuYFiRZrd/f//53TZgwQc8880yii5VRIh0DC574HkSHpnoJYNWhdme3buYYe92tW7eElSud2R2tAw44QB9++KHbx9ZccsuWLRH3vz2HOz7B9xCd4D6r75y35/Xr19d637L2WIY3jkv8WFNW+02y74bhOMTO5MmT9fDDD2vp0qXaa6+9aqbH6jco0jyWOYsbRPUfg3DsBpsJ/S5wDJrOapUsy9rBBx/ssh0OHjxYt912G9+DJDgG4fA9qB+BU4JOYDt5lyxZUqspgb0ObXOK2LFUynb3xO6k2L5v2bJlrf1v1dLWByq4/+3ZqrZDLyCffPJJ9yMQrN5Gw1mzLvthDd3nVoVvfWZC97n9B2rt3oOeeuop990I/pDbPJZu29rFhx4Xu5tG87DG+fzzz10fJ/tuGI5D01leDrtgt+Ywtu/qNmuM1W+QzRO6jOA8/D/ifwzCsTvyJvS7wDGIPfstKS8v53uQBMcgHL4HPqJMJoEYpiO3jGJ/+tOfXBariy66yKUjD81agsb78Y9/7D399NPeqlWrvBdeeMGl0bT0mZZZKZgC1VLTPvXUUy4F6vDhw92jbvrNE0880aWytZSanTt3Jh15Pb7++muXqtQe9tNy6623ur8//fTTmnTkdo7/85//9N5++22X2S1cOvKDDjrIe+WVV7znn3/e69OnT6002JaFydJgn3POOS6Vqn2PLAUqabAbdhzsvZ/85CcuY5V9N/773/96Q4cOdfu5rKysZhkch6a55JJLXOp9+w0KTfFbUlJSM08sfoOCKYCvvvpql41s4cKFaZsCONbH4MMPP/Rmz57t9r19F+x3ab/99vOOOuqommVwDJpu6tSpLpOh7WP73bfXlqHziSeecO/zPUjsMeB7ED0CpwSyPPf2g2HjOVl6chszBbFhaTC7d+/u9u2ee+7pXtsPRJBdrF966aUuJad92b/zne+4/1RDffLJJ97JJ5/sxqexoMuCscrKygRsTWpYunSpu1Cv+7D018GU5D//+c/dBbfdNDjuuOPcmBKhvvrqK3eB3qZNG5fqdOLEie5iP5SNAfWtb33LLcOOrQVkaNhxsItG+8/P/tOzNMC9evVy43fUvWHDcWiacPvfHjauUKx/g+x4DxkyxP3W2QVP6Doymd8xWL16tbs47NixozuHbawyu+gLHb/GcAya5vzzz3e/M7Zv7HfHfveDQZPhe5DYY8D3IHpZ9o9frRQAAAAAZDL6OAEAAACADwInAAAAAPBB4AQAAAAAPgicAAAAAMAHgRMAAAAA+CBwAgAAAAAfBE4AAAAA4IPACQAAAAB8EDgBANLWeeedpzFjxiS6GACANNAi0QUAAKAxsrKy6n1/xowZuu222+R5XrOVCQCQvgicAAApac2aNTV/L168WNOnT9fKlStrprVp08Y9AACIBZrqAQBSUrdu3Woe7dq1czVQodMsaKrbVO/oo4/WlClT9KMf/UgdOnRQ165dddddd2nHjh2aOHGi9thjD+2///76z3/+U2td77zzjk4++WS3TPvMOeeco40bNyZgqwEAiULgBADIKH/+85/VqVMnvfrqqy6IuuSSS/S9731PI0aMUHFxsU488UQXGJWUlLj5t2zZomOPPVYHHXSQXn/9dT322GNat26dzjrrrERvCgCgGRE4AQAyyuDBg3XdddepT58+mjZtmvLz810gNWnSJDfNmvx99dVXevvtt938CxYscEHTjTfeqH79+rm/7777bi1dulTvv/9+ojcHANBM6OMEAMgogwYNqvk7JydHhYWFGjhwYM00a4pn1q9f757feustFySF6y/10Ucf6YADDmiWcgMAEovACQCQUVq2bFnrtfWNCp0WzNZXXV3tnrdv367TTjtNN910027L6t69e9zLCwBIDgROAADUY+jQofrHP/6hffbZRy1a8N8mAGQq+jgBAFCPyy67TJs2bdK4ceP02muvueZ5jz/+uMvCV1VVlejiAQCaCYETAAD16NGjh1544QUXJFnGPesPZenM27dvr+xs/hsFgEyR5TGkOgAAAADUi1tlAAAAAOCDwAkAAAAAfBA4AQAAAIAPAicAAAAA8EHgBAAAAAA+CJwAAAAAwAeBEwAAAAD4IHACAAAAAB8ETgAAAADgg8AJAAAAAHwQOAEAAACA6vf/67nZpElsz+kAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 1000x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import random\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import csv\n",
    "\n",
    "from lifelines.utils import concordance_index\n",
    "\n",
    "# from utils import display_km_curves_fusion\n",
    "# from models import *\n",
    "# from train import test_loader\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "############################# FINAL ###########################################\n",
    "\n",
    "checkpoint_path = r\"..\\checkpoints\\trained-model_2025-03-02_0.757253.pth\" # TODO: to choose\n",
    "\n",
    "model_chkpt = FusionNetwork()\n",
    "model_chkpt.to(device)\n",
    "optimizer = optim.Adam(model_chkpt.parameters())\n",
    "\n",
    "# load from last check point\n",
    "checkpoint = torch.load(checkpoint_path, map_location=device)\n",
    "model_chkpt.load_state_dict(checkpoint['model_state_dict'])\n",
    "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "val_c_index = checkpoint['val_c_index']\n",
    "\n",
    "model_chkpt.eval()\n",
    "\n",
    "test_risks = []\n",
    "test_times = []\n",
    "test_events = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(test_loader):\n",
    "        # unpack the batch\n",
    "        batch_clinical_rna_features, batch_lists_phenotype_clusters, batch_times, batch_events = batch\n",
    "        \n",
    "        # move times and events to the device\n",
    "        batch_times = batch_times.to(device)\n",
    "        batch_events = batch_events.to(device)\n",
    "        \n",
    "        # tterate over each sample in the batch\n",
    "        for i, (clinical_rna_features, list_of_phenotype_tensors) in enumerate(zip(batch_clinical_rna_features, batch_lists_phenotype_clusters)):\n",
    "            \n",
    "            risk_score = model_chkpt(clinical_rna_features, list_of_phenotype_tensors)\n",
    "            \n",
    "            test_risks.append(risk_score.item())\n",
    "            test_times.append(batch_times[i].item())\n",
    "            test_events.append(batch_events[i].item())\n",
    "\n",
    "test_c_index = concordance_index(test_times, -np.array(test_risks), test_events)\n",
    "print(f\"test c-index: {test_c_index}\")\n",
    "display_km_curves_fusion(test_risks, test_times, test_events, \"test set\", val_c_index, save_figure=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
