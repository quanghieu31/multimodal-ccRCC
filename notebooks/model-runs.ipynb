{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "import configparser\n",
    "config = configparser.ConfigParser()\n",
    "config.read(\"../config.ini\")\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "class PatientClinicalDataset(Dataset):\n",
    "    \"\"\"\n",
    "    from csv, so getitem would be something like .loc[idx]\n",
    "    \"\"\"\n",
    "    def __init__(self, csv_file_path):\n",
    "        self.csv_file_path = csv_file_path\n",
    "        self.df = pd.read_csv(self.csv_file_path).drop([\"time\", \"event\"], axis=1)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        patient_series = self.df.iloc[idx]\n",
    "        return patient_series # includes the submitter_id!\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.df.shape[0]\n",
    "\n",
    "\n",
    "class PatientRNASeqDataset(Dataset):\n",
    "    \"\"\"\n",
    "    a csv file, 534 rows and ~20000 columns for normalized RNA-seq counts\n",
    "    \"\"\"\n",
    "    def __init__(self, rna_file_path):\n",
    "        self.rna_file_path = rna_file_path\n",
    "        self.df = pd.read_csv(self.rna_file_path)\n",
    "        self.df.set_index(\"submitter_id\", inplace=True)\n",
    "\n",
    "    def __getitem__(self, case_id):\n",
    "        gene_expressions = list(self.df.loc[case_id])\n",
    "        tensor_gene_expressions = torch.tensor(gene_expressions, dtype=torch.float32).unsqueeze(0)\n",
    "        return tensor_gene_expressions # [1, 19962]\n",
    "\n",
    "\n",
    "class PatientWSIDataset(Dataset):\n",
    "    \"\"\"\n",
    "    dataset for accessing a patient's list of patches features, each is of shape (1, n_patches, n_features)\n",
    "    \"\"\"\n",
    "    def __init__(self, wsi_dir):\n",
    "\n",
    "        self.wsi_dir = wsi_dir\n",
    "        self.case_ids = list(os.listdir(self.wsi_dir))\n",
    "        self.dict_case_id_path = {\n",
    "            c: os.path.join(self.wsi_dir, c) + \"/patches_features.npy\" for c in self.case_ids\n",
    "        }\n",
    "\n",
    "    def __getitem__(self, case_id):\n",
    "        # grab the list of 5 clusters for this case_id\n",
    "\n",
    "        case_npy_file = self.dict_case_id_path[case_id]\n",
    "        patches_features = np.load(case_npy_file, allow_pickle=True).item()\n",
    "        \n",
    "        cluster_ids = self.clustering(patches_features)\n",
    "\n",
    "        features_list = list(patches_features.values())\n",
    "        unique_clusters = np.unique(cluster_ids)\n",
    "        n_clusters = len(unique_clusters)\n",
    "\n",
    "        list_phenotype_tensors = [] # list of tensors, each tensor is a cluster's features of shape i.e. (1, 15 patches in this cluster, 512 as output of resnet18)\n",
    "\n",
    "        for cluster in unique_clusters:\n",
    "            cluster_features = [features for features, c in zip(features_list, cluster_ids) if c == cluster]\n",
    "            tensor_cluster_features = torch.from_numpy(np.array(cluster_features)).float().unsqueeze(0) # (1, n_patches, n_features)\n",
    "\n",
    "            list_phenotype_tensors.append(tensor_cluster_features.to(device))\n",
    "\n",
    "        return list_phenotype_tensors # [t1,t2,t3,t4,t5]\n",
    "\n",
    "    def clustering(self, patches_features, n_clusters=5):\n",
    "        feature_vectors = list(patches_features.values())\n",
    "        kmeans = KMeans(n_clusters=n_clusters, random_state=0, n_init=50)\n",
    "        cluster_ids = kmeans.fit_predict(feature_vectors)\n",
    "        return cluster_ids\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.case_ids)\n",
    "\n",
    "\n",
    "\n",
    "## Fusion multimodal\n",
    "\n",
    "class MultimodalDataset(Dataset):\n",
    "    \"\"\"\n",
    "    takes three data paths (clinical, rna-seq, histopath images)\n",
    "    build a data out of 'em\n",
    "    \"\"\"\n",
    "    def __init__(self, \n",
    "        clinical_data_path, \n",
    "        rna_seq_data_path, \n",
    "        wsi_data_path\n",
    "    ):\n",
    "        # prepare labels from the clinical data path\n",
    "        self.LABELS_DF = pd.read_csv(clinical_data_path)[[\"submitter_id\", \"event\", \"time\"]]\n",
    "        # then by initializing the clinical_dataset, remove the time and event from the clinical features:\n",
    "        self.clinical_dataset = PatientClinicalDataset(clinical_data_path)\n",
    "\n",
    "        # initialize the datasets for each modality\n",
    "        self.wsi_dataset = PatientWSIDataset(wsi_data_path)\n",
    "        self.rna_dataset = PatientRNASeqDataset(rna_seq_data_path)\n",
    "\n",
    "        # label dictionary with key=submitter_id and value=(event,time) for easy lookup\n",
    "        self.labels_dict = {}\n",
    "        for submitter_id, event, time in zip(self.LABELS_DF[\"submitter_id\"], self.LABELS_DF[\"event\"], self.LABELS_DF[\"time\"]):\n",
    "            self.labels_dict[submitter_id] = {\"event\": event, \"time\": time}\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.clinical_dataset)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        # (1) start from clinical dataset\n",
    "        patient_series = self.clinical_dataset[idx]\n",
    "        case_id = patient_series[\"submitter_id\"]\n",
    "        clinical_features = list(patient_series.drop([\"submitter_id\"]))\n",
    "        tensor_clinical_features = torch.tensor(clinical_features, dtype=torch.float32).unsqueeze(0) \n",
    "        # above: add batch dim (1, 13) instead of (13)\n",
    "\n",
    "        # (2) grab the tensor for 20000 (processed) gene counts for that case id\n",
    "        tensor_rna_genes = self.rna_dataset[case_id] # (1, 19962)\n",
    "\n",
    "        # (2.5) NOTE: to save time for this moment, I will concat the clinical and rna together \n",
    "        # and build one feed-forward for the combined\n",
    "        tensor_clinical_rna = torch.cat((tensor_clinical_features, tensor_rna_genes), dim=1) # (1, 19975)\n",
    "\n",
    "        # (3) collect the list of phenotype tensor for that case id\n",
    "        list_of_phenotype_tensors = self.wsi_dataset[case_id]\n",
    "\n",
    "        # (4) labels\n",
    "        time = self.labels_dict[case_id][\"time\"]\n",
    "        event = self.labels_dict[case_id][\"event\"]\n",
    "\n",
    "        return (\n",
    "            tensor_clinical_rna,\n",
    "            list_of_phenotype_tensors,\n",
    "            time,\n",
    "            event\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 first gene counts:\n",
      "tensor(2.4332)\n",
      "tensor(0.)\n",
      "tensor(3.4071)\n",
      "tensor(2.7216)\n",
      "tensor(1.6839)\n",
      "tensor(1.7558)\n",
      "tensor(3.9939)\n",
      "first 13 in clinical and rna:\n",
      "tensor(0.)\n",
      "tensor(1.1109)\n",
      "tensor(0.)\n",
      "tensor(0.)\n",
      "tensor(0.)\n",
      "tensor(1.)\n",
      "tensor(0.)\n",
      "tensor(0.)\n",
      "tensor(0.)\n",
      "tensor(0.)\n",
      "tensor(0.)\n",
      "tensor(1.)\n",
      "tensor(0.)\n"
     ]
    }
   ],
   "source": [
    "check_data = MultimodalDataset(\n",
    "    config[\"clinical\"][\"cleaned_clinical_json\"],\n",
    "    config[\"rna\"][\"cleaned_rna\"],\n",
    "    config[\"wsi\"][\"wsi_slides\"]\n",
    ")\n",
    "\n",
    "case0 = check_data[5]\n",
    "clin_rna, list_tensors = case0[0], case0[1]\n",
    "\n",
    "print(\"5 first gene counts:\")\n",
    "for i in clin_rna.flatten()[13:20]:\n",
    "    print(i)\n",
    "\n",
    "print(\"first 13 in clinical and rna:\")\n",
    "for i in clin_rna.flatten()[0:13]:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1148, 512])\n",
      "torch.Size([1, 1078, 512])\n",
      "torch.Size([1, 984, 512])\n",
      "torch.Size([1, 966, 512])\n",
      "torch.Size([1, 824, 512])\n",
      "\n",
      "torch.Size([1, 1148, 512])\n",
      "torch.Size([1, 1078, 512])\n",
      "torch.Size([1, 984, 512])\n",
      "torch.Size([1, 966, 512])\n",
      "torch.Size([1, 824, 512])\n"
     ]
    }
   ],
   "source": [
    "for tensor in list_tensors:\n",
    "    print(tensor.shape)\n",
    "\n",
    "print()\n",
    "check_wsi = PatientWSIDataset(config[\"wsi\"][\"wsi_slides\"])[\"TCGA-BP-4352\"]\n",
    "for tensor in check_wsi:\n",
    "    print(tensor.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import random\n",
    "import os\n",
    "import math\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "random.seed(0)\n",
    "np.random.seed(0)\n",
    "torch.manual_seed(0)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "dropout_ratio = 0.5\n",
    "\n",
    "class WSI_FCN(nn.Module):\n",
    "    \"\"\"\n",
    "    https://arxiv.org/abs/2009.11169\n",
    "    fully convolutional/connected network for WSI (2 experiments)\n",
    "    takes 1 phenotype tensor/cluster of shape (1, n_patches, 512)\n",
    "    outputs a local representation of that phenotype tensor of shape (1, 64)\n",
    "    why FCN? on the numerical vectors? \n",
    "        - utilize the kernel, and especially kernel_size=1 because we can't have kernel_size>1 for randomly picked patches from the histopathology slides\n",
    "        - so why not a simple fully connected network (MLP)? it's because it requires inputs with fixed dimension and we have varying number of patches for each cluster\n",
    "    also, note that a patch -> FCN -> (1,64) shape. So if we have 300 patches or (300,64) shape, we would use avgpooling and get (1,64) as the final output for that cluster\n",
    "    \"\"\"\n",
    "    def __init__(self, mode, in_features, out_features=64):\n",
    "        super(WSI_FCN, self).__init__()\n",
    "\n",
    "        self.mode = mode\n",
    "\n",
    "        # Experiment 1: (closed March 4)\n",
    "        self.conv = nn.Sequential(\n",
    "            # conv1d because we only have a tensor of shape (N, C, L) = (1, 512, i.e. 272)\n",
    "            nn.Conv1d(\n",
    "                in_features, \n",
    "                out_features, \n",
    "                kernel_size=1 # kernel size = 1 is extremely important because we only want to the a single patch to be learned, \n",
    "                # doing i.e. 3x3 is no use because the patches are picked randomly, so can't use spatial relationship here\n",
    "            ),\n",
    "            nn.ReLU(),\n",
    "            # adaptive avg pooling to get a local representation of the phenotype tensor\n",
    "            # NOTE: adapative pooling from (64, 300 patches) to (64,1) as the final output of that cluster\n",
    "            nn.AdaptiveAvgPool1d(1)\n",
    "        )\n",
    "\n",
    "        # Experiment 2: (start March 4)\n",
    "        self.linear = nn.Sequential(\n",
    "            # https://stackoverflow.com/a/58591606/19562762\n",
    "            nn.Linear(in_features, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3), # NOTE tuning\n",
    "            nn.Linear(256, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3), # NOTE tuning\n",
    "            nn.Linear(128, out_features),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # input x: (1, n_patches, n_features)\n",
    "\n",
    "        if self.mode == \"conv\":\n",
    "            # permute to (1, n_features, n_patches) so that n_features become channels why? because tensor in pytorch reads () https://stackoverflow.com/questions/51541532/which-part-of-pytorch-tensor-represents-channels\n",
    "            # n_patches is the length of the sequence. why?\n",
    "            # FYI: for a conv2D, input should be in (N, C, H, W) format. N is the number of samples/batch_size. C is the channels. H and W are height and width resp: https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html#torch.nn.Conv2d \n",
    "            # but here we have conv1d: https://pytorch.org/docs/stable/generated/torch.nn.Conv1d.html#torch.nn.Conv1d\n",
    "            x = x.permute(0, 2, 1) # (1, 512, 300 patches)\n",
    "            # x = self.conv(x) # (1, 64, 300 patches)\n",
    "            # x = self.relu(x) # (1, 64, 300 patches)\n",
    "            # x = self.pool(x) # (1, 64, 1)\n",
    "            x = self.conv(x)   # (1, 64, 1)\n",
    "            x = x.view(x.size()[0], -1) # (1, 64)\n",
    "            return x\n",
    "\n",
    "        elif self.mode == \"linear\":\n",
    "            x = self.linear(x) # (1, 64, 300 patches)\n",
    "            x = torch.mean(x, dim=1) # (1,64) average\n",
    "            return x # (1, 64)\n",
    "\n",
    "\n",
    "class WSI_Attention(nn.Module):\n",
    "    \"\"\"\n",
    "    https://arxiv.org/abs/2009.11169 \n",
    "    pooling attention mechanism for WSI\n",
    "    takes a local representation of the phenotype tensor of shape (5, 64) in which 5 is the number of clusters\n",
    "    outputs a global representation of the phenotype tensors of shape (64-dim) which is a weighted sum across 5 clusters for 64 features\n",
    "        each case has a global representation\n",
    "    \"\"\"\n",
    "    def __init__(self, in_features, out_features=64):\n",
    "        super(WSI_Attention, self).__init__()\n",
    "        self.attention = nn.Sequential(\n",
    "            nn.Linear(in_features, out_features),\n",
    "            nn.Tanh(),  # tanh because we want to normalize the weights\n",
    "            # why tanh() >> output values in range (-1,1), allowing both neg and pos values, often used in attention scores\n",
    "            nn.Linear(out_features, 1),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # apply softmax because we have different number of clusters for each case\n",
    "        # x: (5, 64) \n",
    "        # stack representation of 5 clusters/phenotypes\n",
    "        scores = self.attention(x) # (5, 1)\n",
    "        att_weights = torch.softmax(scores, dim=0).T # (1,5) which are probabilities\n",
    "        # weighted sum across the 5 clusters:\n",
    "        weights_applied = att_weights @ x  # (1, 64) = (1,5) @ (5,64)\n",
    "        # weighted_sum_vector = torch.sum(weights_applied, dim=0) # (1, 64) or (64)\n",
    "        return weights_applied, att_weights\n",
    "\n",
    "\n",
    "class Clinical_RNA_FeedForward(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim=32, dropout_ratio=dropout_ratio):\n",
    "        # https://www.cs.toronto.edu/~hinton/absps/JMLRdropout.pdf\n",
    "        # https://arxiv.org/pdf/1207.0580\n",
    "        # For fully connected layers, dropout in all hidden layers works\n",
    "        # better than dropout in only one hidden layer and more extreme probabilities tend to be worse,\n",
    "        # which is why we have used 0.5 throughout this paper\n",
    "        \n",
    "        super(Clinical_RNA_FeedForward, self).__init__()\n",
    "\n",
    "        # hidden = [512, 256, 256, 64, 64, 32]\n",
    "        # hidden = [1024, 512, 512, 256, 256, 128, 128, 64, 64, 32]\n",
    "\n",
    "        hidden = [1024, 1024, 512, 512, 256, 256, 128, 128, 64, 64, 32] # final: march 2, 2025\n",
    "\n",
    "        self.feedforward = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden[0]), nn.ReLU(), nn.Dropout(dropout_ratio),\n",
    "            nn.Linear(hidden[0], hidden[1]), nn.ReLU(), nn.Dropout(dropout_ratio),\n",
    "            nn.Linear(hidden[1], hidden[2]), nn.ReLU(), nn.Dropout(dropout_ratio),  \n",
    "            nn.Linear(hidden[2], hidden[3]), nn.ReLU(), nn.Dropout(dropout_ratio),\n",
    "            nn.Linear(hidden[3], hidden[4]), nn.ReLU(), nn.Dropout(dropout_ratio),\n",
    "            nn.Linear(hidden[4], hidden[5]), nn.ReLU(), nn.Dropout(dropout_ratio),\n",
    "            nn.Linear(hidden[5], hidden[6]), nn.ReLU(), nn.Dropout(dropout_ratio),\n",
    "            nn.Linear(hidden[6], hidden[7]), nn.ReLU(), nn.Dropout(dropout_ratio),\n",
    "            nn.Linear(hidden[7], hidden[8]), nn.ReLU(), nn.Dropout(dropout_ratio),\n",
    "            nn.Linear(hidden[8], hidden[9]), nn.ReLU(), nn.Dropout(dropout_ratio),\n",
    "            nn.Linear(hidden[9], hidden[10]), nn.ReLU(), nn.Dropout(dropout_ratio),\n",
    "            nn.Linear(hidden[10], output_dim), nn.ReLU(), nn.Dropout(dropout_ratio),    \n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.feedforward(x)\n",
    "        return out\n",
    "\n",
    "\n",
    "# FusionFeedForward\n",
    "class FusionNetwork(nn.Module):\n",
    "    def __init__(self, \n",
    "        input_dim_clinical_rna=19975, \n",
    "        input_dim_wsi_fcn=512, \n",
    "        input_dim_wsi_attention=64, \n",
    "        input_dim_final=96  # as from 32+64 = (out_dim of clinical_RNA) + (out_dim of WSI)\n",
    "    ): \n",
    "        # NOTE: no dropout for now\n",
    "        super(FusionNetwork, self).__init__()\n",
    "\n",
    "        # Clinical+RNA\n",
    "        self.clinical_rna_feedforward = Clinical_RNA_FeedForward(input_dim_clinical_rna, output_dim=32, dropout_ratio=dropout_ratio)\n",
    "        # WSI_FCN and WSI_Attention\n",
    "        self.wsi_fcn = WSI_FCN(\"linear\", input_dim_wsi_fcn, out_features=64) # NOTE\n",
    "        self.attention = WSI_Attention(input_dim_wsi_attention, out_features=64)\n",
    "\n",
    "        # after fusion:\n",
    "        # TODO: rational -> book: many hidden neurons are good -> with regularization like dropout/weight decay\n",
    "        # for no. layers -> background knowledge and experimentation, for now 4 layers\n",
    "        hidden = [64, 32, 16, 8]\n",
    "\n",
    "        self.baby_feed_forward = nn.Sequential(\n",
    "            nn.Linear(input_dim_final, hidden[0]),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden[0], hidden[1]),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden[1], hidden[2]),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden[2], hidden[3]),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden[3], 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, tensor_clinical_rna, list_of_phenotype_tensors):\n",
    "\n",
    "        # Clinical+RNA:\n",
    "        extracted_clinical_rna = self.clinical_rna_feedforward(tensor_clinical_rna.to(device)) # (1, 32) shape\n",
    "        \n",
    "        # WSI_FCN\n",
    "        local_reps = [] # len=5\n",
    "        # here since tensors have different no. images in each of them\n",
    "        # we use the \"flexiblity\" of the FCN to output 1x64 for each cluster\n",
    "        for tensor in list_of_phenotype_tensors:\n",
    "            tensor = tensor.to(device)\n",
    "            cluster_rep = self.wsi_fcn(tensor) # each of shape (1,64) by pooling from tensors with varying dim\n",
    "            local_reps.append(cluster_rep)\n",
    "        # stack 5 local representation of shape (1,64) >> tensor of shape (5,64)\n",
    "        tensor_local_reps = torch.cat(local_reps)\n",
    "\n",
    "        # WSI_Attention:\n",
    "        wsi_aggregated_vector, att_weights = self.attention(tensor_local_reps) # from (5,64) to weighted vector (1,64)\n",
    "\n",
    "        # concantenate:\n",
    "        concatenated_features = torch.cat((extracted_clinical_rna, wsi_aggregated_vector), dim=1) # shape (1, 96)\n",
    "\n",
    "        risk_score = self.baby_feed_forward(concatenated_features)\n",
    "        return risk_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 64])\n",
      "tensor([[-0.1001],\n",
      "        [-0.0251],\n",
      "        [-0.1315],\n",
      "        [-0.1376],\n",
      "        [-0.1129]], grad_fn=<AddmmBackward0>)\n",
      "tensor([[0.2001, 0.2157, 0.1939, 0.1927, 0.1976]], grad_fn=<PermuteBackward0>)\n",
      "torch.Size([1, 64])\n",
      "torch.Size([1, 64])\n",
      "\n",
      "torch.Size([1, 64])\n",
      "torch.Size([1, 32])\n",
      "torch.Size([5, 64])\n",
      "tensor([[0.0851],\n",
      "        [0.0853],\n",
      "        [0.0864],\n",
      "        [0.0900],\n",
      "        [0.0903]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[0.1995, 0.1996, 0.1998, 0.2005, 0.2006]], device='cuda:0',\n",
      "       grad_fn=<PermuteBackward0>)\n",
      "torch.Size([1, 64])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([[-0.1500]], device='cuda:0', grad_fn=<AddmmBackward0>),\n",
       " torch.Size([1, 1]))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sanity check\n",
    "\n",
    "x = torch.rand(5, 64)\n",
    "a2 = WSI_Attention(64)(x)\n",
    "print(a2[0].shape)\n",
    "\n",
    "x = torch.rand(1, 300, 512) # (1, n_patches, 512)\n",
    "a1 = WSI_FCN(\"linear\", 512)(x)\n",
    "print(a1.shape)\n",
    "\n",
    "x = torch.rand(1, 19975)\n",
    "a3 = Clinical_RNA_FeedForward(19975)(x)\n",
    "print(a3.shape)\n",
    "\n",
    "x1 = torch.rand(1, 19975)\n",
    "x2 = [torch.rand(1, 300, 512), torch.rand(1, 200, 512), torch.rand(1, 50, 512), torch.rand(1, 150, 512), torch.rand(1, 25, 512)]\n",
    "m = FusionNetwork().to(device)\n",
    "a4 = m(x1,x2)\n",
    "a4, a4.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "begin to train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12/12 [14:52<00:00, 74.35s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0, loss: 1.2118743360042572\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12/12 [16:33<00:00, 82.79s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1, loss: 1.150560900568962\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12/12 [13:34<00:00, 67.84s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2, loss: 1.0813533663749695\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12/12 [10:32<00:00, 52.72s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 3, loss: 1.0543317993481953\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12/12 [10:25<00:00, 52.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 4, loss: 1.033355380098025\n",
      "finished training\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from datetime import datetime, date\n",
    "from lifelines.utils import concordance_index\n",
    "from utils import display_km_curves_fusion\n",
    "\n",
    "# from models import *\n",
    "# from data_utils import *\n",
    "\n",
    "# import configparser\n",
    "# config = configparser.ConfigParser()\n",
    "# config.read(\"config.ini\")\n",
    "\n",
    "random.seed(0)\n",
    "np.random.seed(0)\n",
    "torch.manual_seed(0)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "########################## LOSS ###############################################\n",
    "\n",
    "def negative_partial_log_likelihood(hazard_preds, times, events, device, eps=1e-8):\n",
    "\n",
    "    # This calculation credit to Travers Ching https://github.com/traversc/cox-nnet\n",
    "    # Cox-nnet: An artificial neural network method for prognosis prediction of high-throughput omics data\n",
    "\n",
    "    # flatten predictions\n",
    "    hazard_preds = hazard_preds.view(-1)\n",
    "    times = times.to(device).view(-1)\n",
    "    events = events.to(device).view(-1)\n",
    "\n",
    "    # uncensored patients ~ patients with event observed = 1\n",
    "    # censored patients ~ not yet observed\n",
    "    # if this batch only contains censored/alive patients:\n",
    "    if events.sum() == 0:\n",
    "        return torch.tensor(0.0, device=device)\n",
    "\n",
    "    # compute risk set/matrix: R[i,j] = 1 if times[j] >= times[i]\n",
    "    # https://stackoverflow.com/questions/56646261/can-someone-please-explain-np-less-equal-outerrange1-18-range1-13\n",
    "    risk_matrix = torch.tensor(\n",
    "        np.greater_equal.outer(times.cpu(), times.cpu()).T.astype(np.float32), \n",
    "        device=device\n",
    "    )\n",
    "\n",
    "    # standardize theta/hazard prediction\n",
    "    theta = (hazard_preds - hazard_preds.mean()) / (hazard_preds.std(unbiased=False) + eps)\n",
    "\n",
    "    # compute the log risk set using the correct formula\n",
    "    # NOTE: use theta directly without an extra exp()\n",
    "    # First, mask the non-risk set entries by multiplying exp(theta) with risk_matrix,\n",
    "    # then take the log of the sum\n",
    "    log_risk_set = torch.log(torch.sum(torch.exp(theta) * risk_matrix, dim=1) + eps)\n",
    "\n",
    "    # negative partial likelihood only for events=1\n",
    "    # only take the avg loss for the batch across patients in D=1\n",
    "    loss = -torch.mean((theta - log_risk_set) * events)\n",
    "\n",
    "    return loss\n",
    "\n",
    "# one-batch\n",
    "# hazard_pred = torch.tensor([2.1, 1.8, 3.0, 0.5, 2.5], device=device)\n",
    "# time = torch.tensor([5, 3, 6, 2, 4], device=device)\n",
    "# event = torch.tensor([1, 1, 0, 1, 0], device=device)\n",
    "\n",
    "# one_batch_loss = negative_partial_log_likelihood(hazard_pred, time, event, device)\n",
    "# print(one_batch_loss)\n",
    "\n",
    "################## HYPERPARAMS ################################################\n",
    "\n",
    "# https://arxiv.org/pdf/1206.5533 (guide to choose hyperparams)\n",
    "n_epochs = 5\n",
    "lr = 0.0001\n",
    "batch_size = 32\n",
    "\n",
    "# regularizations:\n",
    "dropout_ratio = 0.5\n",
    "weight_decay = 0.0001\n",
    "\n",
    "# since we have relatively small dataset (~300 for training), high weidght decay may lead to udnerfitting\n",
    "# but we might have many interactions between parameters in the final feedforward, so let's try different ones\n",
    "# https://medium.com/towards-data-science/this-thing-called-weight-decay-a7cd4bcfccab\n",
    "# https://stackoverflow.com/questions/44452571/what-is-the-proper-way-to-weight-decay-for-adam-optimizer\n",
    "\n",
    "################### TRAIN #####################################################\n",
    "\n",
    "def custom_collate(batch):\n",
    "    \"\"\"\n",
    "    https://stackoverflow.com/questions/65279115/how-to-use-collate-fn-with-dataloaders \n",
    "    i.e. 32 batch_size\n",
    "    batch = [\n",
    "        (list_of_phenotype_tensors, time1, event1),    => case 1\n",
    "        (list_of_phenotype_tensors, time2, event2),    => case 2\n",
    "        ...                                            => case 32\n",
    "    ]\n",
    "\n",
    "    TODO: more explanation to come\n",
    "    \"\"\"\n",
    "    # each element in batch is a tuple: \n",
    "    # (clinical_rna_tensor, list_of_phenotype_tensors, time, event)\n",
    "    list_of_clinical_rna_features, list_of_lists_of_5_tensors, times, events = zip(*batch)\n",
    "    # i.e. [patient_1_clinical_rna_t1, patient_2_clinical_rna_t2,..., patient32_clinical_rna_t32]\n",
    "    # i.e. [[t1,t2,t3,t4,t5],[t1,t2,t3,t4,t5],...,[t1,t2,t3,t4,t5]] = [32 lists]\n",
    "    \n",
    "    return (\n",
    "        list(list_of_clinical_rna_features),\n",
    "        list(list_of_lists_of_5_tensors),\n",
    "        torch.tensor(times),\n",
    "        torch.tensor(events)\n",
    "    )\n",
    "\n",
    "# dataset and splitting\n",
    "dataset = MultimodalDataset(\n",
    "    config[\"clinical\"][\"cleaned_clinical_json\"],\n",
    "    config[\"rna\"][\"cleaned_rna\"],\n",
    "    config[\"wsi\"][\"wsi_slides\"]\n",
    ")\n",
    "\n",
    "train_size, val_size = int(0.70 * len(dataset)), int(0.15 * len(dataset))\n",
    "test_size = len(dataset) - train_size - val_size\n",
    "train, val, test = random_split(dataset, [train_size, val_size, test_size])\n",
    "\n",
    "# loading data\n",
    "train_loader = DataLoader(train, batch_size=batch_size, shuffle=True, collate_fn=custom_collate)\n",
    "val_loader = DataLoader(val, batch_size=val_size, shuffle=False, collate_fn=custom_collate)\n",
    "test_loader = DataLoader(test, batch_size=test_size, shuffle=False, collate_fn=custom_collate)\n",
    "\n",
    "# initiate model\n",
    "model = FusionNetwork(\n",
    "    input_dim_clinical_rna=19975,\n",
    "    input_dim_wsi_fcn=512,\n",
    "    input_dim_wsi_attention=64,\n",
    "    input_dim_final=96\n",
    ")\n",
    "model.to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "\n",
    "\n",
    "print(\"begin to train\")\n",
    "# training loops\n",
    "for epoch in range(n_epochs):\n",
    "\n",
    "    model.train()\n",
    "    train_loss = 0.0 \n",
    "\n",
    "    # each batch contains 32 cases!\n",
    "    for batch in tqdm(train_loader):\n",
    "        batch_clinical_rna_features, batch_lists_phenotype_clusters, batch_times, batch_events = batch\n",
    "\n",
    "        risk_scores = [] # list of  32 risk scores\n",
    "        for (clinical_rna_features, list_of_phenotype_tensors) in zip(batch_clinical_rna_features, batch_lists_phenotype_clusters):\n",
    "            # process each sample in the batch of 32\n",
    "            risk_score = model(clinical_rna_features, list_of_phenotype_tensors)\n",
    "            risk_scores.append(risk_score)\n",
    "\n",
    "        # convert to tensor type\n",
    "        risk_scores = torch.stack(risk_scores) # of shape (batch_size, 1) or (32,1) \n",
    "\n",
    "        # TODO: explain in detail: meaning of loss of 32 cases in the batch\n",
    "        optimizer.zero_grad() # zero the parameter gradients\n",
    "        loss = negative_partial_log_likelihood(risk_scores, batch_times.to(device), batch_events.to(device), device)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "\n",
    "    # the lower the better i.e. the negative better better\n",
    "    print(f\"epoch {epoch}, loss: {train_loss / len(train_loader)}\")\n",
    "\n",
    "print(\"finished training\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "begin to validate\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [02:06<00:00, 126.42s/it]\n"
     ]
    }
   ],
   "source": [
    "####################### VALIDATION ############################################\n",
    "\n",
    "print(\"begin to validate\")\n",
    "model.eval()\n",
    "\n",
    "val_risks = []\n",
    "val_times = []\n",
    "val_events = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(val_loader):\n",
    "        # unpack the batch\n",
    "        batch_clinical_rna_features, batch_lists_phenotype_clusters, batch_times, batch_events = batch\n",
    "        \n",
    "        # move times and events to the device\n",
    "        batch_times = batch_times.to(device)\n",
    "        batch_events = batch_events.to(device)\n",
    "        \n",
    "        # tterate over each sample in the batch\n",
    "        for idx, (clinical_rna_features, list_of_phenotype_tensors) in enumerate(zip(batch_clinical_rna_features, batch_lists_phenotype_clusters)):\n",
    "            \n",
    "            risk_score = model(clinical_rna_features, list_of_phenotype_tensors)\n",
    "            \n",
    "            val_risks.append(risk_score.item())\n",
    "            val_times.append(batch_times[idx].item())\n",
    "            val_events.append(batch_events[idx].item())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation c-index: 0.6924564796905223\n",
      "validation c-index custom: 0.6928294573643411\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved model: ../checkpoints/trained-model_2025-03-04_0.692456.pth\n"
     ]
    }
   ],
   "source": [
    "from lifelines import KaplanMeierFitter\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def display_km_curves_fusion(risks, times, events, title_name, c_index, save_figure=False):\n",
    "    risks = np.array(risks)\n",
    "    times = np.array(times)\n",
    "    events = np.array(events)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(10, 8)) \n",
    "    high_risk_idx = risks > np.median(risks)\n",
    "    low_risk_idx = risks <= np.median(risks)\n",
    "    kmf_high = KaplanMeierFitter()\n",
    "    kmf_low = KaplanMeierFitter()\n",
    "    # fit low risk\n",
    "    kmf_low.fit(times[low_risk_idx], event_observed=events[low_risk_idx], label='Low risk')\n",
    "    kmf_low.plot_survival_function(ax=ax, ci_show=True, ci_alpha=0.15, show_censors=True, color='orange')\n",
    "    # fit high risk\n",
    "    kmf_high.fit(times[high_risk_idx], event_observed=events[high_risk_idx], label='High risk')\n",
    "    kmf_high.plot_survival_function(ax=ax, ci_alpha=0.15, ci_show=True,show_censors=True, color='blue')\n",
    "    ax.set_title(f\"Kaplan-Meier curve for multimodality model on {title_name}\")\n",
    "    ax.set_xlabel(\"Time\")\n",
    "    ax.set_ylabel(\"Survival probability\")\n",
    "    plt.legend()\n",
    "    if save_figure:\n",
    "        current_time = datetime.now().strftime(\"%H-%M-%S\")\n",
    "        plt.savefig(f\"../evaluation-results/fusion_{title_name}_{date.today()}_{c_index:4f}.png\")\n",
    "    else:\n",
    "        plt.show()\n",
    "\n",
    "def concordance_index_custom(hazards, times, events):\n",
    "    \"\"\"\n",
    "    computes the c-index for survival prediction\n",
    "    - hazards: predicted risk scores (higher means higher risk)\n",
    "    - times: observed survival times\n",
    "    - events: event indicators (1 if event occurred, 0 if censored)\n",
    "    \"\"\"\n",
    "    n = len(times)\n",
    "    concordant = 0.0\n",
    "    permissible = 0.0\n",
    "    for i in range(n):\n",
    "        for j in range(n):\n",
    "            # only compare if i had an event and its time is earlier than j\n",
    "            if times[i] < times[j] and events[i] == 1:\n",
    "                permissible += 1\n",
    "                if hazards[i] > hazards[j]:\n",
    "                    concordant += 1\n",
    "                elif hazards[i] == hazards[j]:\n",
    "                    concordant += 0.5\n",
    "    return concordant / permissible if permissible > 0 else 0\n",
    "\n",
    "\n",
    "val_c_index = concordance_index(val_times, -np.array(val_risks), val_events)\n",
    "print(f\"validation c-index: {val_c_index}\")\n",
    "\n",
    "val_c_index_custom = concordance_index_custom(val_risks, val_times, val_events)\n",
    "print(f\"validation c-index custom: {val_c_index_custom}\")\n",
    "\n",
    "display_km_curves_fusion(val_risks, val_times, val_events, \"validation set\", val_c_index, save_figure=False)\n",
    "\n",
    "\n",
    "saved_model = True\n",
    "\n",
    "if saved_model:\n",
    "    current_time = datetime.now().strftime(\"%H-%M-%S\")\n",
    "    checkpoint_path = f\"../checkpoints/trained-model_{date.today()}_{val_c_index:4f}.pth\"\n",
    "    torch.save({\n",
    "        'model_state_dict': model.state_dict(), # all weights all models\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'batch_size': batch_size,\n",
    "        'dropout_ratio': dropout_ratio,\n",
    "        'learning_rate': lr,\n",
    "        'weight_decay': weight_decay,\n",
    "        'n_epochs': n_epochs,\n",
    "        'random_seed': 0,\n",
    "        'val_c_index': val_c_index,\n",
    "        'hidden': [1024, 1024, 512, 512, 256, 256, 128, 128, 64, 64, 32],\n",
    "        'mode_fcn': 'linear'\n",
    "    }, checkpoint_path)\n",
    "    print(f\"saved model: {checkpoint_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_state_dict OrderedDict([('clinical_rna_feedforward.feedforward.0.weight', tensor([[-1.2345e-03, -4.2677e-03,  2.1296e-05,  ..., -6.9195e-05,\n",
      "          1.6668e-04, -7.3537e-04],\n",
      "        [-5.1345e-03, -3.8178e-03, -5.7655e-03,  ...,  5.6969e-07,\n",
      "          3.6948e-03,  6.0809e-03],\n",
      "        [ 1.1110e-08, -2.8465e-08,  1.4977e-07,  ...,  1.4407e-05,\n",
      "         -2.4255e-08,  3.9335e-06],\n",
      "        ...,\n",
      "        [-5.4654e-03, -1.7705e-03,  8.0576e-07,  ...,  1.8097e-04,\n",
      "         -1.2366e-03,  3.0575e-03],\n",
      "        [ 1.6793e-03, -6.8450e-04,  8.2199e-06,  ...,  4.4877e-08,\n",
      "         -3.7996e-06, -1.6932e-04],\n",
      "        [ 1.1334e-03,  4.7919e-03,  2.8039e-06,  ..., -5.6452e-05,\n",
      "         -7.8428e-04,  1.2821e-03]], device='cuda:0')), ('clinical_rna_feedforward.feedforward.0.bias', tensor([ 5.5707e-04,  6.4389e-03,  4.8782e-06,  ..., -1.1887e-03,\n",
      "         7.3178e-05, -2.8289e-03], device='cuda:0')), ('clinical_rna_feedforward.feedforward.3.weight', tensor([[-1.1577e-05,  4.2631e-03,  3.2045e-06,  ..., -6.6469e-03,\n",
      "          6.6322e-03, -2.0967e-02],\n",
      "        [-2.8982e-02,  3.1869e-02,  3.2645e-06,  ..., -2.6225e-02,\n",
      "         -1.2682e-02,  1.5822e-02],\n",
      "        [ 1.7345e-03,  2.4773e-02,  9.8780e-03,  ..., -2.5114e-02,\n",
      "         -1.2978e-03, -1.1290e-02],\n",
      "        ...,\n",
      "        [ 4.9049e-04, -8.4740e-03,  7.2174e-03,  ..., -1.1271e-02,\n",
      "          6.8059e-06,  1.7055e-03],\n",
      "        [-6.1332e-03, -2.3507e-02,  9.6412e-04,  ..., -2.1500e-02,\n",
      "          1.0600e-03, -6.5858e-03],\n",
      "        [ 7.9609e-03, -8.0085e-03,  2.0562e-05,  ...,  2.2449e-02,\n",
      "         -5.2429e-06, -2.4784e-03]], device='cuda:0')), ('clinical_rna_feedforward.feedforward.3.bias', tensor([ 0.0313, -0.0098, -0.0235,  ...,  0.0258,  0.0270, -0.0160],\n",
      "       device='cuda:0')), ('clinical_rna_feedforward.feedforward.6.weight', tensor([[-0.0288,  0.0002,  0.0260,  ..., -0.0130, -0.0197, -0.0162],\n",
      "        [ 0.0024,  0.0148,  0.0167,  ..., -0.0001, -0.0287, -0.0110],\n",
      "        [ 0.0092,  0.0079, -0.0312,  ...,  0.0257,  0.0046, -0.0217],\n",
      "        ...,\n",
      "        [-0.0077, -0.0303,  0.0262,  ..., -0.0216,  0.0129, -0.0133],\n",
      "        [-0.0296, -0.0179, -0.0047,  ...,  0.0163, -0.0300,  0.0207],\n",
      "        [ 0.0152, -0.0196, -0.0288,  ...,  0.0037,  0.0024, -0.0102]],\n",
      "       device='cuda:0')), ('clinical_rna_feedforward.feedforward.6.bias', tensor([-9.1772e-03, -1.9428e-02,  1.6610e-02, -1.5539e-02, -2.5266e-02,\n",
      "        -3.7242e-03,  4.5728e-03, -2.7521e-03,  1.8689e-02, -6.6866e-03,\n",
      "         1.6080e-03, -1.8504e-02,  1.5926e-02,  2.0741e-02,  1.5715e-02,\n",
      "        -9.9291e-03, -1.2137e-02,  1.9406e-02,  1.2301e-02,  8.8872e-03,\n",
      "         1.0877e-02, -8.0026e-03, -2.2159e-03,  1.0370e-02,  1.7491e-02,\n",
      "        -8.0912e-04,  1.2827e-02,  2.4864e-02,  2.3264e-02,  2.1203e-02,\n",
      "         2.6010e-02,  2.6009e-02,  9.6898e-03, -3.0594e-02, -2.5144e-02,\n",
      "         1.0743e-02,  1.4357e-02, -4.9976e-03, -2.3071e-03, -4.0448e-03,\n",
      "         1.1524e-02,  1.9991e-02,  2.0672e-02, -3.1000e-02,  2.0464e-02,\n",
      "        -1.3495e-03, -1.3113e-02, -1.8833e-02,  8.3741e-03,  5.8479e-03,\n",
      "        -1.6945e-02, -2.4247e-02, -7.1265e-03,  3.0862e-02,  1.7886e-02,\n",
      "        -1.4013e-02,  1.4462e-03, -5.1788e-03,  6.3548e-03,  1.9374e-03,\n",
      "         2.3128e-02, -5.9922e-03,  2.2906e-02, -2.3060e-02, -1.9821e-02,\n",
      "        -2.6932e-02,  1.5594e-02,  2.7635e-02,  2.6746e-03, -1.4084e-02,\n",
      "         8.1593e-03,  3.0591e-02, -2.1785e-02, -2.5480e-02,  2.3558e-03,\n",
      "         1.1923e-02,  9.9673e-03,  1.4895e-02, -8.4893e-04, -3.4571e-05,\n",
      "        -4.2219e-03,  1.2680e-02, -2.7058e-03,  9.2492e-04,  3.0359e-02,\n",
      "         1.9635e-02, -1.6071e-02, -1.3568e-02, -2.0982e-02,  2.4208e-02,\n",
      "         2.4343e-02, -2.3207e-02, -2.0666e-02,  1.1127e-02,  1.5073e-04,\n",
      "         2.5939e-02,  2.3247e-02,  1.6389e-02, -2.7858e-02, -7.2808e-03,\n",
      "        -5.2277e-03, -3.5320e-03, -1.0139e-02,  2.5542e-02, -4.9918e-03,\n",
      "         2.8407e-02, -2.5811e-03,  3.9704e-03, -1.6543e-02, -1.7041e-02,\n",
      "        -3.2327e-02, -2.1848e-02, -1.6159e-02,  2.7140e-02, -2.7475e-02,\n",
      "         2.4770e-02,  1.5731e-02, -8.8296e-03, -3.9173e-03, -6.9022e-03,\n",
      "         5.1156e-03, -7.9415e-03, -1.6810e-02, -3.0578e-02, -1.8130e-02,\n",
      "        -7.6193e-03, -2.2144e-02, -2.7055e-02, -2.3041e-03, -2.8202e-02,\n",
      "        -7.4944e-03, -1.9495e-03, -2.0951e-02,  1.4328e-02, -2.9956e-04,\n",
      "        -2.3599e-02, -2.8752e-02, -2.5932e-02, -2.6017e-02, -2.4000e-03,\n",
      "         1.1066e-02, -3.7990e-03,  7.9212e-03, -3.2367e-02,  1.4094e-03,\n",
      "         1.7808e-02, -1.2136e-02, -2.3835e-02,  3.0103e-02, -1.2368e-02,\n",
      "         5.6431e-03, -2.9792e-02,  6.7978e-03, -7.7381e-03,  1.6167e-02,\n",
      "         2.9620e-02, -1.6504e-02, -2.1548e-02, -2.3208e-04, -1.6639e-02,\n",
      "        -5.2056e-03, -1.3200e-02, -1.4846e-02, -5.4663e-03, -1.1704e-02,\n",
      "         8.4552e-03, -1.2962e-02, -1.3141e-02, -1.9439e-02, -3.3217e-03,\n",
      "        -1.0806e-03, -4.4586e-03, -1.5775e-02,  6.2980e-03, -4.7570e-03,\n",
      "        -1.4781e-02, -3.0207e-02, -2.5249e-02,  8.2210e-03, -9.6665e-03,\n",
      "        -2.1709e-02,  1.0200e-02, -2.0282e-02, -2.4388e-02, -1.6328e-02,\n",
      "        -1.7116e-02, -7.8665e-03,  1.6649e-02, -4.7265e-03, -2.8738e-02,\n",
      "        -2.9338e-02, -9.7383e-03,  1.1948e-02,  1.9008e-02, -4.7672e-03,\n",
      "        -8.7974e-03,  6.5618e-03,  1.8623e-02,  2.9809e-02, -1.7694e-02,\n",
      "         6.8090e-03,  1.6431e-02,  1.6891e-02, -3.5904e-03, -8.3593e-03,\n",
      "         2.5742e-02,  2.6666e-02, -2.6697e-02, -5.4523e-03, -1.9650e-02,\n",
      "         1.6259e-03, -2.7227e-02, -2.4397e-02, -8.7739e-04, -2.4446e-02,\n",
      "        -1.0971e-02, -2.2848e-03,  1.8165e-02, -1.6848e-02,  2.0348e-02,\n",
      "         1.1339e-02, -2.5982e-02,  3.0067e-04,  7.9662e-03,  6.8722e-03,\n",
      "        -1.9554e-02, -1.0006e-02, -1.4402e-02,  5.7194e-03, -2.3930e-02,\n",
      "        -1.8959e-02,  2.5382e-02, -9.4577e-03,  1.1810e-02, -1.6727e-02,\n",
      "         7.5024e-03, -4.6156e-04, -2.1422e-02, -1.6082e-02,  1.8077e-02,\n",
      "         1.5692e-02,  1.1344e-02,  1.6053e-02, -1.8410e-02, -1.3310e-02,\n",
      "         2.2571e-02, -2.1234e-02, -2.4313e-02, -1.6736e-03,  1.5805e-02,\n",
      "        -1.9292e-02, -5.3021e-03,  2.7686e-02, -5.8371e-03,  4.1009e-03,\n",
      "        -1.7694e-03, -9.7871e-03, -2.0281e-02, -1.7670e-02, -2.9158e-02,\n",
      "         1.5956e-02,  3.8302e-03,  2.1074e-02,  2.4062e-02, -1.5757e-02,\n",
      "         1.3846e-02, -3.9629e-03,  1.4209e-03,  2.3504e-02,  5.7536e-03,\n",
      "         1.2300e-02,  8.5112e-03,  2.6257e-02, -1.6211e-02, -5.9647e-03,\n",
      "         2.1442e-02,  8.9557e-03,  1.5665e-02,  2.2722e-02,  8.6469e-03,\n",
      "         1.9870e-02, -3.0935e-02,  7.1539e-03, -2.3184e-02, -2.8040e-02,\n",
      "        -1.3510e-02, -2.5657e-02,  1.2547e-02, -2.7520e-02, -4.8447e-03,\n",
      "         2.3230e-02,  9.0877e-03,  1.3833e-03, -1.6595e-02,  2.0314e-02,\n",
      "        -2.3797e-02, -3.1289e-02,  3.8726e-03,  2.6556e-02, -7.2376e-03,\n",
      "        -8.4550e-03, -1.6983e-02, -2.6657e-02, -1.5768e-02, -1.8979e-02,\n",
      "        -1.9075e-02,  3.6595e-03, -9.9600e-05,  1.2278e-02, -2.4386e-03,\n",
      "        -1.5077e-02,  2.3204e-02, -1.9174e-03,  1.3624e-02, -1.9989e-02,\n",
      "         7.2196e-03,  3.0046e-02,  2.2584e-02,  1.4545e-02, -6.6027e-03,\n",
      "        -1.2028e-02,  1.9991e-02, -2.1835e-02,  1.9873e-02,  3.0485e-03,\n",
      "        -3.8696e-03,  1.9234e-02,  2.7215e-02,  1.7743e-02,  7.2728e-03,\n",
      "        -1.6481e-02, -2.1869e-02, -9.7334e-03, -5.2698e-03,  2.3552e-02,\n",
      "        -2.7526e-02,  2.7995e-02,  7.0394e-04,  4.9626e-03,  1.0161e-02,\n",
      "        -2.9228e-02,  2.2151e-02,  1.4032e-02, -2.7947e-02, -2.1396e-02,\n",
      "        -1.2559e-02, -1.2560e-02, -2.2464e-02,  2.7175e-02,  4.2196e-03,\n",
      "         2.1926e-02,  1.2943e-02,  2.7420e-02, -2.4558e-02, -2.2115e-02,\n",
      "        -2.8568e-02,  2.0243e-02, -1.6288e-02,  1.8103e-02, -2.0492e-02,\n",
      "         7.3502e-03,  2.9493e-02, -2.8266e-02, -1.8748e-02,  5.7485e-03,\n",
      "         4.7502e-03,  7.9331e-03,  7.4369e-03, -1.7783e-02, -2.5659e-02,\n",
      "        -2.8376e-02,  1.3194e-02,  7.5345e-03,  1.8278e-02, -2.1274e-02,\n",
      "         2.3751e-02,  1.1441e-02,  2.4846e-02, -6.3041e-03, -9.1657e-03,\n",
      "        -1.8581e-02, -1.9865e-02,  5.6059e-03,  1.5229e-02, -1.4187e-02,\n",
      "         2.3052e-02,  3.0868e-02,  2.0462e-02,  7.5042e-03, -2.5472e-02,\n",
      "        -1.3921e-02,  1.9400e-02, -6.3040e-03,  2.7265e-02,  1.5023e-02,\n",
      "        -7.2465e-03, -1.7043e-02, -1.3567e-02, -2.4041e-02,  1.7248e-02,\n",
      "         3.5034e-04, -2.0994e-02, -2.3387e-03, -5.0095e-03, -2.5378e-02,\n",
      "        -2.6058e-02,  4.0400e-03, -1.1167e-03,  7.3284e-03,  1.8124e-02,\n",
      "        -3.0346e-02,  2.9198e-02,  1.4955e-02,  3.7301e-03,  7.6423e-03,\n",
      "        -2.6341e-02, -1.6312e-02,  2.6231e-02, -1.8130e-02,  1.3398e-02,\n",
      "        -5.9805e-03, -2.7962e-02, -2.3518e-02, -2.1867e-02,  2.9888e-02,\n",
      "         2.4799e-02, -1.4768e-02,  6.0559e-03, -2.4609e-02, -2.0526e-02,\n",
      "        -1.1310e-03,  2.0032e-02, -3.1227e-02, -7.0228e-03, -1.6503e-02,\n",
      "        -2.8818e-02, -2.3303e-02,  6.7652e-03,  1.5307e-02,  8.5244e-03,\n",
      "        -8.6258e-03,  2.2231e-02,  3.0303e-02, -6.1823e-03, -2.2320e-02,\n",
      "         6.0155e-03,  3.1192e-02, -1.0140e-02,  2.9222e-02,  2.0100e-02,\n",
      "         2.4979e-02,  1.0550e-02, -8.5645e-03, -4.6407e-03, -2.2834e-03,\n",
      "         2.9707e-02,  2.2608e-02, -2.3033e-02,  2.0690e-03,  2.1489e-02,\n",
      "         1.9551e-03,  2.7341e-02,  4.6090e-03,  2.8484e-03,  2.7247e-04,\n",
      "         1.3819e-02,  3.0927e-02,  1.7457e-02,  9.2741e-03, -2.1286e-02,\n",
      "         1.7802e-02,  2.3843e-02, -2.9733e-02, -7.5174e-03, -2.5694e-03,\n",
      "        -5.0712e-04, -1.2360e-02,  9.4557e-03, -2.8475e-03, -1.7715e-02,\n",
      "         2.9832e-02, -6.6939e-03, -1.1700e-02, -2.5773e-02, -1.0148e-02,\n",
      "        -7.6428e-03,  4.1474e-03, -2.8291e-02, -1.1026e-02,  3.0008e-02,\n",
      "        -1.7992e-02,  2.0577e-02, -2.6359e-03,  1.9535e-02, -1.6682e-02,\n",
      "         5.7414e-03,  2.1243e-02, -1.1652e-02, -3.4565e-03, -2.0615e-02,\n",
      "         1.6799e-03,  2.9638e-02, -1.3042e-02,  2.8856e-02, -2.6748e-03,\n",
      "        -1.4667e-04,  1.9808e-02, -1.1420e-02,  2.1088e-02,  1.1416e-02,\n",
      "        -3.1301e-02, -2.9482e-02], device='cuda:0')), ('clinical_rna_feedforward.feedforward.9.weight', tensor([[ 0.0030,  0.0172, -0.0389,  ..., -0.0248, -0.0401,  0.0034],\n",
      "        [-0.0056,  0.0229, -0.0375,  ..., -0.0115, -0.0278,  0.0418],\n",
      "        [-0.0109, -0.0106,  0.0120,  ...,  0.0113, -0.0003, -0.0296],\n",
      "        ...,\n",
      "        [ 0.0352, -0.0020, -0.0366,  ..., -0.0275,  0.0082, -0.0049],\n",
      "        [ 0.0366,  0.0429, -0.0147,  ...,  0.0199, -0.0150, -0.0063],\n",
      "        [-0.0288,  0.0325, -0.0377,  ...,  0.0215,  0.0110,  0.0126]],\n",
      "       device='cuda:0')), ('clinical_rna_feedforward.feedforward.9.bias', tensor([ 1.4828e-02,  1.6854e-02,  4.2669e-02, -4.2617e-03,  3.3298e-02,\n",
      "         2.1518e-02,  3.8774e-02,  2.3076e-03, -2.9341e-02,  1.3388e-02,\n",
      "         1.6615e-02, -2.7186e-02,  3.2945e-02, -1.6107e-02,  2.2373e-03,\n",
      "        -5.6412e-03,  1.9452e-02,  5.1401e-03, -1.2031e-02,  5.7407e-03,\n",
      "        -3.6672e-02,  1.8105e-03,  1.2911e-02, -3.1939e-02, -1.5679e-02,\n",
      "         6.6368e-03,  4.4771e-02, -2.1072e-02,  4.4161e-02, -4.4977e-03,\n",
      "         3.8374e-02, -2.5778e-02,  1.6820e-02, -3.3340e-02, -6.6964e-03,\n",
      "        -4.0274e-03,  5.1214e-03,  1.4510e-02, -1.1011e-02,  2.1831e-02,\n",
      "         2.0952e-02, -1.1353e-02, -9.6020e-03,  1.7607e-02,  1.4320e-02,\n",
      "        -3.9872e-02, -4.5799e-03,  4.1275e-02,  1.1727e-02, -3.9301e-03,\n",
      "        -1.7572e-02,  3.1285e-02, -2.4997e-02,  1.7721e-02, -7.0434e-03,\n",
      "        -1.8046e-02,  4.2528e-02,  1.5482e-02, -4.2827e-02, -1.0908e-02,\n",
      "         1.0187e-02,  3.8808e-02, -8.0284e-03,  2.1035e-02, -3.7995e-02,\n",
      "        -3.0631e-02, -3.0356e-02, -2.9599e-03, -3.6304e-02, -4.2609e-02,\n",
      "         1.9972e-02, -3.3029e-02,  3.8195e-02,  3.3389e-02, -3.5960e-02,\n",
      "        -8.0531e-03,  1.6664e-02, -4.7614e-03, -6.1584e-03,  8.1431e-03,\n",
      "         2.5896e-02,  9.5051e-03,  4.0256e-02, -3.2618e-02,  2.4806e-03,\n",
      "        -3.8946e-02,  9.3338e-03, -2.0548e-02,  2.2110e-02,  3.2245e-02,\n",
      "        -1.3142e-02, -2.6375e-02, -2.3687e-02, -2.5437e-02,  1.7263e-02,\n",
      "        -3.2984e-02, -2.0755e-03, -3.1220e-02, -3.2999e-02,  3.2328e-02,\n",
      "         5.1003e-03, -4.0598e-02, -2.8304e-02, -1.3566e-03, -3.0268e-02,\n",
      "        -2.5459e-02, -3.3985e-02,  2.6304e-02, -2.6688e-02, -6.5346e-03,\n",
      "        -1.2961e-02, -2.7706e-02, -2.2469e-02,  3.7690e-02,  3.8128e-02,\n",
      "         2.5474e-02,  9.8013e-03, -1.6398e-02, -7.1476e-03,  3.9058e-02,\n",
      "        -1.9944e-02,  1.5944e-02, -1.6530e-02, -3.7336e-02, -1.9150e-04,\n",
      "         4.4762e-02, -3.3142e-03, -7.9088e-04,  6.4643e-03,  3.9357e-02,\n",
      "         2.3693e-02, -1.3498e-02,  3.6370e-02,  2.4094e-02,  3.9730e-02,\n",
      "        -1.1512e-03, -1.1824e-03, -4.3515e-02, -1.3403e-02, -4.4049e-02,\n",
      "        -3.9408e-02,  5.3058e-03,  7.3418e-03,  3.6012e-02, -2.1932e-02,\n",
      "         2.8280e-03,  4.1163e-02,  4.6627e-04, -3.8704e-02,  4.2697e-02,\n",
      "        -3.0630e-02, -1.7481e-02,  3.1702e-02,  3.2034e-02, -2.5207e-02,\n",
      "         1.1446e-03,  3.9408e-03,  3.9260e-03,  2.8058e-02, -4.2100e-02,\n",
      "         4.0119e-02,  3.7172e-02, -6.6243e-04,  2.5131e-02, -2.1128e-02,\n",
      "        -1.9494e-02, -3.2067e-02,  3.4816e-02,  1.5410e-02,  3.7154e-02,\n",
      "        -3.4411e-02, -4.1361e-02,  4.1716e-02, -3.3312e-02, -4.0515e-02,\n",
      "        -8.4767e-03,  9.8349e-03, -5.6818e-03, -3.5741e-03, -2.4196e-03,\n",
      "         3.0210e-02, -1.2377e-02, -3.8752e-02, -3.5664e-03, -3.9860e-02,\n",
      "        -2.9383e-02, -3.0057e-02,  3.3810e-02, -9.3425e-04,  2.7357e-02,\n",
      "        -4.5036e-02, -2.9843e-02, -4.1723e-02,  3.2641e-02, -3.3551e-02,\n",
      "         1.5916e-02,  2.7998e-02,  3.5986e-02, -3.3364e-02,  2.6196e-02,\n",
      "        -3.1085e-02,  2.4302e-02,  1.2643e-02, -3.5709e-04,  2.6259e-02,\n",
      "         3.4792e-02,  2.8460e-02, -2.8220e-02, -3.5917e-02,  7.9079e-03,\n",
      "         6.7270e-03,  4.3255e-02, -3.6528e-02, -3.4540e-02, -2.3074e-02,\n",
      "        -4.1841e-03, -3.8413e-02, -3.2069e-02,  1.1363e-04, -2.2433e-02,\n",
      "        -6.9064e-03, -2.4919e-02, -4.1014e-02,  1.8232e-02,  1.4343e-02,\n",
      "         1.0237e-02,  3.5884e-02,  1.8330e-02,  2.0192e-02,  3.4340e-02,\n",
      "         1.3869e-02, -2.5196e-02, -4.2229e-02, -1.0522e-02, -2.0558e-02,\n",
      "         4.2251e-02,  1.4313e-02,  3.9612e-02,  4.0982e-02,  4.0312e-03,\n",
      "         1.2857e-02, -1.0651e-03,  1.0501e-02,  4.4073e-02,  2.8764e-02,\n",
      "         1.8486e-02,  4.3086e-02, -1.8503e-02,  5.4351e-03,  3.1795e-02,\n",
      "        -3.5395e-02,  1.7240e-02, -2.3726e-03, -1.0206e-02,  1.4734e-02,\n",
      "        -1.9274e-02,  2.9954e-02,  2.3764e-02, -2.7346e-02, -2.3996e-02,\n",
      "         4.0190e-02,  2.4386e-02,  1.2525e-02, -3.7621e-02,  2.1802e-02,\n",
      "         1.0882e-04, -2.8361e-02, -1.9796e-02,  2.0401e-02, -1.6625e-02,\n",
      "        -1.4717e-02,  4.4951e-03, -4.3661e-02,  1.2552e-02,  3.8939e-02,\n",
      "         2.5487e-02, -2.4369e-02,  3.7179e-02, -3.9028e-02, -2.7659e-02,\n",
      "        -1.6757e-02, -1.8865e-03, -2.1282e-02, -2.3578e-02, -2.5558e-02,\n",
      "        -1.3131e-02,  2.4481e-02,  5.9085e-03,  1.6594e-02,  2.3417e-02,\n",
      "        -2.6938e-02,  2.4192e-02, -3.4959e-02,  2.8296e-02,  2.8840e-02,\n",
      "        -3.9451e-02,  3.3194e-02,  3.1125e-03, -1.6467e-02,  1.8910e-03,\n",
      "        -2.0728e-02, -9.0408e-03, -3.1726e-02, -1.3173e-02, -2.4029e-02,\n",
      "        -2.5332e-02, -3.0142e-02, -3.8300e-03,  1.0182e-02,  1.9819e-02,\n",
      "        -3.0040e-02, -1.4484e-02, -1.3370e-02, -1.6249e-02,  2.6749e-02,\n",
      "         2.0967e-02,  3.4547e-02, -1.1365e-02,  4.2511e-02, -1.7423e-02,\n",
      "         1.2768e-02, -3.1298e-02, -3.8506e-02, -2.6294e-02,  4.1835e-02,\n",
      "         1.2539e-02,  2.3299e-02,  3.9865e-02,  5.1098e-03,  8.5890e-03,\n",
      "         4.4386e-02,  4.1583e-02,  6.5362e-03,  2.1708e-02,  3.8114e-02,\n",
      "         4.2659e-02,  1.4047e-02, -6.5735e-03, -3.1642e-02, -3.3830e-04,\n",
      "         4.2875e-02, -3.7281e-02,  3.4434e-03, -1.3309e-02,  2.4423e-02,\n",
      "         4.5998e-05,  2.6266e-02,  3.9293e-02, -3.2069e-02,  2.3159e-02,\n",
      "         4.1843e-02,  4.0320e-02,  2.1009e-02,  1.1391e-02,  3.9734e-02,\n",
      "        -3.4137e-02,  2.0603e-02,  2.0797e-02,  2.7760e-02, -2.4365e-02,\n",
      "        -1.3042e-02,  2.9309e-03,  1.7476e-02, -2.8277e-02, -3.4277e-03,\n",
      "         2.1896e-02, -2.7562e-02,  1.3444e-02, -3.6942e-02,  3.1688e-02,\n",
      "         3.2736e-02,  2.0342e-02, -4.2790e-02,  4.2681e-02, -7.7514e-03,\n",
      "         1.8188e-03, -2.4968e-02, -2.8556e-02,  2.6870e-02,  4.2574e-02,\n",
      "         1.7777e-02, -2.5820e-02,  4.9321e-03, -1.6871e-02, -4.3070e-02,\n",
      "        -2.8009e-02, -4.0616e-02,  4.1111e-02, -1.2546e-02, -1.8567e-02,\n",
      "         2.4765e-02, -2.4291e-02,  3.8563e-02, -4.2518e-02, -4.0539e-02,\n",
      "         3.0354e-02,  2.8262e-02, -1.1489e-02, -7.4718e-03,  1.0310e-03,\n",
      "         2.2315e-02,  2.4685e-02, -3.0643e-02, -9.8660e-03,  3.9743e-02,\n",
      "         2.0114e-02, -1.5805e-02, -2.7685e-02,  3.3003e-02,  2.6008e-02,\n",
      "        -3.9625e-02, -5.2705e-03,  3.1695e-02,  1.8152e-03,  6.2066e-03,\n",
      "         3.3127e-02,  1.2979e-02,  1.9365e-03,  2.9576e-02, -5.3636e-03,\n",
      "         3.4947e-02,  3.8646e-02,  8.1713e-03, -1.8396e-02,  1.3056e-02,\n",
      "         2.9909e-02,  3.7744e-02,  1.3143e-02, -3.4468e-02,  4.0321e-02,\n",
      "        -7.6941e-03,  2.4585e-02,  3.3070e-02,  1.1232e-02,  4.2048e-04,\n",
      "        -1.8594e-02,  4.0164e-02,  2.5033e-02, -1.7883e-02,  2.9105e-02,\n",
      "         2.8647e-02, -3.7006e-03, -2.8199e-02,  1.8293e-02, -2.8611e-02,\n",
      "         1.3169e-02, -3.6379e-02, -1.0730e-02,  3.8491e-02,  4.0580e-02,\n",
      "        -2.2358e-03,  1.9360e-02,  4.4192e-02,  3.4210e-02, -4.0898e-02,\n",
      "        -2.6421e-02, -3.3163e-02, -1.5684e-02,  3.3683e-03,  1.5412e-02,\n",
      "         1.3067e-02, -2.2996e-02,  2.6664e-02,  3.0162e-02,  4.2736e-02,\n",
      "         1.2925e-02, -1.9515e-02, -3.2047e-02,  2.2998e-02, -1.4809e-02,\n",
      "         3.7871e-02,  1.2535e-02, -2.6687e-02, -5.3852e-03, -2.6750e-02,\n",
      "        -1.7976e-03,  2.6706e-02, -1.9332e-02,  1.3011e-02,  4.1499e-02,\n",
      "        -1.9100e-02, -5.7636e-04,  1.3861e-02, -2.3387e-02, -9.8295e-03,\n",
      "         2.6593e-04,  3.0776e-02,  1.9377e-02,  1.7994e-02,  1.2701e-02,\n",
      "        -3.7562e-02,  4.1022e-02,  2.9239e-02,  2.9179e-02, -3.9602e-02,\n",
      "         2.1645e-02,  4.0009e-02, -3.3009e-02, -4.5802e-02,  2.1115e-02,\n",
      "         1.9223e-02, -3.9095e-02, -9.7227e-03, -2.4078e-02,  1.5459e-02,\n",
      "        -8.5065e-03, -5.0222e-03,  1.5531e-02, -3.4117e-02, -3.8866e-02,\n",
      "        -2.2250e-02, -2.9054e-02], device='cuda:0')), ('clinical_rna_feedforward.feedforward.12.weight', tensor([[ 0.0344, -0.0035,  0.0404,  ...,  0.0168, -0.0220, -0.0407],\n",
      "        [ 0.0242, -0.0227, -0.0149,  ..., -0.0019,  0.0394,  0.0269],\n",
      "        [ 0.0283,  0.0220,  0.0358,  ..., -0.0377, -0.0048,  0.0221],\n",
      "        ...,\n",
      "        [ 0.0184,  0.0031,  0.0003,  ..., -0.0003, -0.0250,  0.0124],\n",
      "        [ 0.0186, -0.0138,  0.0326,  ..., -0.0397,  0.0138, -0.0199],\n",
      "        [-0.0160, -0.0320, -0.0207,  ..., -0.0146, -0.0091, -0.0114]],\n",
      "       device='cuda:0')), ('clinical_rna_feedforward.feedforward.12.bias', tensor([-0.0383,  0.0224, -0.0229, -0.0368, -0.0054, -0.0201, -0.0274, -0.0403,\n",
      "         0.0295, -0.0367,  0.0260, -0.0444, -0.0185, -0.0416,  0.0198,  0.0347,\n",
      "        -0.0040,  0.0192, -0.0283, -0.0095, -0.0067, -0.0039, -0.0016,  0.0277,\n",
      "        -0.0247,  0.0399, -0.0165, -0.0150,  0.0405,  0.0075, -0.0232, -0.0410,\n",
      "         0.0109, -0.0039,  0.0431,  0.0108, -0.0174,  0.0361,  0.0387, -0.0243,\n",
      "         0.0092, -0.0335,  0.0033, -0.0211, -0.0135,  0.0175,  0.0284,  0.0154,\n",
      "         0.0391, -0.0339,  0.0411,  0.0233, -0.0305,  0.0342, -0.0319, -0.0326,\n",
      "        -0.0263,  0.0338, -0.0089,  0.0035, -0.0067,  0.0192,  0.0159, -0.0266,\n",
      "         0.0018,  0.0122, -0.0285,  0.0400, -0.0037,  0.0418, -0.0040, -0.0240,\n",
      "        -0.0091,  0.0141,  0.0147, -0.0434, -0.0170,  0.0250,  0.0244, -0.0040,\n",
      "         0.0351, -0.0105,  0.0368,  0.0022,  0.0272, -0.0396,  0.0300,  0.0137,\n",
      "         0.0226, -0.0088,  0.0102,  0.0088, -0.0076, -0.0345,  0.0153, -0.0246,\n",
      "        -0.0406,  0.0215, -0.0034, -0.0088,  0.0086,  0.0213,  0.0309,  0.0078,\n",
      "         0.0059,  0.0055, -0.0053,  0.0436, -0.0282, -0.0026, -0.0318, -0.0276,\n",
      "         0.0070, -0.0336, -0.0441, -0.0368, -0.0034, -0.0385, -0.0393,  0.0323,\n",
      "         0.0181, -0.0324, -0.0114,  0.0423, -0.0093, -0.0156,  0.0318, -0.0258,\n",
      "         0.0273,  0.0051, -0.0151,  0.0198, -0.0152,  0.0369,  0.0403, -0.0246,\n",
      "         0.0196, -0.0165, -0.0204, -0.0424, -0.0412,  0.0189,  0.0428,  0.0251,\n",
      "         0.0108, -0.0413,  0.0195, -0.0209, -0.0349,  0.0313,  0.0312, -0.0274,\n",
      "         0.0162,  0.0255, -0.0338,  0.0248, -0.0077, -0.0265, -0.0021,  0.0263,\n",
      "         0.0340,  0.0050, -0.0002, -0.0089,  0.0216,  0.0016,  0.0421,  0.0297,\n",
      "        -0.0214,  0.0070,  0.0080,  0.0135,  0.0227, -0.0229, -0.0096,  0.0185,\n",
      "         0.0277,  0.0247, -0.0073,  0.0385, -0.0121,  0.0080, -0.0005, -0.0211,\n",
      "        -0.0149, -0.0445,  0.0311,  0.0325,  0.0305,  0.0247,  0.0132,  0.0055,\n",
      "        -0.0035,  0.0148,  0.0120, -0.0313, -0.0158,  0.0099,  0.0042,  0.0265,\n",
      "        -0.0085, -0.0141, -0.0279, -0.0203, -0.0254,  0.0304, -0.0078, -0.0312,\n",
      "        -0.0210,  0.0385,  0.0147, -0.0214,  0.0272, -0.0030, -0.0443,  0.0429,\n",
      "         0.0070, -0.0040,  0.0060,  0.0284,  0.0246, -0.0414, -0.0390, -0.0029,\n",
      "         0.0427,  0.0360, -0.0118,  0.0303,  0.0290, -0.0411,  0.0032,  0.0052,\n",
      "         0.0398,  0.0242, -0.0408,  0.0355,  0.0267,  0.0201,  0.0330,  0.0226,\n",
      "        -0.0368, -0.0299, -0.0449,  0.0397, -0.0043,  0.0286, -0.0130,  0.0120,\n",
      "        -0.0311, -0.0311, -0.0261, -0.0435, -0.0360,  0.0244, -0.0261,  0.0113],\n",
      "       device='cuda:0')), ('clinical_rna_feedforward.feedforward.15.weight', tensor([[-0.0395, -0.0613,  0.0592,  ..., -0.0090, -0.0384,  0.0100],\n",
      "        [-0.0082,  0.0101, -0.0223,  ..., -0.0419, -0.0098, -0.0155],\n",
      "        [ 0.0369, -0.0358, -0.0023,  ..., -0.0454, -0.0354,  0.0035],\n",
      "        ...,\n",
      "        [ 0.0305, -0.0622, -0.0005,  ...,  0.0337,  0.0073,  0.0309],\n",
      "        [ 0.0042,  0.0115, -0.0531,  ..., -0.0028,  0.0605, -0.0536],\n",
      "        [-0.0509, -0.0591,  0.0214,  ...,  0.0025,  0.0522,  0.0490]],\n",
      "       device='cuda:0')), ('clinical_rna_feedforward.feedforward.15.bias', tensor([ 0.0495, -0.0206, -0.0603, -0.0089,  0.0064, -0.0334, -0.0443, -0.0017,\n",
      "         0.0050,  0.0158,  0.0480, -0.0225, -0.0458,  0.0276,  0.0266,  0.0160,\n",
      "        -0.0384,  0.0004,  0.0583,  0.0047,  0.0452, -0.0318,  0.0470, -0.0156,\n",
      "         0.0200,  0.0614, -0.0082, -0.0242,  0.0110, -0.0624, -0.0071, -0.0390,\n",
      "         0.0130,  0.0581,  0.0035, -0.0323,  0.0253,  0.0590, -0.0185, -0.0267,\n",
      "        -0.0156, -0.0588, -0.0216, -0.0061,  0.0256,  0.0275, -0.0537, -0.0249,\n",
      "         0.0488,  0.0002,  0.0427,  0.0314, -0.0125, -0.0512,  0.0045,  0.0311,\n",
      "        -0.0424, -0.0045,  0.0200,  0.0485,  0.0331,  0.0070,  0.0207, -0.0485,\n",
      "        -0.0473, -0.0104,  0.0513, -0.0267,  0.0611, -0.0394,  0.0137, -0.0528,\n",
      "         0.0523, -0.0143,  0.0296,  0.0395,  0.0044, -0.0316,  0.0028,  0.0232,\n",
      "         0.0509, -0.0599, -0.0462, -0.0620, -0.0044, -0.0529,  0.0563, -0.0313,\n",
      "        -0.0168,  0.0153,  0.0320,  0.0207, -0.0325, -0.0339,  0.0460, -0.0260,\n",
      "        -0.0608,  0.0085, -0.0581,  0.0123,  0.0380, -0.0239,  0.0018, -0.0273,\n",
      "         0.0303, -0.0358, -0.0503,  0.0371,  0.0537, -0.0448,  0.0345, -0.0066,\n",
      "         0.0405,  0.0502,  0.0528,  0.0300, -0.0366,  0.0369,  0.0618, -0.0209,\n",
      "        -0.0587, -0.0523,  0.0348,  0.0305,  0.0351,  0.0218, -0.0047, -0.0452,\n",
      "        -0.0226, -0.0020,  0.0306,  0.0339,  0.0213, -0.0471,  0.0607,  0.0274,\n",
      "         0.0127,  0.0503, -0.0511, -0.0466,  0.0462,  0.0216,  0.0344,  0.0621,\n",
      "        -0.0412, -0.0519,  0.0341, -0.0615,  0.0149,  0.0529,  0.0418, -0.0497,\n",
      "        -0.0464, -0.0161,  0.0472, -0.0228,  0.0067, -0.0001,  0.0488,  0.0428,\n",
      "         0.0467,  0.0493,  0.0564, -0.0365, -0.0040, -0.0159, -0.0040, -0.0015,\n",
      "        -0.0043, -0.0469, -0.0350,  0.0079, -0.0527, -0.0144,  0.0172,  0.0191,\n",
      "        -0.0168, -0.0067,  0.0197, -0.0356,  0.0305,  0.0437,  0.0475, -0.0485,\n",
      "        -0.0414, -0.0512,  0.0517, -0.0456,  0.0029,  0.0333,  0.0341, -0.0199,\n",
      "         0.0578, -0.0447,  0.0023,  0.0558,  0.0221,  0.0082,  0.0554,  0.0097,\n",
      "        -0.0486, -0.0366, -0.0441,  0.0044, -0.0270, -0.0466,  0.0127, -0.0563,\n",
      "        -0.0355, -0.0424,  0.0375, -0.0275, -0.0119,  0.0591,  0.0291, -0.0611,\n",
      "         0.0112,  0.0234, -0.0628, -0.0520,  0.0305,  0.0526,  0.0325,  0.0134,\n",
      "         0.0049, -0.0224, -0.0407, -0.0546, -0.0116,  0.0196, -0.0407,  0.0566,\n",
      "         0.0506, -0.0433,  0.0173,  0.0170,  0.0208, -0.0301,  0.0481, -0.0146,\n",
      "         0.0312,  0.0377,  0.0024,  0.0184, -0.0485, -0.0177, -0.0228,  0.0388,\n",
      "         0.0346,  0.0530,  0.0043,  0.0546, -0.0572, -0.0389,  0.0100,  0.0577],\n",
      "       device='cuda:0')), ('clinical_rna_feedforward.feedforward.18.weight', tensor([[ 0.0046, -0.0524,  0.0350,  ..., -0.0232, -0.0403,  0.0153],\n",
      "        [-0.0192,  0.0489,  0.0351,  ...,  0.0006, -0.0052,  0.0628],\n",
      "        [-0.0439,  0.0035, -0.0201,  ...,  0.0572, -0.0338, -0.0245],\n",
      "        ...,\n",
      "        [ 0.0435,  0.0623, -0.0300,  ..., -0.0034,  0.0259,  0.0101],\n",
      "        [ 0.0243, -0.0248,  0.0311,  ...,  0.0064,  0.0174, -0.0010],\n",
      "        [ 0.0410, -0.0625,  0.0456,  ..., -0.0560,  0.0280,  0.0436]],\n",
      "       device='cuda:0')), ('clinical_rna_feedforward.feedforward.18.bias', tensor([-0.0202, -0.0439, -0.0167,  0.0164,  0.0142, -0.0488, -0.0363, -0.0575,\n",
      "         0.0315, -0.0044,  0.0096, -0.0500, -0.0172, -0.0042, -0.0566,  0.0439,\n",
      "         0.0503,  0.0447, -0.0054,  0.0212, -0.0011, -0.0033, -0.0248,  0.0067,\n",
      "         0.0286, -0.0055, -0.0320,  0.0062,  0.0465, -0.0044,  0.0317,  0.0052,\n",
      "         0.0502,  0.0090, -0.0175,  0.0509,  0.0473, -0.0042,  0.0035,  0.0300,\n",
      "         0.0386,  0.0068,  0.0565,  0.0364, -0.0256,  0.0439, -0.0246, -0.0379,\n",
      "        -0.0092, -0.0279,  0.0230,  0.0520,  0.0014,  0.0171,  0.0209, -0.0615,\n",
      "         0.0353, -0.0039, -0.0084, -0.0617, -0.0046, -0.0535, -0.0054, -0.0363,\n",
      "         0.0604,  0.0429,  0.0438,  0.0181, -0.0008, -0.0242, -0.0549,  0.0090,\n",
      "         0.0402, -0.0005,  0.0358, -0.0581, -0.0449, -0.0253,  0.0596,  0.0460,\n",
      "        -0.0059,  0.0348,  0.0209,  0.0499, -0.0245,  0.0441, -0.0282,  0.0264,\n",
      "        -0.0309,  0.0281, -0.0388,  0.0078, -0.0209,  0.0038,  0.0352, -0.0434,\n",
      "         0.0295, -0.0606, -0.0031, -0.0542,  0.0073, -0.0052,  0.0084,  0.0046,\n",
      "         0.0320, -0.0543,  0.0377,  0.0129, -0.0134, -0.0403, -0.0489, -0.0139,\n",
      "        -0.0069, -0.0009, -0.0085, -0.0307,  0.0393, -0.0074,  0.0265, -0.0465,\n",
      "         0.0137, -0.0036, -0.0528, -0.0153,  0.0164, -0.0626,  0.0011, -0.0579],\n",
      "       device='cuda:0')), ('clinical_rna_feedforward.feedforward.21.weight', tensor([[ 0.0106,  0.0409,  0.0641,  ...,  0.0812, -0.0063, -0.0803],\n",
      "        [ 0.0408,  0.0094, -0.0303,  ...,  0.0463, -0.0683, -0.0346],\n",
      "        [ 0.0076, -0.0656,  0.0058,  ..., -0.0189,  0.0060,  0.0881],\n",
      "        ...,\n",
      "        [ 0.0177, -0.0740,  0.0670,  ..., -0.0725,  0.0881,  0.0130],\n",
      "        [ 0.0444,  0.0367, -0.0807,  ...,  0.0372, -0.0322, -0.0302],\n",
      "        [-0.0554, -0.0249,  0.0779,  ...,  0.0679, -0.0312, -0.0461]],\n",
      "       device='cuda:0')), ('clinical_rna_feedforward.feedforward.21.bias', tensor([-0.0514, -0.0624,  0.0183,  0.0015,  0.0350, -0.0840,  0.0551,  0.0280,\n",
      "         0.0675,  0.0312, -0.0010, -0.0191, -0.0712, -0.0820, -0.0783,  0.0685,\n",
      "         0.0602,  0.0113, -0.0714, -0.0778, -0.0284, -0.0233,  0.0530, -0.0497,\n",
      "         0.0448, -0.0408, -0.0184, -0.0153,  0.0596,  0.0037,  0.0102,  0.0580,\n",
      "         0.0766,  0.0808, -0.0729, -0.0601, -0.0116,  0.0043,  0.0762,  0.0083,\n",
      "         0.0147,  0.0572, -0.0703, -0.0541,  0.0809,  0.0543, -0.0666,  0.0792,\n",
      "        -0.0034,  0.0521,  0.0723, -0.0560, -0.0507, -0.0504,  0.0782, -0.0221,\n",
      "        -0.0154,  0.0031,  0.0169,  0.0318,  0.0771, -0.0100,  0.0837,  0.0519,\n",
      "        -0.0467, -0.0369, -0.0554,  0.0105,  0.0277,  0.0036, -0.0870,  0.0364,\n",
      "         0.0155,  0.0258, -0.0646,  0.0040, -0.0892,  0.0711, -0.0023,  0.0564,\n",
      "        -0.0593,  0.0290,  0.0710,  0.0693,  0.0228, -0.0196, -0.0307, -0.0021,\n",
      "        -0.0283,  0.0102,  0.0610, -0.0376, -0.0608,  0.0171, -0.0859,  0.0457,\n",
      "        -0.0480,  0.0556,  0.0472, -0.0569, -0.0370,  0.0247, -0.0611, -0.0165,\n",
      "        -0.0522, -0.0540,  0.0642,  0.0059, -0.0326, -0.0793, -0.0305, -0.0195,\n",
      "        -0.0459, -0.0202, -0.0527, -0.0490,  0.0849, -0.0048,  0.0765,  0.0078,\n",
      "         0.0666,  0.0535, -0.0272,  0.0486, -0.0013,  0.0766,  0.0198, -0.0726],\n",
      "       device='cuda:0')), ('clinical_rna_feedforward.feedforward.24.weight', tensor([[ 0.0567,  0.0723, -0.0870,  ...,  0.0853,  0.0080,  0.0209],\n",
      "        [-0.0429,  0.0798, -0.0659,  ..., -0.0886,  0.0762,  0.0197],\n",
      "        [-0.0200,  0.0202,  0.0425,  ...,  0.0017,  0.0442, -0.0379],\n",
      "        ...,\n",
      "        [-0.0634,  0.0513, -0.0848,  ..., -0.0469,  0.0832,  0.0004],\n",
      "        [ 0.0166,  0.0105,  0.0887,  ..., -0.0533,  0.0401,  0.0432],\n",
      "        [ 0.0782,  0.0766, -0.0356,  ...,  0.0021, -0.0588, -0.0827]],\n",
      "       device='cuda:0')), ('clinical_rna_feedforward.feedforward.24.bias', tensor([ 0.0342, -0.0805, -0.0486,  0.0345,  0.0818, -0.0277, -0.0613, -0.0211,\n",
      "         0.0290, -0.0453, -0.0815, -0.0141, -0.0594,  0.0443, -0.0773,  0.0865,\n",
      "        -0.0210, -0.0024, -0.0126, -0.0634, -0.0368, -0.0060,  0.0325,  0.0380,\n",
      "         0.0843, -0.0007, -0.0361, -0.0110, -0.0435, -0.0562, -0.0340, -0.0826,\n",
      "        -0.0838, -0.0603, -0.0743,  0.0381, -0.0110, -0.0086,  0.0225, -0.0464,\n",
      "        -0.0183, -0.0014,  0.0675,  0.0802, -0.0516,  0.0458,  0.0713,  0.0474,\n",
      "        -0.0126,  0.0439,  0.0702,  0.0106, -0.0819, -0.0042, -0.0872,  0.0664,\n",
      "        -0.0797, -0.0349, -0.0700,  0.0760, -0.0660,  0.0441,  0.0879,  0.0594],\n",
      "       device='cuda:0')), ('clinical_rna_feedforward.feedforward.27.weight', tensor([[-0.1004,  0.1162, -0.0299,  ...,  0.0473, -0.0778, -0.1227],\n",
      "        [-0.0366, -0.0608, -0.0603,  ..., -0.0069,  0.0217, -0.0247],\n",
      "        [ 0.0576, -0.0919, -0.0909,  ...,  0.0975, -0.1142,  0.0012],\n",
      "        ...,\n",
      "        [-0.0693,  0.0207, -0.1159,  ...,  0.0805,  0.1228,  0.0682],\n",
      "        [ 0.0599,  0.0814, -0.0505,  ..., -0.0521,  0.1027, -0.0165],\n",
      "        [-0.0966,  0.0484,  0.1055,  ...,  0.0861, -0.0967,  0.0154]],\n",
      "       device='cuda:0')), ('clinical_rna_feedforward.feedforward.27.bias', tensor([-0.0855, -0.0184, -0.0783,  0.0558,  0.1117, -0.0572,  0.0984, -0.1016,\n",
      "        -0.0689, -0.1205,  0.0789, -0.0809, -0.0121,  0.0365,  0.0568, -0.0011,\n",
      "        -0.0764,  0.0283,  0.0114, -0.0019,  0.1044, -0.0090,  0.0584, -0.1056,\n",
      "         0.0918,  0.0269, -0.0846,  0.0455, -0.0765,  0.0535, -0.0602, -0.0889,\n",
      "         0.1103, -0.0392, -0.0052, -0.0942,  0.0575,  0.1100, -0.0438, -0.0460,\n",
      "        -0.1175,  0.0028, -0.0785,  0.0121, -0.1039, -0.0781,  0.0589, -0.1231,\n",
      "         0.0304, -0.1019,  0.1035,  0.0951, -0.0808,  0.0740, -0.0564, -0.1060,\n",
      "         0.0902,  0.0286, -0.0269,  0.0812,  0.0725,  0.0252,  0.0987,  0.0197],\n",
      "       device='cuda:0')), ('clinical_rna_feedforward.feedforward.30.weight', tensor([[ 0.1090, -0.0197,  0.0638,  ..., -0.1040, -0.1108,  0.0828],\n",
      "        [ 0.0892, -0.0350,  0.0103,  ...,  0.0325, -0.0923, -0.0130],\n",
      "        [-0.0872, -0.1143,  0.0739,  ..., -0.0469,  0.1222, -0.0525],\n",
      "        ...,\n",
      "        [ 0.0566, -0.0463,  0.0733,  ...,  0.0572,  0.0168,  0.0636],\n",
      "        [-0.0458,  0.0711, -0.0769,  ..., -0.0562,  0.0103, -0.0405],\n",
      "        [-0.0819, -0.1052, -0.0206,  ...,  0.0255, -0.0291, -0.0797]],\n",
      "       device='cuda:0')), ('clinical_rna_feedforward.feedforward.30.bias', tensor([ 0.0794, -0.1026,  0.0454,  0.1214,  0.0476,  0.1032,  0.0955,  0.0996,\n",
      "        -0.0334, -0.0865, -0.0129, -0.1233,  0.1155,  0.0755,  0.0766,  0.0987,\n",
      "         0.0241, -0.0666,  0.0827, -0.0461,  0.0775, -0.1113, -0.0956,  0.1128,\n",
      "        -0.0411,  0.0555,  0.0505,  0.0691, -0.0429, -0.0628, -0.1021, -0.0803],\n",
      "       device='cuda:0')), ('clinical_rna_feedforward.feedforward.33.weight', tensor([[-0.0027,  0.0430, -0.0957,  ...,  0.1025, -0.0609, -0.1076],\n",
      "        [ 0.1548,  0.1481,  0.1158,  ...,  0.0586,  0.0828,  0.0009],\n",
      "        [ 0.1314, -0.0690, -0.0580,  ..., -0.0901,  0.1418,  0.0782],\n",
      "        ...,\n",
      "        [-0.1105,  0.1505, -0.1571,  ...,  0.0174, -0.1086, -0.1050],\n",
      "        [-0.0402, -0.1637,  0.0911,  ...,  0.0941, -0.1393, -0.1672],\n",
      "        [ 0.1551, -0.0531,  0.0321,  ...,  0.0995,  0.1722,  0.0337]],\n",
      "       device='cuda:0')), ('clinical_rna_feedforward.feedforward.33.bias', tensor([ 0.1424,  0.1417, -0.0130, -0.1173,  0.0165,  0.0589,  0.0942,  0.0369,\n",
      "         0.0028, -0.0452, -0.0840, -0.0293,  0.0752, -0.0914, -0.1141, -0.1628,\n",
      "         0.1381, -0.1446,  0.1152,  0.1258, -0.0031,  0.0578, -0.0460, -0.1432,\n",
      "        -0.0223, -0.0373,  0.0465, -0.0448, -0.0808,  0.1672, -0.0163,  0.0868],\n",
      "       device='cuda:0')), ('wsi_fcn.conv.weight', tensor([[[-0.0144],\n",
      "         [-0.0217],\n",
      "         [-0.0351],\n",
      "         ...,\n",
      "         [-0.0425],\n",
      "         [-0.0021],\n",
      "         [-0.0352]],\n",
      "\n",
      "        [[-0.0044],\n",
      "         [ 0.0066],\n",
      "         [ 0.0141],\n",
      "         ...,\n",
      "         [ 0.0053],\n",
      "         [ 0.0115],\n",
      "         [-0.0200]],\n",
      "\n",
      "        [[ 0.0219],\n",
      "         [-0.0364],\n",
      "         [ 0.0175],\n",
      "         ...,\n",
      "         [-0.0356],\n",
      "         [ 0.0341],\n",
      "         [-0.0404]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0019],\n",
      "         [ 0.0105],\n",
      "         [-0.0329],\n",
      "         ...,\n",
      "         [ 0.0338],\n",
      "         [ 0.0080],\n",
      "         [-0.0359]],\n",
      "\n",
      "        [[ 0.0433],\n",
      "         [ 0.0287],\n",
      "         [-0.0436],\n",
      "         ...,\n",
      "         [-0.0195],\n",
      "         [ 0.0204],\n",
      "         [ 0.0315]],\n",
      "\n",
      "        [[ 0.0287],\n",
      "         [ 0.0075],\n",
      "         [-0.0158],\n",
      "         ...,\n",
      "         [-0.0183],\n",
      "         [-0.0265],\n",
      "         [ 0.0402]]], device='cuda:0')), ('wsi_fcn.conv.bias', tensor([ 0.0383,  0.0337,  0.0159,  0.0107, -0.0200, -0.0323,  0.0259, -0.0249,\n",
      "        -0.0063, -0.0367,  0.0127, -0.0342, -0.0190, -0.0184, -0.0433,  0.0192,\n",
      "        -0.0146,  0.0440, -0.0439,  0.0173,  0.0175,  0.0064, -0.0367,  0.0228,\n",
      "         0.0050,  0.0296,  0.0285,  0.0024,  0.0123,  0.0050,  0.0381, -0.0212,\n",
      "         0.0123,  0.0079,  0.0312, -0.0348, -0.0286, -0.0435, -0.0200,  0.0010,\n",
      "        -0.0108, -0.0292, -0.0006, -0.0177, -0.0271, -0.0243, -0.0031, -0.0338,\n",
      "        -0.0060,  0.0283,  0.0179, -0.0238, -0.0245,  0.0427,  0.0387,  0.0345,\n",
      "        -0.0037, -0.0218,  0.0362, -0.0427,  0.0202,  0.0001, -0.0176,  0.0047],\n",
      "       device='cuda:0')), ('attention.attention.0.weight', tensor([[ 0.0542, -0.0297,  0.0113,  ..., -0.0211, -0.0789, -0.0135],\n",
      "        [ 0.0600,  0.0410,  0.0780,  ...,  0.0130,  0.1163, -0.0278],\n",
      "        [-0.1069, -0.0930,  0.0376,  ...,  0.0101, -0.0301,  0.0829],\n",
      "        ...,\n",
      "        [-0.0809, -0.0338, -0.0499,  ...,  0.0743,  0.0676,  0.0837],\n",
      "        [ 0.1067, -0.0754,  0.0010,  ...,  0.0418, -0.0729,  0.1219],\n",
      "        [-0.0323, -0.0018,  0.0343,  ...,  0.0455, -0.0902,  0.0725]],\n",
      "       device='cuda:0')), ('attention.attention.0.bias', tensor([ 0.0155,  0.0889,  0.0613, -0.0649, -0.1065, -0.0858, -0.0274,  0.0951,\n",
      "         0.0935,  0.0341,  0.0749,  0.0789,  0.0480, -0.0276, -0.0305, -0.0086,\n",
      "        -0.1008,  0.1243,  0.1016,  0.0969, -0.1034, -0.0111,  0.1245,  0.0265,\n",
      "        -0.0523, -0.0314, -0.0973,  0.0906,  0.0863, -0.0149, -0.0785, -0.1167,\n",
      "        -0.0888, -0.0823,  0.0663,  0.0443, -0.0548,  0.0449,  0.1094,  0.0103,\n",
      "         0.0354, -0.0411,  0.0439,  0.0874, -0.0796,  0.0343,  0.1046, -0.0732,\n",
      "        -0.0281,  0.0827,  0.1058, -0.0332,  0.1164, -0.0765,  0.0181,  0.1047,\n",
      "        -0.0513,  0.0433,  0.1025, -0.0851, -0.1093, -0.0420, -0.1176,  0.0013],\n",
      "       device='cuda:0')), ('attention.attention.2.weight', tensor([[-0.0770,  0.0459, -0.0204,  0.0821,  0.0632,  0.1024,  0.0498, -0.1073,\n",
      "          0.0893,  0.0736,  0.0816,  0.0888,  0.0344,  0.0683,  0.0058, -0.0004,\n",
      "         -0.0918, -0.0299, -0.1237,  0.0883,  0.0809,  0.0479, -0.1136,  0.0098,\n",
      "          0.0193, -0.1013, -0.0403, -0.0103, -0.0558,  0.1126,  0.0907,  0.1036,\n",
      "         -0.0704, -0.1099,  0.1153,  0.1215, -0.0288, -0.0803,  0.0374,  0.1210,\n",
      "         -0.0042,  0.0302,  0.0177, -0.0701, -0.0662, -0.0733, -0.1110, -0.0639,\n",
      "         -0.0293, -0.1010, -0.0517, -0.1220, -0.0801, -0.0707,  0.0467,  0.0634,\n",
      "          0.0649,  0.0130,  0.1032, -0.1103, -0.1243,  0.0319, -0.0926, -0.0725]],\n",
      "       device='cuda:0')), ('attention.attention.2.bias', tensor([-0.0713], device='cuda:0')), ('baby_feed_forward.0.weight', tensor([[-0.0016, -0.0179,  0.0710,  ...,  0.0589, -0.0392, -0.0062],\n",
      "        [-0.0700,  0.0184,  0.0417,  ..., -0.0967,  0.0819, -0.0835],\n",
      "        [-0.0835,  0.0423,  0.0128,  ..., -0.0014, -0.0177,  0.0382],\n",
      "        ...,\n",
      "        [ 0.0215, -0.0431, -0.0614,  ..., -0.0901,  0.0224, -0.0833],\n",
      "        [-0.0676,  0.0868,  0.0927,  ...,  0.0789,  0.0305, -0.0085],\n",
      "        [-0.0827, -0.0230, -0.0312,  ..., -0.0751,  0.0896, -0.0882]],\n",
      "       device='cuda:0')), ('baby_feed_forward.0.bias', tensor([ 6.0016e-02, -3.3035e-02,  8.7655e-02, -1.0017e-01, -1.5096e-02,\n",
      "        -7.7603e-02, -6.7904e-02,  7.7002e-02,  1.4510e-02, -6.3682e-02,\n",
      "         4.8034e-02, -5.0411e-02, -6.3090e-02,  1.7112e-06, -6.4653e-02,\n",
      "         2.1158e-02,  4.0585e-02,  8.0243e-03,  7.8483e-03, -3.0089e-02,\n",
      "         4.2563e-02, -4.1304e-02, -6.7679e-02, -2.0703e-02,  4.7222e-02,\n",
      "        -8.9207e-02,  3.3538e-02,  3.8179e-02, -9.8826e-02, -2.3582e-02,\n",
      "        -7.4038e-03, -2.9490e-02,  9.6656e-02, -1.5609e-02,  9.8327e-02,\n",
      "         8.3592e-02, -2.7533e-02,  7.8635e-02,  5.1889e-03,  5.1041e-02,\n",
      "        -9.0503e-02, -9.7781e-02, -9.8819e-02,  4.9850e-02, -6.5948e-02,\n",
      "        -7.7503e-02,  2.1870e-02, -2.4192e-02,  5.2242e-02,  6.9887e-02,\n",
      "        -3.3353e-02,  1.3554e-02,  6.4444e-03,  8.2093e-02,  3.3651e-02,\n",
      "        -1.6312e-02,  5.7039e-02, -2.5767e-02, -2.0896e-02,  4.4032e-02,\n",
      "        -1.9522e-02, -2.1577e-02,  8.4874e-02,  2.1199e-02], device='cuda:0')), ('baby_feed_forward.2.weight', tensor([[ 3.1025e-02,  1.1099e-01, -7.8862e-02,  ..., -1.0573e-01,\n",
      "          6.5878e-05,  3.9599e-02],\n",
      "        [ 7.5267e-02, -8.1519e-02,  5.3735e-02,  ..., -3.3879e-02,\n",
      "          1.0699e-01,  9.8350e-02],\n",
      "        [-8.2498e-02,  1.6799e-02,  9.9452e-02,  ...,  4.3147e-02,\n",
      "          7.3294e-02,  1.8853e-02],\n",
      "        ...,\n",
      "        [ 6.3353e-02, -9.4795e-02,  7.5217e-02,  ...,  9.4055e-02,\n",
      "         -7.3711e-02, -2.1537e-02],\n",
      "        [ 1.5630e-02,  5.7475e-02, -1.9553e-02,  ...,  9.1269e-03,\n",
      "          1.7540e-02, -1.2552e-01],\n",
      "        [ 6.6127e-02, -1.4432e-02,  8.2807e-04,  ..., -3.3289e-02,\n",
      "         -1.8937e-02, -8.3590e-03]], device='cuda:0')), ('baby_feed_forward.2.bias', tensor([-0.0836,  0.1182,  0.0304,  0.0422,  0.0429,  0.1181, -0.0509, -0.0781,\n",
      "         0.0556,  0.0250, -0.0959,  0.0532, -0.0613, -0.0312, -0.0060, -0.0351,\n",
      "        -0.0945,  0.0772,  0.1177,  0.0023,  0.0198, -0.0870,  0.0226, -0.0957,\n",
      "         0.1084, -0.0065,  0.0043, -0.0036, -0.0269,  0.0766,  0.0119, -0.0433],\n",
      "       device='cuda:0')), ('baby_feed_forward.4.weight', tensor([[ 1.1253e-01, -1.0361e-01,  1.3314e-01, -1.1365e-01, -6.9035e-03,\n",
      "          2.9444e-02, -9.9306e-02,  2.9092e-02, -1.2657e-01,  1.2968e-01,\n",
      "          8.4098e-02,  6.3226e-02,  1.1724e-01,  9.9536e-02,  1.1089e-01,\n",
      "         -1.5752e-01, -1.0191e-01,  1.3563e-01,  3.1843e-02, -8.8836e-02,\n",
      "          1.5082e-01, -1.6402e-01, -1.5708e-01, -8.2565e-02, -4.5518e-02,\n",
      "         -1.3323e-01, -1.1096e-01,  1.4023e-01, -1.0741e-01, -1.2627e-01,\n",
      "         -1.1275e-01,  5.9514e-03],\n",
      "        [ 2.6084e-02,  6.9944e-02,  1.5086e-01, -6.5312e-02,  1.9746e-02,\n",
      "          1.1445e-01,  1.0854e-01,  2.4156e-02,  1.1198e-01,  1.5627e-01,\n",
      "          7.5314e-02, -1.4515e-01, -3.2171e-03, -1.0869e-01, -1.1196e-01,\n",
      "          3.1691e-02,  5.5004e-02,  7.0130e-03, -1.0415e-01, -6.4971e-02,\n",
      "          1.4103e-01,  6.3187e-02, -3.9805e-02, -1.5296e-01, -7.1109e-02,\n",
      "          9.5414e-02,  1.0303e-01, -8.7187e-02, -1.3686e-01,  4.0707e-02,\n",
      "         -8.0378e-02,  1.4633e-01],\n",
      "        [-6.6471e-02, -1.1361e-01, -3.5249e-03, -1.5647e-01, -8.0127e-02,\n",
      "         -1.4699e-01,  6.5085e-02, -7.7709e-02, -1.2311e-01, -1.5036e-01,\n",
      "          1.0320e-01, -1.5039e-01, -4.0303e-02, -4.8867e-02, -6.2875e-02,\n",
      "          1.0725e-01, -1.2931e-01, -1.7469e-01,  1.3755e-02, -1.2931e-01,\n",
      "         -1.2901e-01, -1.3501e-01,  2.8980e-02, -1.1230e-03,  6.2316e-04,\n",
      "         -2.2241e-04, -1.3615e-01,  8.2822e-02, -1.4526e-01, -8.1135e-03,\n",
      "          1.6407e-01,  3.3488e-02],\n",
      "        [-1.5339e-01,  1.7377e-01, -1.5211e-01,  1.5752e-01, -1.2234e-01,\n",
      "         -7.7943e-02, -4.2423e-02, -5.2338e-02, -1.5635e-01,  7.4362e-02,\n",
      "          2.1844e-02, -3.4979e-02, -1.0199e-02,  1.8059e-02, -1.1926e-01,\n",
      "          9.2070e-02, -6.9877e-02,  3.7409e-02, -8.1950e-02, -9.9805e-02,\n",
      "          1.5214e-01, -1.2382e-01, -1.4919e-01, -1.0849e-03, -1.4966e-01,\n",
      "          7.8054e-02, -7.7245e-04,  1.2380e-02,  1.4104e-01, -1.9076e-02,\n",
      "         -1.6465e-01,  1.0939e-01],\n",
      "        [ 2.4873e-02,  6.6942e-02,  1.6992e-01, -3.6263e-02, -1.7007e-01,\n",
      "         -1.5541e-01, -3.3388e-02,  7.2728e-02,  2.2371e-02,  4.1802e-02,\n",
      "          9.9116e-02, -1.2094e-01,  9.4390e-02, -5.8024e-02, -1.5090e-01,\n",
      "          1.7128e-01,  1.4306e-01, -1.1697e-01,  7.2065e-02,  1.5267e-02,\n",
      "          1.2059e-02,  1.0795e-02,  8.4905e-02, -4.5340e-02, -1.7576e-01,\n",
      "          5.1803e-02,  1.6553e-01, -2.1272e-03,  1.0271e-01,  1.1745e-01,\n",
      "         -1.0111e-03,  1.7201e-01],\n",
      "        [-7.2726e-02,  4.4461e-02, -4.1402e-02,  6.5758e-03, -1.2396e-01,\n",
      "          7.3559e-02,  1.4622e-01, -9.6881e-02, -3.9187e-02, -7.7356e-02,\n",
      "          1.3547e-01, -8.8700e-02,  1.1756e-01,  8.4641e-02, -5.9521e-02,\n",
      "         -1.1348e-01, -4.0452e-04, -1.5373e-01, -1.3114e-01,  6.5362e-02,\n",
      "         -1.5048e-01,  6.0209e-02,  5.7442e-02,  7.4419e-02, -1.3423e-02,\n",
      "          3.3322e-02,  6.6129e-02, -8.6791e-02,  8.7843e-02, -2.0170e-02,\n",
      "          7.7725e-02, -5.9077e-02],\n",
      "        [-1.8579e-02,  1.1082e-02, -7.1732e-02, -1.3014e-01,  5.9161e-02,\n",
      "          4.9442e-02, -7.2676e-02, -5.4436e-02, -5.7666e-02,  2.4044e-02,\n",
      "          9.7042e-02, -1.3623e-01, -1.3177e-01,  2.8110e-02,  3.8131e-02,\n",
      "          7.7151e-03, -1.4573e-01,  1.2590e-01, -9.0146e-02, -1.1124e-01,\n",
      "          1.5704e-01,  1.3763e-01, -1.0753e-01, -8.5185e-02, -1.2157e-01,\n",
      "         -1.4247e-01,  2.3176e-02,  1.4061e-01,  8.2120e-02,  3.2953e-02,\n",
      "         -1.3511e-01, -3.4501e-03],\n",
      "        [ 6.5155e-07,  1.2758e-01,  1.4349e-01,  1.2434e-01, -1.2246e-01,\n",
      "          1.5375e-01, -8.0154e-02, -1.1140e-01, -1.2993e-01, -1.1218e-01,\n",
      "          1.5758e-01,  1.6221e-01, -1.4878e-01,  1.3627e-01,  1.1435e-01,\n",
      "          4.8191e-02,  1.3694e-01,  4.1044e-03, -1.6465e-01,  6.0266e-02,\n",
      "          2.2740e-02, -8.3730e-02,  7.5008e-02,  8.2342e-02,  2.9860e-02,\n",
      "         -1.5771e-01, -1.1904e-02,  5.1796e-02,  1.5511e-01, -6.4320e-02,\n",
      "         -2.4712e-02, -8.4362e-02],\n",
      "        [ 7.4228e-02, -1.5664e-01, -7.2872e-02,  1.1200e-01,  1.4686e-01,\n",
      "          1.2190e-01, -7.4203e-03, -1.2647e-01,  7.9713e-02,  8.0426e-02,\n",
      "          1.3986e-01, -4.5199e-02, -4.9345e-02,  3.9749e-02, -6.2705e-04,\n",
      "          1.3152e-01, -2.2035e-08, -1.1960e-01,  1.1780e-01,  5.8041e-04,\n",
      "         -7.0317e-02, -9.1532e-03, -1.5709e-02,  1.1030e-03,  3.9994e-02,\n",
      "         -1.0987e-02,  8.2790e-02, -8.3912e-02,  4.7827e-02, -2.5827e-02,\n",
      "         -5.5545e-02,  1.5039e-01],\n",
      "        [-8.7238e-02,  1.1590e-01,  1.0040e-01,  4.4576e-02,  4.0726e-02,\n",
      "          1.2700e-01, -1.2182e-01,  9.2667e-02,  1.3624e-01,  3.5703e-02,\n",
      "          1.3148e-01,  1.5101e-01,  1.2749e-01, -1.5055e-01, -9.3953e-02,\n",
      "         -2.2272e-02, -6.4048e-02,  1.6808e-05, -8.7954e-02,  1.0164e-01,\n",
      "         -1.0392e-01, -8.3365e-02, -1.8906e-02, -9.9389e-02,  6.6964e-02,\n",
      "          7.9030e-02, -9.1707e-02,  8.0507e-02, -1.2259e-01, -8.5427e-02,\n",
      "         -4.9455e-02,  6.4875e-02],\n",
      "        [-1.7900e-02, -1.7407e-01, -1.0279e-01,  1.6063e-01, -1.6283e-01,\n",
      "         -1.0674e-01, -5.3821e-02, -1.4261e-01, -7.6761e-02, -8.9366e-02,\n",
      "         -6.2864e-02,  4.9764e-02, -1.3611e-02,  1.3774e-01, -2.3199e-02,\n",
      "         -7.2149e-03, -3.4113e-02, -2.1461e-02, -1.1882e-01, -8.7517e-02,\n",
      "         -1.6362e-01,  1.2613e-01, -6.7257e-02, -6.3344e-03, -1.3692e-01,\n",
      "          1.5131e-01,  1.5788e-01, -4.9053e-02, -1.6809e-01,  1.7071e-01,\n",
      "         -1.6235e-01,  1.1422e-01],\n",
      "        [-1.5200e-01, -1.1452e-01, -1.0369e-02,  6.2546e-03, -4.5511e-02,\n",
      "          8.2318e-02, -1.1571e-07, -3.4958e-02,  1.6060e-01,  2.1825e-03,\n",
      "         -1.0536e-01, -1.4243e-01,  5.6398e-02, -1.1078e-01, -1.2612e-01,\n",
      "          2.9533e-02,  1.0027e-01, -4.9507e-03,  1.7735e-01,  2.8395e-02,\n",
      "         -2.4475e-03,  1.5958e-01, -5.4867e-02,  1.2657e-01, -1.0504e-01,\n",
      "         -5.7456e-03, -2.0017e-02,  1.6011e-02, -9.1814e-02,  5.2568e-02,\n",
      "          5.2508e-02,  1.5391e-01],\n",
      "        [ 1.2726e-01,  9.4819e-02,  7.6678e-02, -7.4604e-02, -5.7127e-02,\n",
      "          1.7213e-01,  8.7437e-02,  1.3154e-01,  6.2880e-02, -5.3718e-02,\n",
      "          6.0731e-02,  1.3038e-01,  1.7824e-02,  1.3587e-02,  7.5223e-02,\n",
      "          1.3179e-02,  3.8149e-02,  1.3105e-01, -4.4012e-02,  1.7513e-01,\n",
      "          9.5543e-02, -7.4998e-02,  4.1240e-02,  1.7074e-01, -3.2249e-02,\n",
      "          1.1475e-01,  9.3980e-02, -2.6734e-02,  1.1640e-01, -1.5454e-02,\n",
      "          8.6092e-03, -4.2929e-03],\n",
      "        [-1.4837e-01, -1.3168e-01, -1.2298e-01, -2.0759e-02,  8.2222e-02,\n",
      "         -8.1013e-02,  1.3847e-01, -6.2276e-02,  4.2374e-02,  7.2966e-02,\n",
      "         -8.4401e-02,  1.1976e-01,  1.0109e-01, -2.5254e-03,  1.4888e-01,\n",
      "          1.8259e-02, -1.0102e-01, -1.2086e-01, -4.5820e-02,  5.8661e-02,\n",
      "          1.2217e-01, -1.0887e-01, -9.3459e-02,  1.3812e-01,  3.3822e-02,\n",
      "         -1.3445e-01, -8.8002e-02,  4.8430e-02, -4.1506e-02, -1.5385e-01,\n",
      "         -1.5767e-01, -9.9679e-03],\n",
      "        [-4.4852e-04,  4.1006e-02,  8.1942e-02,  3.5352e-02, -2.5615e-02,\n",
      "          1.6432e-01, -9.2838e-02,  9.6055e-02, -1.7156e-01, -1.2171e-01,\n",
      "          1.0505e-01, -9.5729e-02,  1.6939e-01, -1.4802e-01,  7.6230e-02,\n",
      "          1.2906e-01, -3.2007e-02,  6.9676e-02,  1.6788e-01, -6.7675e-02,\n",
      "         -1.0625e-01, -5.6127e-02,  6.0371e-02, -1.8809e-02,  1.0846e-01,\n",
      "         -9.5027e-02,  3.2011e-02, -1.4987e-01,  1.1200e-01, -3.2275e-02,\n",
      "         -1.3986e-01,  2.1303e-02],\n",
      "        [-1.0199e-01,  9.4789e-02,  9.2285e-02, -5.7300e-02, -7.5326e-02,\n",
      "          3.7851e-02,  1.5453e-02,  1.1425e-01,  1.0874e-01, -1.2020e-01,\n",
      "          3.9665e-03, -8.0189e-02,  4.0638e-02,  1.3005e-01,  1.1287e-01,\n",
      "         -5.1499e-02,  9.0966e-02, -1.1209e-01, -2.2689e-02,  1.6573e-01,\n",
      "         -4.1981e-02,  2.3630e-02, -1.1340e-01, -1.1795e-01,  1.3499e-01,\n",
      "         -1.5724e-01,  2.7567e-02,  1.7516e-01,  1.5925e-01, -9.0618e-02,\n",
      "          6.1732e-02, -1.0143e-01]], device='cuda:0')), ('baby_feed_forward.4.bias', tensor([-0.0896, -0.0921,  0.1527,  0.1571,  0.1281, -0.0139,  0.1351,  0.1348,\n",
      "        -0.1280, -0.1091,  0.1261,  0.0784,  0.0512,  0.0134,  0.1358,  0.1423],\n",
      "       device='cuda:0')), ('baby_feed_forward.6.weight', tensor([[ 1.7692e-01,  3.0020e-02,  4.3174e-06, -1.9921e-01, -1.7580e-01,\n",
      "          4.2003e-02, -1.2527e-01,  2.0773e-03,  9.6851e-02, -4.3354e-02,\n",
      "          1.8855e-01, -5.1094e-02, -2.2088e-01,  4.5181e-02, -1.7468e-01,\n",
      "         -1.1275e-01],\n",
      "        [ 2.2621e-01, -6.3241e-02,  1.9768e-01,  1.6265e-01, -1.8494e-01,\n",
      "          2.2035e-01, -1.1713e-01, -1.4898e-01, -1.9841e-01,  5.5567e-02,\n",
      "          4.3026e-02,  1.4082e-01,  6.6573e-02,  1.4551e-01,  1.8150e-01,\n",
      "         -9.0955e-02],\n",
      "        [ 1.4937e-01,  3.9446e-02,  7.5650e-04,  2.0567e-02,  9.0508e-02,\n",
      "         -1.7259e-01, -1.3604e-01,  9.2993e-03, -4.5516e-02, -5.7994e-02,\n",
      "          1.5718e-01, -5.5382e-02,  1.6013e-01,  1.1548e-01, -1.1455e-01,\n",
      "         -6.2460e-02],\n",
      "        [-2.2970e-03, -1.1514e-01,  1.0513e-01,  4.9694e-02, -2.2910e-01,\n",
      "          1.6618e-01,  1.4987e-01,  1.2077e-01,  2.1776e-02, -1.5520e-01,\n",
      "          3.5992e-02, -4.1849e-02, -6.6077e-02,  1.5482e-01, -8.3858e-02,\n",
      "         -2.1341e-01],\n",
      "        [-1.4725e-01,  5.4267e-02, -2.6658e-02,  1.3040e-01, -1.3392e-01,\n",
      "         -1.3587e-01, -2.1352e-02, -1.6421e-01,  4.0202e-02, -8.7158e-02,\n",
      "          1.4967e-01,  1.2002e-01,  2.0240e-02, -2.2176e-01,  4.3976e-02,\n",
      "         -5.9687e-02],\n",
      "        [-1.8997e-01, -1.2878e-01,  7.6839e-02,  1.6062e-01,  4.6794e-02,\n",
      "          1.3345e-01, -9.9619e-02, -1.4153e-01, -1.3107e-01,  1.0690e-01,\n",
      "          6.3837e-02,  2.2198e-02, -1.6479e-01,  1.4200e-01,  2.2330e-08,\n",
      "         -2.1962e-01],\n",
      "        [-1.9305e-01,  2.0752e-01, -2.4849e-01, -6.5035e-02, -1.6202e-01,\n",
      "         -5.5958e-02,  1.4277e-01, -2.3968e-01,  5.7789e-02, -1.7932e-01,\n",
      "          1.6430e-01, -7.3198e-02, -1.9110e-01,  1.3842e-01, -3.2607e-02,\n",
      "          1.0411e-01],\n",
      "        [ 2.1926e-01, -1.1859e-02, -2.3293e-01, -1.4226e-01,  1.9475e-01,\n",
      "         -1.7668e-01, -3.1514e-02,  2.3405e-01,  1.7093e-01,  7.9228e-02,\n",
      "          3.9171e-02, -1.6803e-01,  9.4341e-02, -9.0032e-02, -2.1125e-01,\n",
      "         -2.2348e-01]], device='cuda:0')), ('baby_feed_forward.6.bias', tensor([ 0.1229,  0.1327, -0.1071, -0.1392,  0.0094, -0.1185,  0.0974, -0.0377],\n",
      "       device='cuda:0')), ('baby_feed_forward.8.weight', tensor([[ 0.1167, -0.2544, -0.1444, -0.0986,  0.0946,  0.2997,  0.1566, -0.2967]],\n",
      "       device='cuda:0')), ('baby_feed_forward.8.bias', tensor([-0.2033], device='cuda:0'))])\n",
      "optimizer_state_dict {'state': {0: {'step': tensor(120., device='cuda:0'), 'exp_avg': tensor([[-1.4745e-07, -4.3655e-07, -1.6511e-10,  ..., -1.6829e-08,\n",
      "          2.6450e-08, -1.0113e-07],\n",
      "        [-3.3381e-06, -2.9343e-06, -2.1429e-06,  ...,  1.2061e-10,\n",
      "         -4.7569e-07, -5.3501e-06],\n",
      "        [ 2.6789e-11,  3.2843e-10, -5.1746e-12,  ...,  2.4923e-09,\n",
      "          2.7973e-13,  1.8240e-09],\n",
      "        ...,\n",
      "        [-5.5966e-07, -2.0873e-07, -1.3323e-09,  ...,  3.2855e-08,\n",
      "         -1.5646e-07,  3.3526e-07],\n",
      "        [ 1.9539e-07, -8.0136e-08,  2.1684e-09,  ...,  7.0133e-11,\n",
      "         -1.7876e-09, -3.1240e-08],\n",
      "        [ 1.1552e-07,  4.8328e-07, -1.0823e-09,  ..., -1.4855e-08,\n",
      "         -9.0007e-08,  1.3121e-07]], device='cuda:0'), 'exp_avg_sq': tensor([[5.0966e-14, 2.1484e-12, 5.3077e-15,  ..., 8.9895e-15, 1.4497e-14,\n",
      "         2.2207e-14],\n",
      "        [3.1167e-10, 7.7950e-10, 4.7601e-12,  ..., 6.7988e-17, 1.1856e-11,\n",
      "         6.8836e-11],\n",
      "        [6.4653e-18, 3.3696e-16, 8.5736e-19,  ..., 3.2612e-15, 1.6595e-20,\n",
      "         2.6245e-15],\n",
      "        ...,\n",
      "        [1.9510e-12, 5.7749e-14, 2.3514e-15,  ..., 1.1598e-14, 3.3537e-14,\n",
      "         1.5446e-13],\n",
      "        [6.5880e-14, 6.1474e-14, 2.8710e-15,  ..., 2.9593e-17, 2.6226e-15,\n",
      "         1.1359e-14],\n",
      "        [3.0682e-12, 1.4397e-11, 2.2295e-15,  ..., 8.6386e-15, 7.6578e-14,\n",
      "         2.0858e-12]], device='cuda:0')}, 1: {'step': tensor(120., device='cuda:0'), 'exp_avg': tensor([ 5.7846e-08, -7.3053e-06,  2.7896e-10,  ..., -1.2242e-07,\n",
      "         1.6164e-08, -2.8995e-07], device='cuda:0'), 'exp_avg_sq': tensor([8.1305e-13, 5.2583e-10, 4.9949e-16,  ..., 1.2780e-12, 9.5352e-15,\n",
      "        1.8100e-12], device='cuda:0')}, 2: {'step': tensor(120., device='cuda:0'), 'exp_avg': tensor([[ 2.4402e-12,  8.4938e-04,  1.2115e-10,  ..., -6.7541e-07,\n",
      "          7.1850e-07, -2.1694e-06],\n",
      "        [-2.9264e-06, -7.5519e-05, -1.8531e-11,  ..., -2.6321e-06,\n",
      "         -1.3446e-06,  1.5999e-06],\n",
      "        [ 1.7923e-07, -4.1386e-06,  1.0606e-06,  ..., -2.5424e-06,\n",
      "         -1.6645e-07, -1.1565e-06],\n",
      "        ...,\n",
      "        [ 6.5301e-08,  1.6129e-05,  7.8914e-07,  ..., -1.1383e-06,\n",
      "          6.4873e-09,  1.7927e-07],\n",
      "        [-6.6479e-07,  5.4860e-06,  1.2840e-07,  ..., -2.1611e-06,\n",
      "          1.3950e-07, -6.6652e-07],\n",
      "        [ 8.0223e-07,  5.6785e-04,  2.4881e-09,  ...,  2.2754e-06,\n",
      "         -1.7888e-10, -2.5529e-07]], device='cuda:0'), 'exp_avg_sq': tensor([[5.2546e-15, 5.0187e-07, 2.0500e-16,  ..., 4.2483e-12, 2.0222e-13,\n",
      "         1.0161e-12],\n",
      "        [1.1432e-11, 2.2239e-07, 2.4128e-16,  ..., 7.7266e-11, 3.6764e-13,\n",
      "         8.6438e-12],\n",
      "        [1.0518e-12, 2.0806e-07, 2.5571e-13,  ..., 7.1520e-12, 3.1089e-14,\n",
      "         1.9054e-12],\n",
      "        ...,\n",
      "        [2.5362e-14, 4.7454e-08, 1.6867e-13,  ..., 1.0924e-11, 6.9914e-15,\n",
      "         4.7033e-13],\n",
      "        [1.9922e-13, 3.8603e-08, 2.5562e-14,  ..., 3.8899e-11, 2.7071e-14,\n",
      "         7.3743e-12],\n",
      "        [1.8234e-11, 2.5330e-07, 3.7742e-15,  ..., 5.9229e-12, 5.4415e-16,\n",
      "         1.2704e-12]], device='cuda:0')}, 3: {'step': tensor(120., device='cuda:0'), 'exp_avg': tensor([ 2.8076e-05,  9.2645e-06, -6.5545e-06,  ...,  4.2407e-06,\n",
      "         1.0539e-06,  3.6373e-05], device='cuda:0'), 'exp_avg_sq': tensor([1.5710e-09, 6.7489e-10, 9.9387e-10,  ..., 4.7140e-10, 2.3809e-10,\n",
      "        9.6794e-10], device='cuda:0')}, 4: {'step': tensor(120., device='cuda:0'), 'exp_avg': tensor([[-1.0062e-04, -1.0876e-05, -8.8894e-05,  ..., -9.7393e-07,\n",
      "         -2.2808e-06,  1.1755e-04],\n",
      "        [-1.6585e-04,  3.3345e-05, -4.7025e-04,  ...,  4.2678e-06,\n",
      "         -6.8070e-05, -7.5788e-04],\n",
      "        [ 1.1980e-03,  1.4300e-03, -1.2193e-04,  ...,  3.5270e-05,\n",
      "          3.9275e-06, -1.9487e-04],\n",
      "        ...,\n",
      "        [ 4.9596e-04,  8.7351e-05, -1.2778e-04,  ..., -2.6973e-05,\n",
      "         -1.4842e-04,  1.2673e-06],\n",
      "        [-6.2944e-04, -4.0735e-05, -3.7606e-04,  ...,  2.6869e-05,\n",
      "          1.8777e-05, -8.3865e-04],\n",
      "        [ 5.1071e-04, -5.9076e-04, -1.0201e-03,  ...,  4.3169e-05,\n",
      "         -3.4448e-05,  6.9409e-05]], device='cuda:0'), 'exp_avg_sq': tensor([[6.0560e-07, 3.7516e-07, 2.0816e-07,  ..., 2.8523e-08, 4.0971e-08,\n",
      "         2.0998e-06],\n",
      "        [2.2688e-06, 6.9361e-07, 7.5809e-07,  ..., 3.0433e-07, 4.9910e-08,\n",
      "         6.9803e-07],\n",
      "        [1.2857e-06, 3.3217e-07, 2.8289e-07,  ..., 2.0889e-08, 4.9541e-08,\n",
      "         7.3989e-07],\n",
      "        ...,\n",
      "        [2.6060e-06, 3.4182e-07, 2.9450e-07,  ..., 6.1899e-08, 1.0239e-07,\n",
      "         4.8472e-07],\n",
      "        [1.6775e-06, 3.8153e-07, 7.0397e-07,  ..., 3.6295e-07, 2.8420e-08,\n",
      "         6.3227e-07],\n",
      "        [1.6078e-06, 6.7137e-07, 9.0966e-07,  ..., 1.6601e-07, 2.2676e-08,\n",
      "         8.6494e-07]], device='cuda:0')}, 5: {'step': tensor(120., device='cuda:0'), 'exp_avg': tensor([-1.4572e-05, -3.6370e-05,  2.2146e-05, -3.8509e-05,  6.7303e-06,\n",
      "         3.4518e-07,  2.9155e-05, -4.2494e-05,  2.6522e-05, -1.1672e-05,\n",
      "         5.0134e-06,  5.2111e-05, -2.2248e-05,  5.3470e-05, -1.5931e-05,\n",
      "         1.3370e-05, -2.3366e-05,  4.2656e-06,  5.1342e-05,  6.5307e-06,\n",
      "        -2.7688e-05, -6.5450e-05,  6.3924e-05,  1.0079e-07,  1.7085e-05,\n",
      "         1.8837e-05,  2.0414e-05, -2.0220e-05,  8.4326e-06,  1.7235e-05,\n",
      "        -2.8530e-05,  3.5658e-05,  6.0718e-05,  4.7014e-05,  2.0514e-05,\n",
      "         8.7355e-06, -2.9882e-06,  2.1903e-06, -4.0663e-05,  2.4650e-07,\n",
      "         3.1574e-05, -1.1037e-05,  9.7069e-06, -5.7099e-06, -1.3158e-05,\n",
      "         8.6283e-06,  5.0226e-05,  1.9473e-06,  2.9934e-05, -3.6581e-05,\n",
      "         1.4829e-05, -6.3042e-06, -3.0764e-05,  1.0964e-05,  1.1453e-05,\n",
      "        -8.8930e-06, -9.2123e-06,  4.3539e-05,  3.5190e-05,  6.6136e-05,\n",
      "         1.3570e-05, -5.8076e-05, -5.1600e-06, -1.5121e-05, -1.2272e-06,\n",
      "        -1.7962e-06,  2.9743e-05,  3.2121e-05, -4.1885e-05, -7.9494e-06,\n",
      "         1.7467e-05,  4.0577e-05, -1.8944e-05, -4.7849e-05, -2.5817e-05,\n",
      "         3.0460e-05,  9.9608e-06, -5.5169e-05, -9.8379e-06,  1.2833e-05,\n",
      "        -1.2376e-05, -8.0696e-06,  1.9460e-05,  7.1268e-07, -3.2066e-05,\n",
      "        -2.5468e-05, -3.8434e-05, -9.0675e-06,  6.1190e-05,  5.4090e-05,\n",
      "         3.4618e-05, -9.8461e-06,  3.6376e-05,  8.7588e-06,  4.8600e-05,\n",
      "         3.5815e-05,  6.6689e-06,  5.2961e-05,  4.0582e-06, -5.3381e-05,\n",
      "         7.7691e-06, -1.0451e-05, -3.5210e-05,  1.4387e-05,  7.3389e-05,\n",
      "         4.8848e-05,  1.8538e-05, -3.9473e-05,  1.9363e-05, -6.0222e-05,\n",
      "        -3.2302e-06,  1.1004e-05, -2.6861e-05, -6.6136e-06,  4.0382e-05,\n",
      "        -9.3887e-06,  1.0533e-05,  2.8219e-05, -5.9010e-05, -1.4565e-05,\n",
      "        -6.2734e-06,  1.4691e-05, -5.9747e-05, -4.4302e-05,  9.2839e-06,\n",
      "        -1.1311e-05,  1.4458e-05,  2.4409e-05, -5.2503e-06,  3.3158e-05,\n",
      "         1.1973e-05, -4.2031e-05,  2.4690e-05, -1.5759e-05,  1.7964e-05,\n",
      "        -2.2613e-05, -3.0894e-05, -1.6167e-05,  8.6102e-05, -2.0914e-05,\n",
      "        -3.4042e-05, -1.7711e-05, -1.0714e-05, -1.5524e-05,  6.5195e-05,\n",
      "        -5.0785e-05,  4.0320e-06, -1.4414e-05, -2.0583e-05, -6.8684e-06,\n",
      "         1.6543e-05,  2.2222e-05,  7.0226e-05,  5.2486e-05,  5.1315e-06,\n",
      "         6.4441e-07, -9.8215e-06, -3.0355e-05,  5.1011e-05, -2.5490e-05,\n",
      "        -1.6390e-06,  2.1304e-05, -3.1883e-06,  3.6993e-05, -5.0444e-05,\n",
      "        -1.9409e-05, -3.3895e-05,  9.0972e-06, -1.4228e-05, -1.6093e-05,\n",
      "         2.0758e-05, -1.5241e-05, -5.9685e-05, -1.9293e-05,  1.3511e-05,\n",
      "         2.8784e-05,  2.5769e-05,  1.6315e-05,  5.8500e-07,  3.3250e-05,\n",
      "         3.6438e-06,  9.6137e-06, -2.6262e-05, -6.4063e-07,  2.6258e-05,\n",
      "         4.1727e-06,  1.0011e-05, -8.0997e-05, -1.3245e-06,  2.1409e-05,\n",
      "        -5.7772e-06, -2.1933e-05,  3.0277e-05, -7.5543e-06,  1.3316e-06,\n",
      "        -2.1460e-06, -5.9154e-05, -2.5122e-08, -1.1822e-05,  3.8170e-05,\n",
      "         3.8267e-05,  1.1583e-05,  8.6758e-06,  8.8283e-06, -1.5915e-05,\n",
      "        -2.2236e-05,  3.3104e-05, -1.9364e-06, -1.5857e-05, -1.5715e-05,\n",
      "         3.1225e-06, -1.7401e-05, -4.4634e-05, -4.7333e-05,  1.1210e-05,\n",
      "        -2.1113e-05, -7.4438e-06, -4.8827e-05, -2.3563e-05, -3.6438e-05,\n",
      "         1.0683e-05, -2.7699e-05, -1.4979e-07,  6.8902e-05,  2.8276e-06,\n",
      "        -2.0562e-05,  1.2446e-05,  5.0089e-06,  6.2020e-05,  6.1888e-06,\n",
      "        -1.3501e-06, -8.6158e-06,  7.0310e-06, -1.9412e-05, -2.3996e-05,\n",
      "        -5.1999e-05,  7.2928e-07,  4.4676e-06,  2.3048e-05,  2.4523e-05,\n",
      "        -2.5351e-05,  1.1595e-05, -8.1240e-06,  2.6968e-05,  6.8927e-05,\n",
      "         3.1470e-05,  7.4990e-05,  3.0182e-05, -6.1903e-05,  4.9568e-06,\n",
      "         3.0552e-05, -1.8756e-05,  7.9147e-06,  3.1873e-05,  4.7032e-05,\n",
      "        -3.6819e-05, -1.0428e-05, -7.0858e-06, -2.3877e-05,  5.2628e-06,\n",
      "         1.5489e-05,  2.3165e-06,  1.5963e-05,  3.6199e-05, -4.3038e-05,\n",
      "         1.0509e-05, -1.7189e-05, -1.2312e-05,  3.0138e-05, -1.5670e-06,\n",
      "         2.6054e-05, -2.1784e-05,  5.4937e-05,  5.4380e-05,  7.9822e-05,\n",
      "         1.7659e-05,  5.4097e-05, -4.3670e-05, -1.2232e-05,  1.3793e-05,\n",
      "        -2.0306e-05,  1.8291e-05, -1.5206e-05, -3.0539e-05, -4.4360e-05,\n",
      "        -1.8521e-05, -1.2701e-05, -2.5496e-05, -2.4045e-05,  1.0339e-05,\n",
      "        -3.6925e-05,  4.3797e-06,  1.2185e-05,  1.4582e-05,  5.6007e-06,\n",
      "         2.4951e-06,  1.2983e-05,  8.6974e-06, -5.3220e-06, -4.8321e-05,\n",
      "         8.0105e-05, -1.3714e-07, -1.5881e-05, -1.9047e-05, -2.1589e-05,\n",
      "        -1.0138e-05,  3.0712e-06, -3.1872e-05,  3.9675e-05, -4.0062e-05,\n",
      "         2.1851e-05,  1.0393e-06, -4.7661e-05, -9.1599e-06, -2.0342e-05,\n",
      "         8.0002e-06,  1.7986e-05, -4.4849e-06,  4.6834e-05,  1.2676e-05,\n",
      "        -2.1555e-06,  2.3187e-05,  1.2969e-05,  5.5621e-05, -2.4271e-05,\n",
      "         3.5701e-05,  5.3871e-05, -1.9107e-05,  2.3528e-06, -4.0481e-05,\n",
      "         2.2192e-05, -1.3070e-05,  2.2689e-06,  5.5653e-05, -1.6182e-05,\n",
      "        -2.4236e-05, -6.3086e-06, -1.1982e-04,  3.9637e-06,  1.2136e-05,\n",
      "        -3.3071e-05,  1.0232e-05, -7.6759e-05,  3.9801e-05, -2.2164e-06,\n",
      "         1.6259e-05,  1.2959e-05, -1.9751e-05, -2.1075e-05,  3.9465e-05,\n",
      "        -3.2192e-05, -1.3143e-05,  4.6875e-07, -2.9061e-06, -5.3395e-06,\n",
      "        -6.4736e-05, -5.6023e-05, -1.0785e-05, -1.5156e-06,  4.8810e-05,\n",
      "        -1.1021e-05,  4.9887e-05, -6.5243e-05,  1.8245e-05, -2.1999e-05,\n",
      "         4.1910e-07,  2.7840e-05, -2.2772e-05,  4.8965e-06,  1.3478e-06,\n",
      "        -1.9908e-05,  5.2304e-06,  2.1415e-06,  2.2943e-05,  2.6863e-05,\n",
      "         4.1621e-06, -3.5065e-06,  1.4255e-05,  1.2727e-05,  6.8814e-06,\n",
      "        -3.5208e-05,  4.1278e-05,  2.5821e-06, -1.0921e-05, -2.4746e-05,\n",
      "        -3.8231e-05,  4.1213e-05, -4.1028e-06, -1.0507e-05, -2.2153e-05,\n",
      "        -7.8474e-05, -2.1842e-05,  1.4877e-05, -4.2432e-05, -1.8083e-05,\n",
      "        -1.6628e-06, -5.9131e-05,  5.2457e-05,  3.4639e-05,  1.7945e-05,\n",
      "        -2.2155e-05,  7.3561e-06, -1.2760e-05, -7.1944e-05,  1.0767e-05,\n",
      "         5.4449e-06, -7.4649e-05, -8.1177e-06, -1.9544e-05,  9.2539e-06,\n",
      "         3.8966e-05,  1.7080e-05, -7.7510e-07, -3.0224e-05,  1.3162e-05,\n",
      "        -2.9638e-05, -2.7987e-06,  1.7536e-06, -9.2631e-05,  1.2770e-07,\n",
      "         2.9738e-06, -4.6439e-05,  3.4416e-06,  6.5684e-06,  5.0190e-05,\n",
      "        -1.1960e-05, -1.2156e-06,  3.2582e-05,  1.9486e-05, -1.5190e-05,\n",
      "        -3.7561e-05,  5.2106e-05,  4.3312e-05,  3.3092e-05, -1.2658e-05,\n",
      "        -2.4561e-05,  3.1504e-05, -4.3445e-05,  8.3047e-06, -8.0970e-06,\n",
      "        -8.6165e-06, -2.1191e-05, -1.7206e-05, -3.8997e-05,  4.8152e-05,\n",
      "         2.1034e-05, -3.5101e-05, -7.3319e-06,  7.2508e-07,  1.6914e-05,\n",
      "        -9.7777e-06, -1.5011e-05,  1.5796e-05,  2.2423e-05,  3.7157e-05,\n",
      "         1.5537e-05, -6.6609e-05, -7.3049e-06, -1.4621e-05, -6.3418e-06,\n",
      "        -2.9213e-05,  1.2538e-05,  2.3158e-05,  1.6370e-05,  4.3064e-05,\n",
      "        -3.6829e-05, -1.6736e-05, -2.9276e-06, -2.2502e-06,  1.4152e-05,\n",
      "         1.6343e-05,  1.9078e-05, -2.7717e-05,  1.9371e-05, -1.7634e-05,\n",
      "         1.1005e-05,  1.6435e-05,  1.0462e-05,  6.9780e-07, -4.1047e-05,\n",
      "         2.5181e-05,  1.7460e-06,  1.8209e-05,  5.4741e-05, -2.7955e-05,\n",
      "         2.5915e-07,  1.8489e-05, -6.4261e-05,  2.1632e-05,  1.5732e-06,\n",
      "         1.6819e-06,  5.6156e-05,  3.3711e-05, -6.6810e-06,  1.5160e-06,\n",
      "         3.9614e-05,  2.9972e-06, -5.3756e-05, -4.5599e-06, -3.2722e-05,\n",
      "         2.0538e-05,  7.8267e-06,  2.4014e-05, -2.7163e-05,  3.4104e-05,\n",
      "        -1.6421e-06,  4.9075e-05, -9.5511e-06,  1.3571e-05,  6.2630e-05,\n",
      "        -3.7702e-05,  2.3458e-05], device='cuda:0'), 'exp_avg_sq': tensor([3.8514e-09, 5.0933e-09, 1.7540e-09, 1.6677e-09, 5.9355e-10, 3.1578e-09,\n",
      "        5.8428e-09, 6.6237e-09, 1.4095e-09, 2.6247e-09, 3.7100e-09, 6.4292e-09,\n",
      "        8.3590e-09, 6.9485e-09, 3.6544e-09, 3.4273e-09, 3.4265e-09, 5.0751e-09,\n",
      "        3.1223e-09, 2.3455e-09, 4.7618e-09, 2.0512e-09, 4.0057e-09, 4.0571e-09,\n",
      "        6.0681e-09, 3.1716e-09, 1.3289e-09, 6.2010e-09, 2.2843e-10, 3.0450e-09,\n",
      "        2.9227e-09, 1.2263e-08, 6.5711e-09, 1.8340e-09, 8.5240e-09, 3.2335e-09,\n",
      "        5.2086e-10, 4.1410e-09, 6.2829e-09, 3.6780e-09, 6.1668e-09, 3.0138e-09,\n",
      "        3.6171e-09, 4.3434e-09, 8.8201e-09, 3.5812e-09, 5.3521e-09, 3.8948e-09,\n",
      "        2.1999e-09, 6.0680e-09, 8.2645e-09, 4.8972e-09, 5.7943e-09, 8.1117e-09,\n",
      "        1.2969e-09, 4.9662e-09, 6.2249e-09, 4.7904e-09, 7.0477e-10, 6.3013e-09,\n",
      "        4.0002e-10, 3.6948e-09, 8.7854e-09, 3.6424e-09, 3.7317e-10, 1.0389e-09,\n",
      "        5.7570e-09, 5.4113e-09, 5.4895e-09, 4.4343e-09, 3.8563e-09, 1.7415e-09,\n",
      "        7.4713e-09, 4.9823e-09, 3.2956e-09, 9.8100e-09, 4.9943e-09, 6.6334e-09,\n",
      "        1.8429e-09, 6.3389e-09, 4.5921e-09, 8.7404e-09, 3.2561e-09, 3.7449e-09,\n",
      "        3.7785e-09, 5.2130e-09, 7.3139e-09, 3.5292e-09, 4.9675e-09, 7.4464e-09,\n",
      "        8.4951e-09, 3.6025e-10, 4.5506e-09, 7.1173e-09, 5.9524e-09, 8.1459e-09,\n",
      "        8.7925e-10, 5.1583e-09, 1.2231e-08, 3.9609e-09, 4.4941e-09, 4.3932e-09,\n",
      "        4.9952e-09, 7.5787e-09, 1.0507e-08, 4.8657e-09, 8.6116e-10, 5.3683e-09,\n",
      "        6.9666e-09, 5.2454e-09, 2.4422e-09, 2.7762e-09, 4.4760e-09, 1.3497e-09,\n",
      "        4.5584e-09, 4.9869e-09, 1.9061e-09, 3.8125e-09, 8.8075e-09, 2.3266e-09,\n",
      "        3.2908e-09, 8.8604e-09, 7.0087e-09, 3.4309e-09, 2.1496e-09, 4.3020e-09,\n",
      "        4.4332e-09, 4.3215e-09, 2.4249e-09, 7.4211e-09, 5.2293e-09, 1.9693e-09,\n",
      "        1.0223e-08, 4.9629e-09, 1.0074e-09, 4.9421e-09, 5.2842e-09, 4.1139e-09,\n",
      "        6.6803e-09, 9.0121e-10, 3.3962e-09, 2.6895e-09, 4.0804e-09, 9.1275e-10,\n",
      "        4.5858e-09, 6.5674e-09, 1.9308e-09, 3.0207e-09, 5.6341e-09, 5.7538e-10,\n",
      "        1.6056e-09, 6.9372e-09, 6.5212e-09, 4.3023e-09, 1.4647e-09, 1.1574e-09,\n",
      "        3.4063e-09, 3.3430e-09, 6.5808e-09, 2.4339e-09, 3.7844e-10, 2.6156e-09,\n",
      "        6.1325e-09, 5.2676e-09, 5.1641e-09, 4.5222e-09, 3.1055e-09, 3.2569e-09,\n",
      "        7.0698e-09, 3.9534e-09, 3.8447e-09, 4.6774e-09, 2.3307e-09, 4.2246e-09,\n",
      "        3.6128e-09, 3.9507e-09, 5.6033e-09, 1.7399e-09, 6.3091e-09, 5.8338e-09,\n",
      "        2.2538e-09, 3.7299e-09, 3.9051e-09, 9.6671e-09, 3.0235e-09, 5.1167e-09,\n",
      "        1.7648e-09, 2.2106e-09, 4.1355e-09, 4.1320e-09, 7.4782e-09, 2.5990e-09,\n",
      "        6.4495e-09, 5.8825e-09, 2.4862e-10, 3.2538e-09, 3.3588e-09, 1.7289e-09,\n",
      "        6.3534e-09, 1.4380e-09, 8.4811e-09, 1.7326e-09, 3.1655e-09, 3.3824e-09,\n",
      "        6.1488e-09, 8.7958e-09, 2.2931e-09, 2.1268e-09, 5.3692e-09, 4.5899e-09,\n",
      "        2.7361e-09, 4.5951e-09, 8.8055e-09, 5.8224e-09, 8.2901e-10, 7.7743e-11,\n",
      "        5.3415e-09, 2.2600e-09, 6.2941e-09, 3.7004e-09, 3.9273e-09, 3.2247e-09,\n",
      "        5.2213e-09, 1.3515e-08, 4.7066e-09, 1.0002e-08, 4.9309e-09, 1.4618e-09,\n",
      "        8.3018e-09, 3.9611e-09, 4.1304e-09, 7.4915e-09, 7.3302e-09, 8.1762e-09,\n",
      "        3.9466e-09, 6.5495e-09, 2.5910e-10, 2.5319e-09, 8.2347e-09, 2.5780e-09,\n",
      "        5.2303e-09, 8.1095e-09, 3.4248e-09, 2.3707e-09, 4.0607e-09, 5.9062e-09,\n",
      "        3.3668e-09, 7.4855e-09, 4.4349e-09, 1.9181e-09, 5.9892e-09, 8.6224e-09,\n",
      "        5.9513e-09, 4.2541e-09, 6.5948e-09, 9.4535e-09, 4.6841e-09, 2.2532e-09,\n",
      "        4.3821e-09, 3.6009e-09, 1.1352e-09, 5.3633e-09, 2.6379e-09, 2.6042e-09,\n",
      "        1.9495e-09, 3.5535e-09, 1.4103e-09, 8.1795e-10, 5.7601e-09, 5.6975e-09,\n",
      "        7.5752e-09, 9.9788e-10, 4.2830e-09, 6.4825e-09, 6.2525e-09, 3.3089e-09,\n",
      "        6.0768e-09, 3.9775e-09, 3.2943e-09, 8.1523e-09, 1.4660e-09, 5.0210e-09,\n",
      "        7.7439e-09, 4.2541e-09, 5.2248e-09, 1.5819e-09, 3.2843e-09, 4.2357e-09,\n",
      "        6.0706e-09, 1.2716e-08, 2.2024e-09, 3.6252e-09, 4.3904e-09, 3.2910e-09,\n",
      "        2.0576e-09, 5.9910e-09, 5.3497e-09, 2.1997e-09, 4.6318e-09, 6.9132e-09,\n",
      "        7.6621e-09, 8.0829e-09, 1.8162e-09, 6.0102e-09, 5.4765e-09, 1.2640e-09,\n",
      "        3.4847e-09, 3.0786e-09, 3.8227e-09, 5.2122e-09, 1.0487e-08, 6.9351e-09,\n",
      "        3.8038e-09, 2.4213e-09, 1.0229e-08, 7.7113e-09, 6.1720e-09, 1.5844e-09,\n",
      "        9.2391e-09, 3.0546e-09, 3.0563e-09, 2.2720e-09, 1.6525e-09, 5.8548e-09,\n",
      "        3.1630e-09, 5.7615e-09, 4.4455e-09, 4.9193e-09, 8.0005e-10, 8.3030e-09,\n",
      "        4.6809e-09, 4.3635e-09, 1.5568e-09, 4.9201e-09, 3.1640e-09, 2.6514e-09,\n",
      "        6.1621e-09, 5.9909e-09, 4.3114e-09, 2.8637e-09, 5.0703e-09, 2.1008e-09,\n",
      "        5.2323e-09, 2.8219e-09, 2.7801e-09, 4.3494e-09, 3.5009e-09, 2.1728e-09,\n",
      "        8.3931e-09, 3.1009e-09, 6.8282e-09, 2.2991e-09, 2.9153e-09, 3.9404e-09,\n",
      "        7.4116e-09, 3.0398e-09, 7.2185e-09, 7.2176e-09, 9.1494e-09, 1.2229e-09,\n",
      "        3.8645e-09, 8.9985e-09, 7.5432e-09, 6.5856e-09, 3.7310e-09, 2.3102e-09,\n",
      "        1.9428e-09, 3.9682e-09, 1.1098e-09, 6.4233e-09, 5.4689e-09, 1.1556e-09,\n",
      "        2.9903e-09, 2.2571e-09, 1.6988e-09, 1.7244e-09, 4.8901e-09, 3.3221e-09,\n",
      "        1.3341e-09, 4.0222e-09, 4.0128e-09, 4.5470e-09, 3.2652e-09, 1.0401e-08,\n",
      "        3.5316e-09, 9.4135e-09, 4.0610e-09, 9.2794e-09, 6.1809e-09, 2.7424e-09,\n",
      "        1.5844e-09, 6.7787e-09, 6.9103e-09, 9.3365e-09, 5.2397e-09, 2.8583e-09,\n",
      "        4.5468e-09, 6.1629e-09, 9.5044e-09, 3.2674e-09, 4.4367e-09, 5.9613e-09,\n",
      "        3.4221e-09, 5.0085e-09, 2.7804e-09, 2.6371e-09, 9.4003e-09, 9.1125e-09,\n",
      "        3.7765e-09, 2.7369e-09, 7.5767e-09, 6.9259e-09, 3.8121e-10, 5.7186e-09,\n",
      "        3.4111e-09, 1.9710e-08, 1.3873e-09, 7.8230e-09, 6.1156e-09, 1.7074e-09,\n",
      "        1.4046e-09, 7.7327e-09, 7.1716e-09, 6.8896e-09, 7.3601e-09, 2.8897e-09,\n",
      "        7.7821e-09, 4.5109e-09, 4.9519e-09, 2.5152e-09, 3.5180e-09, 4.8703e-09,\n",
      "        4.3398e-09, 3.9535e-09, 2.4795e-09, 5.9456e-09, 5.8290e-09, 8.2149e-09,\n",
      "        3.2422e-09, 3.6263e-09, 5.8132e-09, 6.3430e-09, 3.7315e-09, 4.8311e-09,\n",
      "        6.7287e-09, 8.7050e-09, 4.1889e-09, 1.1465e-09, 2.7191e-09, 4.2712e-09,\n",
      "        2.9734e-09, 5.4363e-09, 3.8519e-09, 8.8316e-09, 4.4891e-09, 2.3857e-09,\n",
      "        6.7369e-09, 2.5918e-09, 2.3403e-09, 2.9393e-09, 3.2417e-09, 6.0043e-09,\n",
      "        6.5645e-09, 6.8033e-09, 2.2403e-09, 2.8470e-09, 7.5758e-09, 6.0305e-09,\n",
      "        3.0890e-09, 4.0171e-09, 6.6915e-09, 6.1811e-09, 2.2917e-09, 1.9264e-09,\n",
      "        1.4635e-09, 7.8858e-09, 1.6324e-09, 6.0686e-09, 2.8549e-09, 3.9634e-09,\n",
      "        5.5739e-09, 1.3639e-09, 8.9522e-09, 6.6070e-09, 6.0728e-09, 1.0827e-09,\n",
      "        1.3675e-09, 7.0445e-09, 2.7052e-09, 2.0228e-09, 2.1834e-09, 6.9234e-09,\n",
      "        7.6059e-09, 1.7770e-09, 8.5317e-09, 2.4490e-09, 8.6829e-09, 7.2741e-09,\n",
      "        2.0419e-09, 3.4722e-09, 3.1998e-09, 1.3992e-09, 7.7048e-09, 5.2696e-09,\n",
      "        1.9214e-09, 9.1012e-10, 6.7116e-09, 5.5027e-09, 8.3785e-09, 4.2574e-09,\n",
      "        3.2315e-09, 4.5518e-09], device='cuda:0')}, 6: {'step': tensor(120., device='cuda:0'), 'exp_avg': tensor([[-7.7992e-05,  1.1285e-04,  1.0931e-04,  ..., -1.2705e-05,\n",
      "         -8.6096e-05,  4.0529e-05],\n",
      "        [ 1.3491e-04, -5.1397e-04,  1.8528e-04,  ...,  1.2009e-04,\n",
      "         -1.6308e-04, -5.0058e-06],\n",
      "        [ 7.0207e-05,  3.8386e-04,  2.6743e-04,  ...,  8.1814e-05,\n",
      "          1.6058e-04,  8.5312e-04],\n",
      "        ...,\n",
      "        [ 1.3197e-04, -2.4547e-04, -4.3605e-04,  ..., -3.5156e-04,\n",
      "         -1.1747e-04,  2.7266e-04],\n",
      "        [-2.4562e-04,  2.5642e-04, -6.9022e-04,  ..., -1.0040e-04,\n",
      "         -2.6128e-04, -2.8527e-05],\n",
      "        [ 6.8670e-06,  1.5085e-04, -4.4638e-05,  ...,  2.9063e-04,\n",
      "          2.7224e-04,  4.4251e-04]], device='cuda:0'), 'exp_avg_sq': tensor([[4.2162e-07, 7.3699e-07, 1.6812e-07,  ..., 1.8943e-07, 3.8644e-07,\n",
      "         1.1080e-06],\n",
      "        [2.2967e-07, 3.9898e-07, 5.6256e-08,  ..., 1.7893e-07, 1.6052e-07,\n",
      "         4.3679e-07],\n",
      "        [8.9472e-07, 7.4382e-07, 2.8513e-07,  ..., 3.3789e-07, 2.4795e-07,\n",
      "         1.0189e-06],\n",
      "        ...,\n",
      "        [3.6314e-07, 3.3212e-07, 2.8511e-07,  ..., 5.3127e-07, 3.7296e-07,\n",
      "         1.2046e-06],\n",
      "        [5.3422e-07, 4.1095e-07, 3.3403e-07,  ..., 4.3715e-07, 2.9702e-07,\n",
      "         6.2787e-07],\n",
      "        [3.9457e-07, 6.0899e-07, 2.2619e-07,  ..., 5.7654e-07, 4.2131e-07,\n",
      "         8.0502e-07]], device='cuda:0')}, 7: {'step': tensor(120., device='cuda:0'), 'exp_avg': tensor([ 2.7204e-06,  6.2562e-05,  1.5668e-04,  5.4274e-06, -1.4826e-05,\n",
      "        -1.0350e-04, -4.5694e-05,  1.0066e-05,  1.8583e-05, -8.4266e-06,\n",
      "         1.0666e-05,  9.6645e-06, -1.7271e-05, -2.6672e-05,  7.5843e-05,\n",
      "        -1.7117e-05, -8.6119e-05,  3.8043e-05,  1.2611e-06, -3.0040e-05,\n",
      "         1.3653e-05,  2.2333e-05,  4.7918e-05,  2.2425e-05,  8.9119e-05,\n",
      "         6.8064e-05,  7.3514e-05,  5.4924e-05,  2.1573e-05, -4.4144e-05,\n",
      "         6.0683e-05,  5.7116e-06, -1.7146e-05,  4.0167e-05,  3.0854e-05,\n",
      "        -6.5380e-05, -3.8482e-05, -1.5866e-06, -6.7892e-06, -3.6512e-05,\n",
      "         1.7505e-05, -7.3475e-06,  1.2790e-04,  2.8974e-06,  1.0796e-04,\n",
      "         2.2567e-05, -6.1156e-06, -1.8088e-05, -8.8031e-05,  3.5894e-05,\n",
      "        -7.3431e-05, -6.3334e-06,  2.5818e-05,  3.8654e-06, -1.4627e-05,\n",
      "        -5.8164e-05,  2.9673e-05, -1.2673e-05, -7.3607e-05,  2.1979e-05,\n",
      "        -4.8502e-06,  2.7921e-05,  1.7235e-05,  1.4987e-05,  5.9366e-06,\n",
      "        -1.8038e-05,  3.3762e-05, -7.5556e-06,  7.1373e-05, -7.9223e-05,\n",
      "         2.5723e-06,  3.0218e-05,  3.8953e-05, -3.1798e-05,  7.1695e-08,\n",
      "         3.9056e-05,  8.2269e-05,  2.4729e-05, -1.1946e-04, -2.1441e-05,\n",
      "        -4.3910e-05,  2.7227e-05,  3.2239e-05, -4.5523e-05,  5.5938e-05,\n",
      "         6.4506e-05, -1.5835e-06, -9.4818e-05,  8.5192e-06, -2.2052e-05,\n",
      "         2.5488e-06, -2.2404e-05, -8.0229e-05, -2.2604e-05,  9.9876e-06,\n",
      "         7.7448e-06, -1.9547e-05,  3.1184e-05,  3.1997e-05,  3.4974e-06,\n",
      "         3.2253e-06,  2.7843e-05, -2.9228e-06,  1.5185e-05, -1.8119e-06,\n",
      "        -7.0119e-05, -4.0025e-05,  1.4424e-04, -2.2087e-05,  2.2998e-05,\n",
      "         2.1740e-05,  4.0779e-05, -1.8958e-05, -6.6807e-05,  2.3431e-05,\n",
      "         6.2743e-05, -1.0280e-04,  2.6216e-05, -8.4193e-06,  5.6312e-05,\n",
      "         8.6915e-05, -1.9916e-05,  3.7482e-05,  4.8280e-07,  4.7540e-05,\n",
      "         5.8440e-05, -1.4612e-05,  1.1533e-04, -5.2830e-05, -1.9134e-05,\n",
      "        -3.1032e-05,  2.1999e-05, -7.0055e-05,  2.8870e-05,  3.3287e-05,\n",
      "        -6.5186e-05,  3.0326e-05,  3.1185e-05,  1.6620e-05,  9.5158e-05,\n",
      "        -7.9136e-06, -4.5659e-06, -4.4954e-05,  1.0355e-04, -3.0310e-05,\n",
      "         6.6325e-06, -2.6027e-05, -3.3720e-05,  1.5053e-06, -3.7704e-05,\n",
      "         3.0562e-06, -2.7871e-05,  3.3595e-06, -5.1434e-05,  2.4595e-05,\n",
      "        -2.0633e-05, -2.9686e-06,  1.4985e-05,  7.0752e-05, -3.2236e-05,\n",
      "         4.1229e-05,  1.5554e-06,  9.6321e-06, -8.4870e-06, -2.6244e-05,\n",
      "        -1.2420e-05, -4.8948e-05, -6.6273e-06,  1.9740e-06, -1.8220e-05,\n",
      "        -5.1622e-05, -1.5291e-04,  2.9890e-05,  1.6400e-05,  3.8894e-05,\n",
      "        -1.6543e-05, -2.8943e-05,  2.3850e-05,  7.3119e-06, -1.1737e-05,\n",
      "         6.7846e-06, -2.1796e-05, -4.6982e-05,  3.0033e-05,  1.3353e-05,\n",
      "         4.4052e-05,  5.2416e-05,  2.6289e-05,  4.0208e-05, -8.7087e-05,\n",
      "        -2.6313e-05,  5.0362e-05,  1.3439e-05,  2.5887e-05, -2.8640e-05,\n",
      "         1.0040e-04, -1.7684e-06,  1.6582e-04,  1.4210e-05, -1.2844e-04,\n",
      "        -3.7330e-05,  2.1066e-05, -1.0996e-06, -3.4537e-05, -1.4947e-05,\n",
      "        -2.2864e-05,  2.7829e-05,  4.9510e-05,  3.9358e-05,  1.6010e-05,\n",
      "         6.9479e-05,  1.0034e-04, -1.0985e-05, -9.9637e-06, -6.2889e-05,\n",
      "        -4.4610e-05, -5.2354e-05,  1.3840e-05,  3.4609e-05,  9.2852e-05,\n",
      "        -3.9836e-06,  8.1277e-05,  2.7372e-05, -7.5067e-05, -1.9232e-06,\n",
      "        -4.9243e-08, -3.2099e-05,  6.4593e-05, -5.5718e-05, -6.3001e-05,\n",
      "         1.3056e-04,  1.0207e-04,  1.5987e-05, -1.4928e-04, -3.9012e-05,\n",
      "        -1.3134e-05,  1.2871e-04, -2.6620e-05, -1.0638e-04,  4.8381e-05,\n",
      "        -6.5424e-05,  5.0362e-06, -1.9762e-05,  6.8968e-05, -2.3923e-05,\n",
      "        -8.0691e-05,  2.3109e-05, -8.1851e-05, -8.8712e-05, -7.9981e-05,\n",
      "        -5.2369e-05, -1.0805e-04,  1.3026e-05,  3.8544e-06, -1.2535e-04,\n",
      "        -3.6600e-06, -2.6129e-05,  1.6219e-06,  7.0071e-05, -5.6755e-05,\n",
      "        -8.5331e-05, -3.1916e-05, -2.6754e-05, -4.5739e-06,  2.1036e-05,\n",
      "         2.6125e-05, -3.3320e-05,  8.9131e-05,  4.1534e-06, -3.3279e-05,\n",
      "         1.7369e-05,  1.2179e-05,  5.2933e-06, -5.3325e-06, -1.9150e-05,\n",
      "        -3.1282e-05,  6.1600e-06,  1.0957e-05, -8.4725e-06,  4.6821e-05,\n",
      "         4.7858e-05,  5.5311e-05, -7.6582e-06,  1.9144e-06,  5.5834e-05,\n",
      "        -3.7681e-05,  1.5390e-06,  1.4366e-05, -3.1661e-05, -1.6620e-06,\n",
      "        -6.2809e-06, -2.6532e-05,  4.7174e-05, -1.0240e-04, -1.0417e-04,\n",
      "        -1.0577e-04,  4.4464e-05, -1.4907e-04,  2.7477e-05, -1.9514e-05,\n",
      "         7.7328e-05,  1.4601e-05, -5.0856e-06, -5.0695e-07, -6.2861e-06,\n",
      "        -4.5133e-05,  3.2622e-05,  8.8268e-06,  2.6563e-05,  6.7836e-05,\n",
      "         1.2288e-05, -8.5811e-06, -9.3626e-06,  2.2328e-05,  9.5024e-06,\n",
      "        -4.1031e-05,  1.4805e-05,  1.9281e-05,  7.0528e-05,  3.8551e-05,\n",
      "         5.9142e-05,  1.0409e-04, -1.1377e-05, -4.3894e-06,  6.3106e-05,\n",
      "         3.5062e-05, -5.2740e-05,  3.2829e-05, -2.7170e-05, -1.0546e-04,\n",
      "        -1.2535e-04, -9.8233e-06,  1.0604e-04, -6.8410e-06, -6.5475e-07,\n",
      "        -9.6854e-06, -9.5861e-06,  3.0034e-05,  1.3862e-05, -3.2135e-05,\n",
      "         8.4407e-06, -1.2195e-05,  4.2340e-05,  3.7928e-06,  2.1084e-05,\n",
      "        -8.4404e-05, -3.5058e-05, -3.8316e-06, -1.0952e-04, -3.0841e-06,\n",
      "         1.5152e-05,  6.0709e-05,  4.6193e-05,  6.6076e-05,  1.6522e-05,\n",
      "        -4.9546e-05, -6.2964e-05,  1.5466e-05, -1.8723e-05, -4.4745e-05,\n",
      "         1.3529e-05, -5.8564e-05,  6.7334e-05,  8.1406e-06,  1.7020e-05,\n",
      "         2.3237e-05, -3.8774e-05,  3.8517e-06,  5.2320e-06, -3.4197e-05,\n",
      "         1.0915e-05, -1.1397e-05, -3.1882e-05,  1.0772e-05, -1.1804e-04,\n",
      "        -6.5380e-05,  1.3565e-04,  1.3174e-05, -1.2975e-04,  5.2354e-05,\n",
      "         4.3906e-05,  8.7071e-06,  4.5335e-05,  3.5954e-05, -1.8418e-05,\n",
      "         7.3624e-05, -8.9037e-05, -1.1640e-05, -1.2174e-05,  4.3746e-05,\n",
      "         1.7587e-06, -5.1240e-05,  2.2498e-05,  1.9315e-06,  1.3308e-04,\n",
      "         5.8371e-05,  6.7387e-06, -3.8442e-06, -3.8563e-05, -6.6766e-05,\n",
      "         1.5358e-05,  3.0469e-05, -5.2165e-05,  1.1759e-05, -2.2436e-05,\n",
      "        -8.4435e-05,  1.6235e-05,  2.1010e-05, -1.7716e-05, -2.0088e-06,\n",
      "         2.3417e-05, -2.3493e-05,  6.4405e-05,  3.9555e-05, -1.7089e-05,\n",
      "        -6.8661e-05,  7.4565e-05, -4.7599e-06, -1.0218e-06,  2.0961e-04,\n",
      "         3.0422e-05, -4.1709e-05, -9.0385e-06, -2.2195e-05, -2.1097e-05,\n",
      "         3.2799e-06,  3.7359e-05, -6.3737e-05, -5.7699e-05,  6.5308e-07,\n",
      "         1.0848e-04,  5.2251e-05,  3.7685e-05,  1.9976e-05, -9.5033e-06,\n",
      "         5.2010e-05,  1.0041e-04,  8.1470e-06, -2.6319e-05,  1.1898e-04,\n",
      "         4.8152e-05,  2.0623e-05,  3.0460e-05,  5.2553e-05, -1.1946e-04,\n",
      "         2.9021e-05,  4.5021e-06,  5.3695e-05,  8.4135e-05, -4.0144e-06,\n",
      "         6.9471e-05, -1.1246e-04, -8.4068e-05, -6.5090e-05, -7.7473e-05,\n",
      "         3.7347e-05,  4.6650e-05,  8.0651e-05,  1.2192e-04, -1.4365e-05,\n",
      "        -3.3737e-07, -1.6139e-05, -7.9842e-06, -1.5047e-05,  8.1747e-05,\n",
      "        -4.1583e-05, -6.2254e-05, -3.7374e-05, -1.3619e-05, -3.5416e-05,\n",
      "        -5.9948e-06,  1.1212e-05, -2.2259e-05,  4.9333e-05,  9.0876e-06,\n",
      "        -5.0311e-05,  7.3485e-08, -4.6995e-05,  4.2277e-05,  9.6702e-05,\n",
      "        -4.1261e-05, -4.5922e-05, -5.6149e-05, -2.2464e-05, -9.5290e-06,\n",
      "        -4.0236e-05, -1.3283e-04, -4.4389e-05,  1.6602e-05,  9.3581e-06,\n",
      "         1.4823e-05, -1.1821e-05,  2.6652e-05, -6.9187e-05,  5.2229e-05,\n",
      "        -8.3307e-05, -9.3797e-06,  1.5491e-05, -8.5794e-06,  5.0478e-06,\n",
      "         6.7926e-05,  3.0226e-05,  3.7118e-06, -4.4409e-05, -4.8809e-05,\n",
      "         9.5655e-05,  4.6312e-05,  1.3226e-04, -2.7111e-06, -2.9169e-05,\n",
      "         4.2078e-06,  3.4656e-05], device='cuda:0'), 'exp_avg_sq': tensor([1.5242e-08, 7.5543e-09, 2.8309e-08, 1.7285e-08, 1.2569e-08, 1.1486e-08,\n",
      "        1.7618e-08, 1.7350e-08, 7.1811e-09, 1.8177e-08, 9.2888e-09, 8.1247e-09,\n",
      "        1.2363e-08, 1.0716e-08, 1.7844e-08, 1.3619e-08, 1.5387e-08, 1.6257e-08,\n",
      "        3.3994e-09, 5.3752e-09, 1.7808e-08, 8.1236e-09, 7.2540e-09, 2.5090e-08,\n",
      "        7.4834e-09, 2.7828e-09, 2.9466e-08, 1.3865e-08, 6.5581e-09, 1.2089e-08,\n",
      "        1.1792e-08, 2.0382e-08, 1.6778e-08, 1.2401e-08, 7.1009e-09, 1.8291e-08,\n",
      "        1.1387e-08, 1.5556e-08, 1.9985e-08, 7.0836e-09, 1.6863e-08, 9.9647e-09,\n",
      "        8.5522e-09, 2.7309e-08, 9.9306e-09, 1.1402e-08, 5.5445e-09, 1.5793e-08,\n",
      "        1.6154e-08, 2.2137e-08, 9.4216e-09, 6.9205e-09, 2.7822e-09, 1.0407e-08,\n",
      "        2.5398e-08, 1.7368e-08, 1.6824e-08, 8.3335e-09, 1.7819e-08, 1.6243e-08,\n",
      "        1.3246e-09, 1.7546e-08, 1.0799e-08, 3.8067e-09, 2.3565e-08, 7.0524e-09,\n",
      "        9.4893e-09, 1.2916e-08, 1.0797e-08, 2.4199e-08, 9.5729e-09, 7.6272e-09,\n",
      "        6.5792e-09, 1.4403e-08, 1.9514e-08, 1.4496e-08, 2.0690e-08, 6.8991e-09,\n",
      "        1.0373e-08, 1.5591e-08, 1.1501e-08, 1.4040e-08, 1.7022e-08, 1.9510e-08,\n",
      "        1.1741e-08, 2.3234e-08, 1.4949e-08, 1.8411e-08, 1.6885e-08, 1.2754e-08,\n",
      "        1.7969e-09, 1.7749e-08, 1.4900e-08, 1.6991e-08, 2.9171e-09, 1.7366e-08,\n",
      "        4.7620e-09, 1.7988e-08, 2.2175e-08, 3.4672e-09, 3.9202e-09, 4.7914e-09,\n",
      "        1.5479e-08, 1.2365e-08, 1.3183e-08, 2.5834e-08, 1.1023e-08, 3.6684e-09,\n",
      "        1.3442e-08, 2.8361e-09, 1.2931e-08, 1.3148e-08, 8.2444e-09, 1.7075e-08,\n",
      "        9.0468e-09, 1.1503e-08, 1.7726e-08, 1.5390e-08, 7.0747e-09, 1.8996e-08,\n",
      "        2.0912e-08, 1.4601e-08, 1.0207e-08, 5.4381e-09, 1.6940e-08, 1.3607e-08,\n",
      "        9.9219e-09, 2.5095e-08, 1.1222e-08, 1.7478e-08, 1.8542e-08, 1.7017e-08,\n",
      "        1.2511e-08, 1.2437e-08, 8.5035e-09, 6.2342e-09, 1.7459e-09, 1.2761e-08,\n",
      "        1.5243e-08, 2.1798e-08, 1.0558e-08, 1.6210e-08, 1.2284e-08, 5.6237e-09,\n",
      "        3.5986e-09, 1.9422e-08, 1.7189e-08, 1.3879e-08, 6.1793e-09, 1.4715e-08,\n",
      "        1.0268e-08, 2.6214e-08, 1.0114e-11, 1.0131e-08, 3.0845e-08, 1.9196e-08,\n",
      "        4.3681e-09, 1.6264e-08, 2.0473e-08, 1.2302e-08, 2.1576e-08, 3.5943e-08,\n",
      "        3.7362e-09, 3.4737e-09, 8.3408e-09, 1.8511e-08, 1.1578e-08, 6.7352e-09,\n",
      "        8.1069e-09, 5.6508e-09, 9.5299e-09, 1.2816e-08, 1.3835e-08, 9.2710e-09,\n",
      "        1.0240e-08, 8.7288e-09, 1.3831e-08, 1.1551e-08, 1.2152e-08, 1.2625e-08,\n",
      "        2.7289e-09, 1.3827e-08, 8.1904e-09, 1.0653e-08, 1.6631e-08, 5.8700e-09,\n",
      "        1.1747e-08, 1.5346e-08, 2.4140e-08, 1.1001e-08, 1.1479e-08, 1.8429e-08,\n",
      "        2.9191e-08, 1.3256e-08, 6.1674e-09, 2.6837e-08, 1.6998e-08, 2.6756e-08,\n",
      "        1.5026e-08, 1.3997e-08, 1.4036e-08, 1.3424e-08, 7.4849e-09, 6.4910e-09,\n",
      "        1.1285e-08, 8.6956e-09, 8.3441e-09, 2.8055e-08, 1.6297e-08, 2.1997e-08,\n",
      "        7.1089e-09, 2.3207e-08, 2.6288e-08, 1.1774e-09, 8.6970e-09, 1.5103e-08,\n",
      "        1.0293e-08, 3.1831e-08, 6.9937e-09, 1.8699e-08, 2.0987e-08, 1.2760e-08,\n",
      "        2.2397e-08, 1.4299e-08, 9.5493e-09, 1.9365e-08, 1.5054e-08, 1.4537e-08,\n",
      "        1.8100e-08, 9.4765e-09, 1.5073e-08, 1.4481e-08, 3.0586e-09, 1.3163e-08,\n",
      "        1.4518e-08, 1.1820e-08, 1.5123e-08, 2.9784e-08, 3.2894e-08, 1.0363e-08,\n",
      "        1.6657e-08, 1.8332e-08, 9.2632e-09, 1.2577e-08, 1.3948e-08, 1.6396e-08,\n",
      "        1.0368e-08, 2.0095e-09, 3.5966e-08, 1.0387e-08, 1.2889e-08, 1.8239e-08,\n",
      "        5.4013e-09, 2.4204e-08, 1.8636e-08, 8.3580e-10, 1.6440e-08, 7.2010e-09,\n",
      "        1.0981e-08, 1.0221e-08, 1.8499e-08, 6.0520e-09, 2.9627e-08, 2.5490e-08,\n",
      "        7.7034e-09, 1.0931e-08, 7.3318e-09, 1.9005e-08, 1.7044e-08, 1.2711e-08,\n",
      "        2.2570e-08, 2.3137e-08, 3.7690e-09, 9.0565e-09, 1.4859e-08, 7.0897e-09,\n",
      "        1.8313e-08, 5.4755e-09, 4.3055e-08, 2.0582e-08, 9.3323e-09, 1.2872e-08,\n",
      "        1.3636e-08, 2.8595e-08, 2.2470e-08, 2.5161e-08, 1.8021e-08, 1.2808e-08,\n",
      "        2.2072e-08, 2.2633e-08, 4.2632e-09, 8.5178e-09, 2.1358e-08, 1.5724e-08,\n",
      "        9.5518e-09, 2.1982e-08, 1.1027e-08, 7.4293e-09, 9.5316e-09, 7.9150e-09,\n",
      "        2.0768e-08, 5.3443e-09, 2.8667e-08, 1.1427e-08, 1.5369e-08, 1.1623e-08,\n",
      "        1.2284e-08, 1.6592e-08, 8.4389e-09, 6.2880e-09, 1.1717e-08, 8.2781e-09,\n",
      "        1.7627e-08, 1.4392e-08, 8.2889e-09, 1.4945e-08, 1.0170e-08, 1.3305e-08,\n",
      "        1.6963e-08, 9.9024e-09, 1.7981e-08, 1.6710e-08, 1.3019e-08, 1.4999e-09,\n",
      "        1.5609e-08, 1.5251e-08, 5.2870e-09, 2.4933e-08, 8.9189e-09, 1.3735e-08,\n",
      "        3.3446e-08, 1.2171e-08, 1.9732e-08, 1.5988e-08, 7.9250e-09, 2.2622e-08,\n",
      "        9.5589e-09, 1.6203e-08, 4.9141e-09, 1.2746e-08, 1.9144e-08, 1.6359e-08,\n",
      "        1.4593e-08, 1.6453e-08, 1.1076e-08, 4.1083e-09, 2.0385e-08, 1.8494e-08,\n",
      "        2.3715e-08, 2.3421e-08, 7.1052e-09, 1.8412e-08, 1.4177e-08, 7.5108e-09,\n",
      "        2.3468e-08, 1.2174e-08, 2.1589e-08, 1.2348e-08, 2.4138e-08, 8.3269e-09,\n",
      "        1.2921e-08, 1.7302e-08, 1.2544e-08, 6.7582e-09, 9.5995e-09, 1.8277e-08,\n",
      "        1.8352e-08, 6.1717e-09, 4.4587e-09, 1.3939e-08, 6.5287e-09, 8.6830e-09,\n",
      "        1.4343e-08, 2.6588e-09, 2.2229e-08, 1.4569e-08, 1.7027e-08, 1.3018e-08,\n",
      "        2.0218e-08, 1.3045e-08, 5.8030e-09, 1.0868e-08, 9.2364e-09, 9.9031e-09,\n",
      "        1.5203e-08, 2.2650e-08, 2.6385e-08, 4.3229e-09, 4.0532e-09, 4.6970e-09,\n",
      "        8.6517e-09, 2.6154e-08, 1.9446e-08, 1.0811e-08, 2.6888e-08, 2.6253e-08,\n",
      "        5.5444e-09, 3.0349e-09, 1.1298e-08, 1.4880e-08, 1.5966e-08, 1.5134e-08,\n",
      "        2.6305e-08, 9.6970e-09, 1.2606e-08, 1.4570e-08, 9.4757e-09, 1.1180e-08,\n",
      "        1.6809e-08, 1.3292e-08, 1.6317e-08, 1.9468e-08, 1.3851e-08, 1.2162e-08,\n",
      "        6.8449e-09, 1.0719e-08, 9.8460e-09, 3.6096e-09, 1.8882e-08, 4.0590e-08,\n",
      "        1.1675e-08, 1.2135e-08, 1.3572e-08, 8.4682e-09, 1.0020e-08, 7.2258e-09,\n",
      "        1.0545e-08, 1.5803e-08, 2.2692e-08, 1.2801e-08, 3.6309e-08, 1.1881e-08,\n",
      "        1.7236e-08, 1.4999e-08, 1.4950e-08, 1.7623e-08, 1.3396e-08, 1.3893e-08,\n",
      "        1.1382e-08, 3.2832e-08, 1.1783e-08, 6.1334e-09, 1.1578e-08, 1.8141e-08,\n",
      "        1.5663e-08, 3.5252e-09, 2.0730e-08, 1.3941e-08, 8.8917e-09, 1.0529e-08,\n",
      "        3.5405e-08, 7.0380e-09, 2.1552e-08, 6.0090e-09, 1.1694e-08, 1.9778e-09,\n",
      "        1.0886e-08, 1.2344e-08, 1.5324e-08, 1.3723e-08, 1.7623e-08, 1.8460e-09,\n",
      "        2.5197e-08, 2.6811e-08, 1.5987e-08, 1.1363e-08, 1.3337e-08, 1.1712e-08,\n",
      "        9.5031e-09, 1.4895e-08, 1.4361e-08, 3.7028e-09, 1.7940e-08, 1.8696e-08,\n",
      "        5.0978e-09, 2.7158e-08, 9.4764e-09, 2.1107e-08, 1.3938e-08, 2.2954e-08,\n",
      "        2.2437e-08, 2.0353e-08, 1.2792e-08, 7.4026e-09, 1.1019e-08, 1.8211e-08,\n",
      "        1.7370e-08, 7.5780e-09, 1.7293e-08, 1.5900e-08, 1.3046e-08, 1.1851e-09,\n",
      "        5.8356e-09, 1.1179e-08, 2.0678e-08, 2.0570e-08, 4.9183e-09, 8.3351e-09,\n",
      "        3.3620e-09, 7.4693e-09, 1.9296e-08, 1.0739e-08, 2.5704e-10, 1.7910e-08,\n",
      "        4.1967e-09, 1.9941e-08, 2.8182e-09, 2.7395e-08, 9.5993e-09, 1.4508e-08,\n",
      "        1.6572e-08, 1.8385e-08], device='cuda:0')}, 8: {'step': tensor(120., device='cuda:0'), 'exp_avg': tensor([[-1.5313e-05,  3.2314e-05, -1.3052e-04,  ..., -9.1286e-05,\n",
      "         -9.7453e-05,  2.2129e-04],\n",
      "        [ 1.3570e-04,  1.0466e-04, -1.3316e-03,  ..., -7.5493e-04,\n",
      "          1.0418e-04,  2.3254e-04],\n",
      "        [ 7.1486e-05, -7.6567e-04,  9.2126e-04,  ...,  9.3521e-05,\n",
      "          1.2511e-04,  8.7469e-04],\n",
      "        ...,\n",
      "        [ 1.6577e-05, -9.6428e-04, -2.9938e-04,  ..., -1.7178e-04,\n",
      "         -1.1452e-04, -2.3627e-03],\n",
      "        [-2.1602e-04,  1.3692e-04, -3.1219e-04,  ...,  8.5379e-05,\n",
      "         -8.8064e-05, -8.4633e-04],\n",
      "        [ 1.4426e-05, -5.4737e-04,  1.0318e-03,  ...,  6.3966e-04,\n",
      "         -1.0857e-04,  6.0914e-04]], device='cuda:0'), 'exp_avg_sq': tensor([[2.7616e-07, 2.7392e-07, 1.1785e-06,  ..., 4.7099e-07, 2.1428e-07,\n",
      "         7.5600e-07],\n",
      "        [1.7803e-06, 5.0804e-07, 1.2418e-06,  ..., 1.9880e-06, 8.0530e-07,\n",
      "         1.8839e-06],\n",
      "        [5.2269e-07, 5.7946e-07, 2.7790e-06,  ..., 7.3277e-07, 1.2867e-06,\n",
      "         1.9486e-06],\n",
      "        ...,\n",
      "        [9.1109e-07, 9.1938e-07, 2.3204e-06,  ..., 1.2981e-06, 1.7222e-06,\n",
      "         5.7894e-06],\n",
      "        [2.4848e-07, 1.0906e-07, 2.5747e-07,  ..., 5.6614e-07, 3.1574e-07,\n",
      "         9.1496e-07],\n",
      "        [3.6948e-07, 4.3011e-07, 1.1505e-06,  ..., 9.0507e-07, 4.5405e-07,\n",
      "         1.3639e-06]], device='cuda:0')}, 9: {'step': tensor(120., device='cuda:0'), 'exp_avg': tensor([-1.5978e-04, -1.1418e-04, -2.0463e-05, -7.7537e-05, -2.8913e-04,\n",
      "         6.3850e-05,  3.6897e-05, -1.5994e-05, -1.4055e-04, -1.1621e-04,\n",
      "         1.8360e-04,  7.3987e-05, -1.2741e-05,  8.8551e-05,  7.9698e-05,\n",
      "         1.1804e-04,  2.0166e-04,  2.9637e-05, -2.4159e-06, -2.3013e-04,\n",
      "        -1.9367e-05, -6.7713e-06, -4.9488e-05,  1.6455e-04, -1.3482e-04,\n",
      "        -8.4607e-05, -3.1169e-05,  3.9383e-05, -7.4982e-06,  2.2527e-05,\n",
      "         1.4278e-04,  3.2657e-05, -1.7831e-04,  2.5531e-05, -3.3739e-04,\n",
      "        -2.2231e-05,  3.4811e-04,  8.6205e-05, -9.7178e-05,  4.0325e-05,\n",
      "        -1.3817e-04, -2.6632e-04, -2.5926e-04,  8.7211e-05,  9.3681e-05,\n",
      "        -1.0052e-04,  8.4830e-05, -3.9887e-05, -1.2098e-04,  3.9583e-05,\n",
      "        -1.8690e-04,  1.1618e-04,  1.4904e-05, -3.4285e-04, -3.5542e-05,\n",
      "         3.9847e-05, -8.2590e-06, -8.9249e-05, -6.6796e-05, -1.1532e-04,\n",
      "        -4.6669e-04, -8.8791e-05,  2.4439e-04, -7.3027e-05,  7.6979e-05,\n",
      "        -4.0150e-05, -2.5883e-05, -3.0623e-04, -2.0542e-04, -2.9751e-04,\n",
      "         1.9628e-04, -1.1042e-04, -1.1138e-04,  1.0684e-07,  1.5254e-06,\n",
      "        -7.8768e-05,  1.9538e-04,  1.0328e-04,  5.9363e-05, -2.1915e-04,\n",
      "         1.6556e-04, -1.4144e-05, -2.8691e-06, -8.8479e-05,  8.8072e-06,\n",
      "         1.0898e-06,  1.5926e-04, -3.8930e-04, -2.1114e-05, -1.2435e-04,\n",
      "        -8.8354e-05, -1.4151e-04,  1.2214e-04, -3.1179e-05, -1.6603e-04,\n",
      "         2.1223e-05,  3.2820e-05,  5.1760e-05,  3.6254e-04, -7.7236e-06,\n",
      "        -2.5777e-04,  1.7443e-05,  1.8159e-04,  3.5320e-05, -3.8168e-05,\n",
      "         2.2258e-05,  1.8460e-04, -3.6471e-04,  2.6414e-04, -1.4145e-04,\n",
      "        -2.1760e-04,  1.7825e-04,  3.3061e-04, -5.9141e-05,  1.0187e-04,\n",
      "         1.1452e-04,  2.2591e-04, -1.1606e-04,  2.2689e-06, -5.8648e-05,\n",
      "         4.6820e-05, -2.1275e-04, -4.3034e-05, -1.3970e-05,  4.0950e-05,\n",
      "        -1.4159e-05, -9.9717e-05,  3.9114e-05,  2.5674e-04, -5.8090e-05,\n",
      "         1.0379e-04,  6.5951e-05,  9.0479e-05,  2.6246e-06, -1.7675e-05,\n",
      "         1.2415e-04,  3.2697e-05,  1.1540e-04,  1.1616e-04, -9.8197e-05,\n",
      "         1.6830e-04,  1.0721e-04,  7.9900e-05,  3.6788e-05, -1.1296e-04,\n",
      "        -1.5914e-05,  3.4998e-04,  1.9559e-04, -1.2805e-04, -4.0515e-05,\n",
      "         1.0465e-04,  5.0741e-05,  2.5866e-05, -2.7953e-06, -8.1983e-05,\n",
      "        -7.1640e-05,  1.1033e-04, -3.3415e-05,  2.6418e-04, -1.6750e-04,\n",
      "        -1.4727e-04, -2.2510e-05,  9.4869e-05,  8.6053e-05,  3.0055e-05,\n",
      "         1.3287e-04,  1.4875e-04, -1.4812e-05,  1.0014e-04,  2.2168e-06,\n",
      "        -7.3933e-05,  1.0597e-04,  2.8721e-06,  2.2598e-04, -7.0558e-05,\n",
      "        -4.0302e-05,  3.8044e-05, -8.7352e-05,  2.2979e-05, -2.2495e-04,\n",
      "         3.2309e-05, -5.2747e-07,  2.0902e-04,  4.1952e-05, -8.5244e-05,\n",
      "         6.7740e-05,  1.8527e-04,  5.5525e-05, -2.5834e-04, -7.9510e-05,\n",
      "         1.2933e-04, -4.4097e-05,  1.0832e-04, -8.6125e-05, -7.4256e-05,\n",
      "         8.0765e-05, -2.4434e-05,  5.7587e-05, -5.8431e-05, -3.1804e-06,\n",
      "        -1.0025e-04,  1.0035e-04,  5.8743e-05,  2.0279e-04,  1.2557e-04,\n",
      "        -1.2278e-05,  2.9038e-04, -1.5338e-04, -1.8409e-04, -1.4653e-04,\n",
      "         1.3627e-04,  1.5805e-04,  9.9200e-05, -8.6590e-05,  6.2253e-05,\n",
      "         7.8960e-05, -3.1449e-05,  9.0128e-05, -7.6909e-05, -1.5273e-05,\n",
      "         7.8538e-05,  7.6365e-05,  1.4575e-04,  1.1300e-04,  2.2889e-05,\n",
      "        -1.7011e-05,  3.9710e-05,  1.6392e-04,  6.6917e-05,  2.0608e-04,\n",
      "         3.5411e-04,  6.2631e-06, -4.2202e-04, -3.3405e-05,  1.7427e-05,\n",
      "         1.6090e-04,  8.3041e-05, -2.5735e-04,  8.5565e-05,  4.8231e-05,\n",
      "        -5.0611e-05, -2.5236e-04,  4.9085e-05, -3.3649e-04,  1.5474e-05,\n",
      "         9.1068e-05, -1.3599e-04,  1.8837e-04,  5.1766e-05,  2.2217e-04,\n",
      "         3.1457e-05, -1.1378e-04, -3.8606e-05, -2.1203e-05,  1.5247e-04,\n",
      "         1.5942e-04], device='cuda:0'), 'exp_avg_sq': tensor([3.6838e-08, 7.6636e-08, 7.9881e-08, 7.6236e-08, 1.4279e-07, 1.6964e-07,\n",
      "        6.2607e-08, 1.2502e-07, 6.4064e-08, 1.2777e-07, 2.7376e-08, 6.3106e-08,\n",
      "        1.3890e-07, 6.2574e-08, 8.1379e-08, 9.1252e-08, 8.7861e-08, 3.7012e-08,\n",
      "        1.4223e-08, 1.3433e-07, 2.1755e-08, 3.2191e-08, 6.3803e-08, 9.3789e-08,\n",
      "        4.3561e-08, 2.9553e-08, 8.5377e-08, 1.1613e-07, 2.2819e-08, 9.6116e-08,\n",
      "        5.6703e-08, 2.5834e-08, 8.7040e-08, 9.5419e-08, 6.4993e-08, 6.3327e-08,\n",
      "        1.1030e-07, 1.1144e-07, 6.9822e-08, 1.1519e-07, 9.7238e-08, 7.5565e-08,\n",
      "        6.3698e-08, 1.0687e-07, 5.6384e-08, 7.1298e-08, 7.9101e-08, 1.2718e-07,\n",
      "        8.9600e-08, 6.7623e-08, 1.4185e-07, 9.0864e-08, 5.9315e-08, 8.0686e-08,\n",
      "        1.2479e-07, 2.6872e-08, 7.1318e-08, 1.0724e-07, 5.1458e-08, 1.8961e-07,\n",
      "        1.6298e-07, 7.3644e-08, 1.4077e-07, 7.4844e-08, 9.6522e-08, 4.5805e-08,\n",
      "        1.1265e-07, 4.8998e-08, 1.1747e-07, 7.7782e-08, 1.4065e-07, 1.2986e-08,\n",
      "        6.3636e-08, 5.4914e-08, 4.5256e-08, 5.1751e-08, 1.0022e-07, 4.1612e-08,\n",
      "        7.3857e-08, 5.4418e-08, 8.2695e-08, 3.8628e-08, 1.0887e-07, 7.7433e-08,\n",
      "        1.4742e-07, 1.2340e-07, 1.2638e-07, 1.3506e-07, 9.2676e-08, 6.6784e-08,\n",
      "        4.3189e-08, 7.8916e-08, 2.3121e-08, 1.8015e-07, 6.8982e-08, 8.5950e-08,\n",
      "        9.6301e-08, 4.7808e-08, 1.4633e-07, 1.0601e-07, 1.1408e-07, 1.1274e-07,\n",
      "        1.5459e-07, 2.8960e-08, 1.4605e-07, 4.3568e-08, 7.1942e-08, 6.8780e-08,\n",
      "        7.9637e-08, 7.9366e-08, 7.9041e-08, 6.1866e-08, 9.5084e-08, 4.7601e-08,\n",
      "        4.7830e-08, 7.7705e-08, 1.1477e-07, 7.2156e-08, 5.5759e-08, 1.2656e-07,\n",
      "        3.8741e-08, 7.7763e-08, 7.5607e-08, 4.6459e-08, 1.0012e-07, 5.2283e-08,\n",
      "        7.9863e-08, 1.7236e-07, 1.2415e-07, 2.4618e-08, 9.5451e-08, 8.1124e-09,\n",
      "        5.8505e-08, 1.7122e-07, 6.7831e-08, 4.5385e-08, 7.6637e-08, 4.1939e-08,\n",
      "        4.1539e-08, 1.5525e-08, 9.1121e-08, 1.2940e-07, 7.4325e-08, 2.4856e-08,\n",
      "        9.1984e-08, 1.6655e-07, 9.1250e-08, 1.0731e-07, 4.8245e-08, 6.0486e-08,\n",
      "        4.6663e-08, 2.4055e-08, 5.2036e-08, 5.1338e-08, 1.9790e-08, 4.2519e-08,\n",
      "        8.1954e-08, 9.0992e-08, 7.2037e-08, 8.7967e-08, 2.4180e-08, 1.1035e-07,\n",
      "        4.2767e-08, 1.0266e-07, 9.2920e-09, 6.6236e-08, 9.2692e-08, 5.8444e-08,\n",
      "        8.0891e-08, 7.3658e-09, 5.4416e-08, 1.1554e-07, 4.6117e-08, 3.4152e-08,\n",
      "        6.0876e-08, 7.6234e-08, 8.7999e-08, 5.0021e-08, 6.8125e-08, 6.6166e-08,\n",
      "        1.4382e-08, 5.2850e-08, 1.0454e-07, 2.9669e-08, 7.4819e-08, 8.1462e-08,\n",
      "        3.2507e-07, 9.9978e-08, 1.1144e-07, 1.3621e-07, 9.0921e-08, 4.5879e-08,\n",
      "        5.2727e-08, 7.7249e-08, 8.7177e-08, 8.6653e-08, 1.3962e-08, 9.9659e-08,\n",
      "        1.3850e-07, 4.7305e-08, 8.5683e-08, 1.0645e-07, 3.2053e-08, 1.4018e-07,\n",
      "        8.1972e-08, 2.8610e-08, 1.1084e-07, 1.3488e-07, 4.8228e-08, 1.4091e-07,\n",
      "        5.7089e-08, 8.1201e-08, 8.4830e-08, 1.1435e-07, 8.6208e-08, 3.6889e-08,\n",
      "        4.4705e-08, 8.7804e-08, 1.6453e-07, 9.5528e-09, 1.2061e-07, 6.7233e-08,\n",
      "        3.2054e-08, 1.0989e-07, 2.7382e-08, 2.9813e-08, 4.3376e-08, 1.7400e-07,\n",
      "        5.0440e-08, 6.6479e-08, 1.2368e-07, 6.3325e-08, 1.5035e-07, 4.0016e-08,\n",
      "        5.9242e-08, 1.8057e-07, 5.3503e-08, 1.1186e-07, 4.3240e-08, 1.1120e-07,\n",
      "        5.6848e-08, 7.6173e-08, 7.3744e-08, 4.6241e-08, 4.8622e-08, 4.3212e-08,\n",
      "        1.2141e-07, 8.7827e-08, 8.0252e-08, 1.2533e-07, 1.7635e-07, 9.6736e-08,\n",
      "        6.6371e-08, 1.2688e-07, 3.5152e-08, 5.0449e-08], device='cuda:0')}, 10: {'step': tensor(120., device='cuda:0'), 'exp_avg': tensor([[-2.5424e-05,  4.4413e-05,  3.8325e-05,  ...,  6.7514e-04,\n",
      "         -2.1808e-04, -4.7038e-06],\n",
      "        [-2.5760e-04, -3.2881e-04,  2.0549e-03,  ..., -1.3460e-04,\n",
      "         -3.3368e-04, -6.0813e-04],\n",
      "        [ 6.9076e-05, -1.3792e-04,  1.6844e-03,  ...,  2.9989e-03,\n",
      "          3.9077e-04,  1.7009e-03],\n",
      "        ...,\n",
      "        [-2.0163e-04, -3.4684e-04,  2.1396e-04,  ...,  7.9804e-05,\n",
      "          3.4065e-05,  3.0144e-03],\n",
      "        [ 1.1239e-04,  5.1563e-05,  1.5419e-03,  ..., -7.6072e-04,\n",
      "         -6.5175e-04,  6.2580e-04],\n",
      "        [ 2.4780e-04,  8.8288e-05, -9.5863e-04,  ...,  7.6768e-04,\n",
      "          1.9458e-04, -8.0524e-04]], device='cuda:0'), 'exp_avg_sq': tensor([[1.5246e-07, 1.4156e-07, 1.5410e-06,  ..., 6.0966e-07, 2.5792e-07,\n",
      "         3.2124e-07],\n",
      "        [8.4727e-07, 7.1219e-07, 4.5557e-06,  ..., 4.6673e-06, 3.1329e-07,\n",
      "         9.2154e-07],\n",
      "        [8.9671e-07, 8.9027e-07, 2.4305e-06,  ..., 5.5660e-06, 4.9520e-07,\n",
      "         1.6970e-06],\n",
      "        ...,\n",
      "        [1.9598e-06, 5.4952e-07, 2.8591e-06,  ..., 5.3871e-06, 5.6301e-07,\n",
      "         2.8272e-06],\n",
      "        [1.5610e-07, 3.3241e-07, 1.3467e-06,  ..., 2.2824e-06, 3.9427e-07,\n",
      "         7.0736e-07],\n",
      "        [1.1032e-06, 8.3395e-07, 1.4853e-06,  ..., 3.6932e-06, 8.9859e-07,\n",
      "         2.0238e-06]], device='cuda:0')}, 11: {'step': tensor(120., device='cuda:0'), 'exp_avg': tensor([ 2.1119e-04,  1.0620e-05,  2.8397e-04,  1.8085e-04,  1.5423e-04,\n",
      "        -1.2402e-04, -3.1316e-04,  2.0676e-04,  4.2141e-04, -9.3498e-05,\n",
      "         1.9686e-05,  1.9267e-04, -3.7587e-04,  2.7891e-04, -1.6074e-04,\n",
      "         4.5240e-06,  3.9096e-04, -1.2182e-04,  4.3479e-04, -1.4268e-04,\n",
      "        -5.5005e-05, -1.0108e-05, -1.9798e-04,  1.7008e-04,  1.8853e-04,\n",
      "         4.1839e-04, -3.6542e-04,  2.1808e-04, -1.6296e-04, -4.6807e-04,\n",
      "        -1.7676e-04, -4.1152e-04,  1.2837e-04,  7.6908e-05, -1.5148e-04,\n",
      "        -8.0744e-05, -1.5504e-05,  1.4797e-05,  2.0200e-04,  9.1010e-05,\n",
      "         2.1365e-04,  8.6425e-05,  4.0096e-05,  3.6697e-04,  1.8873e-05,\n",
      "         5.1022e-04,  5.9736e-05,  2.7233e-04, -6.2349e-05, -8.9427e-05,\n",
      "         5.5026e-04, -4.8443e-04, -4.3560e-04, -6.4839e-05, -1.9283e-04,\n",
      "        -3.4658e-04,  6.7517e-05, -1.8407e-04,  6.0923e-05,  1.2992e-05,\n",
      "        -6.3352e-05, -3.9958e-05,  3.8445e-05,  2.6892e-05, -1.9034e-04,\n",
      "        -5.6269e-06, -5.9142e-05,  1.0228e-04,  2.2958e-04, -2.3641e-04,\n",
      "        -3.5082e-04, -3.1797e-05,  2.3142e-05,  5.9646e-06,  1.1586e-04,\n",
      "         1.8434e-04,  3.9236e-05, -2.1269e-04, -4.1825e-05, -1.2398e-04,\n",
      "        -1.2514e-04, -3.2890e-04,  4.1039e-04,  2.5415e-05, -1.4483e-05,\n",
      "        -2.2946e-04, -5.0169e-05,  8.3039e-05, -1.2400e-04,  3.8456e-05,\n",
      "        -3.0991e-04,  5.8450e-05, -1.0113e-04, -1.1140e-04,  2.9057e-04,\n",
      "         2.3646e-05, -2.1749e-04,  4.2105e-04, -5.6610e-06, -6.3597e-05,\n",
      "         5.3189e-04,  7.0460e-05,  2.5390e-04, -8.9224e-05, -3.8019e-04,\n",
      "         3.3516e-04,  7.4201e-05, -4.6641e-05,  1.1513e-04, -2.2331e-04,\n",
      "        -1.3277e-04, -7.0107e-05,  2.2177e-04,  1.8748e-05,  7.7830e-05,\n",
      "         3.4718e-04, -3.4845e-04, -1.4905e-05,  4.1450e-05, -1.8185e-04,\n",
      "         4.5829e-05,  1.1929e-04, -2.2644e-04,  2.0972e-04, -3.5848e-04,\n",
      "         7.8089e-04, -1.3507e-04,  3.8683e-05, -8.9292e-05,  3.9383e-04,\n",
      "        -1.5996e-04, -8.0539e-05, -2.4960e-05, -4.0847e-04, -2.3400e-04,\n",
      "        -2.6587e-04,  7.6662e-04,  4.6143e-04,  3.0239e-04, -1.1278e-04,\n",
      "         7.6997e-05, -2.8810e-04,  5.5115e-04, -5.0430e-05,  1.4063e-04,\n",
      "        -1.5649e-04,  5.3431e-04,  4.1940e-04,  1.4658e-04, -1.1680e-05,\n",
      "         3.3935e-05, -4.7934e-05,  6.8187e-04, -1.7595e-04,  7.1780e-05,\n",
      "         2.1191e-05, -3.8099e-04,  4.0980e-04,  3.9832e-05,  3.3570e-04,\n",
      "        -3.6840e-05, -6.9989e-05, -6.3091e-04,  1.9947e-04,  1.2684e-04,\n",
      "        -1.7877e-04, -2.9237e-04,  1.4379e-04,  5.4531e-05, -3.2933e-05,\n",
      "        -2.9457e-04, -3.1403e-04,  2.5830e-04,  6.8735e-06, -4.8397e-05,\n",
      "        -4.8209e-05, -1.0382e-04,  1.2710e-04, -2.5844e-04, -1.3281e-04,\n",
      "         2.1547e-04, -3.2553e-04,  6.4225e-04,  1.4886e-04, -3.4075e-04,\n",
      "         6.6780e-05,  6.2923e-05,  1.8584e-04, -3.8158e-04, -4.2185e-04,\n",
      "        -6.4781e-06,  3.9715e-04,  2.0508e-04,  2.1307e-04, -2.8654e-04,\n",
      "         3.8178e-04,  2.4745e-04,  1.0234e-04,  7.7545e-05,  8.3662e-05,\n",
      "         2.6230e-04,  2.6980e-04, -3.2003e-04,  5.5032e-04,  3.4415e-06,\n",
      "         6.2253e-05,  2.0367e-04, -6.6724e-06, -2.5302e-04, -8.1792e-05,\n",
      "        -1.7587e-04,  1.5746e-04,  1.7405e-05,  1.0111e-04, -1.0706e-04,\n",
      "         8.7739e-05, -1.1080e-04, -2.0786e-04,  5.4867e-06, -1.5735e-05,\n",
      "         2.0798e-05, -1.5706e-04, -5.6997e-05,  5.7955e-05, -2.7101e-04,\n",
      "        -2.9234e-04,  2.7080e-04, -1.8807e-04,  6.9581e-05, -7.8843e-05,\n",
      "         1.3733e-05, -4.8102e-05, -4.0308e-05, -1.0527e-04,  2.6833e-04,\n",
      "        -5.1005e-05, -9.5626e-05,  2.4897e-04,  3.5382e-05,  1.9911e-04,\n",
      "         1.2301e-04, -6.4500e-05,  5.9307e-05,  3.9790e-04,  5.7281e-05,\n",
      "         2.9773e-05, -3.4015e-04,  5.7742e-05,  1.6467e-04, -3.0417e-04,\n",
      "         2.5297e-05, -1.5313e-04,  6.3976e-05,  1.6407e-04,  1.0711e-05,\n",
      "         1.3446e-04], device='cuda:0'), 'exp_avg_sq': tensor([7.7664e-08, 3.4768e-07, 2.6583e-07, 3.5617e-07, 8.9206e-08, 2.1407e-07,\n",
      "        4.5486e-07, 2.2881e-07, 3.3921e-07, 1.8788e-07, 1.7503e-07, 4.3756e-07,\n",
      "        2.2637e-07, 2.4321e-07, 2.5675e-07, 9.6171e-08, 2.4690e-07, 2.4148e-07,\n",
      "        1.7624e-07, 6.2341e-08, 2.7335e-07, 8.2521e-08, 1.9653e-07, 1.0996e-07,\n",
      "        2.0006e-07, 2.1456e-07, 4.3341e-07, 3.0278e-07, 1.1141e-07, 2.4664e-07,\n",
      "        2.0731e-07, 2.5001e-07, 3.0650e-07, 2.8024e-07, 3.1947e-07, 1.3632e-07,\n",
      "        4.5870e-07, 1.3034e-07, 1.3082e-07, 2.7780e-07, 1.1773e-07, 8.8497e-08,\n",
      "        1.5768e-07, 2.5715e-07, 2.2259e-07, 8.8420e-08, 3.1056e-07, 2.1023e-07,\n",
      "        2.6118e-07, 4.7752e-07, 2.8924e-07, 2.0863e-07, 1.4874e-07, 2.3070e-07,\n",
      "        2.2212e-07, 1.2986e-07, 2.3683e-07, 2.5820e-07, 2.4361e-07, 5.7142e-08,\n",
      "        1.4620e-07, 2.3576e-07, 1.5633e-07, 1.9437e-07, 1.1235e-07, 1.9863e-07,\n",
      "        2.0344e-07, 1.2177e-07, 3.4378e-07, 3.1138e-07, 4.2731e-07, 5.8454e-07,\n",
      "        1.0402e-07, 1.0163e-07, 1.2427e-07, 3.4686e-07, 2.4627e-07, 2.7115e-07,\n",
      "        6.1590e-08, 3.5422e-07, 2.4170e-07, 3.7229e-07, 2.5481e-07, 4.1542e-07,\n",
      "        2.8738e-07, 3.0394e-07, 3.2475e-07, 3.2631e-07, 1.2594e-07, 1.9050e-07,\n",
      "        7.2572e-07, 2.4306e-07, 2.2511e-07, 7.4250e-08, 1.1981e-07, 2.9446e-07,\n",
      "        3.4566e-07, 2.2984e-07, 2.4324e-07, 2.1253e-07, 3.0261e-07, 8.5611e-08,\n",
      "        2.8190e-07, 1.5260e-07, 2.3696e-07, 2.1107e-07, 2.0666e-07, 1.5566e-07,\n",
      "        5.4791e-08, 3.2403e-07, 2.1345e-07, 2.1518e-07, 1.3868e-07, 4.0908e-07,\n",
      "        2.3299e-07, 1.5452e-07, 3.7172e-07, 1.9620e-07, 1.8402e-07, 3.8885e-07,\n",
      "        2.7003e-07, 2.2677e-07, 1.8203e-07, 1.2846e-07, 2.4284e-07, 4.2656e-07,\n",
      "        1.7539e-07, 3.1222e-07, 2.0792e-07, 5.0978e-07, 2.7187e-07, 3.1003e-07,\n",
      "        1.4518e-07, 3.3300e-07, 1.9472e-07, 2.3488e-07, 3.6566e-07, 1.4416e-07,\n",
      "        1.6950e-07, 2.3704e-07, 2.8266e-07, 2.6299e-07, 4.5488e-07, 2.6879e-07,\n",
      "        2.1669e-07, 2.7182e-07, 3.0546e-07, 3.0650e-07, 1.8192e-07, 1.6374e-07,\n",
      "        1.4225e-07, 6.2072e-08, 3.8058e-07, 4.9521e-07, 1.5227e-07, 2.0520e-07,\n",
      "        2.0158e-07, 4.5147e-07, 2.7452e-07, 1.8253e-07, 3.7526e-07, 3.4542e-07,\n",
      "        3.2822e-07, 2.9644e-07, 1.0071e-07, 1.4449e-07, 1.0800e-07, 1.6808e-07,\n",
      "        9.2210e-08, 2.6169e-07, 7.9942e-08, 2.2486e-07, 4.3508e-07, 1.4169e-07,\n",
      "        1.8698e-07, 3.2240e-07, 3.9714e-07, 5.0163e-07, 1.7685e-07, 1.0867e-07,\n",
      "        2.1289e-07, 2.4071e-07, 3.1117e-07, 7.2137e-08, 2.5750e-07, 1.8357e-07,\n",
      "        3.8921e-07, 4.0924e-08, 3.2791e-07, 2.4235e-07, 1.8029e-07, 2.1065e-07,\n",
      "        2.8139e-07, 3.5711e-07, 3.1796e-07, 2.0144e-07, 3.1871e-07, 2.9516e-07,\n",
      "        4.4498e-07, 1.2660e-07, 1.7192e-07, 1.8111e-07, 2.9394e-07, 3.9905e-07,\n",
      "        1.2514e-07, 1.7959e-07, 3.8588e-07, 4.3187e-07, 1.0474e-07, 1.4385e-07,\n",
      "        2.0709e-07, 2.9570e-07, 2.4674e-07, 3.2751e-07, 2.0057e-07, 4.0390e-07,\n",
      "        1.1235e-07, 2.7272e-07, 2.1270e-07, 1.1245e-07, 3.7212e-07, 3.6782e-07,\n",
      "        4.3578e-07, 1.4553e-07, 2.3761e-07, 1.8027e-07, 2.2783e-07, 6.5999e-07,\n",
      "        3.2979e-07, 3.5375e-07, 9.7386e-08, 5.0615e-07, 2.2660e-07, 1.5046e-07,\n",
      "        2.0486e-07, 1.6008e-07, 3.4992e-07, 2.5794e-07, 3.5576e-07, 1.5316e-07,\n",
      "        2.4831e-07, 2.7508e-07, 9.1920e-08, 2.2683e-07, 2.5211e-07, 4.1127e-07,\n",
      "        2.0564e-07, 8.7191e-08, 1.8685e-07, 4.9565e-07, 4.4245e-07, 2.7403e-07,\n",
      "        3.1440e-07, 4.0359e-07, 1.8704e-07, 2.0062e-07], device='cuda:0')}, 12: {'step': tensor(120., device='cuda:0'), 'exp_avg': tensor([[ 2.7940e-04,  4.9836e-04,  5.5300e-04,  ...,  2.0054e-03,\n",
      "         -7.2399e-05,  2.9600e-04],\n",
      "        [ 3.9575e-05,  3.3318e-03,  1.5011e-03,  ...,  1.3926e-03,\n",
      "          5.0670e-04,  1.3241e-04],\n",
      "        [ 3.7859e-04,  7.3260e-04,  3.6432e-04,  ...,  1.8718e-03,\n",
      "          3.5104e-05,  1.4816e-03],\n",
      "        ...,\n",
      "        [-2.1970e-04, -2.8515e-03, -8.5448e-04,  ..., -6.0481e-04,\n",
      "         -2.7708e-04,  3.2307e-05],\n",
      "        [ 3.3413e-04, -7.3596e-04,  6.0351e-04,  ...,  1.1487e-03,\n",
      "         -1.9194e-04,  4.5912e-04],\n",
      "        [-4.0631e-04, -5.3217e-04, -6.9436e-04,  ..., -2.2971e-04,\n",
      "         -6.0166e-05,  4.9527e-05]], device='cuda:0'), 'exp_avg_sq': tensor([[1.0853e-06, 3.3157e-06, 1.0888e-05,  ..., 7.7859e-06, 1.8123e-06,\n",
      "         4.3399e-06],\n",
      "        [6.4255e-07, 1.2818e-05, 1.2310e-05,  ..., 6.2241e-06, 1.7772e-06,\n",
      "         6.3332e-06],\n",
      "        [1.0728e-06, 4.6578e-06, 4.4601e-06,  ..., 7.0062e-06, 9.6858e-07,\n",
      "         3.9927e-06],\n",
      "        ...,\n",
      "        [1.5339e-07, 4.7638e-06, 2.4734e-06,  ..., 1.5059e-06, 3.1715e-07,\n",
      "         1.0436e-06],\n",
      "        [1.1500e-06, 1.2290e-05, 1.8720e-05,  ..., 1.4391e-05, 3.0685e-06,\n",
      "         2.8977e-05],\n",
      "        [1.4893e-06, 2.7568e-06, 1.6517e-05,  ..., 6.0064e-06, 1.1043e-06,\n",
      "         3.0564e-06]], device='cuda:0')}, 13: {'step': tensor(120., device='cuda:0'), 'exp_avg': tensor([ 3.2241e-04,  1.3235e-03,  8.0590e-04,  2.8998e-04, -5.3034e-04,\n",
      "        -2.6166e-04, -5.2717e-04,  9.2513e-05,  8.2768e-05, -1.8925e-04,\n",
      "        -2.2329e-04, -5.1589e-04,  5.6224e-04, -3.9852e-04, -1.1442e-04,\n",
      "         4.1704e-04,  6.7865e-04, -2.3023e-04,  1.5143e-04,  1.5470e-04,\n",
      "         2.7705e-04,  5.6570e-04, -1.3449e-04, -6.2491e-04,  1.7584e-05,\n",
      "        -8.3267e-04,  5.1877e-05,  1.2434e-05, -1.3653e-04,  7.7332e-05,\n",
      "         1.0949e-04, -8.1343e-04, -6.5732e-04, -2.7895e-04, -8.5353e-04,\n",
      "        -2.6187e-04,  2.1051e-05,  1.7843e-04,  4.1412e-05, -1.3203e-03,\n",
      "         5.0633e-04,  3.3650e-04,  2.8578e-05, -3.8406e-04, -2.9889e-04,\n",
      "        -4.0911e-04,  1.8997e-03,  4.7909e-04, -1.4081e-03,  7.3663e-06,\n",
      "         7.6681e-04, -6.4197e-04, -2.7596e-04,  2.4710e-04, -6.0025e-04,\n",
      "        -3.3869e-04, -3.2088e-05, -3.1561e-04, -7.1665e-05,  5.5722e-05,\n",
      "         1.4709e-03, -1.6117e-04, -1.1159e-03, -1.3209e-04, -8.8037e-04,\n",
      "        -3.1096e-04, -6.8601e-04,  3.9494e-04, -7.1589e-04, -7.1480e-05,\n",
      "        -2.9587e-04,  1.4315e-04,  1.5238e-04, -3.9938e-04, -3.9772e-05,\n",
      "        -3.2827e-04, -7.4302e-04, -7.7004e-04,  2.7943e-04, -4.0512e-04,\n",
      "        -1.3018e-04, -1.2185e-04, -1.7771e-05,  7.5318e-05,  1.9074e-04,\n",
      "        -6.4748e-05,  1.4531e-04,  6.8021e-04,  8.9330e-05, -2.4444e-04,\n",
      "        -1.1224e-04,  3.6309e-04,  4.8976e-04,  1.3224e-04, -2.5935e-04,\n",
      "        -4.2301e-04, -8.6654e-04,  3.5540e-04, -9.6607e-05, -3.8246e-04,\n",
      "         7.5982e-04,  2.4499e-04,  2.2919e-04,  1.4103e-03,  6.0038e-04,\n",
      "         1.1647e-04,  2.1549e-04, -8.4236e-04, -4.8415e-04, -2.3214e-05,\n",
      "        -2.1098e-04,  1.5901e-04,  1.3033e-03,  2.3239e-04,  4.9004e-04,\n",
      "         1.6522e-04, -4.0789e-04, -1.8907e-04,  2.8808e-04,  4.8372e-04,\n",
      "         7.6699e-04, -3.6368e-04, -5.5450e-04,  1.3536e-04,  5.0639e-04,\n",
      "        -3.2667e-04, -9.3510e-05, -9.5216e-04], device='cuda:0'), 'exp_avg_sq': tensor([1.4472e-06, 1.8024e-06, 1.9042e-06, 1.0655e-06, 5.3780e-07, 6.7972e-07,\n",
      "        1.0662e-06, 2.0407e-06, 4.6068e-07, 6.2487e-07, 7.9989e-07, 2.4409e-06,\n",
      "        2.8100e-06, 8.9933e-07, 2.3918e-06, 1.4371e-06, 2.1216e-06, 1.3213e-06,\n",
      "        8.6157e-07, 8.0038e-07, 3.1126e-06, 1.9801e-06, 1.2722e-06, 3.4056e-07,\n",
      "        5.0197e-07, 1.9746e-06, 5.2245e-07, 1.0486e-06, 2.3256e-06, 3.0802e-06,\n",
      "        8.1266e-07, 1.7427e-06, 1.1087e-06, 1.6485e-06, 1.5220e-06, 1.7383e-06,\n",
      "        1.5635e-06, 1.4592e-06, 6.3940e-07, 1.4029e-06, 1.5406e-06, 1.1265e-06,\n",
      "        1.3864e-06, 1.8985e-06, 2.0411e-06, 9.1335e-07, 1.9605e-06, 2.4317e-06,\n",
      "        1.2672e-06, 1.6213e-06, 2.4239e-06, 6.4669e-07, 9.2333e-07, 5.6607e-07,\n",
      "        1.2747e-06, 4.5876e-07, 2.2210e-06, 2.3263e-06, 2.1168e-07, 1.7872e-06,\n",
      "        1.9350e-06, 1.3300e-06, 1.3597e-06, 1.4970e-06, 1.1559e-06, 1.4804e-06,\n",
      "        2.1190e-06, 2.6851e-06, 1.0052e-06, 5.7907e-07, 1.6774e-06, 1.2101e-06,\n",
      "        2.1364e-06, 2.0675e-06, 9.9906e-07, 1.3689e-06, 1.3439e-06, 1.4785e-06,\n",
      "        1.7599e-06, 1.6153e-06, 1.1636e-06, 4.1449e-06, 4.6317e-07, 1.3722e-06,\n",
      "        2.0613e-06, 1.4141e-07, 1.3686e-06, 3.4490e-06, 1.1884e-06, 5.8370e-07,\n",
      "        1.1884e-06, 2.7225e-06, 9.5803e-07, 1.4424e-06, 9.0265e-07, 8.3811e-07,\n",
      "        8.8433e-07, 2.2937e-06, 1.0742e-06, 1.2933e-06, 1.2143e-06, 1.1372e-06,\n",
      "        2.6138e-06, 2.6905e-06, 9.6304e-07, 6.4727e-07, 1.6145e-06, 1.3577e-06,\n",
      "        1.7972e-06, 2.0809e-06, 9.3166e-07, 1.4035e-06, 1.0916e-06, 1.0585e-06,\n",
      "        1.3707e-06, 1.6375e-06, 2.0471e-06, 1.5578e-06, 1.9121e-06, 1.3572e-06,\n",
      "        2.0935e-06, 1.5164e-06, 2.0078e-06, 9.6246e-07, 1.9233e-06, 3.3668e-07,\n",
      "        3.8325e-06, 1.3321e-06], device='cuda:0')}, 14: {'step': tensor(120., device='cuda:0'), 'exp_avg': tensor([[-1.3641e-03, -2.2732e-04, -3.4494e-04,  ..., -2.8193e-04,\n",
      "         -1.5284e-04,  1.8452e-04],\n",
      "        [-1.3020e-03, -3.4630e-03, -6.0495e-04,  ...,  1.6584e-05,\n",
      "         -3.9028e-03, -5.5332e-04],\n",
      "        [ 8.9391e-05,  3.6173e-03, -1.9902e-04,  ..., -1.6433e-04,\n",
      "         -9.6383e-04, -8.1938e-04],\n",
      "        ...,\n",
      "        [ 1.6515e-04, -7.7642e-04,  4.1571e-04,  ...,  1.3710e-04,\n",
      "         -1.6866e-03, -9.2012e-04],\n",
      "        [-5.9239e-04,  1.4130e-04,  5.4948e-05,  ..., -1.3753e-03,\n",
      "         -1.3907e-03, -1.5648e-03],\n",
      "        [-6.0852e-04, -1.0685e-03, -2.6449e-04,  ..., -9.5019e-04,\n",
      "          3.1638e-04,  2.2733e-04]], device='cuda:0'), 'exp_avg_sq': tensor([[3.7931e-06, 1.4722e-05, 2.2910e-06,  ..., 3.7001e-07, 1.5861e-05,\n",
      "         2.7188e-06],\n",
      "        [2.2174e-05, 9.8106e-06, 1.4681e-06,  ..., 1.3795e-06, 1.1167e-05,\n",
      "         5.3086e-06],\n",
      "        [4.7589e-06, 3.0293e-06, 1.1030e-06,  ..., 1.5358e-07, 1.1791e-05,\n",
      "         4.4799e-06],\n",
      "        ...,\n",
      "        [3.1599e-06, 1.2558e-06, 7.3174e-07,  ..., 6.1204e-07, 1.3131e-05,\n",
      "         1.0472e-06],\n",
      "        [7.0884e-07, 3.1275e-06, 3.0249e-07,  ..., 2.4869e-07, 1.4606e-06,\n",
      "         3.5464e-07],\n",
      "        [7.3777e-06, 2.5532e-06, 1.4872e-06,  ..., 2.7647e-07, 3.2501e-06,\n",
      "         8.3991e-07]], device='cuda:0')}, 15: {'step': tensor(120., device='cuda:0'), 'exp_avg': tensor([-1.6963e-04, -1.9174e-03, -1.2694e-04,  4.2722e-04,  7.4859e-04,\n",
      "        -1.0642e-03, -5.8923e-04,  8.4969e-04, -1.7838e-04,  5.8692e-04,\n",
      "        -4.9973e-05, -2.1756e-03, -1.3534e-04,  7.6973e-04, -4.4738e-04,\n",
      "         2.3868e-03, -7.5040e-04, -1.7465e-03,  2.2193e-04, -7.4823e-04,\n",
      "         1.0807e-03, -3.4414e-04,  1.0245e-03,  6.1990e-05, -6.2790e-04,\n",
      "         3.0823e-04,  5.9406e-05,  1.2252e-04, -8.1230e-04,  2.5943e-04,\n",
      "        -3.9884e-05, -9.9864e-04, -1.9534e-04,  1.2432e-03,  1.0329e-03,\n",
      "        -3.4437e-04,  1.4015e-03,  7.3148e-04, -3.1856e-06,  4.4879e-04,\n",
      "         4.8652e-05,  4.7354e-04, -2.0705e-04, -2.4935e-03, -2.1441e-03,\n",
      "         1.9812e-03, -2.4226e-04,  5.0905e-04,  2.9724e-03,  1.3823e-03,\n",
      "        -9.6851e-04, -7.6207e-04,  5.9761e-04,  1.3372e-04, -9.5569e-04,\n",
      "         1.4887e-04, -7.1179e-04, -6.9455e-04, -1.2648e-03,  2.6353e-03,\n",
      "         7.2717e-04, -2.5480e-03,  7.0473e-04, -6.0563e-04, -1.3174e-03,\n",
      "        -5.4995e-04,  2.3369e-03, -9.0123e-04,  4.0659e-04,  7.4052e-04,\n",
      "         9.4715e-04, -6.5804e-04, -1.1282e-03,  3.3276e-03,  1.2813e-04,\n",
      "         1.7606e-04, -2.2105e-03,  2.2978e-03,  1.9237e-03,  5.7977e-07,\n",
      "         6.9738e-04,  4.9476e-05,  5.8712e-04, -6.2360e-04,  2.7123e-04,\n",
      "         1.9682e-05,  2.6634e-04, -6.8122e-04, -1.4817e-03,  4.5346e-04,\n",
      "         7.8843e-04, -5.2490e-04,  1.0505e-03,  2.1991e-03,  1.4287e-04,\n",
      "         5.6085e-04,  8.6172e-04, -8.4025e-04,  1.1752e-03, -3.2078e-05,\n",
      "        -6.0990e-04,  4.8413e-04, -6.5584e-04, -4.2236e-04, -1.6360e-03,\n",
      "        -6.9845e-04,  3.1523e-04, -4.8912e-04, -1.5242e-03,  1.2409e-03,\n",
      "         2.0594e-03,  6.7990e-04,  4.6588e-04,  2.5289e-03,  6.3345e-04,\n",
      "         1.5348e-03,  6.0508e-04, -1.5179e-04,  6.6545e-04, -4.6152e-05,\n",
      "         6.7209e-04,  1.6276e-04, -1.6269e-03, -1.3805e-03, -1.6850e-03,\n",
      "        -4.9458e-05, -7.2362e-04, -3.6830e-04], device='cuda:0'), 'exp_avg_sq': tensor([4.7666e-06, 5.5400e-06, 4.1838e-06, 2.9534e-06, 3.5037e-06, 5.9775e-06,\n",
      "        4.3396e-06, 4.5623e-06, 4.4141e-06, 2.7630e-06, 7.6645e-06, 4.4129e-06,\n",
      "        7.9696e-06, 5.2193e-06, 4.8067e-06, 7.3383e-06, 4.6918e-06, 8.3693e-06,\n",
      "        4.6159e-06, 9.3126e-07, 4.2227e-06, 2.4909e-06, 6.4090e-06, 1.7767e-06,\n",
      "        2.8511e-06, 3.8365e-06, 5.4378e-06, 1.8374e-06, 5.2944e-06, 6.0364e-06,\n",
      "        5.0528e-06, 6.0998e-06, 2.8449e-06, 5.9024e-06, 1.6264e-06, 4.4807e-06,\n",
      "        5.1816e-06, 8.3352e-06, 6.6545e-06, 4.2714e-06, 4.9020e-06, 3.6645e-06,\n",
      "        3.8533e-06, 3.0371e-06, 5.1227e-06, 5.8778e-06, 3.1355e-06, 5.3755e-06,\n",
      "        6.3047e-06, 3.8934e-06, 3.1007e-06, 2.7947e-06, 4.6093e-06, 1.2451e-06,\n",
      "        2.2667e-06, 8.5736e-07, 3.6478e-06, 6.2582e-06, 5.0429e-06, 4.3478e-06,\n",
      "        7.0542e-06, 6.1613e-06, 5.7221e-06, 1.3312e-06, 2.3435e-06, 2.9235e-06,\n",
      "        8.4819e-06, 2.5142e-06, 1.1548e-06, 5.1750e-06, 8.5602e-06, 6.8026e-06,\n",
      "        3.8947e-06, 3.8370e-06, 2.9103e-06, 4.9298e-06, 3.2079e-06, 7.1309e-06,\n",
      "        4.7219e-06, 3.9182e-06, 8.2412e-06, 2.6024e-06, 9.8815e-06, 7.3207e-06,\n",
      "        1.1914e-06, 8.2729e-06, 2.1030e-06, 3.6101e-06, 9.4571e-06, 1.7756e-06,\n",
      "        4.4359e-06, 2.6088e-06, 1.0064e-06, 5.2084e-06, 5.7878e-07, 4.1015e-06,\n",
      "        5.0190e-06, 7.2174e-06, 7.1337e-06, 1.6693e-06, 2.3131e-06, 3.8501e-06,\n",
      "        3.0036e-06, 4.5937e-06, 8.9746e-06, 3.9146e-06, 5.2388e-06, 7.7281e-06,\n",
      "        4.9452e-06, 2.9864e-06, 4.6297e-06, 1.0916e-06, 4.5629e-06, 9.4603e-06,\n",
      "        1.6101e-06, 3.4498e-06, 5.5087e-06, 2.4062e-06, 5.7166e-06, 2.1886e-06,\n",
      "        5.3710e-06, 4.6673e-06, 4.8229e-06, 8.6417e-06, 3.5037e-06, 1.6094e-06,\n",
      "        1.1152e-06, 2.1146e-06], device='cuda:0')}, 16: {'step': tensor(120., device='cuda:0'), 'exp_avg': tensor([[ 2.3720e-03,  1.2322e-04, -5.0483e-04,  ..., -1.3281e-04,\n",
      "         -1.7196e-04,  6.7542e-04],\n",
      "        [-3.7562e-03,  2.7670e-03,  6.2870e-04,  ...,  1.2201e-04,\n",
      "         -3.1620e-04, -1.3165e-04],\n",
      "        [ 4.5453e-04,  9.7366e-04,  1.1401e-03,  ...,  1.1438e-04,\n",
      "         -1.9085e-04, -4.3390e-05],\n",
      "        ...,\n",
      "        [-3.3948e-04, -1.7030e-03, -9.0923e-04,  ..., -4.0805e-04,\n",
      "         -5.2104e-04, -4.4305e-04],\n",
      "        [-2.0746e-03, -2.4817e-03, -1.8034e-03,  ..., -4.9984e-04,\n",
      "         -1.6211e-03, -3.4571e-04],\n",
      "        [ 4.9868e-03,  2.3583e-03,  9.0633e-04,  ...,  4.4066e-04,\n",
      "          9.0663e-04,  2.7183e-04]], device='cuda:0'), 'exp_avg_sq': tensor([[6.6531e-06, 1.2092e-05, 2.2676e-06,  ..., 1.3437e-06, 4.9319e-07,\n",
      "         1.4805e-06],\n",
      "        [1.7521e-05, 1.8002e-05, 5.5586e-06,  ..., 1.4085e-06, 1.8060e-06,\n",
      "         2.8308e-06],\n",
      "        [4.2770e-06, 1.9622e-05, 1.5198e-06,  ..., 4.6527e-07, 1.0775e-07,\n",
      "         6.7666e-07],\n",
      "        ...,\n",
      "        [7.2257e-06, 1.1330e-05, 3.7333e-06,  ..., 2.0256e-06, 9.7582e-07,\n",
      "         1.0264e-06],\n",
      "        [9.6562e-06, 1.3123e-05, 5.0109e-06,  ..., 2.1674e-06, 1.9894e-06,\n",
      "         9.5975e-07],\n",
      "        [8.2393e-06, 1.3730e-05, 9.4513e-06,  ..., 1.3616e-06, 1.2776e-06,\n",
      "         1.7766e-06]], device='cuda:0')}, 17: {'step': tensor(120., device='cuda:0'), 'exp_avg': tensor([ 2.7806e-03, -1.6789e-03,  3.3875e-03, -9.0062e-04,  3.0634e-03,\n",
      "         1.6432e-03, -1.0935e-03,  5.1450e-03, -2.8377e-03, -6.1070e-04,\n",
      "        -2.8189e-03,  2.7574e-04, -2.2137e-03,  4.6440e-03,  3.2316e-03,\n",
      "         3.8905e-03,  4.6789e-04,  2.7240e-03, -4.4638e-04, -1.4629e-03,\n",
      "        -4.2016e-03, -3.2955e-03, -4.1829e-03,  1.1490e-03, -1.0908e-03,\n",
      "         3.1472e-03, -9.1664e-04,  2.5806e-03, -3.4818e-03,  3.1855e-03,\n",
      "         3.2578e-03, -5.8222e-04, -1.0286e-03,  9.5284e-04,  1.7954e-03,\n",
      "        -2.7654e-04,  4.0090e-03,  1.3199e-03, -1.8276e-03,  3.1637e-03,\n",
      "        -5.6704e-04,  1.2921e-03, -2.3265e-03,  5.9504e-05,  1.5439e-03,\n",
      "        -9.9378e-03, -2.3419e-03,  7.8808e-03,  7.7128e-03,  1.8969e-03,\n",
      "        -2.1972e-03, -2.8306e-03,  3.8578e-04, -2.8151e-03,  4.5893e-03,\n",
      "        -6.2829e-03,  2.6445e-04, -1.3760e-03, -2.9953e-03, -4.3242e-04,\n",
      "        -2.0753e-03, -6.2081e-03, -3.4837e-03,  6.0660e-03], device='cuda:0'), 'exp_avg_sq': tensor([4.0455e-05, 4.3743e-05, 1.6584e-05, 2.9478e-05, 1.6924e-05, 1.8125e-05,\n",
      "        2.3077e-05, 3.7175e-05, 2.3213e-05, 1.3956e-05, 1.4119e-05, 5.7558e-05,\n",
      "        1.2328e-05, 4.9444e-05, 3.4299e-05, 3.5277e-05, 4.7438e-05, 1.6330e-05,\n",
      "        4.1930e-05, 1.3385e-05, 2.0211e-05, 3.8851e-05, 1.7988e-05, 2.1036e-05,\n",
      "        4.1878e-05, 1.9733e-05, 5.0197e-05, 1.1246e-05, 2.8892e-05, 4.9889e-06,\n",
      "        3.7165e-05, 1.0465e-05, 9.8833e-06, 3.4360e-05, 2.3114e-05, 3.5871e-05,\n",
      "        1.5946e-05, 2.5368e-05, 5.3530e-05, 1.8363e-05, 2.7954e-05, 5.8564e-05,\n",
      "        4.4462e-05, 3.7223e-05, 1.0951e-05, 2.5535e-05, 1.8991e-05, 5.3545e-05,\n",
      "        3.4152e-05, 3.6127e-05, 4.2399e-05, 1.5200e-05, 1.6795e-05, 2.3971e-05,\n",
      "        1.0522e-05, 5.2945e-05, 7.9663e-06, 1.6409e-05, 5.1881e-05, 8.1559e-06,\n",
      "        6.2790e-06, 2.5795e-05, 2.4840e-05, 3.8569e-05], device='cuda:0')}, 18: {'step': tensor(120., device='cuda:0'), 'exp_avg': tensor([[ 7.3816e-04, -2.1864e-03,  1.1384e-03,  ..., -3.6349e-04,\n",
      "          6.3867e-04, -1.0394e-03],\n",
      "        [ 1.2191e-04, -4.0337e-04,  3.0652e-04,  ..., -1.1470e-03,\n",
      "         -1.4679e-03, -1.1185e-03],\n",
      "        [-1.1566e-03, -1.7465e-03, -2.3899e-04,  ...,  5.7155e-04,\n",
      "         -3.3240e-04, -2.1695e-03],\n",
      "        ...,\n",
      "        [-8.2490e-03,  5.1378e-03, -1.3772e-03,  ...,  2.8819e-03,\n",
      "         -2.0518e-03, -6.3785e-03],\n",
      "        [-3.9751e-04, -2.6734e-03, -4.6139e-04,  ..., -4.7719e-05,\n",
      "         -1.6984e-04, -3.4011e-03],\n",
      "        [ 3.0217e-04,  2.9447e-03,  1.0083e-03,  ...,  1.4310e-03,\n",
      "          1.9316e-03,  4.1583e-03]], device='cuda:0'), 'exp_avg_sq': tensor([[2.8649e-06, 1.8091e-05, 7.0604e-06,  ..., 3.0023e-06, 1.0791e-05,\n",
      "         1.7172e-05],\n",
      "        [1.0025e-05, 8.0845e-06, 3.4637e-06,  ..., 5.0761e-06, 6.2736e-06,\n",
      "         1.7124e-05],\n",
      "        [5.7119e-06, 4.3909e-06, 3.4161e-06,  ..., 3.7975e-06, 1.6986e-06,\n",
      "         7.7981e-06],\n",
      "        ...,\n",
      "        [2.0190e-05, 3.3788e-05, 4.1839e-06,  ..., 1.2857e-05, 2.4642e-05,\n",
      "         3.5808e-05],\n",
      "        [1.4145e-05, 3.3014e-05, 4.0501e-06,  ..., 9.4645e-06, 9.2701e-06,\n",
      "         2.5965e-05],\n",
      "        [1.0045e-05, 1.7096e-05, 5.6244e-06,  ..., 6.5121e-06, 6.0548e-06,\n",
      "         1.3294e-05]], device='cuda:0')}, 19: {'step': tensor(120., device='cuda:0'), 'exp_avg': tensor([-3.5155e-06, -2.4290e-03, -4.6794e-04, -1.1157e-03,  1.9373e-03,\n",
      "         2.4296e-03, -6.3334e-04, -2.7246e-03,  2.7620e-03, -3.4392e-03,\n",
      "         1.8842e-03,  1.4431e-03,  6.3793e-03, -5.2827e-03,  2.1196e-03,\n",
      "         4.4349e-03,  2.0788e-03, -1.9903e-03,  4.2592e-03,  1.8636e-03,\n",
      "        -5.9239e-03, -2.9520e-03, -7.1850e-03, -1.4147e-03, -1.7174e-03,\n",
      "         5.7288e-03, -1.7227e-03, -8.5611e-03,  4.2661e-03, -5.6979e-03,\n",
      "        -4.8863e-03, -3.9610e-03,  1.8918e-03, -2.4249e-03, -3.8996e-03,\n",
      "         4.2529e-03,  3.0465e-04,  1.1550e-02, -1.0286e-03, -8.9068e-03,\n",
      "        -8.5492e-04, -2.1497e-03,  8.8130e-03, -2.7418e-03,  3.5702e-03,\n",
      "        -4.9001e-03,  1.5628e-03,  5.9450e-03, -6.1301e-03,  1.5656e-03,\n",
      "         2.2745e-03, -8.3837e-03, -6.2276e-04,  8.1109e-03, -1.8649e-03,\n",
      "        -8.8780e-04, -2.9975e-03, -1.3996e-03,  1.3236e-02,  5.4919e-04,\n",
      "        -5.8295e-03, -5.7660e-03,  4.6383e-04,  7.5794e-03], device='cuda:0'), 'exp_avg_sq': tensor([6.0174e-05, 1.2162e-04, 4.3632e-05, 1.0791e-04, 1.0880e-04, 3.1005e-05,\n",
      "        1.0506e-04, 3.6929e-05, 3.8119e-05, 1.9745e-05, 1.3833e-04, 2.4024e-05,\n",
      "        5.1114e-05, 1.5630e-04, 9.7562e-05, 3.9815e-05, 1.4746e-05, 8.6183e-05,\n",
      "        9.0312e-05, 8.6956e-05, 1.4109e-04, 1.3298e-04, 1.4108e-04, 1.5942e-05,\n",
      "        8.1344e-05, 1.1374e-04, 1.4796e-05, 1.7113e-04, 8.0604e-05, 5.6871e-05,\n",
      "        3.1952e-05, 7.6954e-05, 1.3203e-04, 3.0847e-05, 1.9273e-04, 5.1835e-05,\n",
      "        1.6851e-04, 1.6895e-04, 9.3703e-06, 5.3164e-05, 3.0040e-05, 3.2004e-05,\n",
      "        5.6567e-05, 3.4605e-05, 3.9996e-05, 3.3127e-05, 7.6005e-05, 7.8292e-05,\n",
      "        9.3848e-05, 4.4941e-05, 7.8714e-05, 1.3032e-04, 6.1804e-05, 1.3683e-04,\n",
      "        1.5857e-05, 1.1673e-05, 1.4160e-04, 5.5642e-05, 7.5493e-05, 8.4779e-05,\n",
      "        7.4604e-05, 1.5659e-04, 9.5446e-05, 8.4960e-05], device='cuda:0')}, 20: {'step': tensor(120., device='cuda:0'), 'exp_avg': tensor([[ 2.1851e-04,  3.5899e-03,  2.9872e-03,  ...,  5.4336e-03,\n",
      "          1.8315e-03,  4.1116e-03],\n",
      "        [-1.1740e-03,  9.8345e-05, -4.7945e-05,  ...,  7.3002e-04,\n",
      "         -3.8442e-05, -1.0745e-04],\n",
      "        [ 4.1151e-04,  7.8042e-04,  3.9460e-04,  ...,  4.1378e-03,\n",
      "         -3.8109e-03, -2.6809e-03],\n",
      "        ...,\n",
      "        [ 1.7643e-04,  5.4961e-04, -3.5349e-04,  ...,  2.3147e-03,\n",
      "          7.7704e-04,  2.2428e-03],\n",
      "        [ 6.6039e-05, -4.3542e-03, -4.6852e-06,  ..., -7.4852e-05,\n",
      "         -4.8917e-03, -2.6417e-04],\n",
      "        [-1.9792e-04, -1.6980e-03, -2.1113e-03,  ..., -3.5066e-05,\n",
      "          1.5909e-03, -6.2814e-04]], device='cuda:0'), 'exp_avg_sq': tensor([[5.4678e-06, 7.8593e-06, 4.9192e-06,  ..., 1.6477e-05, 1.2337e-05,\n",
      "         7.0459e-05],\n",
      "        [1.1698e-05, 1.5437e-06, 2.5614e-06,  ..., 2.8675e-05, 3.1857e-06,\n",
      "         4.3159e-05],\n",
      "        [4.0907e-06, 9.3228e-06, 1.1022e-05,  ..., 3.4149e-05, 5.7936e-05,\n",
      "         6.0365e-05],\n",
      "        ...,\n",
      "        [6.6801e-06, 8.6637e-06, 1.0740e-05,  ..., 2.3360e-05, 1.0212e-05,\n",
      "         1.1131e-04],\n",
      "        [1.4196e-06, 7.4973e-06, 6.1581e-07,  ..., 1.6067e-06, 9.3189e-06,\n",
      "         2.0718e-05],\n",
      "        [1.6567e-06, 3.1725e-06, 5.5599e-06,  ..., 1.4903e-05, 4.6297e-06,\n",
      "         8.7225e-06]], device='cuda:0')}, 21: {'step': tensor(120., device='cuda:0'), 'exp_avg': tensor([ 0.0304, -0.0006,  0.0082,  0.0140, -0.0226,  0.0011, -0.0142,  0.0123,\n",
      "        -0.0136, -0.0066, -0.0184,  0.0099,  0.0100, -0.0079,  0.0150,  0.0024,\n",
      "         0.0164,  0.0005,  0.0145,  0.0050,  0.0070,  0.0043, -0.0021,  0.0137,\n",
      "        -0.0095,  0.0172,  0.0048,  0.0234,  0.0072,  0.0093, -0.0055, -0.0048],\n",
      "       device='cuda:0'), 'exp_avg_sq': tensor([6.7310e-04, 2.2447e-04, 6.8642e-04, 5.3174e-04, 3.3258e-04, 5.6692e-04,\n",
      "        6.6268e-04, 1.1469e-03, 2.8167e-04, 1.1314e-04, 4.2861e-04, 5.5635e-05,\n",
      "        1.3139e-03, 4.7890e-04, 8.2034e-04, 7.2889e-04, 3.5494e-04, 1.0702e-04,\n",
      "        4.1282e-04, 2.1831e-04, 6.5949e-04, 1.1973e-04, 1.0280e-04, 6.5916e-04,\n",
      "        1.1739e-04, 9.6631e-04, 1.3788e-03, 7.0022e-04, 1.7069e-04, 2.3476e-04,\n",
      "        6.0080e-05, 1.7289e-04], device='cuda:0')}, 22: {'step': tensor(120., device='cuda:0'), 'exp_avg': tensor([[ 1.4449e-03,  5.4277e-04,  7.7072e-04,  ..., -9.0636e-04,\n",
      "          2.0200e-04, -3.5583e-04],\n",
      "        [-3.1410e-03, -7.2719e-04,  1.5609e-02,  ..., -2.5784e-04,\n",
      "         -1.0668e-03,  2.5938e-04],\n",
      "        [ 2.0124e-03,  3.0763e-04,  5.8460e-04,  ..., -2.6085e-03,\n",
      "          1.7357e-04, -1.0308e-03],\n",
      "        ...,\n",
      "        [-5.9489e-03,  1.2914e-03,  4.8279e-03,  ...,  1.8611e-03,\n",
      "         -8.2735e-04,  6.6102e-05],\n",
      "        [-3.5922e-04, -1.8745e-05,  1.0897e-02,  ..., -1.3127e-03,\n",
      "         -2.7181e-05, -1.0884e-04],\n",
      "        [ 5.6606e-05, -2.4278e-04, -3.6133e-05,  ...,  7.8543e-04,\n",
      "         -9.4420e-05,  5.7692e-04]], device='cuda:0'), 'exp_avg_sq': tensor([[1.3278e-05, 4.4471e-06, 2.6598e-05,  ..., 6.0650e-06, 9.5495e-07,\n",
      "         5.3800e-07],\n",
      "        [3.5014e-05, 8.3476e-06, 1.0082e-04,  ..., 2.8454e-05, 2.3762e-06,\n",
      "         2.5794e-06],\n",
      "        [1.8618e-05, 1.0172e-05, 4.3135e-05,  ..., 1.1400e-05, 3.7473e-07,\n",
      "         3.4357e-06],\n",
      "        ...,\n",
      "        [1.7919e-05, 2.2328e-06, 4.5566e-05,  ..., 8.2865e-06, 1.0905e-06,\n",
      "         7.0827e-07],\n",
      "        [3.4138e-06, 3.9398e-07, 9.0700e-05,  ..., 1.0276e-05, 1.0404e-07,\n",
      "         2.4687e-07],\n",
      "        [1.8738e-05, 3.3207e-06, 4.4225e-05,  ..., 8.1667e-06, 1.5224e-06,\n",
      "         8.4422e-07]], device='cuda:0')}, 23: {'step': tensor(120., device='cuda:0'), 'exp_avg': tensor([ 0.0142,  0.0567,  0.0157,  0.0012,  0.0029,  0.0115,  0.0770,  0.0069,\n",
      "        -0.0234, -0.0149, -0.0002,  0.0770,  0.0714, -0.0035, -0.0021,  0.0035,\n",
      "         0.0101, -0.0004,  0.0245,  0.0091,  0.0167, -0.0002,  0.0080, -0.0004,\n",
      "        -0.0003,  0.0254,  0.0004, -0.0017,  0.0024,  0.0050,  0.0076,  0.0190],\n",
      "       device='cuda:0'), 'exp_avg_sq': tensor([8.3802e-04, 2.3588e-03, 1.7078e-03, 2.1289e-04, 1.3470e-03, 2.0787e-03,\n",
      "        5.6590e-03, 9.2905e-04, 7.4900e-04, 7.2270e-04, 1.2036e-04, 1.0040e-03,\n",
      "        6.2592e-03, 9.3242e-06, 4.0654e-05, 3.1256e-04, 1.2726e-03, 5.4321e-06,\n",
      "        4.1744e-03, 1.4506e-03, 2.3072e-03, 1.3885e-03, 5.3877e-04, 1.4608e-05,\n",
      "        4.2822e-04, 4.6187e-03, 1.9301e-03, 5.9587e-05, 2.5040e-04, 9.2987e-04,\n",
      "        1.0476e-03, 1.8969e-03], device='cuda:0')}, 24: {'step': tensor(120., device='cuda:0'), 'exp_avg': tensor([[[-7.0439e-03],\n",
      "         [-2.1382e-03],\n",
      "         [-3.0037e-03],\n",
      "         ...,\n",
      "         [ 3.6589e-03],\n",
      "         [-9.6157e-04],\n",
      "         [ 1.1149e-03]],\n",
      "\n",
      "        [[-6.9211e-03],\n",
      "         [-1.0820e-03],\n",
      "         [-1.4336e-03],\n",
      "         ...,\n",
      "         [ 4.3163e-03],\n",
      "         [-3.9653e-04],\n",
      "         [ 9.1589e-04]],\n",
      "\n",
      "        [[ 2.1862e-02],\n",
      "         [ 4.4032e-03],\n",
      "         [ 6.1013e-03],\n",
      "         ...,\n",
      "         [ 7.9562e-03],\n",
      "         [ 4.0414e-03],\n",
      "         [ 6.0957e-03]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 2.5656e-05],\n",
      "         [ 1.2402e-05],\n",
      "         [ 8.7432e-06],\n",
      "         ...,\n",
      "         [ 4.1298e-05],\n",
      "         [ 7.5443e-05],\n",
      "         [ 3.1939e-06]],\n",
      "\n",
      "        [[ 4.0265e-03],\n",
      "         [ 2.5958e-03],\n",
      "         [ 1.1914e-03],\n",
      "         ...,\n",
      "         [-3.3150e-04],\n",
      "         [ 5.7549e-04],\n",
      "         [ 1.7298e-04]],\n",
      "\n",
      "        [[-3.8602e-02],\n",
      "         [-6.2682e-03],\n",
      "         [-8.3391e-03],\n",
      "         ...,\n",
      "         [-1.1081e-02],\n",
      "         [-6.4996e-03],\n",
      "         [-8.1717e-03]]], device='cuda:0'), 'exp_avg_sq': tensor([[[4.1093e-04],\n",
      "         [2.1478e-05],\n",
      "         [3.4332e-05],\n",
      "         ...,\n",
      "         [2.6107e-04],\n",
      "         [2.6201e-05],\n",
      "         [1.6140e-05]],\n",
      "\n",
      "        [[6.1934e-04],\n",
      "         [3.3117e-05],\n",
      "         [4.2508e-05],\n",
      "         ...,\n",
      "         [3.3512e-04],\n",
      "         [3.4744e-05],\n",
      "         [5.5826e-05]],\n",
      "\n",
      "        [[8.8840e-04],\n",
      "         [4.1973e-05],\n",
      "         [6.5465e-05],\n",
      "         ...,\n",
      "         [4.6086e-04],\n",
      "         [4.2538e-05],\n",
      "         [5.9459e-05]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[2.6754e-09],\n",
      "         [6.1253e-11],\n",
      "         [9.4427e-10],\n",
      "         ...,\n",
      "         [7.0574e-09],\n",
      "         [2.3311e-08],\n",
      "         [1.1544e-10]],\n",
      "\n",
      "        [[8.6045e-06],\n",
      "         [1.0201e-06],\n",
      "         [1.5399e-06],\n",
      "         ...,\n",
      "         [3.6399e-06],\n",
      "         [8.6116e-07],\n",
      "         [7.6748e-07]],\n",
      "\n",
      "        [[5.1374e-04],\n",
      "         [2.3105e-05],\n",
      "         [4.0703e-05],\n",
      "         ...,\n",
      "         [2.1627e-04],\n",
      "         [1.4601e-05],\n",
      "         [6.3878e-05]]], device='cuda:0')}, 25: {'step': tensor(120., device='cuda:0'), 'exp_avg': tensor([ 1.0230e-02,  5.5275e-03,  8.3075e-03, -7.5874e-03,  3.0699e-04,\n",
      "         2.1452e-04,  3.3554e-03, -1.3191e-02, -3.2129e-04, -4.3665e-03,\n",
      "        -1.7359e-04, -1.2505e-02,  4.8562e-04, -1.9734e-04, -4.5273e-04,\n",
      "        -4.0368e-03,  1.5194e-03,  6.5415e-03,  1.8998e-03, -6.4922e-05,\n",
      "        -4.9788e-03,  2.2092e-03,  4.1296e-03, -1.2146e-03, -1.1318e-02,\n",
      "         1.0463e-02, -6.2988e-03,  4.3291e-03,  7.6471e-04, -1.4734e-03,\n",
      "         6.9144e-03,  2.5822e-03, -1.2478e-02,  4.0917e-03, -1.1756e-05,\n",
      "         5.9766e-03,  4.2889e-03, -1.2699e-04, -1.9490e-06,  2.3959e-03,\n",
      "         2.7310e-04,  1.3503e-02, -5.8050e-03,  2.2665e-05, -1.6668e-02,\n",
      "        -8.5917e-03, -1.3291e-03, -9.6786e-03,  1.5055e-03, -1.3327e-02,\n",
      "        -5.4796e-03, -4.0751e-03,  1.3110e-02, -3.5170e-03,  3.1984e-04,\n",
      "        -3.0261e-04,  1.5774e-02,  2.5056e-04, -8.8401e-03,  6.3432e-04,\n",
      "         2.1226e-03,  2.6803e-04, -2.5645e-03, -1.1910e-02], device='cuda:0'), 'exp_avg_sq': tensor([2.2618e-04, 2.7398e-04, 4.8725e-04, 7.1539e-05, 2.1247e-06, 1.8099e-06,\n",
      "        2.6061e-04, 4.6779e-05, 1.8092e-04, 2.9730e-04, 1.7758e-06, 3.8305e-04,\n",
      "        2.6997e-05, 2.1834e-07, 5.1308e-05, 3.4601e-04, 8.5008e-06, 4.2391e-04,\n",
      "        2.7859e-04, 7.9719e-08, 3.4159e-04, 2.0084e-04, 3.1048e-04, 3.6834e-06,\n",
      "        2.4680e-04, 5.5019e-04, 3.3033e-04, 1.2273e-04, 4.7137e-05, 8.7819e-05,\n",
      "        7.5298e-05, 5.6273e-04, 3.9669e-04, 2.8485e-05, 6.1451e-06, 4.2771e-04,\n",
      "        7.0852e-05, 3.0203e-05, 3.1315e-11, 2.7976e-04, 1.9016e-06, 3.8214e-04,\n",
      "        2.2202e-04, 9.5051e-08, 2.8599e-04, 2.1906e-04, 1.0983e-04, 2.1184e-04,\n",
      "        1.1845e-04, 1.3899e-04, 1.0278e-04, 1.8217e-04, 2.4209e-04, 6.4233e-04,\n",
      "        7.6699e-06, 4.6936e-06, 1.1080e-03, 1.3942e-06, 5.4183e-04, 4.1896e-06,\n",
      "        3.3731e-04, 2.1400e-07, 2.4189e-06, 2.8397e-04], device='cuda:0')}, 26: {'step': tensor(120., device='cuda:0'), 'exp_avg': tensor([[ 1.2721e-04, -1.1031e-04, -4.4139e-04,  ..., -2.7580e-06,\n",
      "          7.1345e-05,  8.3180e-06],\n",
      "        [-4.3954e-05,  1.1451e-04,  3.8547e-04,  ...,  1.7303e-06,\n",
      "         -3.6583e-05,  5.6319e-05],\n",
      "        [ 1.2717e-05, -5.5845e-05, -1.5941e-04,  ...,  8.9673e-07,\n",
      "          1.8414e-05, -1.1344e-05],\n",
      "        ...,\n",
      "        [-2.9929e-05,  7.7152e-05,  2.5748e-04,  ...,  7.7811e-06,\n",
      "         -2.3102e-05,  6.7469e-05],\n",
      "        [ 1.0582e-04, -2.0689e-04, -6.9517e-04,  ...,  3.4679e-06,\n",
      "          8.1209e-05, -8.2064e-05],\n",
      "        [ 9.1306e-05, -1.4679e-04, -5.2213e-04,  ...,  4.0067e-06,\n",
      "          6.4331e-05, -5.2383e-05]], device='cuda:0'), 'exp_avg_sq': tensor([[5.4838e-08, 4.4927e-08, 2.4215e-07,  ..., 4.5902e-12, 5.8781e-10,\n",
      "         7.7225e-08],\n",
      "        [3.6669e-08, 2.9309e-08, 1.8087e-07,  ..., 1.9714e-12, 2.2860e-10,\n",
      "         3.7079e-08],\n",
      "        [5.9766e-09, 4.9460e-09, 2.9193e-08,  ..., 3.0736e-13, 4.4876e-11,\n",
      "         6.1502e-09],\n",
      "        ...,\n",
      "        [1.5848e-08, 1.2382e-08, 7.9997e-08,  ..., 8.8933e-12, 9.4319e-11,\n",
      "         1.6336e-08],\n",
      "        [1.2840e-07, 1.0418e-07, 6.4850e-07,  ..., 5.7650e-12, 8.0797e-10,\n",
      "         1.2125e-07],\n",
      "        [7.3082e-08, 6.1710e-08, 3.5425e-07,  ..., 4.4553e-12, 5.3887e-10,\n",
      "         9.2784e-08]], device='cuda:0')}, 27: {'step': tensor(120., device='cuda:0'), 'exp_avg': tensor([ 1.7119e-04,  2.5948e-05,  7.0261e-06, -1.6752e-05, -9.9125e-06,\n",
      "         5.1622e-06,  6.0155e-06, -3.9237e-05,  2.0825e-05, -4.3375e-05,\n",
      "         6.6385e-05, -2.2022e-05,  3.3631e-06,  5.4380e-06, -9.4296e-06,\n",
      "        -9.5555e-07, -3.3511e-05, -3.0942e-06,  1.8833e-05,  6.7121e-05,\n",
      "        -9.0792e-05, -4.1508e-06,  4.1854e-05, -4.7395e-07, -3.9360e-06,\n",
      "        -1.1594e-05, -1.2116e-05,  8.4733e-06,  4.0900e-05, -2.6712e-06,\n",
      "         2.6946e-05, -1.5198e-04, -1.0405e-05, -2.0280e-05,  5.1748e-05,\n",
      "        -9.2184e-05, -1.1137e-05,  5.0953e-05,  2.6948e-05, -2.1449e-05,\n",
      "         5.1023e-06, -2.1560e-05,  8.6720e-06, -1.3123e-05, -1.1261e-05,\n",
      "         9.0846e-05, -1.2307e-06,  5.2503e-05,  6.0809e-07,  1.7617e-04,\n",
      "         2.4768e-05, -3.8972e-05,  2.9573e-05, -5.4438e-05, -5.3784e-05,\n",
      "         6.8758e-05,  6.9953e-07,  7.2527e-06,  3.4977e-05, -2.2189e-05,\n",
      "        -4.0525e-05,  3.9950e-05, -1.5579e-05,  4.5469e-05], device='cuda:0'), 'exp_avg_sq': tensor([1.7171e-08, 9.0077e-11, 2.1321e-11, 2.1839e-10, 2.7807e-10, 1.5258e-08,\n",
      "        3.5699e-10, 2.4810e-09, 3.9523e-10, 7.2209e-10, 7.8234e-09, 1.9040e-09,\n",
      "        1.2564e-10, 1.9454e-10, 1.7796e-11, 1.8347e-12, 9.5741e-10, 7.0598e-10,\n",
      "        3.0133e-10, 1.1813e-08, 2.3964e-09, 3.2093e-11, 6.6311e-09, 1.7552e-11,\n",
      "        4.7896e-11, 4.9472e-09, 4.3106e-10, 1.7443e-11, 4.5820e-10, 1.9334e-08,\n",
      "        5.9933e-10, 3.5181e-08, 2.6011e-09, 2.9352e-09, 1.0389e-09, 7.1163e-09,\n",
      "        2.6344e-10, 1.7640e-08, 1.1790e-09, 5.7694e-09, 5.2888e-12, 9.4448e-10,\n",
      "        5.9670e-11, 1.4350e-09, 1.8853e-10, 1.4874e-08, 3.1899e-10, 7.7343e-09,\n",
      "        1.0368e-09, 1.7083e-08, 1.2853e-09, 3.1864e-09, 4.5460e-10, 2.3756e-09,\n",
      "        1.7036e-09, 3.3149e-09, 3.8987e-10, 1.0217e-11, 6.5127e-09, 3.8608e-10,\n",
      "        1.2231e-09, 4.2700e-10, 5.2982e-09, 4.6898e-09], device='cuda:0')}, 28: {'step': tensor(120., device='cuda:0'), 'exp_avg': tensor([[ 2.9979e-03,  1.3189e-03,  1.6569e-03,  6.8144e-04,  3.3814e-03,\n",
      "         -2.1910e-04, -4.1498e-04, -1.7849e-03, -4.0070e-04,  2.7093e-03,\n",
      "          9.7456e-04,  7.2191e-04, -1.1709e-04,  2.9819e-03, -2.5981e-03,\n",
      "          5.9186e-04, -1.1881e-03, -6.9446e-04,  1.7509e-03, -6.4414e-04,\n",
      "          2.3960e-03, -9.9944e-04,  6.7478e-04,  1.8247e-03, -1.7687e-04,\n",
      "         -1.0402e-04, -1.5917e-04,  2.4708e-04, -2.1331e-03, -1.5745e-04,\n",
      "          3.6969e-04, -1.6239e-03,  8.0320e-04, -1.0226e-04, -2.0759e-03,\n",
      "          2.4499e-03, -4.8571e-04, -1.1893e-03, -6.1635e-04, -1.8792e-03,\n",
      "         -1.1418e-03,  1.0299e-03, -1.1362e-03, -5.3578e-04, -1.4508e-03,\n",
      "         -1.4482e-03,  3.2083e-04, -1.0523e-03,  8.7705e-05,  2.1275e-03,\n",
      "          7.7761e-04,  1.3145e-03,  2.3502e-03,  1.4240e-03, -2.1980e-03,\n",
      "         -1.4740e-03, -3.9097e-04,  1.5768e-03, -2.1898e-04, -2.5728e-04,\n",
      "          1.3930e-03, -2.4163e-03, -1.0358e-04, -1.0028e-03]], device='cuda:0'), 'exp_avg_sq': tensor([[4.9326e-06, 2.1373e-06, 2.5969e-06, 2.4317e-06, 4.7521e-06, 3.8385e-06,\n",
      "         1.9661e-06, 3.4610e-06, 2.5199e-06, 2.3354e-06, 6.1780e-06, 9.4084e-07,\n",
      "         2.5106e-06, 3.0121e-06, 2.8655e-06, 8.9059e-06, 3.7293e-06, 3.0234e-06,\n",
      "         2.4985e-06, 4.5512e-06, 2.5803e-06, 1.2688e-06, 1.8054e-06, 6.9945e-06,\n",
      "         1.5389e-06, 1.9374e-06, 3.1698e-06, 2.2436e-06, 4.0319e-06, 3.0590e-06,\n",
      "         1.8085e-06, 5.1547e-06, 5.5300e-06, 2.4158e-06, 3.7828e-06, 3.2317e-06,\n",
      "         4.4762e-06, 6.4758e-06, 2.9448e-06, 5.0983e-06, 2.1495e-06, 5.5567e-06,\n",
      "         3.7857e-06, 1.5837e-06, 2.2733e-06, 6.3233e-06, 1.6340e-06, 2.2984e-06,\n",
      "         2.7475e-06, 2.9657e-06, 5.0373e-06, 7.4018e-06, 4.2612e-06, 3.3410e-06,\n",
      "         4.2664e-06, 3.3521e-06, 2.9940e-06, 1.6892e-06, 1.9308e-06, 1.5831e-06,\n",
      "         1.8647e-06, 3.6308e-06, 3.0995e-06, 7.9672e-06]], device='cuda:0')}, 29: {'step': tensor(120., device='cuda:0'), 'exp_avg': tensor([-7.2165e-06], device='cuda:0'), 'exp_avg_sq': tensor([6.7198e-12], device='cuda:0')}, 30: {'step': tensor(120., device='cuda:0'), 'exp_avg': tensor([[-1.0546e-03, -3.1494e-04,  9.6067e-03,  ...,  1.8387e-05,\n",
      "         -1.6126e-03,  7.4269e-03],\n",
      "        [-1.9192e-03,  1.4275e-04,  4.6666e-03,  ..., -9.2666e-06,\n",
      "         -1.8702e-04,  7.9754e-03],\n",
      "        [-6.2012e-03,  8.1348e-03,  1.7509e-02,  ...,  1.0560e-05,\n",
      "         -2.3855e-03, -4.1517e-03],\n",
      "        ...,\n",
      "        [ 1.2125e-04, -4.4043e-06,  1.9872e-06,  ..., -9.1060e-06,\n",
      "          4.9624e-06,  1.0289e-04],\n",
      "        [ 3.9313e-03,  2.3824e-03,  1.6607e-02,  ...,  2.1627e-05,\n",
      "         -1.8735e-03, -4.3396e-03],\n",
      "        [ 4.0284e-03,  3.0455e-03,  4.0204e-04,  ..., -7.8291e-06,\n",
      "         -1.3410e-05,  5.9654e-03]], device='cuda:0'), 'exp_avg_sq': tensor([[4.4581e-04, 2.9821e-04, 8.8623e-05,  ..., 2.4383e-09, 1.4306e-07,\n",
      "         3.4234e-04],\n",
      "        [9.2685e-05, 1.1948e-04, 5.1331e-05,  ..., 1.8545e-10, 7.5193e-08,\n",
      "         2.7457e-04],\n",
      "        [5.0016e-04, 4.1555e-04, 1.3024e-04,  ..., 4.3571e-09, 6.5111e-07,\n",
      "         7.8719e-04],\n",
      "        ...,\n",
      "        [3.3104e-07, 2.6955e-12, 1.5291e-09,  ..., 1.0406e-11, 1.7204e-10,\n",
      "         1.0336e-06],\n",
      "        [5.5444e-04, 3.8307e-04, 1.3511e-04,  ..., 4.4279e-09, 2.6287e-07,\n",
      "         4.2675e-04],\n",
      "        [1.5207e-04, 1.6758e-04, 2.6862e-05,  ..., 2.8524e-09, 4.6196e-08,\n",
      "         3.2098e-04]], device='cuda:0')}, 31: {'step': tensor(120., device='cuda:0'), 'exp_avg': tensor([ 2.2461e-04,  1.5303e-02, -1.8080e-02,  4.5101e-03, -1.5890e-06,\n",
      "        -7.8549e-06, -6.8843e-06,  3.8799e-04, -3.3398e-02, -1.0683e-02,\n",
      "        -5.6976e-04, -6.3668e-05,  4.9771e-03, -2.2414e-10,  1.7324e-02,\n",
      "         1.0918e-02, -2.4120e-02,  1.9779e-03,  7.6054e-03,  4.0637e-02,\n",
      "        -6.4602e-03, -1.9815e-02, -6.8617e-06, -9.5563e-04,  6.6809e-03,\n",
      "        -1.1257e-05,  9.7047e-04,  3.9078e-06, -8.8035e-03, -2.4433e-06,\n",
      "         1.7819e-02, -5.3286e-03, -4.5674e-04,  2.5377e-03,  1.2509e-03,\n",
      "         4.5307e-03,  8.5563e-03,  7.9581e-06, -6.4158e-03,  2.1748e-03,\n",
      "         4.7450e-02, -3.1885e-02,  2.2469e-03,  9.1632e-04, -7.1085e-06,\n",
      "        -7.8449e-06, -5.6937e-02,  1.1994e-01,  9.6348e-03, -3.2326e-02,\n",
      "        -3.2941e-06,  1.6620e-06, -1.7039e-02, -7.9805e-03,  7.8779e-05,\n",
      "        -1.7117e-06,  2.2726e-02,  9.0004e-03, -5.2037e-04,  5.3764e-03,\n",
      "        -2.4134e-03,  2.1359e-04, -2.3329e-02,  9.0552e-03], device='cuda:0'), 'exp_avg_sq': tensor([3.1507e-03, 2.3238e-03, 4.6368e-03, 1.9166e-04, 4.7288e-13, 7.8659e-12,\n",
      "        6.1393e-12, 1.3318e-05, 2.0328e-03, 1.9577e-03, 1.5711e-03, 8.8511e-06,\n",
      "        2.3451e-03, 2.9621e-16, 1.8689e-04, 1.7558e-02, 4.1275e-03, 2.7898e-06,\n",
      "        2.6019e-03, 2.5898e-03, 3.3358e-03, 2.0282e-03, 6.1016e-12, 3.3122e-03,\n",
      "        1.3461e-03, 7.0999e-05, 2.0473e-03, 2.1733e-12, 3.9710e-03, 9.5776e-13,\n",
      "        1.1565e-03, 4.0660e-03, 6.5300e-03, 7.8334e-03, 1.5746e-04, 1.5656e-03,\n",
      "        1.8126e-03, 8.0621e-12, 7.2890e-03, 2.8350e-03, 4.6460e-03, 3.3818e-04,\n",
      "        1.8715e-03, 6.3365e-05, 4.7481e-07, 7.8470e-12, 1.0572e-02, 5.0979e-03,\n",
      "        1.6663e-03, 5.7995e-03, 9.5820e-06, 1.0532e-04, 2.2649e-03, 2.2651e-03,\n",
      "        1.3736e-03, 5.3238e-13, 2.1663e-03, 1.8321e-03, 1.7374e-03, 2.2327e-03,\n",
      "        2.6170e-03, 5.4759e-06, 3.8202e-03, 3.0356e-03], device='cuda:0')}, 32: {'step': tensor(120., device='cuda:0'), 'exp_avg': tensor([[ 3.1905e-06,  1.1195e-05, -7.9809e-06,  ..., -1.0669e-05,\n",
      "          1.6319e-08,  4.0501e-06],\n",
      "        [-1.1966e-03,  1.7622e-03,  3.2175e-03,  ..., -3.8248e-06,\n",
      "          1.3367e-03, -7.4182e-05],\n",
      "        [-2.0413e-03,  2.3006e-03, -1.7741e-03,  ...,  4.3898e-06,\n",
      "         -1.4906e-03,  1.1579e-03],\n",
      "        ...,\n",
      "        [-2.7086e-03,  8.6577e-04,  7.6471e-03,  ...,  1.2843e-05,\n",
      "          1.0269e-02, -3.1908e-03],\n",
      "        [-1.6756e-05, -1.4412e-05, -1.7296e-05,  ...,  9.8420e-07,\n",
      "         -8.3318e-05, -1.2190e-05],\n",
      "        [ 3.5648e-03, -2.4719e-04, -1.9485e-02,  ..., -3.5989e-06,\n",
      "         -9.7085e-03,  7.5778e-03]], device='cuda:0'), 'exp_avg_sq': tensor([[1.5173e-12, 1.5437e-11, 8.1056e-12,  ..., 1.4077e-11, 8.8999e-15,\n",
      "         2.3172e-12],\n",
      "        [4.1598e-05, 4.4523e-05, 5.9255e-05,  ..., 1.0845e-10, 2.9076e-04,\n",
      "         4.4770e-05],\n",
      "        [7.3499e-05, 7.5915e-05, 1.0581e-04,  ..., 8.6421e-11, 7.1219e-04,\n",
      "         1.1280e-04],\n",
      "        ...,\n",
      "        [6.2693e-05, 3.0222e-05, 6.6257e-05,  ..., 4.5095e-10, 2.7691e-04,\n",
      "         4.5791e-05],\n",
      "        [8.8104e-05, 2.3994e-05, 3.1749e-04,  ..., 2.2952e-13, 1.1398e-03,\n",
      "         1.3270e-05],\n",
      "        [4.3394e-04, 2.3352e-04, 5.8154e-04,  ..., 1.6849e-09, 4.9972e-03,\n",
      "         3.5865e-04]], device='cuda:0')}, 33: {'step': tensor(120., device='cuda:0'), 'exp_avg': tensor([-8.4532e-06, -4.3675e-03, -1.4731e-02,  4.5880e-03,  1.7925e-03,\n",
      "        -5.3577e-04, -5.1864e-06, -1.5273e-06, -1.0260e-03,  1.0233e-04,\n",
      "         5.6033e-04, -1.5808e-03,  4.9907e-03, -6.7238e-04,  1.1232e-03,\n",
      "         6.0613e-04, -9.5446e-06,  3.1381e-03,  2.7469e-03, -8.0297e-03,\n",
      "         5.6253e-02,  1.2969e-01, -4.3838e-03,  3.2992e-04, -4.5513e-03,\n",
      "        -7.1796e-07, -7.7154e-02, -4.8218e-02,  1.5044e-05,  4.4952e-03,\n",
      "        -3.8564e-04, -3.0623e-02], device='cuda:0'), 'exp_avg_sq': tensor([9.0366e-12, 5.1555e-03, 1.4481e-02, 4.0002e-03, 2.6198e-02, 3.1189e-04,\n",
      "        3.6312e-12, 4.1266e-05, 1.3343e-03, 2.8477e-03, 1.1529e-05, 5.8397e-04,\n",
      "        2.7569e-02, 6.0385e-02, 1.8808e-03, 1.0495e-01, 1.1381e-11, 3.2345e-03,\n",
      "        8.5615e-04, 4.8659e-03, 1.2565e-02, 9.4005e-03, 6.9567e-03, 1.6343e-03,\n",
      "        2.8300e-03, 1.4860e-13, 6.3470e-02, 8.8862e-02, 3.9132e-04, 3.3655e-03,\n",
      "        2.2843e-02, 1.0202e-01], device='cuda:0')}, 34: {'step': tensor(120., device='cuda:0'), 'exp_avg': tensor([[ 1.1350e-05, -1.0457e-05,  1.3410e-05, -1.1461e-05, -7.5695e-07,\n",
      "          3.0320e-06, -1.0026e-05,  2.9966e-06, -1.2754e-05,  1.3064e-05,\n",
      "          8.5047e-06,  6.4161e-06,  1.1820e-05,  1.0049e-05,  1.1186e-05,\n",
      "         -1.5850e-05, -1.0287e-05,  1.3660e-05,  3.2727e-06, -8.9788e-06,\n",
      "          1.5179e-05, -1.6499e-05, -1.5805e-05, -8.3513e-06, -4.6432e-06,\n",
      "         -1.3420e-05, -1.1192e-05,  1.4120e-05, -1.0837e-05, -1.2724e-05,\n",
      "         -1.1371e-05,  6.5903e-07],\n",
      "        [ 2.6947e-06,  7.0885e-06,  1.5183e-05, -6.6249e-06,  2.0576e-06,\n",
      "          1.1541e-05,  1.0950e-05,  2.5010e-06,  1.1294e-05,  1.5724e-05,\n",
      "          7.6259e-06, -1.4612e-05, -3.7406e-07, -1.0965e-05, -1.1292e-05,\n",
      "          3.2573e-06,  5.5930e-06,  7.6819e-07, -1.0511e-05, -6.5907e-06,\n",
      "          1.4200e-05,  6.4122e-06, -4.0708e-06, -1.5393e-05, -7.2050e-06,\n",
      "          9.6369e-06,  1.0399e-05, -8.8138e-06, -1.3783e-05,  4.1611e-06,\n",
      "         -8.1326e-06,  1.4730e-05],\n",
      "        [-6.7409e-06, -4.6879e-02, -2.5797e-02, -2.5842e-02,  1.0543e-03,\n",
      "          2.8209e-02,  6.6022e-06, -7.6211e-06,  3.1187e-02,  1.3333e-02,\n",
      "          1.5921e-05, -2.1060e-02, -3.2105e-02, -2.8623e-05, -6.1020e-05,\n",
      "         -1.4554e-02, -1.3027e-05,  1.9888e-02, -2.0828e-02, -6.9835e-02,\n",
      "         -6.3411e-03, -4.8200e-04, -1.6859e-02,  4.5025e-06, -1.2061e-03,\n",
      "         -3.8443e-08, -3.5764e-03, -2.3329e-02, -1.6013e-05, -2.1606e-02,\n",
      "         -1.1077e-05, -1.2471e-02],\n",
      "        [-1.5436e-05, -2.0842e-02, -1.3030e-02, -1.2020e-02,  4.9418e-05,\n",
      "          5.9579e-03, -4.3331e-06, -3.5606e-06,  1.9155e-02,  1.0563e-02,\n",
      "          4.5688e-06, -1.0158e-02, -2.6228e-02, -1.0588e-05, -3.5941e-05,\n",
      "         -1.2280e-02, -7.0817e-06,  9.8106e-03, -4.5271e-03, -3.8398e-02,\n",
      "         -3.2944e-03, -2.8315e-04, -1.5492e-02,  2.7071e-06, -1.1135e-03,\n",
      "          7.9000e-06, -4.9471e-03, -1.8048e-02,  1.3350e-05, -1.5881e-02,\n",
      "         -3.2492e-05, -1.4277e-03],\n",
      "        [ 2.5730e-06,  6.4083e-03,  4.5741e-03,  3.8956e-03,  3.8754e-04,\n",
      "          3.4934e-03, -3.4275e-06,  5.4022e-06, -8.5970e-03, -5.7968e-03,\n",
      "          9.4229e-06,  3.4257e-03,  1.5606e-02, -5.5702e-07, -8.8685e-06,\n",
      "          7.7323e-03,  1.4403e-05, -3.0115e-03, -1.6395e-03,  1.5340e-02,\n",
      "          1.2519e-03,  1.1510e-04,  9.8934e-03, -5.8419e-06,  9.3088e-04,\n",
      "          5.2726e-06,  3.8167e-03,  1.0224e-02,  1.0552e-05,  8.6881e-03,\n",
      "          7.2088e-06, -2.3776e-03],\n",
      "        [-7.3669e-06,  4.5372e-06, -4.2308e-06,  7.2330e-07, -1.2493e-05,\n",
      "          7.4503e-06,  1.4719e-05, -9.7837e-06, -4.0089e-06, -7.8302e-06,\n",
      "          1.3644e-05, -8.9652e-06,  1.1852e-05,  8.5591e-06, -6.0452e-06,\n",
      "         -1.1444e-05, -6.1851e-08, -1.5470e-05, -1.3210e-05,  6.6299e-06,\n",
      "         -1.5145e-05,  6.1141e-06,  5.8371e-06,  7.5363e-06, -1.4200e-06,\n",
      "          3.4209e-06,  6.7067e-06, -8.7743e-06,  8.8794e-06, -2.1003e-06,\n",
      "          7.8671e-06, -6.0008e-06],\n",
      "        [-1.9402e-06,  2.5803e-02,  1.4564e-02,  1.4347e-02, -4.9473e-04,\n",
      "         -1.3897e-02, -7.3619e-06, -6.6656e-06, -1.8529e-02, -8.4761e-03,\n",
      "          6.6775e-06,  1.1757e-02,  2.0661e-02,  1.5350e-05,  3.3845e-05,\n",
      "          9.4735e-03, -1.4670e-05, -1.1157e-02,  1.0241e-02,  4.0250e-02,\n",
      "          3.6170e-03,  2.8756e-04,  1.1254e-02, -1.1233e-05,  7.7256e-04,\n",
      "         -1.4344e-05,  2.8002e-03,  1.4788e-02,  9.0446e-06,  1.3479e-02,\n",
      "          2.4618e-06,  5.8214e-03],\n",
      "        [-2.9669e-10, -5.8004e-03, -1.9008e-03, -2.7345e-03,  7.7609e-04,\n",
      "          1.2050e-02, -8.1102e-06, -1.2598e-05, -1.3120e-03, -3.1399e-03,\n",
      "          1.6780e-05, -1.8944e-03,  9.1353e-03,  1.3495e-05,  3.0971e-06,\n",
      "          4.8771e-03,  1.3791e-05,  2.0305e-03, -7.8948e-03, -1.6766e-03,\n",
      "         -3.2670e-04, -6.3594e-06,  6.8346e-03,  8.0575e-06,  7.5122e-04,\n",
      "         -1.5868e-05,  3.4312e-03,  5.3980e-03,  1.5421e-05,  4.0419e-03,\n",
      "         -1.8709e-06, -6.3361e-03],\n",
      "        [ 7.5171e-06, -1.5761e-05, -7.3814e-06,  1.1297e-05,  1.4783e-05,\n",
      "          1.2286e-05, -8.0993e-07, -1.2743e-05,  8.0660e-06,  8.1373e-06,\n",
      "          1.4083e-05, -4.6112e-06, -5.0264e-06,  4.0652e-06, -8.8973e-08,\n",
      "          1.3249e-05,  9.6986e-14, -1.2057e-05,  1.1876e-05,  8.3381e-08,\n",
      "         -7.1258e-06, -9.8687e-07, -1.6509e-06,  1.4426e-07,  4.0898e-06,\n",
      "         -1.1733e-06,  8.3739e-06, -8.4861e-06,  4.8744e-06, -2.6689e-06,\n",
      "         -5.6472e-06,  1.5136e-05],\n",
      "        [-8.8189e-06,  1.1686e-05,  1.0136e-05,  4.5488e-06,  4.1630e-06,\n",
      "          1.2796e-05, -1.2278e-05,  9.3621e-06,  1.3720e-05,  3.6596e-06,\n",
      "          1.3244e-05,  1.5198e-05,  1.2845e-05, -1.5152e-05, -9.4908e-06,\n",
      "         -2.3117e-06, -6.4983e-06, -1.4817e-09, -8.8906e-06,  1.0260e-05,\n",
      "         -1.0488e-05, -8.4314e-06, -1.9731e-06, -1.0035e-05,  6.7902e-06,\n",
      "          7.9977e-06, -9.2660e-06,  8.1455e-06, -1.2355e-05, -8.6377e-06,\n",
      "         -5.0374e-06,  6.5812e-06],\n",
      "        [-1.8717e-06,  1.3702e-02,  6.1092e-03,  7.0756e-03, -7.7544e-04,\n",
      "         -1.5108e-02, -5.4746e-06, -1.4287e-05, -4.0617e-03,  5.8365e-04,\n",
      "         -8.0948e-06,  5.4132e-03, -2.4386e-03,  1.6920e-05,  1.4272e-05,\n",
      "         -1.5603e-03, -3.5003e-06, -5.0244e-03,  1.0787e-02,  1.3440e-02,\n",
      "          1.3491e-03,  9.0220e-05, -3.0118e-03, -1.2208e-06, -2.8720e-04,\n",
      "          1.5228e-05, -2.3164e-03, -7.2376e-04, -1.6477e-05,  1.8741e-04,\n",
      "         -1.2036e-05,  7.7956e-03],\n",
      "        [-1.5297e-05, -1.9055e-02, -1.1911e-02, -1.1014e-02,  9.3797e-05,\n",
      "          5.5241e-03, -3.3478e-10, -2.0325e-06,  1.7648e-02,  9.6601e-03,\n",
      "         -8.3829e-06, -9.3023e-03, -2.4055e-02, -2.2497e-05, -3.4680e-05,\n",
      "         -1.1251e-02,  1.0123e-05,  8.9969e-03, -4.0663e-03, -3.5171e-02,\n",
      "         -3.0416e-03, -2.3240e-04, -1.4170e-02,  1.5245e-05, -9.7376e-04,\n",
      "         -6.3780e-07, -4.5371e-03, -1.6557e-02, -9.8779e-06, -1.4561e-02,\n",
      "         -9.4330e-06, -1.2804e-03],\n",
      "        [ 1.2822e-05, -2.2649e-02, -1.3024e-02, -1.2714e-02,  5.4180e-04,\n",
      "          1.2705e-02,  8.8388e-06,  1.3881e-05,  1.6744e-02,  7.6819e-03,\n",
      "          8.8342e-06, -1.0431e-02, -1.8479e-02, -1.0008e-05, -1.9499e-05,\n",
      "         -8.3371e-03,  3.9049e-06,  1.0148e-02, -8.9342e-03, -3.6053e-02,\n",
      "         -3.2228e-03, -2.5351e-04, -1.0012e-02,  1.9526e-05, -5.6245e-04,\n",
      "          1.1572e-05, -2.4514e-03, -1.3247e-02,  1.0890e-05, -1.2075e-02,\n",
      "         -1.3428e-05, -5.1438e-03],\n",
      "        [-1.4935e-05, -1.3265e-05, -1.2394e-05, -2.1596e-06,  8.3171e-06,\n",
      "         -8.1961e-06,  1.3944e-05, -6.3210e-06,  4.3282e-06,  7.3909e-06,\n",
      "         -8.5351e-06,  1.2073e-05,  1.0205e-05, -3.0041e-07,  1.4985e-05,\n",
      "          1.9079e-06, -1.0197e-05, -1.2182e-05, -4.6734e-06,  5.9592e-06,\n",
      "          1.2314e-05, -1.0983e-05, -9.4413e-06,  1.3909e-05,  3.4710e-06,\n",
      "         -1.3542e-05, -8.8954e-06,  4.9348e-06, -4.2412e-06, -1.5482e-05,\n",
      "         -1.5864e-05, -1.0698e-06],\n",
      "        [-6.7314e-08, -2.4821e-02, -1.4089e-02, -1.3836e-02,  3.1674e-04,\n",
      "          1.1841e-02, -9.3792e-06,  1.1472e-05,  1.8328e-02,  8.7569e-03,\n",
      "          1.3400e-05, -1.1394e-02, -2.1713e-02, -2.7186e-05, -2.0784e-05,\n",
      "         -1.0131e-02, -3.2890e-06,  1.0674e-02, -9.1110e-03, -3.9434e-02,\n",
      "         -3.5139e-03, -2.7487e-04, -1.2123e-02,  8.3405e-07, -9.6912e-04,\n",
      "         -9.5982e-06, -3.2763e-03, -1.5339e-02,  1.0386e-05, -1.3838e-02,\n",
      "         -3.0014e-05, -4.8828e-03],\n",
      "        [-1.0295e-05,  1.7600e-02,  1.0472e-02,  9.9609e-03, -2.2834e-04,\n",
      "         -7.4718e-03,  1.6250e-06,  1.0461e-05, -1.4358e-02, -7.2899e-03,\n",
      "         -1.6571e-06,  8.2845e-03,  1.7924e-02,  2.2587e-05,  3.1772e-05,\n",
      "          8.2795e-03,  9.1919e-06, -7.9790e-03,  5.4804e-03,  2.9901e-02,\n",
      "          2.6196e-03,  2.0954e-04,  1.0214e-02, -1.3916e-05,  7.1172e-04,\n",
      "         -1.5821e-05,  2.9709e-03,  1.2561e-02,  1.6535e-05,  1.1215e-02,\n",
      "          1.8349e-05,  2.6611e-03]], device='cuda:0'), 'exp_avg_sq': tensor([[1.5848e-11, 1.3547e-11, 2.1851e-11, 1.6149e-11, 1.5945e-13, 1.3880e-12,\n",
      "         1.2501e-11, 1.3599e-12, 1.9835e-11, 2.0776e-11, 9.1411e-12, 5.3825e-12,\n",
      "         1.7135e-11, 1.2556e-11, 1.5412e-11, 3.0198e-11, 1.3129e-11, 2.2643e-11,\n",
      "         1.5865e-12, 1.0132e-11, 2.7770e-11, 3.2646e-11, 3.0035e-11, 8.8315e-12,\n",
      "         2.9666e-12, 2.1881e-11, 1.5429e-11, 2.4141e-11, 1.4504e-11, 1.9744e-11,\n",
      "         1.5906e-11, 1.3285e-13],\n",
      "        [1.1319e-12, 6.4847e-12, 2.7784e-11, 5.7139e-12, 7.1841e-13, 1.6365e-11,\n",
      "         1.4795e-11, 9.9647e-13, 1.5700e-11, 2.9737e-11, 7.4393e-12, 2.5795e-11,\n",
      "         6.7676e-14, 1.4834e-11, 1.5695e-11, 1.5734e-12, 4.1724e-12, 1.6264e-13,\n",
      "         1.3680e-11, 5.6589e-12, 2.4404e-11, 5.3764e-12, 2.3385e-12, 2.8534e-11,\n",
      "         6.6862e-12, 1.1591e-11, 1.3403e-11, 9.7812e-12, 2.3039e-11, 2.4327e-12,\n",
      "         8.3991e-12, 2.6200e-11],\n",
      "        [5.9022e-12, 8.4869e-03, 5.0982e-03, 3.1547e-03, 2.9025e-03, 6.1111e-03,\n",
      "         5.6773e-12, 1.3778e-06, 3.9067e-03, 6.8593e-03, 1.1369e-09, 2.9962e-03,\n",
      "         4.9197e-03, 6.4444e-05, 1.0915e-07, 2.2139e-03, 2.0663e-11, 3.7487e-03,\n",
      "         4.5157e-03, 5.2352e-03, 3.6774e-03, 1.4681e-06, 5.4183e-03, 2.9385e-07,\n",
      "         5.2479e-03, 1.2450e-14, 4.3026e-03, 2.1231e-03, 3.2749e-06, 5.2947e-03,\n",
      "         1.1714e-04, 1.0547e-03],\n",
      "        [2.8688e-11, 4.4419e-03, 1.8912e-03, 9.4462e-04, 9.2442e-04, 2.0754e-03,\n",
      "         2.6171e-12, 2.5556e-06, 1.4729e-03, 1.8289e-03, 2.0053e-10, 1.1607e-03,\n",
      "         1.6707e-03, 2.0244e-05, 3.1088e-08, 7.7751e-04, 6.4732e-12, 1.2053e-03,\n",
      "         2.3702e-03, 1.8282e-03, 1.3331e-03, 4.8735e-07, 2.0575e-03, 9.6570e-08,\n",
      "         2.0555e-03, 7.9513e-12, 1.4319e-03, 6.6546e-04, 1.0764e-06, 1.7157e-03,\n",
      "         3.8065e-05, 3.4530e-04],\n",
      "        [1.0458e-12, 3.8069e-03, 6.4677e-04, 5.8492e-04, 2.0334e-04, 9.4594e-04,\n",
      "         1.7211e-12, 2.8949e-06, 4.3133e-04, 3.9064e-04, 2.0887e-11, 6.3889e-04,\n",
      "         3.9208e-04, 6.0614e-06, 4.9531e-09, 3.1632e-04, 2.5086e-11, 5.6420e-04,\n",
      "         1.9354e-03, 5.7410e-04, 5.2549e-04, 9.3470e-08, 7.6073e-04, 1.8251e-08,\n",
      "         7.6262e-04, 3.7428e-12, 3.3210e-04, 1.4475e-04, 2.1410e-07, 4.1562e-04,\n",
      "         8.1434e-06, 9.2504e-05],\n",
      "        [6.9711e-12, 2.8447e-12, 2.5066e-12, 1.5007e-13, 1.9059e-11, 7.1202e-12,\n",
      "         2.6161e-11, 1.1930e-11, 2.2750e-12, 7.8194e-12, 2.2592e-11, 1.0103e-11,\n",
      "         1.7224e-11, 9.2521e-12, 4.8183e-12, 1.6102e-11, 1.5893e-14, 2.8812e-11,\n",
      "         2.1226e-11, 5.7219e-12, 2.7649e-11, 4.9207e-12, 4.5153e-12, 7.2756e-12,\n",
      "         3.9655e-13, 1.7152e-12, 5.8463e-12, 9.6980e-12, 9.9198e-12, 7.4324e-13,\n",
      "         7.8890e-12, 4.7528e-12],\n",
      "        [6.5221e-13, 2.1950e-03, 1.7650e-03, 9.3756e-04, 9.5270e-04, 1.9582e-03,\n",
      "         6.9622e-12, 1.5381e-06, 1.3299e-03, 2.1081e-03, 3.2694e-10, 9.4211e-04,\n",
      "         1.6484e-03, 2.0661e-05, 3.5169e-08, 7.2234e-04, 2.5993e-11, 1.0829e-03,\n",
      "         1.3817e-03, 1.7441e-03, 1.2903e-03, 4.9152e-07, 1.8591e-03, 9.8553e-08,\n",
      "         1.7307e-03, 2.4885e-11, 1.4575e-03, 6.9896e-04, 1.0883e-06, 1.7404e-03,\n",
      "         3.9401e-05, 3.6017e-04],\n",
      "        [3.2225e-16, 5.4054e-03, 2.8423e-04, 7.4082e-04, 9.4711e-05, 1.0322e-03,\n",
      "         8.3555e-12, 1.7730e-06, 2.0499e-04, 3.7141e-04, 6.7457e-11, 6.1019e-04,\n",
      "         1.8777e-04, 2.3446e-06, 9.8372e-10, 3.1019e-04, 2.3063e-11, 8.5908e-04,\n",
      "         2.2885e-03, 2.6731e-04, 2.5785e-04, 5.8398e-11, 4.6417e-04, 1.9643e-10,\n",
      "         5.1380e-04, 3.0266e-11, 7.3564e-05, 5.0899e-05, 1.2521e-09, 2.5221e-04,\n",
      "         3.7047e-07, 3.5668e-05],\n",
      "        [7.2408e-12, 2.9872e-11, 6.9970e-12, 1.5707e-11, 2.6383e-11, 1.8457e-11,\n",
      "         1.7474e-13, 1.9803e-11, 8.2696e-12, 8.4085e-12, 2.4019e-11, 2.9295e-12,\n",
      "         3.4285e-12, 2.3327e-12, 1.9803e-14, 2.1346e-11, 1.2570e-20, 1.7800e-11,\n",
      "         1.7291e-11, 1.8997e-14, 6.5489e-12, 2.3041e-13, 5.0249e-13, 2.7935e-14,\n",
      "         2.3581e-12, 2.9671e-13, 8.8767e-12, 9.1033e-12, 3.2413e-12, 1.1133e-12,\n",
      "         4.2474e-12, 2.7616e-11],\n",
      "        [9.7920e-12, 1.6764e-11, 1.2764e-11, 2.8579e-12, 2.4347e-12, 1.9961e-11,\n",
      "         1.8434e-11, 1.0970e-11, 2.2837e-11, 1.9331e-12, 2.1332e-11, 2.7836e-11,\n",
      "         2.0109e-11, 2.7674e-11, 1.1259e-11, 8.7231e-13, 5.5118e-12, 5.7324e-15,\n",
      "         9.9435e-12, 1.3064e-11, 1.3623e-11, 8.9925e-12, 6.7045e-13, 1.2520e-11,\n",
      "         5.9832e-12, 8.1380e-12, 1.0757e-11, 8.4243e-12, 1.8657e-11, 9.4139e-12,\n",
      "         3.4423e-12, 5.6436e-12],\n",
      "        [6.1507e-13, 3.5930e-03, 1.6555e-04, 5.6415e-04, 1.7515e-04, 8.8579e-04,\n",
      "         4.0109e-12, 3.3453e-08, 2.0482e-04, 6.4747e-04, 1.2076e-10, 3.3830e-04,\n",
      "         2.8566e-04, 1.9028e-06, 5.3447e-09, 2.8605e-04, 1.7862e-12, 8.4028e-04,\n",
      "         1.3617e-03, 2.6092e-04, 1.4100e-04, 3.6913e-08, 3.2346e-04, 7.9913e-09,\n",
      "         3.4688e-04, 2.7943e-11, 1.5812e-04, 1.0896e-04, 8.0915e-08, 3.9888e-04,\n",
      "         2.9289e-06, 5.1490e-05],\n",
      "        [2.8190e-11, 3.8160e-03, 1.6158e-03, 8.0371e-04, 7.9290e-04, 1.7703e-03,\n",
      "         3.4036e-16, 1.9907e-06, 1.2594e-03, 1.5727e-03, 1.7164e-10, 9.8942e-04,\n",
      "         1.4208e-03, 1.7334e-05, 2.6389e-08, 6.6189e-04, 1.2731e-11, 1.0403e-03,\n",
      "         2.0065e-03, 1.5591e-03, 1.1325e-03, 4.1325e-07, 1.7501e-03, 8.2000e-08,\n",
      "         1.7505e-03, 1.2737e-13, 1.2126e-03, 5.7013e-04, 9.2027e-07, 1.4705e-03,\n",
      "         3.3824e-05, 2.9130e-04],\n",
      "        [2.0041e-11, 2.3198e-03, 1.4288e-03, 8.0507e-04, 7.7818e-04, 1.6498e-03,\n",
      "         9.8339e-12, 7.2544e-07, 1.0842e-03, 1.7381e-03, 2.7571e-10, 8.1007e-04,\n",
      "         1.3614e-03, 1.6649e-05, 2.8373e-08, 5.9894e-04, 2.1703e-12, 9.6391e-04,\n",
      "         1.2397e-03, 1.3889e-03, 1.0153e-03, 4.0031e-07, 1.5154e-03, 8.0476e-08,\n",
      "         1.4421e-03, 1.6449e-11, 1.1722e-03, 5.6607e-04, 8.8196e-07, 1.4234e-03,\n",
      "         3.1597e-05, 2.8582e-04],\n",
      "        [2.6908e-11, 2.1397e-11, 1.8772e-11, 7.7839e-13, 8.7631e-12, 8.5235e-12,\n",
      "         2.3562e-11, 5.2348e-12, 2.6117e-12, 7.0138e-12, 9.2031e-12, 1.7846e-11,\n",
      "         1.2929e-11, 5.3749e-14, 2.7084e-11, 6.3456e-13, 1.2911e-11, 1.8159e-11,\n",
      "         3.0018e-12, 4.6918e-12, 1.8537e-11, 1.4882e-11, 1.1147e-11, 2.3447e-11,\n",
      "         1.7599e-12, 2.2267e-11, 9.9537e-12, 3.3151e-12, 2.5177e-12, 2.8853e-11,\n",
      "         3.0252e-11, 2.5893e-13],\n",
      "        [1.6682e-14, 2.0242e-03, 1.8469e-03, 9.2846e-04, 9.1818e-04, 1.9205e-03,\n",
      "         1.1008e-11, 3.1053e-06, 1.3408e-03, 1.9556e-03, 3.1473e-10, 9.8199e-04,\n",
      "         1.5922e-03, 2.1274e-05, 3.3484e-08, 7.1602e-04, 1.6005e-12, 9.4572e-04,\n",
      "         1.5591e-03, 1.8068e-03, 1.4033e-03, 4.8570e-07, 1.9348e-03, 9.6628e-08,\n",
      "         1.7656e-03, 1.1502e-11, 1.4638e-03, 6.8247e-04, 1.0826e-06, 1.6793e-03,\n",
      "         3.9065e-05, 3.6547e-04],\n",
      "        [1.3148e-11, 1.8191e-03, 1.0618e-03, 5.2458e-04, 5.4682e-04, 1.1451e-03,\n",
      "         4.9000e-13, 9.4364e-07, 8.1178e-04, 1.1419e-03, 1.4786e-10, 6.0008e-04,\n",
      "         9.6829e-04, 1.1941e-05, 1.9397e-08, 4.2646e-04, 1.0594e-11, 6.4818e-04,\n",
      "         1.0124e-03, 1.0271e-03, 7.5024e-04, 2.8779e-07, 1.1294e-03, 5.7377e-08,\n",
      "         1.0955e-03, 3.0092e-11, 8.3999e-04, 3.9760e-04, 6.4222e-07, 1.0017e-03,\n",
      "         2.2947e-05, 2.0187e-04]], device='cuda:0')}, 35: {'step': tensor(120., device='cuda:0'), 'exp_avg': tensor([-9.0536e-06, -9.3100e-06,  1.6664e-03,  1.7262e-02, -1.2867e-02,\n",
      "        -1.4665e-06, -5.0218e-03, -1.5081e-02, -1.2893e-05, -1.1005e-05,\n",
      "         1.5240e-02,  1.6139e-02,  6.2801e-03,  1.4225e-06,  6.2105e-03,\n",
      "        -8.9255e-03], device='cuda:0'), 'exp_avg_sq': tensor([1.0293e-11, 1.0854e-11, 5.3507e-02, 3.8487e-02, 4.7741e-02, 4.1693e-13,\n",
      "        8.3168e-03, 7.8617e-02, 2.0255e-11, 1.4938e-11, 5.5538e-02, 3.3299e-02,\n",
      "        1.4237e-02, 3.9762e-13, 4.6282e-03, 1.1632e-02], device='cuda:0')}, 36: {'step': tensor(120., device='cuda:0'), 'exp_avg': tensor([[ 1.7790e-05,  3.0897e-06, -1.7362e-10, -2.0019e-05, -1.7677e-05,\n",
      "          4.2910e-06, -1.2623e-05,  2.5210e-07,  9.7807e-06, -4.4263e-06,\n",
      "          1.8953e-05, -5.2015e-06, -2.2186e-05,  4.6093e-06, -1.7566e-05,\n",
      "         -1.1371e-05],\n",
      "        [ 2.2719e-05, -6.4176e-06,  1.9421e-02, -1.2077e-02, -6.9217e-02,\n",
      "          2.2133e-05,  5.8527e-02, -4.2466e-02, -1.9939e-05,  5.6494e-06,\n",
      "          1.5864e-02,  1.5922e-02, -3.3527e-02,  1.4648e-05, -2.0953e-02,\n",
      "         -4.0124e-02],\n",
      "        [ 1.5034e-05,  4.0348e-06,  1.0430e-07,  2.1403e-06,  9.1461e-06,\n",
      "         -1.7357e-05, -1.3701e-05,  1.0018e-06, -4.6429e-06, -5.8924e-06,\n",
      "          1.5816e-05, -5.6309e-06,  1.6110e-05,  1.1644e-05, -1.1552e-05,\n",
      "         -6.3394e-06],\n",
      "        [-2.7586e-07, -1.1610e-05,  1.0609e-05,  5.0614e-06, -2.3008e-05,\n",
      "          1.6715e-05,  1.5084e-05,  1.2173e-05,  2.2619e-06, -1.5618e-05,\n",
      "          3.6886e-06, -4.2756e-06, -6.7014e-06,  1.5579e-05, -8.4808e-06,\n",
      "         -2.1438e-05],\n",
      "        [-1.4822e-05,  5.5193e-06,  1.4604e-02,  3.6612e-02,  2.4339e-02,\n",
      "         -1.3684e-05,  5.2969e-03,  7.3593e-03,  4.1105e-06, -8.8109e-06,\n",
      "          1.1090e-02,  1.1665e-02, -4.9814e-03, -2.2274e-05,  1.8608e-03,\n",
      "          1.4041e-02],\n",
      "        [-1.9094e-05, -1.2975e-05,  7.7785e-06,  1.6159e-05,  4.7710e-06,\n",
      "          1.3442e-05, -1.0058e-05, -1.4250e-05, -1.3204e-05,  1.0786e-05,\n",
      "          6.4772e-06,  2.3043e-06, -1.6577e-05,  1.4297e-05, -1.1497e-13,\n",
      "         -2.2060e-05],\n",
      "        [-1.9403e-05,  2.0850e-05, -1.2750e-02,  4.3509e-03,  3.9613e-02,\n",
      "         -5.6885e-06, -3.7443e-02,  2.2507e-02,  5.8718e-06, -1.8030e-05,\n",
      "         -1.0204e-02, -1.1336e-02,  1.8120e-02,  1.3939e-05,  8.4939e-03,\n",
      "          2.1512e-02],\n",
      "        [ 2.2024e-05, -1.2617e-06, -2.3391e-05, -1.4323e-05,  1.9572e-05,\n",
      "         -1.7765e-05, -3.2396e-06,  2.3503e-05,  1.7191e-05,  8.0175e-06,\n",
      "          4.0073e-06, -1.6901e-05,  9.5296e-06, -9.0985e-06, -2.1223e-05,\n",
      "         -2.2446e-05]], device='cuda:0'), 'exp_avg_sq': tensor([[3.7798e-11, 1.4344e-12, 6.7401e-16, 4.7583e-11, 3.7334e-11, 2.5714e-12,\n",
      "         1.9445e-11, 4.5242e-14, 1.1923e-11, 2.7199e-12, 4.2763e-11, 3.6507e-12,\n",
      "         5.8171e-11, 2.9274e-12, 3.6876e-11, 1.5906e-11],\n",
      "        [6.0938e-11, 5.3848e-12, 5.4404e-03, 1.2822e-02, 9.2258e-03, 5.7897e-11,\n",
      "         7.8938e-03, 1.1826e-02, 4.7211e-11, 4.2505e-12, 1.0088e-02, 4.1054e-03,\n",
      "         8.7422e-03, 2.5918e-11, 5.0685e-03, 7.8057e-03],\n",
      "        [2.7257e-11, 2.3015e-12, 2.2023e-14, 7.6686e-13, 1.0493e-11, 3.6027e-11,\n",
      "         2.2775e-11, 2.3541e-13, 2.9663e-12, 4.5948e-12, 3.0072e-11, 4.2247e-12,\n",
      "         3.1169e-11, 1.6647e-11, 1.6395e-11, 5.2633e-12],\n",
      "        [4.9365e-14, 1.6555e-11, 1.3927e-11, 3.4723e-12, 6.2465e-11, 3.3482e-11,\n",
      "         2.7434e-11, 1.8132e-11, 8.4096e-13, 2.9346e-11, 1.9604e-12, 2.5548e-12,\n",
      "         5.8378e-12, 2.9206e-11, 9.0924e-12, 5.4398e-11],\n",
      "        [2.6516e-11, 4.0715e-12, 4.7039e-03, 6.2474e-02, 3.8951e-02, 2.2719e-11,\n",
      "         2.4910e-02, 5.8507e-02, 2.3797e-12, 9.7751e-12, 3.9627e-03, 1.4097e-02,\n",
      "         2.6558e-02, 5.8622e-11, 7.8559e-02, 4.5878e-02],\n",
      "        [4.3388e-11, 2.0503e-11, 7.7222e-12, 3.1354e-11, 3.1169e-12, 2.1950e-11,\n",
      "         1.2575e-11, 2.4572e-11, 2.1205e-11, 1.4373e-11, 5.4785e-12, 8.6759e-13,\n",
      "         3.2946e-11, 2.4729e-11, 1.2978e-20, 5.7524e-11],\n",
      "        [4.4764e-11, 5.1515e-11, 2.3692e-03, 1.6225e-02, 9.4724e-03, 4.3050e-12,\n",
      "         6.7659e-03, 1.5376e-02, 4.5652e-12, 3.8798e-11, 4.1192e-03, 3.0368e-03,\n",
      "         7.3103e-03, 2.3545e-11, 1.5563e-02, 9.4765e-03],\n",
      "        [5.7342e-11, 3.3090e-13, 6.4518e-11, 2.4815e-11, 4.5532e-11, 3.7697e-11,\n",
      "         1.5584e-12, 6.5127e-11, 3.5360e-11, 8.1760e-12, 2.2734e-12, 3.4209e-11,\n",
      "         1.1346e-11, 1.0390e-11, 5.3335e-11, 5.9510e-11]], device='cuda:0')}, 37: {'step': tensor(120., device='cuda:0'), 'exp_avg': tensor([ 1.2391e-05,  1.3856e-04, -1.0803e-05, -1.4017e-05,  1.2072e-01,\n",
      "        -1.1941e-05, -1.8828e-02, -3.8600e-06], device='cuda:0'), 'exp_avg_sq': tensor([1.8760e-11, 2.5130e-07, 1.4417e-11, 2.3802e-11, 2.1573e+00, 1.7474e-11,\n",
      "        3.6440e-01, 2.1259e-12], device='cuda:0')}, 38: {'step': tensor(120., device='cuda:0'), 'exp_avg': tensor([[ 1.1765e-05, -5.8096e-02, -1.4536e-05, -9.9544e-06,  3.8453e-02,\n",
      "          3.0067e-05, -1.1781e-01, -2.9773e-05]], device='cuda:0'), 'exp_avg_sq': tensor([[1.6981e-11, 1.1903e-02, 2.5536e-11, 1.2330e-11, 2.0327e-03, 1.0564e-10,\n",
      "         2.8286e-02, 1.0361e-10]], device='cuda:0')}, 39: {'step': tensor(120., device='cuda:0'), 'exp_avg': tensor([-0.0005], device='cuda:0'), 'exp_avg_sq': tensor([3.8514e-06], device='cuda:0')}}, 'param_groups': [{'lr': 0.0001, 'betas': (0.9, 0.999), 'eps': 1e-08, 'weight_decay': 0.0001, 'amsgrad': False, 'maximize': False, 'foreach': None, 'capturable': False, 'differentiable': False, 'fused': None, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39]}]}\n",
      "batch_size 32\n",
      "dropout_ratio 0.5\n",
      "learning_rate 0.0001\n",
      "weight_decay 0.0001\n",
      "n_epochs 10\n",
      "random_seed 0\n",
      "val_c_index 0.7572533849129593\n",
      "hidden [1024, 1024, 512, 512, 256, 256, 128, 128, 64, 64, 32]\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning) # ignore the loading security warning\n",
    "\n",
    "model_chkpt = FusionNetwork()\n",
    "model_chkpt.to(device)\n",
    "optimizer = optim.Adam(model_chkpt.parameters())\n",
    "\n",
    "# load from last check point (the best one)\n",
    "checkpoint_path = ____\n",
    "\n",
    "checkpoint = torch.load(checkpoint_path, map_location=device)\n",
    "model_chkpt.load_state_dict(checkpoint['model_state_dict'])\n",
    "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "val_c_index = checkpoint['val_c_index']\n",
    "\n",
    "for k, v in checkpoint.items():\n",
    "    print(k, v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_22788\\2694761428.py:31: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(checkpoint_path, map_location=device)\n",
      "100%|██████████| 1/1 [02:13<00:00, 133.53s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test c-index: 0.7748279252704031\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import random\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import csv\n",
    "\n",
    "from lifelines.utils import concordance_index\n",
    "\n",
    "# from utils import display_km_curves_fusion\n",
    "# from models import *\n",
    "# from train import test_loader\n",
    "\n",
    "random.seed(0)\n",
    "np.random.seed(0)\n",
    "torch.manual_seed(0)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "############################# FINAL ###########################################\n",
    "\n",
    "checkpoint_path = r\"..\\\\checkpoints\\trained-model_2025-03-04_0.692456.pth\" # TODO: to choose\n",
    "\n",
    "model_chkpt = FusionNetwork()\n",
    "model_chkpt.to(device)\n",
    "optimizer = optim.Adam(model_chkpt.parameters())\n",
    "\n",
    "# load from last check point\n",
    "checkpoint = torch.load(checkpoint_path, map_location=device)\n",
    "model_chkpt.load_state_dict(checkpoint['model_state_dict'])\n",
    "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "val_c_index = checkpoint['val_c_index']\n",
    "\n",
    "model_chkpt.eval()\n",
    "\n",
    "test_risks = []\n",
    "test_times = []\n",
    "test_events = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(test_loader):\n",
    "        # unpack the batch\n",
    "        batch_clinical_rna_features, batch_lists_phenotype_clusters, batch_times, batch_events = batch\n",
    "        \n",
    "        # move times and events to the device\n",
    "        batch_times = batch_times.to(device)\n",
    "        batch_events = batch_events.to(device)\n",
    "        \n",
    "        # tterate over each sample in the batch\n",
    "        for i, (clinical_rna_features, list_of_phenotype_tensors) in enumerate(zip(batch_clinical_rna_features, batch_lists_phenotype_clusters)):\n",
    "            \n",
    "            risk_score = model_chkpt(clinical_rna_features, list_of_phenotype_tensors)\n",
    "            \n",
    "            test_risks.append(risk_score.item())\n",
    "            test_times.append(batch_times[i].item())\n",
    "            test_events.append(batch_events[i].item())\n",
    "\n",
    "test_c_index = concordance_index(test_times, -np.array(test_risks), test_events)\n",
    "print(f\"test c-index: {test_c_index}\")\n",
    "display_km_curves_fusion(test_risks, test_times, test_events, \"test set\", test_c_index, save_figure=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bootstrap mean c-index: 0.7752918765296727, standard deviation: 0.04279807565228312\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def bootstrap_c_index(times, risks, events, n_bootstrap=300): # TODO: to choose\n",
    "    random.seed(0)\n",
    "    np.random.seed(0)\n",
    "\n",
    "    indices = np.arange(len(times))\n",
    "    bootstrap_scores = []\n",
    "\n",
    "    for _ in range(n_bootstrap):\n",
    "        # sample with replacement\n",
    "        sample_indices = np.random.choice(indices, size=len(indices), replace=True)\n",
    "        boot_times = np.array(times)[sample_indices]\n",
    "        boot_risks = np.array(risks)[sample_indices]\n",
    "        boot_events = np.array(events)[sample_indices]\n",
    "        score = concordance_index(boot_times, -boot_risks, boot_events)\n",
    "        bootstrap_scores.append(score)\n",
    "        \n",
    "    return np.mean(bootstrap_scores), np.std(bootstrap_scores)\n",
    "\n",
    "mean_c_index, std_c_index = bootstrap_c_index(test_times, test_risks, test_events)\n",
    "print(f\"bootstrap mean c-index: {mean_c_index}, standard deviation: {std_c_index}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# append to csv file\n",
    "with open(\"../evaluation-results/c-index-results.csv\", \"a\", newline=\"\") as f:\n",
    "    writer = csv.DictWriter(f, fieldnames=[\"model\", \"c-index\"])\n",
    "    writer.writerow({\"model\": \"multimodality\", \"c-index\": mean_c_index})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
