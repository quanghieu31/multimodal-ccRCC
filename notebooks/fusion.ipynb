{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "import configparser\n",
    "config = configparser.ConfigParser()\n",
    "config.read(\"../config.ini\")\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "class PatientClinicalDataset(Dataset):\n",
    "    \"\"\"\n",
    "    from csv, so getitem would be something like .loc[idx]\n",
    "    \"\"\"\n",
    "    def __init__(self, csv_file_path):\n",
    "        self.csv_file_path = csv_file_path\n",
    "        self.df = pd.read_csv(self.csv_file_path).drop([\"time\", \"event\"], axis=1)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        patient_series = self.df.iloc[idx]\n",
    "        return patient_series # includes the submitter_id!\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.df.shape[0]\n",
    "\n",
    "\n",
    "class PatientRNASeqDataset(Dataset):\n",
    "    \"\"\"\n",
    "    a csv file, 534 rows and ~20000 columns for normalized RNA-seq counts\n",
    "    \"\"\"\n",
    "    def __init__(self, rna_file_path):\n",
    "        self.rna_file_path = rna_file_path\n",
    "        self.df = pd.read_csv(self.rna_file_path)\n",
    "        self.df.set_index(\"submitter_id\", inplace=True)\n",
    "\n",
    "    def __getitem__(self, case_id):\n",
    "        gene_expressions = list(self.df.loc[case_id])\n",
    "        tensor_gene_expressions = torch.tensor(gene_expressions, dtype=torch.float32).unsqueeze(0)\n",
    "        return tensor_gene_expressions # [1, 19962]\n",
    "\n",
    "\n",
    "class PatientWSIDataset(Dataset):\n",
    "    \"\"\"\n",
    "    dataset for accessing a patient's list of patches features, each is of shape (1, n_patches, n_features)\n",
    "    \"\"\"\n",
    "    def __init__(self, wsi_dir):\n",
    "\n",
    "        self.wsi_dir = wsi_dir\n",
    "        self.case_ids = list(os.listdir(self.wsi_dir))\n",
    "        self.dict_case_id_path = {\n",
    "            c: os.path.join(self.wsi_dir, c) + \"/patches_features.npy\" for c in self.case_ids\n",
    "        }\n",
    "\n",
    "    def __getitem__(self, case_id):\n",
    "        # grab the list of 5 clusters for this case_id\n",
    "\n",
    "        case_npy_file = self.dict_case_id_path[case_id]\n",
    "        patches_features = np.load(case_npy_file, allow_pickle=True).item()\n",
    "        \n",
    "        cluster_ids = self.clustering(patches_features)\n",
    "\n",
    "        features_list = list(patches_features.values())\n",
    "        unique_clusters = np.unique(cluster_ids)\n",
    "        n_clusters = len(unique_clusters)\n",
    "\n",
    "        list_phenotype_tensors = [] # list of tensors, each tensor is a cluster's features of shape i.e. (1, 15 patches in this cluster, 512 as output of resnet18)\n",
    "\n",
    "        for cluster in unique_clusters:\n",
    "            cluster_features = [features for features, c in zip(features_list, cluster_ids) if c == cluster]\n",
    "            tensor_cluster_features = torch.from_numpy(np.array(cluster_features)).float().unsqueeze(0) # (1, n_patches, n_features)\n",
    "\n",
    "            list_phenotype_tensors.append(tensor_cluster_features.to(device))\n",
    "\n",
    "        return list_phenotype_tensors # [t1,t2,t3,t4,t5]\n",
    "\n",
    "    def clustering(self, patches_features, n_clusters=5):\n",
    "        feature_vectors = list(patches_features.values())\n",
    "        kmeans = KMeans(n_clusters=n_clusters, random_state=0, n_init=50)\n",
    "        cluster_ids = kmeans.fit_predict(feature_vectors)\n",
    "        return cluster_ids\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.case_ids)\n",
    "\n",
    "\n",
    "\n",
    "## Fusion multimodal\n",
    "\n",
    "class MultimodalDataset(Dataset):\n",
    "    \"\"\"\n",
    "    takes three data paths (clinical, rna-seq, histopath images)\n",
    "    build a data out of 'em\n",
    "    \"\"\"\n",
    "    def __init__(self, \n",
    "        clinical_data_path, \n",
    "        rna_seq_data_path, \n",
    "        wsi_data_path\n",
    "    ):\n",
    "        # prepare labels from the clinical data path\n",
    "        self.LABELS_DF = pd.read_csv(clinical_data_path)[[\"submitter_id\", \"event\", \"time\"]]\n",
    "        # then by initializing the clinical_dataset, remove the time and event from the clinical features:\n",
    "        self.clinical_dataset = PatientClinicalDataset(clinical_data_path)\n",
    "\n",
    "        # initialize the datasets for each modality\n",
    "        self.wsi_dataset = PatientWSIDataset(wsi_data_path)\n",
    "        self.rna_dataset = PatientRNASeqDataset(rna_seq_data_path)\n",
    "\n",
    "        # label dictionary with key=submitter_id and value=(event,time) for easy lookup\n",
    "        self.labels_dict = {}\n",
    "        for submitter_id, event, time in zip(self.LABELS_DF[\"submitter_id\"], self.LABELS_DF[\"event\"], self.LABELS_DF[\"time\"]):\n",
    "            self.labels_dict[submitter_id] = {\"event\": event, \"time\": time}\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.clinical_dataset)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        # (1) start from clinical dataset\n",
    "        patient_series = self.clinical_dataset[idx]\n",
    "        case_id = patient_series[\"submitter_id\"]\n",
    "        clinical_features = list(patient_series.drop([\"submitter_id\"]))\n",
    "        tensor_clinical_features = torch.tensor(clinical_features, dtype=torch.float32).unsqueeze(0) \n",
    "        # above: add batch dim (1, 13) instead of (13)\n",
    "\n",
    "        # (2) grab the tensor for 20000 (processed) gene counts for that case id\n",
    "        tensor_rna_genes = self.rna_dataset[case_id] # (1, 19962)\n",
    "\n",
    "        # (2.5) NOTE: to save time for this moment, I will concat the clinical and rna together \n",
    "        # and build one feed-forward for the combined\n",
    "        tensor_clinical_rna = torch.cat((tensor_clinical_features, tensor_rna_genes), dim=1) # (1, 19975)\n",
    "\n",
    "        # (3) collect the list of phenotype tensor for that case id\n",
    "        list_of_phenotype_tensors = self.wsi_dataset[case_id]\n",
    "\n",
    "        # (4) labels\n",
    "        time = self.labels_dict[case_id][\"time\"]\n",
    "        event = self.labels_dict[case_id][\"event\"]\n",
    "\n",
    "        return (\n",
    "            tensor_clinical_rna,\n",
    "            list_of_phenotype_tensors,\n",
    "            time,\n",
    "            event\n",
    "        )\n",
    "\n",
    "        # return (\n",
    "        #     tensor_clinical_features, \n",
    "        #     tensor_rna_genes, \n",
    "        #     list_of_phenotype_tensors,\n",
    "        #     time,\n",
    "        #     event\n",
    "        # )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_data = MultimodalDataset(\n",
    "    config[\"clinical\"][\"cleaned_clinical_json\"],\n",
    "    config[\"rna\"][\"cleaned_rna\"],\n",
    "    config[\"wsi\"][\"wsi_slides\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 first gene counts:\n",
      "tensor(2.4332)\n",
      "tensor(0.)\n",
      "tensor(3.4071)\n",
      "tensor(2.7216)\n",
      "tensor(1.6839)\n",
      "tensor(1.7558)\n",
      "tensor(3.9939)\n",
      "clinical:\n",
      "tensor(0.)\n",
      "tensor(1.1109)\n",
      "tensor(0.)\n",
      "tensor(0.)\n",
      "tensor(0.)\n",
      "tensor(1.)\n",
      "tensor(0.)\n",
      "tensor(0.)\n",
      "tensor(0.)\n",
      "tensor(0.)\n",
      "tensor(0.)\n",
      "tensor(1.)\n",
      "tensor(0.)\n"
     ]
    }
   ],
   "source": [
    "case0 = check_data[5]\n",
    "clin_rna, list_tensors = case0[0], case0[1]\n",
    "\n",
    "print(\"5 first gene counts:\")\n",
    "for i in clin_rna.flatten()[13:20]:\n",
    "    print(i)\n",
    "\n",
    "print(\"clinical:\")\n",
    "for i in clin_rna.flatten()[0:13]:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1148, 512])\n",
      "torch.Size([1, 1078, 512])\n",
      "torch.Size([1, 984, 512])\n",
      "torch.Size([1, 966, 512])\n",
      "torch.Size([1, 824, 512])\n",
      "\n",
      "torch.Size([1, 1148, 512])\n",
      "torch.Size([1, 1078, 512])\n",
      "torch.Size([1, 984, 512])\n",
      "torch.Size([1, 966, 512])\n",
      "torch.Size([1, 824, 512])\n"
     ]
    }
   ],
   "source": [
    "for tensor in list_tensors:\n",
    "    print(tensor.shape)\n",
    "\n",
    "print()\n",
    "check_wsi = PatientWSIDataset(config[\"wsi\"][\"wsi_slides\"])[\"TCGA-BP-4352\"]\n",
    "for tensor in check_wsi:\n",
    "    print(tensor.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import random\n",
    "import os\n",
    "import math\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "random.seed(0)\n",
    "np.random.seed(0)\n",
    "torch.manual_seed(0)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "class WSI_FCN(nn.Module):\n",
    "    \"\"\"\n",
    "    https://arxiv.org/abs/2009.11169\n",
    "    fully convolutional network for WSI\n",
    "    takes 1 phenotype tensor/cluster of shape (1, n_patches, 512)\n",
    "    outputs a local representation of that phenotype tensor of shape (1, 64)\n",
    "    why FCN? on the numerical vectors? \n",
    "        - utilize the kernel, and especially kernel_size=1 because we can't have kernel_size>1 for randomly picked patches from the histopathology slides\n",
    "        - so why not a simple fully connected network (MLP)? it's because it requires inputs with fixed dimension and we have varying number of patches for each cluster\n",
    "    also, note that a patch -> FCN -> (1,64) shape. So if we have 300 patches or (300,64) shape, we would use avgpooling and get (1,64) as the final output for that cluster\n",
    "    \"\"\"\n",
    "    def __init__(self, in_features, out_features=64):\n",
    "        super(WSI_FCN, self).__init__()\n",
    "        # conv1d because we only have a tensor of shape (N, C, L) = (1, 512, i.e. 272)\n",
    "        self.conv = nn.Conv1d(in_features, out_features, \n",
    "            kernel_size=1 # kernel size = 1 is extremely important because we only want to the a single patch to be learned, \n",
    "            # doing i.e. 3x3 is no use because the patches are picked randomly, so can't use spatial relationship here\n",
    "        )\n",
    "        self.relu = nn.ReLU()\n",
    "        # adaptive avg pooling to get a local representation of the phenotype tensor\n",
    "        # NOTE: adapative pooling from (64, 300 patches) to (64,1) as the final output of that cluster\n",
    "        self.pool = nn.AdaptiveAvgPool1d(1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: (1, n_patches, n_features)\n",
    "        # permute to (1, n_features, n_patches) so that n_features become channels why? because tensor in pytorch reads () https://stackoverflow.com/questions/51541532/which-part-of-pytorch-tensor-represents-channels\n",
    "        # n_patches is the length of the sequence. why?\n",
    "        # FYI: for a conv2D, input should be in (N, C, H, W) format. N is the number of samples/batch_size. C is the channels. H and W are height and width resp: https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html#torch.nn.Conv2d \n",
    "        # but here we have conv1d: https://pytorch.org/docs/stable/generated/torch.nn.Conv1d.html#torch.nn.Conv1d\n",
    "\n",
    "        x = x.permute(0, 2, 1) # (1, 512, 300 patches)\n",
    "        x = self.conv(x) # (1, 64, 300 patches)\n",
    "        x = self.relu(x) # (1, 64, 300 patches)\n",
    "        x = self.pool(x) # (1, 64, 1)\n",
    "        x = x.view(x.size()[0], -1) # (1, 64)\n",
    "        return x # (1, 64)\n",
    "\n",
    "\n",
    "\n",
    "class WSI_Attention(nn.Module):\n",
    "    \"\"\"\n",
    "    https://arxiv.org/abs/2009.11169 \n",
    "    pooling attention mechanism for WSI\n",
    "    takes a local representation of the phenotype tensor of shape (5, 64) in which 5 is the number of clusters\n",
    "    outputs a global representation of the phenotype tensors of shape (64-dim) which is a weighted sum across 5 clusters for 64 features\n",
    "        each case has a global representation\n",
    "    \"\"\"\n",
    "    def __init__(self, in_features, out_features=64):\n",
    "        super(WSI_Attention, self).__init__()\n",
    "        self.attention = nn.Sequential(\n",
    "            nn.Linear(in_features, out_features),\n",
    "            nn.Tanh(),  # tanh because we want to normalize the weights\n",
    "            # why tanh() >> output values in range (-1,1), allowing both neg and pos values, often used in attention scores\n",
    "            nn.Linear(out_features, 1),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # apply softmax because we have different number of clusters for each case\n",
    "        # x: (5, 64) stack representation of 5 clusters/phenotypes\n",
    "        scores = self.attention(x) # (5, 1)\n",
    "        att_weights = torch.softmax(scores, dim=0).T # (1,5) which is probabilities\n",
    "        # weighted sum across the 5 clusters:\n",
    "        weights_applied = att_weights @ x  # (5, 64) = (1,5) @ (5,64)\n",
    "        # weighted_sum_vector = torch.sum(weights_applied, dim=0) # (1, 64) or (64)\n",
    "        return weights_applied, att_weights\n",
    "\n",
    "\n",
    "\n",
    "# Clinical_RNA_FeedForward()\n",
    "class Clinical_RNA_FeedForward(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim=32, dropout_ratio=0.5):\n",
    "        # https://www.cs.toronto.edu/~hinton/absps/JMLRdropout.pdf\n",
    "        # https://arxiv.org/pdf/1207.0580\n",
    "        # For fully connected layers, dropout in all hidden layers works\n",
    "        # better than dropout in only one hidden layer and more extreme probabilities tend to be worse,\n",
    "        # which is why we have used 0.5 throughout this paper\n",
    "        \n",
    "        super(Clinical_RNA_FeedForward, self).__init__()\n",
    "\n",
    "        hidden = [512, 256, 256, 64, 64, 32]\n",
    "\n",
    "        self.feedforward = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden[0]),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_ratio),\n",
    "            nn.Linear(hidden[0], hidden[1]),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_ratio),\n",
    "            nn.Linear(hidden[1], hidden[2]),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_ratio),\n",
    "            nn.Linear(hidden[2], hidden[3]),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_ratio),\n",
    "            nn.Linear(hidden[3], hidden[4]),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_ratio),   \n",
    "            nn.Linear(hidden[4], hidden[5]),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_ratio),      \n",
    "            nn.Linear(hidden[5], output_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_ratio),    \n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.feedforward(x)\n",
    "        return out\n",
    "\n",
    "\n",
    "\n",
    "# FusionFeedForward\n",
    "class FusionNetwork(nn.Module):\n",
    "    def __init__(self, \n",
    "        input_dim_clinical_rna=19975, \n",
    "        input_dim_wsi_fcn=512, \n",
    "        input_dim_wsi_attention=64, \n",
    "        input_dim_final=96  # as from 32+64 = (out_dim of clinical_RNA) + (out_dim of WSI)\n",
    "    ): \n",
    "        # NOTE: no dropout for now\n",
    "        super(FusionNetwork, self).__init__()\n",
    "\n",
    "        # Clinical+RNA\n",
    "        self.clinical_rna_feedforward = Clinical_RNA_FeedForward(input_dim_clinical_rna, output_dim=32, dropout_ratio=0.5)\n",
    "        # WSI_FCN and WSI_Attention\n",
    "        self.wsi_fcn = WSI_FCN(input_dim_wsi_fcn, out_features=64)\n",
    "        self.attention = WSI_Attention(input_dim_wsi_attention, out_features=64)\n",
    "\n",
    "        # after fusion:\n",
    "        # TODO: rational -> book: many hidden neurons are good -> with regularization like dropout/weight decay\n",
    "        # for no. layers -> background knowledge and experimentation, for now 4 layers\n",
    "        hidden = [64, 32, 16, 8]\n",
    "\n",
    "        self.baby_feed_forward = nn.Sequential(\n",
    "            nn.Linear(input_dim_final, hidden[0]),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden[0], hidden[1]),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden[1], hidden[2]),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden[2], hidden[3]),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden[3], 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, tensor_clinical_rna, list_of_phenotype_tensors):\n",
    "\n",
    "        # Clinical+RNA:\n",
    "        extracted_clinical_rna = self.clinical_rna_feedforward(tensor_clinical_rna.to(device)) # (1, 32) shape\n",
    "        \n",
    "        # WSI_FCN\n",
    "        local_reps = [] # len=5\n",
    "        # here since tensors have different no. images in each of them\n",
    "        # we use the \"flexiblity\" of the FCN to output 1x64 for each cluster\n",
    "        for tensor in list_of_phenotype_tensors:\n",
    "            tensor = tensor.to(device)\n",
    "            cluster_rep = self.wsi_fcn(tensor) # each of shape (1,64) by pooling from tensors with varying dim\n",
    "            local_reps.append(cluster_rep)\n",
    "        # stack 5 local representation of shape (1,64) >> tensor of shape (5,64)\n",
    "        tensor_local_reps = torch.cat(local_reps)\n",
    "\n",
    "        # WSI_Attention:\n",
    "        wsi_aggregated_vector, att_weights = self.attention(tensor_local_reps) # from (5,64) to weighted vector (1,64)\n",
    "\n",
    "        # concantenate:\n",
    "        concatenated_features = torch.cat((extracted_clinical_rna, wsi_aggregated_vector), dim=1) # shape (1, 96)\n",
    "\n",
    "        risk_score = self.baby_feed_forward(concatenated_features)\n",
    "        return risk_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 64])\n",
      "torch.Size([1, 64])\n",
      "torch.Size([1, 32])\n",
      "tensor([[0.0000e+00, 0.0000e+00, 0.0000e+00, 3.5658e-01, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.0425e-01, 0.0000e+00,\n",
      "         1.2746e-01, 0.0000e+00, 7.0787e-03, 0.0000e+00, 0.0000e+00, 9.5001e-02,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         3.0261e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.8875e-01,\n",
      "         0.0000e+00, 0.0000e+00, 1.2209e-01, 1.0836e-01, 2.8932e-03, 2.2614e-01,\n",
      "         9.2687e-03, 6.3728e-03, 1.7022e-02, 3.8967e-03, 1.3704e-01, 9.0195e-02,\n",
      "         2.7706e-02, 4.3793e-01, 1.7130e-01, 2.0586e-02, 1.8607e-01, 1.7123e-01,\n",
      "         2.4836e-02, 7.5491e-05, 7.4750e-04, 3.8565e-02, 0.0000e+00, 0.0000e+00,\n",
      "         9.7185e-02, 0.0000e+00, 2.4274e-04, 2.3251e-01, 3.3170e-01, 3.7862e-01,\n",
      "         4.9373e-01, 0.0000e+00, 4.0629e-02, 9.4351e-04, 1.9384e-02, 4.2680e-01,\n",
      "         0.0000e+00, 2.0478e-01, 2.0699e-01, 3.4272e-02, 1.2658e-01, 3.3546e-01,\n",
      "         2.0275e-01, 3.2935e-01, 5.5159e-02, 4.1671e-03, 2.8822e-02, 4.6618e-02,\n",
      "         2.7219e-02, 1.1946e-01, 3.0639e-02, 2.1472e-02, 1.8393e-04, 5.0718e-02,\n",
      "         2.7776e-01, 3.7483e-01, 5.8126e-01, 1.3583e-03, 4.3354e-02, 3.8832e-01,\n",
      "         2.2270e-01, 1.4062e-01, 1.1395e-01, 1.2829e-01, 8.9928e-02, 1.6439e-02]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>) torch.Size([1, 96])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0.3337]], device='cuda:0', grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.rand(5, 64)\n",
    "a2 = WSI_Attention(64)(x)\n",
    "print(a2[0].shape)\n",
    "\n",
    "x = torch.rand(1, 300, 512) # (1, n_patches, 512)\n",
    "a1 = WSI_FCN(512)(x)\n",
    "print(a1.shape)\n",
    "\n",
    "x = torch.rand(1, 19975)\n",
    "a3 = Clinical_RNA_FeedForward(19975)(x)\n",
    "print(a3.shape)\n",
    "\n",
    "x1 = torch.rand(1, 19975)\n",
    "x2 = [torch.rand(1, 300, 512), torch.rand(1, 200, 512), torch.rand(1, 50, 512), torch.rand(1, 150, 512), torch.rand(1, 25, 512)]\n",
    "m = FusionNetwork().to(device)\n",
    "a4 = m(x1,x2)\n",
    "a4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 1/12 [00:54<10:01, 54.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.5029065608978271\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 2/12 [01:54<09:36, 57.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.051903247833252\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 3/12 [02:45<08:11, 54.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9399006962776184\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 4/12 [03:41<07:20, 55.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.3526320457458496\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 5/12 [04:32<06:15, 53.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.1010545492172241\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 6/12 [05:26<05:23, 53.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5114282369613647\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 7/12 [06:21<04:30, 54.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0871713161468506\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 8/12 [07:15<03:36, 54.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.1460793018341064\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 9/12 [08:09<02:42, 54.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2503597736358643\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 10/12 [09:03<01:47, 53.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8117800951004028\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 11/12 [09:50<00:51, 51.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0740275382995605\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12/12 [10:28<00:00, 52.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.708879828453064\n",
      "epoch 0, loss: 1.0448435992002487\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from datetime import datetime, date\n",
    "from lifelines.utils import concordance_index\n",
    "from utils import display_km_curves_fusion\n",
    "\n",
    "# from models import *\n",
    "# from data_utils import *\n",
    "\n",
    "# import configparser\n",
    "# config = configparser.ConfigParser()\n",
    "# config.read(\"config.ini\")\n",
    "\n",
    "random.seed(0)\n",
    "np.random.seed(0)\n",
    "torch.manual_seed(0)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "########################## LOSS ###############################################\n",
    "\n",
    "def negative_partial_log_likelihood(hazard_preds, times, events, device, eps=1e-8):\n",
    "\n",
    "    # This calculation credit to Travers Ching https://github.com/traversc/cox-nnet\n",
    "    # Cox-nnet: An artificial neural network method for prognosis prediction of high-throughput omics data\n",
    "    # flatten predictions\n",
    "\n",
    "    hazard_preds = hazard_preds.view(-1)\n",
    "    times = times.to(device, dtype=torch.float).view(-1)\n",
    "    events = events.to(device, dtype=torch.float).view(-1)\n",
    "\n",
    "    if events.sum() == 0:\n",
    "        return torch.tensor(0.0, device=device)\n",
    "\n",
    "    # compute risk set: R[i, j] = 1 if times[j] >= times[i]\n",
    "    # https://stackoverflow.com/questions/56646261/can-someone-please-explain-np-less-equal-outerrange1-18-range1-13\n",
    "    R_mat = torch.tensor(\n",
    "        np.greater_equal.outer(times.cpu(), times.cpu()).T.astype(np.float32), \n",
    "        device=device\n",
    "    )\n",
    "\n",
    "    # standardize theta/hazard prediction\n",
    "    theta = (hazard_preds - hazard_preds.mean()) / (hazard_preds.std(unbiased=False) + eps)\n",
    "\n",
    "    # compute the log risk set using the correct formula\n",
    "    # NOTE: use theta directly without an extra exp()\n",
    "    # First, mask the non-risk set entries by multiplying exp(theta) with R_mat,\n",
    "    # then take the log of the sum\n",
    "    log_risk_set = torch.log(torch.sum(torch.exp(theta) * R_mat, dim=1) + eps)\n",
    "\n",
    "    # negative partial likelihood only for events\n",
    "    loss = -torch.mean((theta - log_risk_set) * events)\n",
    "\n",
    "    return loss\n",
    "\n",
    "# one-batch\n",
    "# hazard_pred = torch.tensor([2.1, 1.8, 3.0, 0.5, 2.5], device=device)\n",
    "# time = torch.tensor([5, 3, 6, 2, 4], device=device)\n",
    "# event = torch.tensor([1, 1, 0, 1, 0], device=device)\n",
    "\n",
    "# one_batch_loss = negative_partial_log_likelihood(hazard_pred, time, event, device)\n",
    "# print(one_batch_loss)\n",
    "\n",
    "\n",
    "################## HYPERPARAMS ################################################\n",
    "\n",
    "n_epochs = 3\n",
    "lr = 0.001\n",
    "batch_size = 32\n",
    "dropout_ratio = 0.5\n",
    "weight_decay = 0.01\n",
    "# since we have relatively small dataset (~300 for training), high weidght decay may lead to udnerfitting\n",
    "# but we might have many interactions between parameters in the final feedforward, so let's try different ones\n",
    "# https://medium.com/towards-data-science/this-thing-called-weight-decay-a7cd4bcfccab\n",
    "# https://stackoverflow.com/questions/44452571/what-is-the-proper-way-to-weight-decay-for-adam-optimizer\n",
    "\n",
    "\n",
    "################### TRAIN #####################################################\n",
    "\n",
    "def custom_collate(batch):\n",
    "    \"\"\"\n",
    "    https://stackoverflow.com/questions/65279115/how-to-use-collate-fn-with-dataloaders \n",
    "    i.e. 32 batch_size\n",
    "    batch = [\n",
    "        (list_of_phenotype_tensors, time1, event1),    => case 1\n",
    "        (list_of_phenotype_tensors, time2, event2),    => case 2\n",
    "        ...                                            => case 32\n",
    "    ]\n",
    "\n",
    "    TODO: more explanation to come\n",
    "    \"\"\"\n",
    "    # each element in batch is a tuple: \n",
    "    # (clinical_rna_tensor, list_of_phenotype_tensors, time, event)\n",
    "    list_of_clinical_rna_features, list_of_lists_of_5_tensors, times, events = zip(*batch)\n",
    "    # i.e. [patient_1_clinical_rna_t1, patient_2_clinical_rna_t2,..., patient32_clinical_rna_t32]\n",
    "    # i.e. [[t1,t2,t3,t4,t5],[t1,t2,t3,t4,t5],...,[t1,t2,t3,t4,t5]] = [32 lists]\n",
    "    \n",
    "    return (\n",
    "        list(list_of_clinical_rna_features),\n",
    "        list(list_of_lists_of_5_tensors),\n",
    "        torch.tensor(times),\n",
    "        torch.tensor(events)\n",
    "    )\n",
    "\n",
    "# dataset and splitting\n",
    "dataset = MultimodalDataset(\n",
    "    config[\"clinical\"][\"cleaned_clinical_json\"],\n",
    "    config[\"rna\"][\"cleaned_rna\"],\n",
    "    config[\"wsi\"][\"wsi_slides\"]\n",
    ")\n",
    "\n",
    "train_size, val_size = int(0.7 * len(dataset)), int(0.15 * len(dataset))\n",
    "test_size = len(dataset) - train_size - val_size\n",
    "train, val, test = random_split(dataset, [train_size, val_size, test_size])\n",
    "\n",
    "# loading data\n",
    "train_loader = DataLoader(train, batch_size=batch_size, shuffle=True, collate_fn=custom_collate)\n",
    "val_loader = DataLoader(val, batch_size=val_size, shuffle=False, collate_fn=custom_collate)\n",
    "test_loader = DataLoader(test, batch_size=test_size, shuffle=False, collate_fn=custom_collate)\n",
    "\n",
    "# initiate model\n",
    "model = FusionNetwork(\n",
    "    input_dim_clinical_rna=19975,\n",
    "    input_dim_wsi_fcn=512,\n",
    "    input_dim_wsi_attention=64,\n",
    "    input_dim_final=96\n",
    ")\n",
    "model.to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "\n",
    "\n",
    "print(\"begin to train\")\n",
    "# training loops\n",
    "for epoch in range(n_epochs):\n",
    "\n",
    "    model.train()\n",
    "    train_loss = 0.0 \n",
    "\n",
    "    # each batch contains 32 cases!\n",
    "    for batch in tqdm(train_loader):\n",
    "        batch_clinical_rna_features, batch_lists_phenotype_clusters, batch_times, batch_events = batch\n",
    "\n",
    "        risk_scores = [] # list of  32 risk scores\n",
    "        for (clinical_rna_features, list_of_phenotype_tensors) in zip(batch_clinical_rna_features, batch_lists_phenotype_clusters):\n",
    "            # process each sample in the batch of 32\n",
    "            risk_score = model(clinical_rna_features, list_of_phenotype_tensors)\n",
    "            risk_scores.append(risk_score)\n",
    "\n",
    "        # convert to tensor type\n",
    "        risk_scores = torch.stack(risk_scores) # of shape (batch_size, 1) or (32,1) \n",
    "\n",
    "        # TODO: explain in detail: meaning of loss of 32 cases in the batch\n",
    "        optimizer.zero_grad() # zero the parameter gradients\n",
    "        loss = negative_partial_log_likelihood(risk_scores, batch_times.to(device), batch_events.to(device), device)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "\n",
    "    print(f\"epoch {epoch}, loss: {train_loss / len(train_loader)}\")\n",
    "\n",
    "print(\"finished training\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "####################### VALIDATION ############################################\n",
    "\n",
    "print(\"begin to validate\")\n",
    "model.eval()\n",
    "\n",
    "val_risks = []\n",
    "val_times = []\n",
    "val_events = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(val_loader):\n",
    "        # unpack the batch\n",
    "        batch_clinical_rna_features, batch_lists_phenotype_clusters, batch_times, batch_events = batch\n",
    "        \n",
    "        # move times and events to the device\n",
    "        batch_times = batch_times.to(device)\n",
    "        batch_events = batch_events.to(device)\n",
    "        \n",
    "        # tterate over each sample in the batch\n",
    "        for i, (clinical_rna_features, list_of_phenotype_tensors) in enumerate(zip(batch_clinical_rna_features, batch_lists_phenotype_clusters)):\n",
    "            \n",
    "            risk_score = model(clinical_rna_features, list_of_phenotype_tensors)\n",
    "            \n",
    "            val_risks.append(risk_score.item())\n",
    "            val_times.append(batch_times[i].item())\n",
    "            val_events.append(batch_events[i].item())\n",
    "\n",
    "val_c_index = concordance_index(val_times, -val_risks, val_events)\n",
    "print(f\"validation c-index: {val_c_index}\\n\")\n",
    "display_km_curves_fusion(val_risks, val_times, val_events, \"validation set\", save_figure=False)\n",
    "\n",
    "saved_model = True\n",
    "if saved_model:\n",
    "    current_time = datetime.now().strftime(\"%H-%M-%S\")\n",
    "    checkpoint_path = f\"checkpoints/trained-model_{date.today()}_{current_time}.pth\"\n",
    "    torch.save({\n",
    "        'model_state_dict': model.state_dict(), # all weights all models\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'batch_size': batch_size,\n",
    "        'dropout_ratio': dropout_ratio,\n",
    "        'learning_rate': lr,\n",
    "        'weight_decay': weight_decay,\n",
    "        'n_epochs': n_epochs,\n",
    "        'random_seed': 0,\n",
    "        'val_c_index': val_c_index\n",
    "    }, checkpoint_path)\n",
    "    print(f\"saved model: {checkpoint_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_km_curves_fusion(risks, times, events, title_name, save_figure=False):\n",
    "    risks = np.array(risks)\n",
    "    times = np.array(times)\n",
    "    events = np.array(events)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(10, 8)) \n",
    "    \n",
    "    high_risk_idx = risks > np.median(risks)\n",
    "    low_risk_idx = risks <= np.median(risks)\n",
    "    kmf_high = KaplanMeierFitter()\n",
    "    kmf_low = KaplanMeierFitter()\n",
    "    # fit low risk\n",
    "    kmf_low.fit(times[low_risk_idx], event_observed=events[low_risk_idx], label='Low risk')\n",
    "    kmf_low.plot_survival_function(ax=ax, ci_show=True)\n",
    "\n",
    "    # fit high risk\n",
    "    kmf_high.fit(times[high_risk_idx], event_observed=events[high_risk_idx], label='High risk')\n",
    "    kmf_high.plot_survival_function(ax=ax, ci_show=True)\n",
    "    ax.set_title(f\"Kaplan-Meier curve for final model on {title_name}\")\n",
    "    ax.set_xlabel(\"Time\")\n",
    "    ax.set_ylabel(\"Survival probability\")\n",
    "    plt.legend()\n",
    "    if save_figure:\n",
    "        plt.savefig(f\"evaluation-results/{title_name}-baseline.png\")\n",
    "    else:\n",
    "        plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
