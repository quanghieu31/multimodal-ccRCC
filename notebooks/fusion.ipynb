{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "import configparser\n",
    "config = configparser.ConfigParser()\n",
    "config.read(\"../config.ini\")\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "class PatientClinicalDataset(Dataset):\n",
    "    \"\"\"\n",
    "    from csv, so getitem would be something like .loc[idx]\n",
    "    \"\"\"\n",
    "    def __init__(self, csv_file_path):\n",
    "        self.csv_file_path = csv_file_path\n",
    "        self.df = pd.read_csv(self.csv_file_path).drop([\"time\", \"event\"], axis=1)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        patient_series = self.df.iloc[idx]\n",
    "        return patient_series # includes the submitter_id!\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.df.shape[0]\n",
    "\n",
    "\n",
    "class PatientRNASeqDataset(Dataset):\n",
    "    \"\"\"\n",
    "    a csv file, 534 rows and ~20000 columns for normalized RNA-seq counts\n",
    "    \"\"\"\n",
    "    def __init__(self, rna_file_path):\n",
    "        self.rna_file_path = rna_file_path\n",
    "        self.df = pd.read_csv(self.rna_file_path)\n",
    "        self.df.set_index(\"submitter_id\", inplace=True)\n",
    "\n",
    "    def __getitem__(self, case_id):\n",
    "        gene_expressions = list(self.df.loc[case_id])\n",
    "        tensor_gene_expressions = torch.tensor(gene_expressions, dtype=torch.float32).unsqueeze(0)\n",
    "        return tensor_gene_expressions # [1, 19962]\n",
    "\n",
    "\n",
    "class PatientWSIDataset(Dataset):\n",
    "    \"\"\"\n",
    "    dataset for accessing a patient's list of patches features, each is of shape (1, n_patches, n_features)\n",
    "    \"\"\"\n",
    "    def __init__(self, wsi_dir):\n",
    "\n",
    "        self.wsi_dir = wsi_dir\n",
    "        self.case_ids = list(os.listdir(self.wsi_dir))\n",
    "        self.dict_case_id_path = {\n",
    "            c: os.path.join(self.wsi_dir, c) + \"/patches_features.npy\" for c in self.case_ids\n",
    "        }\n",
    "\n",
    "    def __getitem__(self, case_id):\n",
    "        # grab the list of 5 clusters for this case_id\n",
    "\n",
    "        case_npy_file = self.dict_case_id_path[case_id]\n",
    "        patches_features = np.load(case_npy_file, allow_pickle=True).item()\n",
    "        \n",
    "        cluster_ids = self.clustering(patches_features)\n",
    "\n",
    "        features_list = list(patches_features.values())\n",
    "        unique_clusters = np.unique(cluster_ids)\n",
    "        n_clusters = len(unique_clusters)\n",
    "\n",
    "        list_phenotype_tensors = [] # list of tensors, each tensor is a cluster's features of shape i.e. (1, 15 patches in this cluster, 512 as output of resnet18)\n",
    "\n",
    "        for cluster in unique_clusters:\n",
    "            cluster_features = [features for features, c in zip(features_list, cluster_ids) if c == cluster]\n",
    "            tensor_cluster_features = torch.from_numpy(np.array(cluster_features)).float().unsqueeze(0) # (1, n_patches, n_features)\n",
    "\n",
    "            list_phenotype_tensors.append(tensor_cluster_features.to(device))\n",
    "\n",
    "        return list_phenotype_tensors # [t1,t2,t3,t4,t5]\n",
    "\n",
    "    def clustering(self, patches_features, n_clusters=5):\n",
    "        feature_vectors = list(patches_features.values())\n",
    "        kmeans = KMeans(n_clusters=n_clusters, random_state=0, n_init=50)\n",
    "        cluster_ids = kmeans.fit_predict(feature_vectors)\n",
    "        return cluster_ids\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.case_ids)\n",
    "\n",
    "\n",
    "\n",
    "## Fusion multimodal\n",
    "\n",
    "class MultimodalDataset(Dataset):\n",
    "    \"\"\"\n",
    "    takes three data paths (clinical, rna-seq, histopath images)\n",
    "    build a data out of 'em\n",
    "    \"\"\"\n",
    "    def __init__(self, \n",
    "        clinical_data_path, \n",
    "        rna_seq_data_path, \n",
    "        wsi_data_path\n",
    "    ):\n",
    "        # prepare labels from the clinical data path\n",
    "        self.LABELS_DF = pd.read_csv(clinical_data_path)[[\"submitter_id\", \"event\", \"time\"]]\n",
    "        # then by initializing the clinical_dataset, remove the time and event from the clinical features:\n",
    "        self.clinical_dataset = PatientClinicalDataset(clinical_data_path)\n",
    "\n",
    "        # initialize the datasets for each modality\n",
    "        self.wsi_dataset = PatientWSIDataset(wsi_data_path)\n",
    "        self.rna_dataset = PatientRNASeqDataset(rna_seq_data_path)\n",
    "\n",
    "        # label dictionary with key=submitter_id and value=(event,time) for easy lookup\n",
    "        self.labels_dict = {}\n",
    "        for submitter_id, event, time in zip(self.LABELS_DF[\"submitter_id\"], self.LABELS_DF[\"event\"], self.LABELS_DF[\"time\"]):\n",
    "            self.labels_dict[submitter_id] = {\"event\": event, \"time\": time}\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.clinical_dataset)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        # (1) start from clinical dataset\n",
    "        patient_series = self.clinical_dataset[idx]\n",
    "        case_id = patient_series[\"submitter_id\"]\n",
    "        clinical_features = list(patient_series.drop([\"submitter_id\"]))\n",
    "        tensor_clinical_features = torch.tensor(clinical_features, dtype=torch.float32).unsqueeze(0) \n",
    "        # above: add batch dim (1, 13) instead of (13)\n",
    "\n",
    "        # (2) grab the tensor for 20000 (processed) gene counts for that case id\n",
    "        tensor_rna_genes = self.rna_dataset[case_id] # (1, 19962)\n",
    "\n",
    "        # (2.5) NOTE: to save time for this moment, I will concat the clinical and rna together \n",
    "        # and build one feed-forward for the combined\n",
    "        tensor_clinical_rna = torch.cat((tensor_clinical_features, tensor_rna_genes), dim=1) # (1, 19975)\n",
    "\n",
    "        # (3) collect the list of phenotype tensor for that case id\n",
    "        list_of_phenotype_tensors = self.wsi_dataset[case_id]\n",
    "\n",
    "        # (4) labels\n",
    "        time = self.labels_dict[case_id][\"time\"]\n",
    "        event = self.labels_dict[case_id][\"event\"]\n",
    "\n",
    "        return (\n",
    "            tensor_clinical_rna,\n",
    "            list_of_phenotype_tensors,\n",
    "            time,\n",
    "            event\n",
    "        )\n",
    "\n",
    "        # return (\n",
    "        #     tensor_clinical_features, \n",
    "        #     tensor_rna_genes, \n",
    "        #     list_of_phenotype_tensors,\n",
    "        #     time,\n",
    "        #     event\n",
    "        # )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_data = MultimodalDataset(\n",
    "    config[\"clinical\"][\"cleaned_clinical_json\"],\n",
    "    config[\"rna\"][\"cleaned_rna\"],\n",
    "    config[\"wsi\"][\"wsi_slides\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 first gene counts:\n",
      "tensor(2.4332)\n",
      "tensor(0.)\n",
      "tensor(3.4071)\n",
      "tensor(2.7216)\n",
      "tensor(1.6839)\n",
      "tensor(1.7558)\n",
      "tensor(3.9939)\n",
      "first 13 in clinical and rna:\n",
      "tensor(0.)\n",
      "tensor(1.1109)\n",
      "tensor(0.)\n",
      "tensor(0.)\n",
      "tensor(0.)\n",
      "tensor(1.)\n",
      "tensor(0.)\n",
      "tensor(0.)\n",
      "tensor(0.)\n",
      "tensor(0.)\n",
      "tensor(0.)\n",
      "tensor(1.)\n",
      "tensor(0.)\n"
     ]
    }
   ],
   "source": [
    "case0 = check_data[5]\n",
    "clin_rna, list_tensors = case0[0], case0[1]\n",
    "\n",
    "print(\"5 first gene counts:\")\n",
    "for i in clin_rna.flatten()[13:20]:\n",
    "    print(i)\n",
    "\n",
    "print(\"first 13 in clinical and rna:\")\n",
    "for i in clin_rna.flatten()[0:13]:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1148, 512])\n",
      "torch.Size([1, 1078, 512])\n",
      "torch.Size([1, 984, 512])\n",
      "torch.Size([1, 966, 512])\n",
      "torch.Size([1, 824, 512])\n",
      "\n",
      "torch.Size([1, 1148, 512])\n",
      "torch.Size([1, 1078, 512])\n",
      "torch.Size([1, 984, 512])\n",
      "torch.Size([1, 966, 512])\n",
      "torch.Size([1, 824, 512])\n"
     ]
    }
   ],
   "source": [
    "for tensor in list_tensors:\n",
    "    print(tensor.shape)\n",
    "\n",
    "print()\n",
    "check_wsi = PatientWSIDataset(config[\"wsi\"][\"wsi_slides\"])[\"TCGA-BP-4352\"]\n",
    "for tensor in check_wsi:\n",
    "    print(tensor.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import random\n",
    "import os\n",
    "import math\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "random.seed(0)\n",
    "np.random.seed(0)\n",
    "torch.manual_seed(0)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "dropout_ratio = 0.5\n",
    "\n",
    "class WSI_FCN(nn.Module):\n",
    "    \"\"\"\n",
    "    https://arxiv.org/abs/2009.11169\n",
    "    fully convolutional network for WSI\n",
    "    takes 1 phenotype tensor/cluster of shape (1, n_patches, 512)\n",
    "    outputs a local representation of that phenotype tensor of shape (1, 64)\n",
    "    why FCN? on the numerical vectors? \n",
    "        - utilize the kernel, and especially kernel_size=1 because we can't have kernel_size>1 for randomly picked patches from the histopathology slides\n",
    "        - so why not a simple fully connected network (MLP)? it's because it requires inputs with fixed dimension and we have varying number of patches for each cluster\n",
    "    also, note that a patch -> FCN -> (1,64) shape. So if we have 300 patches or (300,64) shape, we would use avgpooling and get (1,64) as the final output for that cluster\n",
    "    \"\"\"\n",
    "    def __init__(self, in_features, out_features=64):\n",
    "        super(WSI_FCN, self).__init__()\n",
    "        # conv1d because we only have a tensor of shape (N, C, L) = (1, 512, i.e. 272)\n",
    "        self.conv = nn.Conv1d(in_features, out_features, \n",
    "            kernel_size=1 # kernel size = 1 is extremely important because we only want to the a single patch to be learned, \n",
    "            # doing i.e. 3x3 is no use because the patches are picked randomly, so can't use spatial relationship here\n",
    "        )\n",
    "        self.relu = nn.ReLU()\n",
    "        # adaptive avg pooling to get a local representation of the phenotype tensor\n",
    "        # NOTE: adapative pooling from (64, 300 patches) to (64,1) as the final output of that cluster\n",
    "        self.pool = nn.AdaptiveAvgPool1d(1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: (1, n_patches, n_features)\n",
    "        # permute to (1, n_features, n_patches) so that n_features become channels why? because tensor in pytorch reads () https://stackoverflow.com/questions/51541532/which-part-of-pytorch-tensor-represents-channels\n",
    "        # n_patches is the length of the sequence. why?\n",
    "        # FYI: for a conv2D, input should be in (N, C, H, W) format. N is the number of samples/batch_size. C is the channels. H and W are height and width resp: https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html#torch.nn.Conv2d \n",
    "        # but here we have conv1d: https://pytorch.org/docs/stable/generated/torch.nn.Conv1d.html#torch.nn.Conv1d\n",
    "\n",
    "        x = x.permute(0, 2, 1) # (1, 512, 300 patches)\n",
    "        x = self.conv(x) # (1, 64, 300 patches)\n",
    "        x = self.relu(x) # (1, 64, 300 patches)\n",
    "        x = self.pool(x) # (1, 64, 1)\n",
    "        x = x.view(x.size()[0], -1) # (1, 64)\n",
    "        return x # (1, 64)\n",
    "\n",
    "\n",
    "class WSI_Attention(nn.Module):\n",
    "    \"\"\"\n",
    "    https://arxiv.org/abs/2009.11169 \n",
    "    pooling attention mechanism for WSI\n",
    "    takes a local representation of the phenotype tensor of shape (5, 64) in which 5 is the number of clusters\n",
    "    outputs a global representation of the phenotype tensors of shape (64-dim) which is a weighted sum across 5 clusters for 64 features\n",
    "        each case has a global representation\n",
    "    \"\"\"\n",
    "    def __init__(self, in_features, out_features=64):\n",
    "        super(WSI_Attention, self).__init__()\n",
    "        self.attention = nn.Sequential(\n",
    "            nn.Linear(in_features, out_features),\n",
    "            nn.Tanh(),  # tanh because we want to normalize the weights\n",
    "            # why tanh() >> output values in range (-1,1), allowing both neg and pos values, often used in attention scores\n",
    "            nn.Linear(out_features, 1),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # apply softmax because we have different number of clusters for each case\n",
    "        # x: (5, 64) stack representation of 5 clusters/phenotypes\n",
    "        scores = self.attention(x) # (5, 1)\n",
    "        att_weights = torch.softmax(scores, dim=0).T # (1,5) which is probabilities\n",
    "        # weighted sum across the 5 clusters:\n",
    "        weights_applied = att_weights @ x  # (5, 64) = (1,5) @ (5,64)\n",
    "        # weighted_sum_vector = torch.sum(weights_applied, dim=0) # (1, 64) or (64)\n",
    "        return weights_applied, att_weights\n",
    "\n",
    "\n",
    "class Clinical_RNA_FeedForward(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim=32, dropout_ratio=dropout_ratio):\n",
    "        # https://www.cs.toronto.edu/~hinton/absps/JMLRdropout.pdf\n",
    "        # https://arxiv.org/pdf/1207.0580\n",
    "        # For fully connected layers, dropout in all hidden layers works\n",
    "        # better than dropout in only one hidden layer and more extreme probabilities tend to be worse,\n",
    "        # which is why we have used 0.5 throughout this paper\n",
    "        \n",
    "        super(Clinical_RNA_FeedForward, self).__init__()\n",
    "\n",
    "        # hidden = [512, 256, 256, 64, 64, 32]\n",
    "\n",
    "        # self.feedforward = nn.Sequential(\n",
    "        #     nn.Linear(input_dim, hidden[0]),\n",
    "        #     nn.ReLU(),\n",
    "        #     nn.Dropout(dropout_ratio),\n",
    "        #     nn.Linear(hidden[0], hidden[1]),\n",
    "        #     nn.ReLU(),\n",
    "        #     nn.Dropout(dropout_ratio),\n",
    "        #     nn.Linear(hidden[1], hidden[2]),\n",
    "        #     nn.ReLU(),\n",
    "        #     nn.Dropout(dropout_ratio),\n",
    "        #     nn.Linear(hidden[2], hidden[3]),\n",
    "        #     nn.ReLU(),\n",
    "        #     nn.Dropout(dropout_ratio),\n",
    "        #     nn.Linear(hidden[3], hidden[4]),\n",
    "        #     nn.ReLU(),\n",
    "        #     nn.Dropout(dropout_ratio),   \n",
    "        #     nn.Linear(hidden[4], hidden[5]),\n",
    "        #     nn.ReLU(),\n",
    "        #     nn.Dropout(dropout_ratio),      \n",
    "        #     nn.Linear(hidden[5], output_dim),\n",
    "        #     nn.ReLU(),\n",
    "        #     nn.Dropout(dropout_ratio),    \n",
    "        # )\n",
    "\n",
    "        # [1024, 512, 512, 256, 256, 128, 128, 64, 64, 32]\n",
    "\n",
    "        hidden = [1024, 1024, 512, 512, 256, 256, 128, 128, 64, 64, 32] # TODO: next time try\n",
    "\n",
    "        self.feedforward = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden[0]), nn.ReLU(), nn.Dropout(dropout_ratio),\n",
    "            nn.Linear(hidden[0], hidden[1]), nn.ReLU(), nn.Dropout(dropout_ratio),\n",
    "            nn.Linear(hidden[1], hidden[2]), nn.ReLU(), nn.Dropout(dropout_ratio),  \n",
    "            nn.Linear(hidden[2], hidden[3]), nn.ReLU(), nn.Dropout(dropout_ratio),\n",
    "            nn.Linear(hidden[3], hidden[4]), nn.ReLU(), nn.Dropout(dropout_ratio),\n",
    "            nn.Linear(hidden[4], hidden[5]), nn.ReLU(), nn.Dropout(dropout_ratio),\n",
    "            nn.Linear(hidden[5], hidden[6]), nn.ReLU(), nn.Dropout(dropout_ratio),\n",
    "            nn.Linear(hidden[6], hidden[7]), nn.ReLU(), nn.Dropout(dropout_ratio),\n",
    "            nn.Linear(hidden[7], hidden[8]), nn.ReLU(), nn.Dropout(dropout_ratio),\n",
    "            nn.Linear(hidden[8], hidden[9]), nn.ReLU(), nn.Dropout(dropout_ratio),\n",
    "            nn.Linear(hidden[9], hidden[10]), nn.ReLU(), nn.Dropout(dropout_ratio),\n",
    "            nn.Linear(hidden[10], output_dim), nn.ReLU(), nn.Dropout(dropout_ratio),    \n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.feedforward(x)\n",
    "        return out\n",
    "\n",
    "\n",
    "# FusionFeedForward\n",
    "class FusionNetwork(nn.Module):\n",
    "    def __init__(self, \n",
    "        input_dim_clinical_rna=19975, \n",
    "        input_dim_wsi_fcn=512, \n",
    "        input_dim_wsi_attention=64, \n",
    "        input_dim_final=96  # as from 32+64 = (out_dim of clinical_RNA) + (out_dim of WSI)\n",
    "    ): \n",
    "        # NOTE: no dropout for now\n",
    "        super(FusionNetwork, self).__init__()\n",
    "\n",
    "        # Clinical+RNA\n",
    "        self.clinical_rna_feedforward = Clinical_RNA_FeedForward(input_dim_clinical_rna, output_dim=32, dropout_ratio=dropout_ratio)\n",
    "        # WSI_FCN and WSI_Attention\n",
    "        self.wsi_fcn = WSI_FCN(input_dim_wsi_fcn, out_features=64)\n",
    "        self.attention = WSI_Attention(input_dim_wsi_attention, out_features=64)\n",
    "\n",
    "        # after fusion:\n",
    "        # TODO: rational -> book: many hidden neurons are good -> with regularization like dropout/weight decay\n",
    "        # for no. layers -> background knowledge and experimentation, for now 4 layers\n",
    "        hidden = [64, 32, 16, 8]\n",
    "\n",
    "        self.baby_feed_forward = nn.Sequential(\n",
    "            nn.Linear(input_dim_final, hidden[0]),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden[0], hidden[1]),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden[1], hidden[2]),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden[2], hidden[3]),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden[3], 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, tensor_clinical_rna, list_of_phenotype_tensors):\n",
    "\n",
    "        # Clinical+RNA:\n",
    "        extracted_clinical_rna = self.clinical_rna_feedforward(tensor_clinical_rna.to(device)) # (1, 32) shape\n",
    "        \n",
    "        # WSI_FCN\n",
    "        local_reps = [] # len=5\n",
    "        # here since tensors have different no. images in each of them\n",
    "        # we use the \"flexiblity\" of the FCN to output 1x64 for each cluster\n",
    "        for tensor in list_of_phenotype_tensors:\n",
    "            tensor = tensor.to(device)\n",
    "            cluster_rep = self.wsi_fcn(tensor) # each of shape (1,64) by pooling from tensors with varying dim\n",
    "            local_reps.append(cluster_rep)\n",
    "        # stack 5 local representation of shape (1,64) >> tensor of shape (5,64)\n",
    "        tensor_local_reps = torch.cat(local_reps)\n",
    "\n",
    "        # WSI_Attention:\n",
    "        wsi_aggregated_vector, att_weights = self.attention(tensor_local_reps) # from (5,64) to weighted vector (1,64)\n",
    "\n",
    "        # concantenate:\n",
    "        concatenated_features = torch.cat((extracted_clinical_rna, wsi_aggregated_vector), dim=1) # shape (1, 96)\n",
    "\n",
    "        risk_score = self.baby_feed_forward(concatenated_features)\n",
    "        return risk_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 64])\n",
      "torch.Size([1, 64])\n",
      "torch.Size([1, 32])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([[0.2094]], device='cuda:0', grad_fn=<AddmmBackward0>),\n",
       " torch.Size([1, 1]))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sanity check\n",
    "\n",
    "x = torch.rand(5, 64)\n",
    "a2 = WSI_Attention(64)(x)\n",
    "print(a2[0].shape)\n",
    "\n",
    "x = torch.rand(1, 300, 512) # (1, n_patches, 512)\n",
    "a1 = WSI_FCN(512)(x)\n",
    "print(a1.shape)\n",
    "\n",
    "x = torch.rand(1, 19975)\n",
    "a3 = Clinical_RNA_FeedForward(19975)(x)\n",
    "print(a3.shape)\n",
    "\n",
    "x1 = torch.rand(1, 19975)\n",
    "x2 = [torch.rand(1, 300, 512), torch.rand(1, 200, 512), torch.rand(1, 50, 512), torch.rand(1, 150, 512), torch.rand(1, 25, 512)]\n",
    "m = FusionNetwork().to(device)\n",
    "a4 = m(x1,x2)\n",
    "a4, a4.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "begin to train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12/12 [16:18<00:00, 81.54s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0, loss: 1.1736237357060115\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12/12 [18:15<00:00, 91.25s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1, loss: 1.106985181570053\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12/12 [13:06<00:00, 65.50s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2, loss: 1.0525387277205784\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12/12 [10:21<00:00, 51.75s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 3, loss: 1.052827815214793\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12/12 [10:13<00:00, 51.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 4, loss: 1.04255161434412\n",
      "finished training\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from datetime import datetime, date\n",
    "from lifelines.utils import concordance_index\n",
    "from utils import display_km_curves_fusion\n",
    "\n",
    "# from models import *\n",
    "# from data_utils import *\n",
    "\n",
    "# import configparser\n",
    "# config = configparser.ConfigParser()\n",
    "# config.read(\"config.ini\")\n",
    "\n",
    "random.seed(0)\n",
    "np.random.seed(0)\n",
    "torch.manual_seed(0)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "########################## LOSS ###############################################\n",
    "\n",
    "def negative_partial_log_likelihood(hazard_preds, times, events, device, eps=1e-8):\n",
    "\n",
    "    # This calculation credit to Travers Ching https://github.com/traversc/cox-nnet\n",
    "    # Cox-nnet: An artificial neural network method for prognosis prediction of high-throughput omics data\n",
    "    # flatten predictions\n",
    "\n",
    "    hazard_preds = hazard_preds.view(-1)\n",
    "    times = times.to(device, dtype=torch.float).view(-1)\n",
    "    events = events.to(device, dtype=torch.float).view(-1)\n",
    "\n",
    "    if events.sum() == 0:\n",
    "        return torch.tensor(0.0, device=device)\n",
    "\n",
    "    # compute risk set: R[i, j] = 1 if times[j] >= times[i]\n",
    "    # https://stackoverflow.com/questions/56646261/can-someone-please-explain-np-less-equal-outerrange1-18-range1-13\n",
    "    R_mat = torch.tensor(\n",
    "        np.greater_equal.outer(times.cpu(), times.cpu()).T.astype(np.float32), \n",
    "        device=device\n",
    "    )\n",
    "\n",
    "    # standardize theta/hazard prediction\n",
    "    theta = (hazard_preds - hazard_preds.mean()) / (hazard_preds.std(unbiased=False) + eps)\n",
    "\n",
    "    # compute the log risk set using the correct formula\n",
    "    # NOTE: use theta directly without an extra exp()\n",
    "    # First, mask the non-risk set entries by multiplying exp(theta) with R_mat,\n",
    "    # then take the log of the sum\n",
    "    log_risk_set = torch.log(torch.sum(torch.exp(theta) * R_mat, dim=1) + eps)\n",
    "\n",
    "    # negative partial likelihood only for events\n",
    "    loss = -torch.mean((theta - log_risk_set) * events)\n",
    "\n",
    "    return loss\n",
    "\n",
    "# one-batch\n",
    "# hazard_pred = torch.tensor([2.1, 1.8, 3.0, 0.5, 2.5], device=device)\n",
    "# time = torch.tensor([5, 3, 6, 2, 4], device=device)\n",
    "# event = torch.tensor([1, 1, 0, 1, 0], device=device)\n",
    "\n",
    "# one_batch_loss = negative_partial_log_likelihood(hazard_pred, time, event, device)\n",
    "# print(one_batch_loss)\n",
    "\n",
    "################## HYPERPARAMS ################################################\n",
    "\n",
    "# https://arxiv.org/pdf/1206.5533 (guide to choose hyperparams)\n",
    "n_epochs = 5\n",
    "lr = 0.0001\n",
    "batch_size = 32\n",
    "\n",
    "# regularizations:\n",
    "dropout_ratio = 0.5\n",
    "weight_decay = 0.0001\n",
    "\n",
    "# since we have relatively small dataset (~300 for training), high weidght decay may lead to udnerfitting\n",
    "# but we might have many interactions between parameters in the final feedforward, so let's try different ones\n",
    "# https://medium.com/towards-data-science/this-thing-called-weight-decay-a7cd4bcfccab\n",
    "# https://stackoverflow.com/questions/44452571/what-is-the-proper-way-to-weight-decay-for-adam-optimizer\n",
    "\n",
    "################### TRAIN #####################################################\n",
    "\n",
    "def custom_collate(batch):\n",
    "    \"\"\"\n",
    "    https://stackoverflow.com/questions/65279115/how-to-use-collate-fn-with-dataloaders \n",
    "    i.e. 32 batch_size\n",
    "    batch = [\n",
    "        (list_of_phenotype_tensors, time1, event1),    => case 1\n",
    "        (list_of_phenotype_tensors, time2, event2),    => case 2\n",
    "        ...                                            => case 32\n",
    "    ]\n",
    "\n",
    "    TODO: more explanation to come\n",
    "    \"\"\"\n",
    "    # each element in batch is a tuple: \n",
    "    # (clinical_rna_tensor, list_of_phenotype_tensors, time, event)\n",
    "    list_of_clinical_rna_features, list_of_lists_of_5_tensors, times, events = zip(*batch)\n",
    "    # i.e. [patient_1_clinical_rna_t1, patient_2_clinical_rna_t2,..., patient32_clinical_rna_t32]\n",
    "    # i.e. [[t1,t2,t3,t4,t5],[t1,t2,t3,t4,t5],...,[t1,t2,t3,t4,t5]] = [32 lists]\n",
    "    \n",
    "    return (\n",
    "        list(list_of_clinical_rna_features),\n",
    "        list(list_of_lists_of_5_tensors),\n",
    "        torch.tensor(times),\n",
    "        torch.tensor(events)\n",
    "    )\n",
    "\n",
    "# dataset and splitting\n",
    "dataset = MultimodalDataset(\n",
    "    config[\"clinical\"][\"cleaned_clinical_json\"],\n",
    "    config[\"rna\"][\"cleaned_rna\"],\n",
    "    config[\"wsi\"][\"wsi_slides\"]\n",
    ")\n",
    "\n",
    "train_size, val_size = int(0.7 * len(dataset)), int(0.15 * len(dataset))\n",
    "test_size = len(dataset) - train_size - val_size\n",
    "train, val, test = random_split(dataset, [train_size, val_size, test_size])\n",
    "\n",
    "# loading data\n",
    "train_loader = DataLoader(train, batch_size=batch_size, shuffle=True, collate_fn=custom_collate)\n",
    "val_loader = DataLoader(val, batch_size=val_size, shuffle=False, collate_fn=custom_collate)\n",
    "test_loader = DataLoader(test, batch_size=test_size, shuffle=False, collate_fn=custom_collate)\n",
    "\n",
    "# initiate model\n",
    "model = FusionNetwork(\n",
    "    input_dim_clinical_rna=19975,\n",
    "    input_dim_wsi_fcn=512,\n",
    "    input_dim_wsi_attention=64,\n",
    "    input_dim_final=96\n",
    ")\n",
    "model.to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "\n",
    "\n",
    "print(\"begin to train\")\n",
    "# training loops\n",
    "for epoch in range(n_epochs):\n",
    "\n",
    "    model.train()\n",
    "    train_loss = 0.0 \n",
    "\n",
    "    # each batch contains 32 cases!\n",
    "    for batch in tqdm(train_loader):\n",
    "        batch_clinical_rna_features, batch_lists_phenotype_clusters, batch_times, batch_events = batch\n",
    "\n",
    "        risk_scores = [] # list of  32 risk scores\n",
    "        for (clinical_rna_features, list_of_phenotype_tensors) in zip(batch_clinical_rna_features, batch_lists_phenotype_clusters):\n",
    "            # process each sample in the batch of 32\n",
    "            risk_score = model(clinical_rna_features, list_of_phenotype_tensors)\n",
    "            risk_scores.append(risk_score)\n",
    "\n",
    "        # convert to tensor type\n",
    "        risk_scores = torch.stack(risk_scores) # of shape (batch_size, 1) or (32,1) \n",
    "\n",
    "        # TODO: explain in detail: meaning of loss of 32 cases in the batch\n",
    "        optimizer.zero_grad() # zero the parameter gradients\n",
    "        loss = negative_partial_log_likelihood(risk_scores, batch_times.to(device), batch_events.to(device), device)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "\n",
    "    print(f\"epoch {epoch}, loss: {train_loss / len(train_loader)}\")\n",
    "\n",
    "print(\"finished training\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "begin to validate\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [02:02<00:00, 122.30s/it]\n"
     ]
    }
   ],
   "source": [
    "####################### VALIDATION ############################################\n",
    "\n",
    "print(\"begin to validate\")\n",
    "model.eval()\n",
    "\n",
    "val_risks = []\n",
    "val_times = []\n",
    "val_events = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(val_loader):\n",
    "        # unpack the batch\n",
    "        batch_clinical_rna_features, batch_lists_phenotype_clusters, batch_times, batch_events = batch\n",
    "        \n",
    "        # move times and events to the device\n",
    "        batch_times = batch_times.to(device)\n",
    "        batch_events = batch_events.to(device)\n",
    "        \n",
    "        # tterate over each sample in the batch\n",
    "        for idx, (clinical_rna_features, list_of_phenotype_tensors) in enumerate(zip(batch_clinical_rna_features, batch_lists_phenotype_clusters)):\n",
    "            \n",
    "            risk_score = model(clinical_rna_features, list_of_phenotype_tensors)\n",
    "            \n",
    "            val_risks.append(risk_score.item())\n",
    "            val_times.append(batch_times[idx].item())\n",
    "            val_events.append(batch_events[idx].item())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation c-index: 0.7205029013539652\n",
      "validation c-index custom: 0.7209302325581395\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved model: ../checkpoints/trained-model_2025-03-02_0.720503.pth\n"
     ]
    }
   ],
   "source": [
    "from lifelines import KaplanMeierFitter\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def display_km_curves_fusion(risks, times, events, title_name, save_figure=False):\n",
    "    risks = np.array(risks)\n",
    "    times = np.array(times)\n",
    "    events = np.array(events)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(10, 8)) \n",
    "    high_risk_idx = risks > np.median(risks)\n",
    "    low_risk_idx = risks <= np.median(risks)\n",
    "    kmf_high = KaplanMeierFitter()\n",
    "    kmf_low = KaplanMeierFitter()\n",
    "    # fit low risk\n",
    "    kmf_low.fit(times[low_risk_idx], event_observed=events[low_risk_idx], label='Low risk')\n",
    "    kmf_low.plot_survival_function(ax=ax, ci_show=True, ci_alpha=0.15, show_censors=True, color='orange')\n",
    "    # fit high risk\n",
    "    kmf_high.fit(times[high_risk_idx], event_observed=events[high_risk_idx], label='High risk')\n",
    "    kmf_high.plot_survival_function(ax=ax, ci_alpha=0.15, ci_show=True,show_censors=True, color='blue')\n",
    "    ax.set_title(f\"Kaplan-Meier curve for final model on {title_name}\")\n",
    "    ax.set_xlabel(\"Time\")\n",
    "    ax.set_ylabel(\"Survival probability\")\n",
    "    plt.legend()\n",
    "    if save_figure:\n",
    "        current_time = datetime.now().strftime(\"%H-%M-%S\")\n",
    "        plt.savefig(f\"../evaluation-results/fusion_{title_name}_{current_time}.png\")\n",
    "    else:\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "val_c_index = concordance_index(val_times, -np.array(val_risks), val_events)\n",
    "print(f\"validation c-index: {val_c_index}\")\n",
    "\n",
    "val_c_index_custom = concordance_index_custom(val_risks, val_times, val_events)\n",
    "print(f\"validation c-index custom: {val_c_index_custom}\")\n",
    "\n",
    "display_km_curves_fusion(val_risks, val_times, val_events, \"validation set\", save_figure=False)\n",
    "\n",
    "\n",
    "saved_model = True\n",
    "\n",
    "if saved_model:\n",
    "    current_time = datetime.now().strftime(\"%H-%M-%S\")\n",
    "    checkpoint_path = f\"../checkpoints/trained-model_{date.today()}_{val_c_index:4f}.pth\"\n",
    "    torch.save({\n",
    "        'model_state_dict': model.state_dict(), # all weights all models\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'batch_size': batch_size,\n",
    "        'dropout_ratio': dropout_ratio,\n",
    "        'learning_rate': lr,\n",
    "        'weight_decay': weight_decay,\n",
    "        'n_epochs': n_epochs,\n",
    "        'random_seed': 0,\n",
    "        'val_c_index': val_c_index,\n",
    "        'hidden': [1024, 1024, 512, 512, 256, 256, 128, 128, 64, 64, 32]\n",
    "    }, checkpoint_path)\n",
    "    print(f\"saved model: {checkpoint_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_42568\\985707259.py:7: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(checkpoint_path, map_location=device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_state_dict OrderedDict([('clinical_rna_feedforward.feedforward.0.weight', tensor([[-4.4670e-03, -4.9903e-03, -7.8401e-04,  ..., -1.5176e-03,\n",
      "          2.3944e-03, -6.8020e-03],\n",
      "        [-5.3324e-03, -4.7748e-03, -1.4722e-03,  ..., -1.3165e-05,\n",
      "          2.7448e-03,  4.1667e-03],\n",
      "        [ 1.3362e-05,  1.9953e-05,  8.7845e-07,  ..., -3.0789e-04,\n",
      "         -5.6543e-07, -1.5444e-04],\n",
      "        ...,\n",
      "        [-6.5022e-03, -3.3865e-03,  8.9988e-05,  ...,  1.9591e-03,\n",
      "         -6.5236e-03,  5.8753e-03],\n",
      "        [ 4.0021e-03, -1.7496e-03, -2.1362e-04,  ..., -2.9120e-05,\n",
      "          2.3713e-03, -4.4062e-03],\n",
      "        [ 1.7569e-03,  4.0997e-03,  3.4807e-03,  ..., -1.4538e-03,\n",
      "         -1.8979e-03,  1.7372e-03]], device='cuda:0')), ('clinical_rna_feedforward.feedforward.0.bias', tensor([ 7.0904e-04,  5.4083e-03,  8.7102e-05,  ..., -1.4847e-03,\n",
      "         4.2162e-03, -2.9810e-03], device='cuda:0')), ('clinical_rna_feedforward.feedforward.3.weight', tensor([[ 2.2736e-03,  3.4764e-03,  4.5084e-05,  ..., -8.7361e-03,\n",
      "          7.4506e-03, -3.0058e-02],\n",
      "        [-2.9858e-02,  2.5050e-02,  2.8633e-05,  ..., -2.5350e-02,\n",
      "         -2.1968e-02,  1.7770e-02],\n",
      "        [ 4.8179e-04,  2.5002e-02,  1.4621e-02,  ..., -2.5152e-02,\n",
      "         -4.3672e-03, -1.2139e-02],\n",
      "        ...,\n",
      "        [-1.7433e-02,  4.9457e-03,  1.8493e-02,  ...,  6.9932e-03,\n",
      "          2.8477e-02,  5.1491e-03],\n",
      "        [ 1.7167e-02, -6.5439e-03, -1.3673e-04,  ...,  9.3292e-03,\n",
      "          1.0009e-02,  1.8374e-02],\n",
      "        [ 2.4951e-02, -8.3583e-04, -3.7726e-04,  ...,  2.9197e-02,\n",
      "         -4.6149e-04,  8.5287e-03]], device='cuda:0')), ('clinical_rna_feedforward.feedforward.3.bias', tensor([ 3.4333e-03,  8.2590e-03,  3.1533e-02,  1.8314e-02, -2.5316e-03,\n",
      "         1.4008e-02,  7.1533e-03,  2.3433e-02, -2.3994e-02,  3.0112e-02,\n",
      "        -2.5155e-02,  1.3970e-02, -5.4051e-03, -1.3498e-02,  2.4096e-02,\n",
      "        -2.7216e-02,  1.3026e-02, -1.0277e-03, -2.5849e-02, -1.1109e-02,\n",
      "        -2.5127e-02,  1.2796e-02, -1.2671e-02, -2.8202e-02,  2.8099e-02,\n",
      "         4.5063e-03,  2.3543e-03,  1.9265e-02, -7.6757e-03, -2.8697e-02,\n",
      "        -2.2571e-02,  8.9489e-03, -4.6939e-03,  1.7652e-02, -1.6881e-02,\n",
      "        -5.3379e-04,  2.3806e-02,  2.7806e-03,  1.4225e-02,  1.8556e-03,\n",
      "        -5.3702e-03, -5.5550e-03,  2.7120e-02, -2.9116e-02,  9.3826e-03,\n",
      "        -1.5168e-02,  1.9453e-02, -6.0629e-03,  1.6707e-02,  2.3766e-02,\n",
      "        -1.9779e-02,  1.6244e-02, -3.1246e-02, -2.9529e-02,  1.9030e-02,\n",
      "        -2.6813e-02, -7.9567e-04, -2.4407e-03, -1.2946e-02,  3.6006e-04,\n",
      "        -7.1363e-03,  3.3425e-03, -1.3446e-02,  1.2850e-02,  1.2878e-02,\n",
      "         2.4778e-02,  3.0885e-02, -4.7781e-03,  1.3687e-02, -7.3367e-04,\n",
      "        -2.9322e-02, -2.0427e-02, -3.1017e-03,  2.5811e-02,  2.0119e-02,\n",
      "        -1.6377e-02, -1.4731e-02,  6.7626e-04, -1.1723e-02,  2.8445e-02,\n",
      "        -1.5720e-03,  1.1668e-02, -1.4926e-02,  6.4023e-03,  4.0717e-03,\n",
      "         1.6851e-03, -2.6700e-02,  1.7755e-02, -2.8974e-02,  2.6788e-03,\n",
      "         1.1308e-02,  4.5681e-03, -3.0514e-02,  1.5081e-02,  2.9983e-02,\n",
      "         7.0905e-03,  1.2596e-02, -1.1972e-02, -1.9037e-02, -2.6381e-02,\n",
      "         1.7372e-02,  3.0273e-02,  6.7326e-03,  7.3557e-03,  2.7663e-02,\n",
      "        -9.8714e-03,  1.4885e-02,  3.9011e-03,  2.3953e-02, -1.2870e-02,\n",
      "         7.7925e-03, -9.5913e-03, -2.4982e-02,  1.2812e-02, -2.4102e-02,\n",
      "         1.7600e-02, -9.4243e-03, -1.0125e-02,  4.2758e-03,  2.5307e-02,\n",
      "        -6.0672e-05, -1.2322e-02, -2.6788e-02,  1.2473e-02, -7.9732e-03,\n",
      "         3.0791e-02, -8.9823e-03,  1.7741e-02, -7.2342e-03, -2.8953e-03,\n",
      "        -9.0409e-03,  9.7975e-03, -2.8607e-02,  1.5227e-02,  7.8386e-03,\n",
      "        -2.5327e-02,  1.4668e-02,  1.3649e-02,  1.1679e-03,  5.4268e-03,\n",
      "        -2.2029e-02, -3.5957e-03,  9.7352e-04,  2.1231e-02, -1.2233e-04,\n",
      "         1.5807e-02, -1.3247e-02, -9.0438e-03,  3.0438e-02,  1.4897e-02,\n",
      "        -2.4057e-02,  1.8510e-02, -1.4944e-02,  2.8718e-02, -5.5614e-03,\n",
      "         1.4380e-02, -2.5464e-02, -2.3971e-03,  6.9680e-03,  1.4966e-02,\n",
      "        -1.2842e-02, -1.7087e-02,  3.5464e-03,  1.7384e-02,  4.8889e-03,\n",
      "        -1.6853e-02, -7.6863e-03,  1.1029e-02, -2.8129e-02, -2.4702e-02,\n",
      "         8.6166e-04, -2.3113e-02,  1.2928e-02, -3.6303e-03, -5.2816e-03,\n",
      "        -1.5597e-02, -1.7860e-02,  3.0247e-02,  2.5960e-02,  1.2211e-03,\n",
      "        -2.2807e-02, -2.1606e-02,  1.3429e-02, -8.6457e-03, -2.7333e-03,\n",
      "         1.7762e-02,  2.5101e-02,  2.8136e-02, -2.0184e-02,  1.6985e-02,\n",
      "        -4.6029e-03, -2.6201e-02, -2.8269e-02,  3.0125e-02,  9.1873e-03,\n",
      "        -9.1748e-03,  2.1146e-02,  1.3747e-03, -3.8760e-03,  1.5010e-02,\n",
      "        -1.9994e-02, -6.2575e-03,  6.7716e-03, -2.6080e-02,  2.3354e-02,\n",
      "         2.7935e-02,  1.2224e-03,  2.0602e-02,  1.2934e-02,  1.1019e-02,\n",
      "        -6.9891e-03, -2.3161e-02, -2.9295e-02, -8.1965e-03,  2.9775e-02,\n",
      "        -2.1101e-02,  2.3375e-02,  1.1193e-02,  3.3115e-03,  8.3225e-03,\n",
      "         4.5781e-03, -2.1940e-02, -2.7822e-02,  2.7811e-02, -2.3235e-02,\n",
      "         4.0585e-03,  9.3411e-03, -7.5673e-03, -1.4666e-03,  2.5827e-02,\n",
      "        -1.0067e-02, -9.1859e-04, -9.6964e-04, -2.9349e-02, -1.9907e-02,\n",
      "         3.4092e-03, -1.0278e-02,  2.3392e-02, -2.8761e-02,  1.1498e-02,\n",
      "        -1.9248e-02,  1.1667e-02,  9.6244e-03,  2.6033e-02,  1.8145e-02,\n",
      "        -2.5507e-02,  2.9597e-02, -3.6796e-03,  1.3945e-02,  2.9619e-02,\n",
      "         6.8135e-03, -9.4038e-03,  1.5109e-02, -3.1002e-02, -1.7760e-03,\n",
      "        -2.9334e-02,  1.0186e-02, -3.7340e-03,  2.9107e-02,  2.1591e-02,\n",
      "         2.9531e-02, -1.7447e-02,  1.9049e-02,  5.7802e-03,  1.1154e-03,\n",
      "         1.2052e-02, -2.8684e-03,  2.9942e-02,  2.3893e-02, -7.6244e-03,\n",
      "        -2.2930e-02, -1.4544e-02,  3.9468e-03,  1.0509e-02,  3.0954e-02,\n",
      "        -2.3947e-02, -1.2935e-02, -7.2185e-03,  8.6414e-03, -1.2218e-03,\n",
      "        -2.6245e-02,  1.4791e-02,  5.5526e-03,  2.3455e-02, -9.4116e-03,\n",
      "         9.7615e-03,  2.2063e-02,  1.1917e-02,  1.0460e-02,  2.1092e-02,\n",
      "         1.9107e-02,  3.2607e-03, -1.6513e-02,  2.2006e-02,  2.8605e-02,\n",
      "         2.9482e-02,  9.5711e-04, -4.5790e-04,  1.2353e-02, -6.0832e-03,\n",
      "         2.7814e-02,  1.1366e-04,  2.9109e-02, -2.3610e-02, -3.2948e-03,\n",
      "        -1.2658e-02, -1.6600e-02, -6.3593e-03,  3.0004e-02, -6.8513e-03,\n",
      "        -5.9842e-03,  2.8214e-02,  3.2902e-03, -3.0672e-03, -9.3350e-03,\n",
      "        -2.0540e-02, -8.5620e-03, -1.1450e-02, -2.5636e-02, -8.6186e-03,\n",
      "         2.2876e-02,  3.4641e-03,  7.5318e-03,  1.3549e-02, -1.9270e-02,\n",
      "        -4.4826e-03, -2.7460e-02, -2.7544e-02,  9.9934e-03,  2.3046e-02,\n",
      "        -1.7460e-02,  2.1813e-04,  1.9708e-02, -5.3704e-03,  1.1355e-02,\n",
      "         4.0020e-03, -6.5192e-04, -5.0683e-03,  2.9166e-02, -1.0367e-02,\n",
      "        -2.8499e-03,  2.3235e-02, -2.1474e-02,  2.2723e-02,  1.0120e-02,\n",
      "         9.9550e-03, -1.0173e-02, -2.6700e-02, -7.5833e-03, -7.0001e-03,\n",
      "        -7.7007e-03, -2.6369e-03,  2.7002e-02, -2.7494e-02,  3.0318e-02,\n",
      "         2.7216e-03, -3.1404e-02,  1.1904e-02, -2.7292e-02, -2.6708e-02,\n",
      "         2.6772e-02, -1.6425e-02, -7.5930e-03, -2.8204e-02,  6.7972e-03,\n",
      "         2.8029e-02,  6.3312e-03,  1.1544e-02, -8.4310e-03,  4.2591e-03,\n",
      "         1.2049e-02, -1.7935e-02,  2.8151e-02, -2.1797e-02,  1.3833e-02,\n",
      "        -1.0062e-02, -2.9353e-02,  2.5925e-02,  1.0969e-02, -1.4586e-02,\n",
      "         9.5193e-03, -1.8510e-03,  2.1672e-02, -2.6277e-02,  7.3037e-03,\n",
      "        -1.0334e-02, -1.0729e-02,  2.6428e-02,  1.4889e-02, -1.1930e-02,\n",
      "        -1.8942e-02,  1.7410e-02,  2.6007e-02,  1.3124e-02, -2.7966e-03,\n",
      "        -1.9147e-02,  1.8019e-02, -1.4517e-02,  5.7747e-03, -2.0340e-02,\n",
      "        -3.2011e-02, -2.8144e-02, -2.8529e-02,  4.2409e-03,  6.4605e-03,\n",
      "         4.0704e-03,  2.4859e-02,  2.3574e-02,  2.2919e-02, -7.5202e-03,\n",
      "         9.4755e-03, -3.5772e-03, -5.9474e-03, -1.9298e-02, -1.5161e-02,\n",
      "        -1.3769e-02,  2.9891e-02,  1.5993e-02, -2.6857e-02,  3.3339e-03,\n",
      "        -2.7078e-02, -4.4380e-03, -2.9014e-02,  1.9235e-02, -1.8536e-02,\n",
      "         3.9248e-03, -2.1562e-02, -6.3876e-03,  1.0907e-02, -5.2933e-03,\n",
      "        -7.7503e-04,  2.3638e-03,  2.5232e-02, -8.0772e-03, -1.4381e-02,\n",
      "         2.3829e-02, -2.1127e-02, -1.2528e-02, -1.4751e-02, -9.6263e-03,\n",
      "         2.2216e-03, -1.1942e-02, -8.6459e-03,  2.2716e-02, -2.7795e-02,\n",
      "         1.3345e-02,  2.3357e-02,  2.2976e-02, -8.6638e-03, -2.5690e-02,\n",
      "        -1.7904e-02, -1.3400e-02,  1.2543e-02, -6.7853e-03, -1.7948e-03,\n",
      "         2.0967e-02,  2.5354e-03, -8.9484e-03,  2.3300e-02, -6.5764e-04,\n",
      "         9.3061e-03,  1.4608e-02,  2.5751e-02,  1.4952e-02, -2.5843e-02,\n",
      "        -2.0380e-02, -2.8151e-02,  2.0351e-02,  2.1194e-02, -2.7460e-02,\n",
      "        -1.9550e-02,  1.7860e-02,  4.7208e-04,  8.3081e-03, -1.8529e-02,\n",
      "        -7.3933e-03,  2.8741e-02, -2.1455e-02, -1.3846e-02, -8.9864e-03,\n",
      "        -2.5389e-02,  1.0736e-02, -9.9393e-03,  2.4845e-02, -1.3274e-02,\n",
      "        -9.1560e-03,  2.6168e-02,  2.5686e-02, -2.8269e-02,  8.1440e-03,\n",
      "        -6.0520e-03, -1.2994e-02,  1.2232e-03, -1.1588e-02, -2.2147e-02,\n",
      "         2.8325e-03,  1.9355e-02,  1.5922e-02, -1.3008e-02,  3.3085e-03,\n",
      "         2.5107e-02,  2.0571e-02, -1.0834e-02, -2.1506e-02, -3.1769e-02,\n",
      "        -1.0277e-02,  1.1506e-02, -2.4796e-02, -2.9748e-02,  1.1558e-02,\n",
      "         2.6707e-02, -2.8027e-02], device='cuda:0')), ('clinical_rna_feedforward.feedforward.6.weight', tensor([[ 0.0120, -0.0030,  0.0338,  ..., -0.0372, -0.0278, -0.0066],\n",
      "        [-0.0202,  0.0138,  0.0308,  ...,  0.0414,  0.0331, -0.0142],\n",
      "        [-0.0192,  0.0256, -0.0136,  ...,  0.0069,  0.0231,  0.0344],\n",
      "        ...,\n",
      "        [-0.0338, -0.0031,  0.0263,  ..., -0.0196,  0.0406,  0.0117],\n",
      "        [-0.0368, -0.0129,  0.0226,  ..., -0.0256,  0.0087,  0.0211],\n",
      "        [ 0.0342,  0.0067, -0.0438,  ...,  0.0403, -0.0149, -0.0131]],\n",
      "       device='cuda:0')), ('clinical_rna_feedforward.feedforward.6.bias', tensor([ 1.2164e-02, -1.3098e-02,  3.0600e-02,  1.7347e-02, -1.8165e-02,\n",
      "         1.4925e-02, -3.6019e-02, -9.8099e-03, -5.3041e-03, -3.0645e-02,\n",
      "         2.5567e-02,  2.0582e-02,  1.7082e-02,  9.1003e-03,  4.3125e-02,\n",
      "         2.8265e-03, -2.2232e-02, -1.8972e-02, -6.4683e-03, -2.9411e-02,\n",
      "        -2.9764e-02,  2.4819e-02, -3.5500e-02,  4.0221e-02,  1.0602e-02,\n",
      "        -2.4037e-02,  4.0829e-02,  2.3108e-02,  2.7324e-02, -2.7247e-02,\n",
      "         3.3703e-02, -1.9533e-02,  3.4655e-02, -3.7768e-02,  1.8771e-03,\n",
      "         1.2897e-02,  1.2600e-02, -3.4693e-02,  2.8163e-02, -4.1432e-02,\n",
      "        -1.1873e-02,  7.8544e-04, -2.5314e-02,  2.2484e-02,  2.6385e-02,\n",
      "        -3.1645e-02, -7.6363e-03, -6.9917e-03, -2.8627e-02,  2.3355e-02,\n",
      "        -3.4059e-02, -1.6641e-02,  2.6099e-02,  3.7323e-02,  7.3009e-03,\n",
      "        -1.8715e-02, -2.3524e-02, -4.1067e-02,  3.8857e-02,  6.0772e-03,\n",
      "         3.9376e-02, -1.8287e-02,  3.6681e-02,  1.0309e-03, -1.6769e-02,\n",
      "        -3.6408e-02,  1.5115e-02, -3.2110e-02, -2.1707e-02, -8.5067e-03,\n",
      "         4.8615e-03,  4.1954e-02, -3.8529e-05, -3.7760e-03,  3.3425e-02,\n",
      "         3.0220e-03,  3.2710e-02,  2.6410e-02,  2.0261e-02,  3.6781e-02,\n",
      "        -2.8796e-02, -3.4376e-02, -3.1802e-02, -3.5498e-02, -2.7733e-02,\n",
      "         3.3808e-02,  1.1954e-02,  3.7791e-02,  1.9816e-02, -2.1038e-02,\n",
      "        -4.0796e-02, -1.4630e-02,  3.2776e-02, -1.3522e-03,  4.0942e-02,\n",
      "         2.7935e-02,  2.3464e-02,  3.5780e-02, -1.6709e-02,  8.3027e-03,\n",
      "        -8.7750e-03, -1.2763e-02, -3.9915e-02, -8.9280e-03, -3.6790e-02,\n",
      "         2.6681e-02, -3.0519e-02,  1.6827e-02,  1.6595e-02,  2.0208e-02,\n",
      "        -2.2708e-02, -4.4632e-02,  2.3312e-02, -1.7859e-02,  3.5243e-02,\n",
      "         2.1519e-02,  9.5336e-03, -2.9713e-02,  1.5989e-02, -8.1608e-03,\n",
      "         1.6051e-02,  3.0329e-02, -1.5594e-02, -4.0148e-02,  2.2076e-02,\n",
      "        -3.7199e-02, -2.3873e-02,  1.8645e-02,  2.6267e-02,  4.4379e-03,\n",
      "        -1.5351e-02,  2.7737e-02, -6.2589e-03, -2.2625e-02, -3.7680e-02,\n",
      "         2.3161e-02,  3.9945e-02,  2.0921e-02,  3.3510e-02,  1.3553e-02,\n",
      "        -1.0846e-02,  3.1779e-02, -2.9074e-02,  1.2147e-02, -3.7132e-02,\n",
      "        -2.4269e-02,  2.3967e-02,  1.9261e-02,  3.8535e-02,  1.7827e-02,\n",
      "         3.5049e-02, -3.0339e-02, -6.4951e-03, -2.7789e-02,  2.8899e-02,\n",
      "        -4.1845e-02, -3.0247e-02, -8.3386e-05,  1.1906e-02, -2.5622e-03,\n",
      "         9.3417e-03,  2.9959e-02, -7.0763e-03, -2.7114e-02,  2.6159e-02,\n",
      "         1.0897e-02, -2.2580e-02,  1.9992e-02, -1.7204e-02, -2.5327e-02,\n",
      "        -3.8633e-02, -1.1132e-03,  2.7657e-02,  3.3198e-02,  3.2518e-02,\n",
      "         7.7912e-03,  3.6883e-02, -2.7380e-02, -1.9396e-02, -3.3058e-02,\n",
      "         3.6037e-03, -3.4150e-02, -3.8924e-02, -1.6350e-02, -1.1612e-02,\n",
      "        -2.7910e-03, -3.9637e-02, -2.9021e-02, -1.0062e-02,  3.7384e-03,\n",
      "        -2.2755e-02,  1.6688e-02, -3.9786e-02, -1.4188e-02,  2.0702e-02,\n",
      "         3.1908e-02,  3.2143e-02,  7.9831e-03,  1.2485e-02,  2.3365e-02,\n",
      "        -4.0588e-02,  3.0631e-02,  3.6300e-02,  4.0793e-02,  3.9496e-02,\n",
      "         4.2517e-02,  4.2980e-02, -3.1448e-02,  2.4544e-02,  3.7806e-02,\n",
      "        -4.2219e-02,  4.1956e-02,  3.1803e-02, -3.5306e-02, -3.5834e-02,\n",
      "         1.1955e-02, -7.2585e-03,  2.5515e-02,  1.1585e-02, -3.1083e-02,\n",
      "        -1.9464e-02,  1.8793e-02, -2.9003e-02, -4.2986e-02, -5.8744e-03,\n",
      "         2.8224e-02,  6.6430e-03, -3.4370e-02,  8.4963e-03,  1.2712e-02,\n",
      "         1.9147e-02,  3.1725e-02,  1.2705e-02, -3.8762e-03, -2.8770e-04,\n",
      "        -3.5626e-02,  2.5127e-04, -2.2253e-02, -2.3536e-02,  4.3375e-02,\n",
      "        -3.2865e-02,  4.1156e-02, -3.0298e-02, -1.6015e-02,  2.3856e-02,\n",
      "        -3.4371e-02, -1.5856e-02, -3.5123e-02,  2.8119e-02, -1.1382e-02,\n",
      "         1.4872e-02, -1.5517e-02,  2.6213e-02,  2.6279e-02,  1.5159e-02,\n",
      "         3.6046e-02, -1.8200e-02, -6.4360e-04,  1.0027e-03, -9.6952e-03,\n",
      "        -3.0332e-02,  1.0311e-02, -2.7222e-02,  1.9504e-02,  1.5756e-02,\n",
      "         1.8206e-02, -5.6448e-03,  7.3056e-04, -1.5779e-02, -4.8123e-03,\n",
      "        -2.0190e-02, -1.6461e-02, -4.1633e-02,  1.2786e-02,  9.9628e-03,\n",
      "        -5.7494e-03,  3.6260e-02, -4.3893e-02, -2.4682e-02, -2.0511e-02,\n",
      "        -2.3295e-03, -3.5434e-02,  1.7051e-02,  3.4668e-02, -1.3703e-02,\n",
      "        -3.3060e-02,  4.2671e-02,  3.7252e-02, -2.8556e-02,  3.4510e-03,\n",
      "        -3.3477e-02,  1.5827e-02, -1.2723e-02, -4.2499e-03, -4.3710e-02,\n",
      "         2.2355e-02,  3.1131e-02, -1.5944e-02,  5.6748e-03,  1.3250e-02,\n",
      "        -1.5000e-02,  4.1694e-02, -1.9416e-02, -3.8726e-03, -9.5151e-03,\n",
      "        -1.9214e-02, -2.5054e-02,  3.1644e-02, -1.8720e-02,  3.8697e-02,\n",
      "        -5.4158e-03, -3.4674e-02,  3.6820e-02, -1.0499e-02,  2.1087e-02,\n",
      "         1.4505e-02,  2.7025e-02, -1.0192e-02,  1.1137e-02, -3.3674e-02,\n",
      "        -2.0519e-02,  2.3159e-02,  4.3337e-02,  2.1907e-03,  2.8617e-02,\n",
      "        -4.4829e-02,  6.6520e-03,  2.6178e-02, -2.2990e-03, -3.4797e-02,\n",
      "        -9.7735e-03,  1.7545e-02, -2.5879e-02,  8.4951e-03, -3.6748e-03,\n",
      "        -3.9828e-02,  3.1416e-02,  1.0730e-02, -2.0457e-02, -2.4280e-02,\n",
      "         1.9656e-02, -1.8806e-02, -4.0373e-02,  4.3161e-02, -4.6257e-03,\n",
      "         3.1180e-02, -1.7348e-02, -4.0899e-02,  1.9971e-02, -4.1077e-02,\n",
      "         4.7682e-03,  1.5877e-03, -3.2515e-02,  6.1901e-03,  2.6078e-02,\n",
      "        -4.0905e-02, -1.7682e-02, -3.0975e-02,  2.7767e-02,  2.9221e-02,\n",
      "         3.5317e-02,  5.3848e-03,  2.3723e-02, -4.2998e-02, -3.8283e-02,\n",
      "        -3.4088e-03, -2.6239e-02,  3.4308e-03,  2.1507e-02, -3.2663e-02,\n",
      "         5.5860e-03, -1.7040e-02, -1.2550e-03, -1.3036e-03, -1.9149e-02,\n",
      "        -4.2450e-02, -1.1075e-02, -2.0948e-02,  4.2591e-02,  2.9826e-03,\n",
      "        -3.2014e-03, -3.6854e-02, -3.3556e-02, -2.3282e-02, -2.3268e-02,\n",
      "         6.9185e-03,  1.0371e-02, -2.5568e-02, -3.6929e-02, -3.1992e-02,\n",
      "         4.0013e-02, -3.9594e-02,  4.0932e-02, -2.8845e-02,  2.8277e-02,\n",
      "         2.3437e-02, -3.9037e-02,  4.0715e-02,  8.1299e-03,  1.4862e-02,\n",
      "         4.0741e-03,  2.0749e-02, -1.8169e-04,  3.5938e-02,  1.9021e-02,\n",
      "         7.5933e-03, -2.7034e-03,  2.5566e-02, -1.8231e-02, -3.4835e-02,\n",
      "        -2.5392e-02,  3.6563e-02, -1.4695e-02, -2.1966e-02,  1.8688e-02,\n",
      "        -3.9369e-02, -8.8945e-03,  1.6408e-02,  8.0018e-03,  1.5915e-02,\n",
      "        -2.8027e-02,  3.5829e-03, -1.8914e-02,  1.7311e-02, -2.6768e-02,\n",
      "        -2.7816e-02, -5.4923e-03, -4.4188e-02, -2.0001e-02, -3.7167e-02,\n",
      "         2.9355e-02,  4.1105e-02,  1.1857e-02, -4.4950e-02,  2.0103e-02,\n",
      "         3.5791e-02, -1.8608e-02, -2.5770e-02, -7.7514e-03, -3.0230e-02,\n",
      "         3.8009e-02,  1.1477e-02,  1.9081e-02,  3.9687e-02,  3.0008e-02,\n",
      "        -2.6009e-02, -8.6252e-03, -2.5151e-02,  2.4045e-02,  4.8168e-03,\n",
      "         4.3798e-02, -4.2053e-02,  1.2901e-02,  6.4844e-03, -2.7912e-02,\n",
      "        -3.6351e-02,  2.5135e-02,  2.1608e-02, -1.6181e-02, -1.4915e-02,\n",
      "         1.5211e-02, -3.8558e-03, -1.6401e-02, -2.8932e-02, -2.9456e-02,\n",
      "        -1.6704e-02, -4.3631e-02,  2.2320e-02, -1.1171e-02, -3.8911e-02,\n",
      "         8.9261e-03,  1.7983e-02,  2.3452e-02,  3.5886e-02, -1.6475e-02,\n",
      "        -4.2067e-02, -3.0636e-02,  4.1776e-02, -3.8704e-02,  1.8107e-02,\n",
      "         1.7924e-02, -3.2142e-02, -1.7857e-02, -2.1648e-02, -3.3312e-02,\n",
      "        -1.9184e-02, -1.3637e-02, -4.3199e-02, -3.6546e-02, -1.7961e-02,\n",
      "         1.0576e-02, -2.5187e-03, -5.5365e-03, -6.6478e-03,  3.4842e-02,\n",
      "         3.0577e-02, -2.0606e-02, -2.2357e-02, -4.4532e-02,  2.2559e-02,\n",
      "         3.4061e-02,  3.7074e-02, -3.8730e-02, -5.3429e-03,  2.2555e-02,\n",
      "         3.3006e-02,  2.2462e-02, -3.2498e-02, -2.1476e-02,  1.3158e-02,\n",
      "        -2.7887e-02,  9.7406e-03], device='cuda:0')), ('clinical_rna_feedforward.feedforward.9.weight', tensor([[-0.0415,  0.0331, -0.0246,  ...,  0.0049, -0.0200, -0.0365],\n",
      "        [-0.0244, -0.0231,  0.0119,  ...,  0.0407,  0.0320,  0.0216],\n",
      "        [-0.0258, -0.0177, -0.0203,  ..., -0.0382,  0.0442, -0.0211],\n",
      "        ...,\n",
      "        [ 0.0397,  0.0063,  0.0123,  ...,  0.0242,  0.0395, -0.0251],\n",
      "        [-0.0221, -0.0062, -0.0062,  ..., -0.0267, -0.0241,  0.0249],\n",
      "        [ 0.0349, -0.0357, -0.0020,  ...,  0.0091,  0.0358,  0.0002]],\n",
      "       device='cuda:0')), ('clinical_rna_feedforward.feedforward.9.bias', tensor([ 2.6441e-02,  4.8406e-03, -3.5955e-02,  4.6601e-03,  1.7022e-02,\n",
      "        -2.2013e-02,  3.4302e-02, -1.6413e-02, -1.6071e-02, -2.8301e-02,\n",
      "        -4.2086e-03,  1.6062e-02,  2.8019e-02, -1.2079e-02, -1.6679e-02,\n",
      "         1.9565e-02,  9.2162e-03,  3.1300e-02, -2.3485e-02, -2.2207e-02,\n",
      "         3.7462e-02,  2.9459e-03, -2.4873e-02,  4.0690e-02,  1.3106e-02,\n",
      "        -2.7247e-02, -1.8697e-02, -3.8069e-02, -1.0648e-02, -2.8337e-02,\n",
      "         2.4823e-02, -2.2916e-02, -3.4535e-02, -7.7547e-03, -2.4984e-02,\n",
      "         8.1814e-03,  1.3485e-02, -1.8958e-03, -9.1120e-03, -2.3976e-02,\n",
      "        -1.6622e-02, -1.8641e-03,  1.9436e-02, -1.2858e-02, -8.5238e-03,\n",
      "         3.8024e-02,  4.0365e-02,  9.7322e-05, -4.3185e-02, -2.9202e-02,\n",
      "        -1.4110e-02, -2.9122e-03,  3.2514e-02, -2.6536e-02, -2.8229e-03,\n",
      "         3.2177e-02,  2.3945e-02, -2.7204e-02, -1.7714e-02, -3.5159e-02,\n",
      "         2.8377e-02,  9.1115e-03,  2.5248e-02, -4.3667e-02, -4.1183e-02,\n",
      "         3.7857e-02, -1.5562e-02,  8.2463e-03, -1.2520e-02, -1.5676e-03,\n",
      "         3.9869e-03, -2.2591e-02, -1.0050e-02, -1.2401e-03,  1.7404e-02,\n",
      "         2.9751e-02, -3.8810e-03,  3.9157e-02,  7.7147e-03,  3.1238e-02,\n",
      "         1.5804e-02, -9.4926e-03,  3.9970e-02, -4.4317e-02,  4.1850e-02,\n",
      "         2.0561e-02, -2.9307e-02, -3.1938e-02,  1.2690e-02,  2.8729e-02,\n",
      "         3.6801e-02, -1.4301e-02,  7.2024e-03,  1.6912e-02, -3.1265e-02,\n",
      "         2.2219e-02, -4.0967e-02, -1.5349e-02, -3.7142e-02,  3.8376e-02,\n",
      "        -3.3258e-02,  3.0571e-02, -6.3244e-03,  2.3074e-02, -5.4983e-03,\n",
      "         2.6080e-02,  3.2898e-02, -1.8949e-02,  3.8122e-03, -1.1888e-02,\n",
      "         1.0322e-02,  2.8579e-02, -2.4699e-02, -1.0963e-02, -3.4843e-02,\n",
      "         1.9485e-02, -3.0729e-02,  4.5466e-03, -1.0282e-02,  2.9012e-02,\n",
      "         3.3172e-02, -3.7395e-03, -6.9242e-03,  2.7777e-02,  9.8823e-03,\n",
      "         1.6729e-02,  7.4246e-04,  3.9714e-02, -3.4735e-02,  2.6808e-02,\n",
      "         3.8579e-02, -2.5851e-02, -1.4944e-02, -4.3367e-02,  4.3280e-02,\n",
      "        -8.7680e-03,  3.3820e-02, -4.4098e-02, -1.5168e-02, -8.5571e-03,\n",
      "         1.1762e-02, -5.2993e-04, -2.6841e-02,  2.6510e-03,  3.8938e-02,\n",
      "        -4.4533e-02,  4.3167e-02, -2.8623e-02,  2.4046e-02, -4.8977e-03,\n",
      "         2.0355e-02, -3.7410e-02,  3.8309e-02, -2.9457e-02,  1.8067e-02,\n",
      "         2.4643e-02, -4.3274e-02,  2.0264e-02,  2.3597e-02, -1.2834e-02,\n",
      "        -3.5494e-02, -8.3196e-03, -1.9249e-02, -4.8698e-03,  2.7010e-02,\n",
      "        -1.7250e-02, -2.5822e-03, -1.0709e-02,  2.0340e-03, -3.2919e-02,\n",
      "         5.8647e-03, -1.3539e-02,  2.4604e-03, -4.3610e-02,  2.0206e-02,\n",
      "         6.5620e-03,  3.7901e-02,  6.1931e-03, -1.1467e-02, -2.6116e-02,\n",
      "        -3.9767e-02, -4.4539e-03, -2.7679e-02, -3.0788e-02, -2.2951e-02,\n",
      "        -3.5337e-02,  1.1206e-02,  3.9892e-02,  1.1250e-02, -2.7621e-02,\n",
      "         1.9006e-02, -3.4054e-02,  2.0147e-02, -3.1276e-02, -2.7209e-02,\n",
      "         3.4106e-03,  1.9062e-03,  3.7392e-02,  1.3545e-02, -3.5020e-02,\n",
      "        -1.7593e-02,  1.4155e-02, -3.4090e-02, -1.1384e-02, -3.8230e-02,\n",
      "        -2.5274e-02, -3.3309e-02, -4.1257e-02, -1.3625e-02,  1.5260e-02,\n",
      "         3.2363e-02, -1.0574e-02, -2.3993e-03,  2.4366e-02, -1.7866e-02,\n",
      "        -1.4642e-02, -3.8474e-02,  2.1540e-02,  1.0246e-02, -4.2865e-03,\n",
      "        -3.4647e-02,  4.1700e-02, -8.8070e-03, -3.2859e-02, -4.1804e-02,\n",
      "        -6.1552e-03,  5.3086e-03, -3.1616e-02, -2.0086e-02, -1.8330e-02,\n",
      "        -1.9089e-03,  1.6553e-02,  3.7160e-02,  1.1759e-02,  7.4703e-04,\n",
      "        -2.0370e-02, -2.9184e-02,  3.4953e-02,  2.7299e-02,  1.9461e-02,\n",
      "         5.3394e-03, -3.6976e-02, -2.4615e-02,  2.2264e-03, -3.4433e-02,\n",
      "        -1.3782e-02,  3.1887e-02,  4.1076e-02,  1.1616e-03,  3.1584e-02,\n",
      "        -1.9848e-02, -2.4351e-02, -2.6871e-02,  7.3135e-03, -3.8188e-02,\n",
      "         8.6508e-03], device='cuda:0')), ('clinical_rna_feedforward.feedforward.12.weight', tensor([[ 0.0145, -0.0438, -0.0305,  ..., -0.0594, -0.0035, -0.0491],\n",
      "        [ 0.0233, -0.0574, -0.0207,  ...,  0.0599,  0.0155,  0.0238],\n",
      "        [ 0.0206, -0.0575,  0.0454,  ...,  0.0437, -0.0103, -0.0484],\n",
      "        ...,\n",
      "        [ 0.0410, -0.0242, -0.0283,  ..., -0.0315,  0.0500,  0.0447],\n",
      "        [-0.0451, -0.0460,  0.0536,  ..., -0.0290, -0.0238, -0.0168],\n",
      "        [-0.0240, -0.0603, -0.0132,  ..., -0.0483,  0.0005, -0.0416]],\n",
      "       device='cuda:0')), ('clinical_rna_feedforward.feedforward.12.bias', tensor([-0.0500, -0.0321, -0.0581, -0.0030,  0.0350, -0.0616, -0.0110, -0.0312,\n",
      "        -0.0351,  0.0504,  0.0449, -0.0330,  0.0607, -0.0363,  0.0557,  0.0562,\n",
      "         0.0229, -0.0590, -0.0423, -0.0375, -0.0627,  0.0004, -0.0343,  0.0343,\n",
      "        -0.0561, -0.0590,  0.0240, -0.0318,  0.0380, -0.0263,  0.0448,  0.0485,\n",
      "         0.0174, -0.0075,  0.0064,  0.0270, -0.0043,  0.0422,  0.0242,  0.0318,\n",
      "         0.0424,  0.0429, -0.0593,  0.0503,  0.0527,  0.0408, -0.0598,  0.0532,\n",
      "        -0.0532, -0.0146, -0.0343, -0.0302, -0.0613,  0.0177,  0.0088, -0.0259,\n",
      "         0.0070, -0.0527,  0.0157, -0.0445,  0.0334, -0.0468, -0.0007, -0.0410,\n",
      "         0.0022,  0.0560, -0.0173, -0.0098, -0.0166,  0.0245,  0.0480,  0.0457,\n",
      "        -0.0302, -0.0390, -0.0131,  0.0581,  0.0236,  0.0266,  0.0312, -0.0446,\n",
      "        -0.0398,  0.0226,  0.0301, -0.0293, -0.0534,  0.0135, -0.0274, -0.0491,\n",
      "        -0.0162,  0.0539,  0.0075, -0.0419, -0.0116, -0.0073, -0.0310, -0.0333,\n",
      "        -0.0076,  0.0410,  0.0475,  0.0523, -0.0526,  0.0242, -0.0216,  0.0333,\n",
      "        -0.0512, -0.0389, -0.0207,  0.0156, -0.0513, -0.0589,  0.0617,  0.0238,\n",
      "        -0.0463,  0.0348,  0.0359,  0.0357, -0.0507, -0.0206,  0.0605, -0.0340,\n",
      "         0.0085, -0.0199,  0.0349, -0.0581,  0.0562,  0.0031, -0.0161, -0.0505,\n",
      "        -0.0016, -0.0013, -0.0354, -0.0505,  0.0308, -0.0125,  0.0623,  0.0087,\n",
      "        -0.0043, -0.0028, -0.0355, -0.0002,  0.0346, -0.0331, -0.0475,  0.0289,\n",
      "        -0.0157, -0.0263, -0.0446, -0.0060, -0.0564, -0.0261,  0.0315,  0.0441,\n",
      "        -0.0300, -0.0515,  0.0161,  0.0393,  0.0585, -0.0066, -0.0521, -0.0273,\n",
      "         0.0034, -0.0209, -0.0119,  0.0231,  0.0473, -0.0460, -0.0115,  0.0282,\n",
      "        -0.0196,  0.0544, -0.0070,  0.0300,  0.0071, -0.0338,  0.0519, -0.0320,\n",
      "         0.0425, -0.0101, -0.0172,  0.0405,  0.0204, -0.0459, -0.0211,  0.0385,\n",
      "        -0.0233,  0.0001,  0.0527,  0.0038, -0.0512, -0.0376, -0.0074,  0.0627,\n",
      "        -0.0213, -0.0143,  0.0088, -0.0292, -0.0238, -0.0243,  0.0357,  0.0368,\n",
      "        -0.0228, -0.0524, -0.0607,  0.0122,  0.0113, -0.0101,  0.0229, -0.0202,\n",
      "        -0.0089,  0.0490,  0.0340, -0.0390,  0.0461,  0.0575,  0.0441,  0.0490,\n",
      "        -0.0318, -0.0472, -0.0231,  0.0019,  0.0487,  0.0567, -0.0173,  0.0280,\n",
      "         0.0354, -0.0409,  0.0464, -0.0205, -0.0094,  0.0521,  0.0585,  0.0325,\n",
      "         0.0497, -0.0073, -0.0016, -0.0543, -0.0032, -0.0593,  0.0220,  0.0115,\n",
      "        -0.0403,  0.0427,  0.0273,  0.0596,  0.0451,  0.0595,  0.0257,  0.0018,\n",
      "        -0.0354,  0.0190,  0.0363, -0.0113, -0.0399,  0.0366, -0.0102, -0.0162],\n",
      "       device='cuda:0')), ('clinical_rna_feedforward.feedforward.15.weight', tensor([[-0.0447,  0.0587, -0.0289,  ..., -0.0318, -0.0391, -0.0057],\n",
      "        [ 0.0518,  0.0541,  0.0008,  ...,  0.0495,  0.0138, -0.0517],\n",
      "        [-0.0038, -0.0289,  0.0103,  ...,  0.0060,  0.0464, -0.0310],\n",
      "        ...,\n",
      "        [-0.0289, -0.0276,  0.0583,  ...,  0.0029,  0.0461,  0.0234],\n",
      "        [-0.0539,  0.0547, -0.0533,  ..., -0.0175,  0.0470, -0.0557],\n",
      "        [ 0.0258,  0.0395, -0.0280,  ...,  0.0329,  0.0252, -0.0007]],\n",
      "       device='cuda:0')), ('clinical_rna_feedforward.feedforward.15.bias', tensor([-0.0253, -0.0475,  0.0120, -0.0582, -0.0252, -0.0016, -0.0239, -0.0349,\n",
      "        -0.0062, -0.0599,  0.0342,  0.0609,  0.0088, -0.0460,  0.0501,  0.0553,\n",
      "         0.0510, -0.0595,  0.0187,  0.0471, -0.0564, -0.0612, -0.0162,  0.0622,\n",
      "         0.0141, -0.0382, -0.0389,  0.0337, -0.0376,  0.0568,  0.0584,  0.0107,\n",
      "        -0.0523, -0.0404, -0.0054,  0.0202,  0.0048, -0.0299,  0.0391, -0.0038,\n",
      "        -0.0309,  0.0157,  0.0242, -0.0511,  0.0354, -0.0137, -0.0623,  0.0235,\n",
      "        -0.0286,  0.0297,  0.0551,  0.0058, -0.0050,  0.0442, -0.0011,  0.0518,\n",
      "         0.0198,  0.0357,  0.0571, -0.0336, -0.0140,  0.0425, -0.0395, -0.0511,\n",
      "        -0.0200, -0.0386, -0.0477,  0.0232,  0.0303,  0.0017,  0.0367,  0.0306,\n",
      "         0.0450,  0.0149,  0.0406,  0.0345, -0.0272, -0.0346, -0.0478,  0.0467,\n",
      "        -0.0577,  0.0365, -0.0119, -0.0307,  0.0107, -0.0130, -0.0359,  0.0080,\n",
      "        -0.0014, -0.0358,  0.0579,  0.0273, -0.0601, -0.0088,  0.0189,  0.0614,\n",
      "         0.0560,  0.0416,  0.0273,  0.0002, -0.0523, -0.0221,  0.0275,  0.0093,\n",
      "        -0.0254,  0.0226, -0.0154, -0.0429,  0.0461,  0.0219,  0.0430, -0.0129,\n",
      "        -0.0443,  0.0179,  0.0366,  0.0115, -0.0603, -0.0517,  0.0550,  0.0044,\n",
      "         0.0633, -0.0010, -0.0540, -0.0516,  0.0485, -0.0522, -0.0563,  0.0474],\n",
      "       device='cuda:0')), ('clinical_rna_feedforward.feedforward.18.weight', tensor([[-7.5660e-02,  5.7047e-03,  1.7665e-02,  ...,  8.5873e-02,\n",
      "         -5.9697e-02,  7.9260e-03],\n",
      "        [ 4.9420e-02,  4.3970e-02,  3.6135e-03,  ...,  7.5675e-02,\n",
      "          4.1040e-02,  2.8430e-03],\n",
      "        [-6.5860e-03,  8.2849e-02, -8.1894e-02,  ...,  3.0770e-02,\n",
      "         -7.8159e-02,  7.2528e-02],\n",
      "        ...,\n",
      "        [-7.5276e-02,  8.2337e-02, -4.3636e-02,  ...,  5.5368e-02,\n",
      "          3.9737e-02, -7.3101e-02],\n",
      "        [-6.3485e-02, -4.8946e-05,  3.6723e-02,  ..., -5.1730e-04,\n",
      "         -9.5213e-03, -3.9928e-03],\n",
      "        [ 1.0392e-02, -1.7968e-03, -9.1951e-03,  ..., -6.7809e-02,\n",
      "         -5.8157e-02,  5.6859e-02]], device='cuda:0')), ('clinical_rna_feedforward.feedforward.18.bias', tensor([-0.0786,  0.0091,  0.0601, -0.0400,  0.0792, -0.0256,  0.0753,  0.0346,\n",
      "         0.0853, -0.0130,  0.0236,  0.0725,  0.0060,  0.0055, -0.0892,  0.0192,\n",
      "         0.0350, -0.0087,  0.0228,  0.0471, -0.0890,  0.0260,  0.0147, -0.0721,\n",
      "         0.0209,  0.0208, -0.0057,  0.0200,  0.0827, -0.0671,  0.0363, -0.0127,\n",
      "         0.0122,  0.0712,  0.0276, -0.0779,  0.0192,  0.0472, -0.0537, -0.0656,\n",
      "        -0.0731, -0.0603, -0.0608,  0.0147,  0.0706, -0.0673,  0.0210,  0.0511,\n",
      "        -0.0718,  0.0206, -0.0597, -0.0602, -0.0558,  0.0549,  0.0476, -0.0101,\n",
      "         0.0007,  0.0848,  0.0835,  0.0710, -0.0255,  0.0611,  0.0080,  0.0257,\n",
      "        -0.0396,  0.0587, -0.0509,  0.0430, -0.0172,  0.0376,  0.0536, -0.0586,\n",
      "         0.0419, -0.0013, -0.0025,  0.0039,  0.0606, -0.0392,  0.0364,  0.0364,\n",
      "         0.0873,  0.0301,  0.0053,  0.0508, -0.0403,  0.0095, -0.0540,  0.0530,\n",
      "        -0.0273, -0.0666, -0.0436,  0.0632,  0.0464, -0.0668,  0.0622, -0.0426,\n",
      "        -0.0688,  0.0723,  0.0342,  0.0009, -0.0026,  0.0836,  0.0472, -0.0291,\n",
      "        -0.0500,  0.0418,  0.0157,  0.0160,  0.0298, -0.0316,  0.0801,  0.0404,\n",
      "        -0.0296, -0.0380,  0.0100, -0.0740, -0.0566, -0.0475, -0.0882, -0.0751,\n",
      "         0.0195, -0.0074, -0.0244, -0.0209,  0.0242, -0.0220, -0.0168,  0.0306],\n",
      "       device='cuda:0')), ('clinical_rna_feedforward.feedforward.21.weight', tensor([[-1.2562e-02,  5.8053e-02,  3.1237e-02,  ...,  4.3226e-05,\n",
      "         -4.4509e-02, -8.1474e-02],\n",
      "        [ 1.9155e-02, -2.8855e-02, -8.0143e-02,  ...,  4.2267e-02,\n",
      "          6.5245e-02,  6.4750e-03],\n",
      "        [-4.4388e-02,  1.7138e-02,  4.3275e-02,  ..., -6.5293e-02,\n",
      "          6.3193e-02, -4.5631e-02],\n",
      "        ...,\n",
      "        [-2.9465e-02,  4.4614e-02,  2.8502e-02,  ..., -8.3072e-02,\n",
      "          3.5914e-02,  6.5752e-02],\n",
      "        [ 3.0862e-02,  5.3782e-02, -4.4414e-02,  ...,  6.1685e-02,\n",
      "         -5.1280e-02, -1.3627e-03],\n",
      "        [-7.8091e-02,  1.2843e-02, -7.8293e-02,  ...,  4.7409e-02,\n",
      "         -3.7867e-02, -1.2481e-02]], device='cuda:0')), ('clinical_rna_feedforward.feedforward.21.bias', tensor([-0.0322, -0.0430, -0.0387, -0.0337,  0.0439, -0.0508, -0.0476,  0.0124,\n",
      "        -0.0459,  0.0659,  0.0280, -0.0417, -0.0173, -0.0049,  0.0632,  0.0338,\n",
      "         0.0313, -0.0154, -0.0696,  0.0879,  0.0809,  0.0125,  0.0847,  0.0864,\n",
      "        -0.0731, -0.0396, -0.0351, -0.0337,  0.0706,  0.0729,  0.0543,  0.0542,\n",
      "        -0.0790, -0.0394,  0.0043,  0.0741, -0.0651, -0.0506,  0.0444, -0.0507,\n",
      "         0.0272, -0.0003, -0.0396, -0.0522,  0.0662, -0.0539, -0.0791,  0.0009,\n",
      "         0.0743,  0.0791,  0.0831, -0.0197, -0.0545, -0.0518, -0.0125, -0.0752,\n",
      "         0.0405,  0.0706, -0.0183, -0.0782,  0.0821, -0.0854, -0.0446,  0.0730],\n",
      "       device='cuda:0')), ('clinical_rna_feedforward.feedforward.24.weight', tensor([[ 0.0460, -0.0825,  0.0475,  ..., -0.0251,  0.0222,  0.1170],\n",
      "        [-0.1116, -0.0813,  0.1080,  ..., -0.1097, -0.0695, -0.0245],\n",
      "        [ 0.0330,  0.0187, -0.0408,  ..., -0.0516,  0.1203, -0.1063],\n",
      "        ...,\n",
      "        [ 0.1132, -0.0862,  0.0723,  ..., -0.0062, -0.0928,  0.0935],\n",
      "        [-0.1011,  0.0913,  0.0754,  ...,  0.1204,  0.1171, -0.0696],\n",
      "        [-0.0106,  0.1231,  0.0382,  ...,  0.0359, -0.1106, -0.0056]],\n",
      "       device='cuda:0')), ('clinical_rna_feedforward.feedforward.24.bias', tensor([ 0.1122,  0.1166,  0.0776,  0.1171, -0.0553, -0.1210, -0.0697, -0.0519,\n",
      "         0.0827,  0.0813, -0.0231,  0.0705,  0.0300,  0.0807,  0.0969,  0.0017,\n",
      "         0.0542, -0.0073,  0.0602, -0.0845, -0.1118, -0.1095,  0.0963, -0.0626,\n",
      "        -0.0895, -0.0898,  0.0612, -0.0481, -0.0351, -0.0383,  0.0779,  0.0300,\n",
      "        -0.1044, -0.0579,  0.0201,  0.0726,  0.1205, -0.0933, -0.0531,  0.0370,\n",
      "         0.0228, -0.0120, -0.0213,  0.0370,  0.0986, -0.0460,  0.0391, -0.0751,\n",
      "        -0.0746,  0.0776,  0.0208,  0.0431, -0.0797,  0.0139,  0.0632, -0.0623,\n",
      "        -0.0196,  0.0391, -0.0703,  0.0494, -0.0349, -0.0476, -0.0542,  0.0190],\n",
      "       device='cuda:0')), ('clinical_rna_feedforward.feedforward.27.weight', tensor([[-0.1142, -0.0871, -0.0561,  ..., -0.0834, -0.0473,  0.0420],\n",
      "        [-0.1171,  0.0016,  0.1194,  ..., -0.0486,  0.0233,  0.0074],\n",
      "        [-0.0477, -0.0856,  0.0347,  ..., -0.0423, -0.1189, -0.0650],\n",
      "        ...,\n",
      "        [-0.0757,  0.1194,  0.0158,  ..., -0.0626,  0.0357,  0.1087],\n",
      "        [ 0.0090, -0.0205,  0.0423,  ..., -0.0698, -0.0006,  0.1211],\n",
      "        [-0.0807,  0.0466,  0.0640,  ..., -0.0352,  0.0798,  0.0911]],\n",
      "       device='cuda:0')), ('clinical_rna_feedforward.feedforward.27.bias', tensor([ 0.0722, -0.0706, -0.0666, -0.0720, -0.0938,  0.0400,  0.1085, -0.0108,\n",
      "         0.0789, -0.0287,  0.1088, -0.0327, -0.0126,  0.0425,  0.1216, -0.0125,\n",
      "        -0.0575,  0.0009,  0.1230,  0.1037, -0.0995, -0.0556, -0.0433,  0.0532,\n",
      "         0.1189, -0.0040,  0.0534,  0.0657, -0.0364, -0.0514,  0.0452, -0.0232],\n",
      "       device='cuda:0')), ('clinical_rna_feedforward.feedforward.30.weight', tensor([[-0.0670, -0.0326, -0.1719,  ..., -0.0786,  0.0357, -0.1389],\n",
      "        [-0.0538, -0.0226,  0.0662,  ...,  0.1097, -0.1490,  0.1342],\n",
      "        [-0.0053, -0.0286, -0.1014,  ...,  0.1369,  0.0141, -0.0152],\n",
      "        ...,\n",
      "        [ 0.1045,  0.0621,  0.0824,  ..., -0.1418,  0.0109,  0.1514],\n",
      "        [ 0.0649,  0.0280,  0.0378,  ...,  0.1563, -0.0248, -0.1519],\n",
      "        [ 0.1494,  0.0668,  0.1174,  ..., -0.1362,  0.0121, -0.1582]],\n",
      "       device='cuda:0')), ('clinical_rna_feedforward.feedforward.30.bias', tensor([ 0.1321,  0.1088,  0.1537, -0.0023,  0.0190,  0.1374, -0.1319,  0.0589,\n",
      "        -0.0865,  0.0243, -0.0177,  0.0878, -0.1422,  0.1325,  0.1686, -0.0889,\n",
      "         0.0986, -0.0280, -0.0243,  0.1505, -0.1072, -0.0844,  0.1213,  0.1194,\n",
      "        -0.0757, -0.0449, -0.1570,  0.1170,  0.1627, -0.0643,  0.0366, -0.0468],\n",
      "       device='cuda:0')), ('wsi_fcn.conv.weight', tensor([[[ 0.0369],\n",
      "         [-0.0253],\n",
      "         [-0.0017],\n",
      "         ...,\n",
      "         [ 0.0271],\n",
      "         [-0.0328],\n",
      "         [ 0.0209]],\n",
      "\n",
      "        [[ 0.0441],\n",
      "         [ 0.0309],\n",
      "         [-0.0279],\n",
      "         ...,\n",
      "         [-0.0290],\n",
      "         [-0.0201],\n",
      "         [ 0.0378]],\n",
      "\n",
      "        [[-0.0237],\n",
      "         [ 0.0159],\n",
      "         [-0.0199],\n",
      "         ...,\n",
      "         [ 0.0333],\n",
      "         [ 0.0398],\n",
      "         [-0.0056]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0267],\n",
      "         [ 0.0144],\n",
      "         [ 0.0254],\n",
      "         ...,\n",
      "         [ 0.0139],\n",
      "         [-0.0294],\n",
      "         [-0.0097]],\n",
      "\n",
      "        [[ 0.0189],\n",
      "         [-0.0403],\n",
      "         [ 0.0238],\n",
      "         ...,\n",
      "         [-0.0365],\n",
      "         [-0.0065],\n",
      "         [ 0.0028]],\n",
      "\n",
      "        [[ 0.0261],\n",
      "         [-0.0415],\n",
      "         [ 0.0148],\n",
      "         ...,\n",
      "         [-0.0304],\n",
      "         [ 0.0096],\n",
      "         [ 0.0144]]], device='cuda:0')), ('wsi_fcn.conv.bias', tensor([-0.0024, -0.0267, -0.0039,  0.0290,  0.0244,  0.0248,  0.0136, -0.0039,\n",
      "         0.0247, -0.0127,  0.0261, -0.0063, -0.0303, -0.0034,  0.0024, -0.0270,\n",
      "        -0.0053, -0.0328,  0.0073, -0.0125, -0.0413, -0.0157,  0.0435, -0.0387,\n",
      "        -0.0333,  0.0114,  0.0202,  0.0093,  0.0116, -0.0171, -0.0130, -0.0174,\n",
      "         0.0401, -0.0374, -0.0031,  0.0155,  0.0120, -0.0136,  0.0339,  0.0307,\n",
      "        -0.0106,  0.0285, -0.0180,  0.0090,  0.0274,  0.0086, -0.0310, -0.0032,\n",
      "         0.0434, -0.0390,  0.0197, -0.0170, -0.0302,  0.0386, -0.0208, -0.0055,\n",
      "        -0.0197,  0.0030, -0.0154,  0.0022,  0.0047,  0.0374, -0.0368,  0.0124],\n",
      "       device='cuda:0')), ('attention.attention.0.weight', tensor([[-0.0758, -0.0994,  0.0751,  ..., -0.0905,  0.0123,  0.1197],\n",
      "        [ 0.0934, -0.0111, -0.1194,  ...,  0.0291,  0.0588, -0.1241],\n",
      "        [-0.0307,  0.0526, -0.0486,  ..., -0.0390, -0.0071, -0.1074],\n",
      "        ...,\n",
      "        [-0.0703, -0.0999, -0.0131,  ..., -0.0185,  0.1106,  0.0344],\n",
      "        [-0.0865, -0.0432, -0.0981,  ..., -0.0318,  0.1078,  0.1000],\n",
      "        [-0.0221,  0.0346,  0.0573,  ...,  0.0761,  0.0228, -0.0019]],\n",
      "       device='cuda:0')), ('attention.attention.0.bias', tensor([-4.3029e-02,  3.6069e-02,  2.8885e-02, -1.1315e-01,  4.6238e-02,\n",
      "        -4.3703e-02,  2.5301e-02,  2.6090e-02,  1.1597e-02,  3.0215e-02,\n",
      "        -7.7429e-02,  5.8835e-02, -5.6131e-05, -5.2957e-02, -6.3396e-03,\n",
      "        -2.8177e-02, -1.0985e-03,  7.3535e-02,  1.0870e-01,  9.9604e-02,\n",
      "         1.5241e-03,  3.0347e-02,  1.2244e-02,  2.5110e-02, -1.1305e-01,\n",
      "         8.3149e-02, -1.0150e-01, -1.2305e-02,  4.9354e-03,  5.7896e-02,\n",
      "        -3.4161e-02, -1.0749e-01,  3.3086e-02, -8.3560e-02, -3.0897e-02,\n",
      "        -1.0817e-01,  7.0501e-02, -6.3126e-02, -5.2935e-02,  9.5598e-02,\n",
      "        -4.5114e-02,  3.6938e-02, -6.7041e-02, -8.3000e-02, -5.2392e-02,\n",
      "         5.6214e-02, -1.1169e-01, -4.3936e-02, -1.1630e-01, -5.5005e-02,\n",
      "         9.7932e-02, -1.2108e-01, -6.4323e-02,  9.6599e-02, -7.9922e-02,\n",
      "        -1.2751e-03, -4.1443e-02, -2.7290e-02, -7.6073e-02,  1.1869e-01,\n",
      "        -9.4563e-02, -4.4780e-03, -9.9188e-02, -3.6612e-02], device='cuda:0')), ('attention.attention.2.weight', tensor([[-0.0341,  0.0455, -0.0836, -0.0162,  0.0509, -0.0384, -0.1009,  0.0284,\n",
      "         -0.1239,  0.0177,  0.0240, -0.1104, -0.0652,  0.0565, -0.0276, -0.0561,\n",
      "         -0.0808, -0.0171,  0.0817,  0.0959, -0.0565,  0.1159,  0.0918, -0.0012,\n",
      "          0.0436,  0.0862,  0.0743, -0.0167, -0.0042,  0.0627, -0.1184,  0.0293,\n",
      "         -0.0022,  0.0139, -0.1004,  0.0703,  0.0931,  0.0486,  0.0415,  0.1155,\n",
      "         -0.0526,  0.0708,  0.0754, -0.1039,  0.0148, -0.0665,  0.0773, -0.0429,\n",
      "          0.0069, -0.0707, -0.0678, -0.1229,  0.0284, -0.0147,  0.0369,  0.1013,\n",
      "         -0.1237, -0.0798,  0.0447, -0.0189, -0.0296,  0.0284,  0.0263, -0.0250]],\n",
      "       device='cuda:0')), ('attention.attention.2.bias', tensor([-0.0205], device='cuda:0')), ('baby_feed_forward.0.weight', tensor([[ 9.5803e-02,  4.8157e-02,  3.1474e-05,  ..., -7.5473e-02,\n",
      "         -3.7538e-02,  6.2166e-02],\n",
      "        [-8.7097e-02, -6.1821e-02,  1.9924e-04,  ..., -3.8122e-02,\n",
      "         -2.6167e-02,  8.1226e-02],\n",
      "        [-8.5436e-02, -9.0960e-02, -5.0701e-02,  ..., -7.7558e-02,\n",
      "         -6.3879e-02,  3.0693e-03],\n",
      "        ...,\n",
      "        [-7.0020e-02,  3.1666e-02,  5.6366e-02,  ...,  1.0803e-02,\n",
      "          2.4650e-02, -4.7515e-02],\n",
      "        [-2.8866e-02, -3.3110e-02, -1.6991e-02,  ...,  1.4341e-02,\n",
      "          8.3670e-02,  3.6831e-02],\n",
      "        [ 7.5975e-02, -1.4985e-02,  6.6388e-02,  ..., -7.8865e-02,\n",
      "          8.1104e-02, -1.2910e-02]], device='cuda:0')), ('baby_feed_forward.0.bias', tensor([-0.0704, -0.0520, -0.0045,  0.0241, -0.0897,  0.0002,  0.0725,  0.0959,\n",
      "        -0.0508, -0.0653,  0.0026, -0.0419, -0.0641,  0.0790,  0.0613,  0.0189,\n",
      "         0.0822, -0.0004, -0.0861, -0.0317,  0.0326,  0.0803,  0.0445, -0.0037,\n",
      "        -0.0138,  0.0663, -0.0002,  0.0960,  0.0180,  0.0841,  0.0878,  0.0130,\n",
      "         0.0574, -0.0663, -0.0561, -0.0445, -0.0061,  0.0500,  0.0787,  0.0839,\n",
      "         0.0683, -0.0617,  0.0293,  0.0950,  0.0831, -0.0675,  0.0026,  0.0398,\n",
      "         0.0176,  0.0216, -0.0588, -0.0560,  0.0522,  0.0695, -0.0159,  0.0192,\n",
      "        -0.0719,  0.0659,  0.0441,  0.1004, -0.0646,  0.0783, -0.0763,  0.0886],\n",
      "       device='cuda:0')), ('baby_feed_forward.2.weight', tensor([[-0.0913, -0.0176,  0.0298,  ..., -0.0228,  0.0969,  0.1156],\n",
      "        [-0.0073,  0.0463,  0.0006,  ..., -0.1190,  0.0598,  0.0699],\n",
      "        [ 0.0149, -0.0806, -0.0611,  ..., -0.1068,  0.0439,  0.0055],\n",
      "        ...,\n",
      "        [ 0.0821,  0.0501,  0.0554,  ..., -0.0794, -0.0996, -0.0500],\n",
      "        [-0.0333,  0.0773,  0.0125,  ..., -0.0101,  0.0198, -0.1006],\n",
      "        [ 0.0169,  0.1189, -0.0187,  ...,  0.1126, -0.0334, -0.0914]],\n",
      "       device='cuda:0')), ('baby_feed_forward.2.bias', tensor([ 0.0811,  0.0765,  0.0562, -0.0154, -0.1178,  0.1009,  0.1161, -0.0342,\n",
      "         0.0075, -0.0601, -0.0870,  0.0402, -0.0724, -0.0102,  0.0272,  0.0970,\n",
      "         0.0900, -0.0290,  0.1119, -0.0799, -0.0364,  0.0759, -0.0601,  0.0970,\n",
      "         0.0249,  0.1169,  0.1059,  0.0631, -0.0948,  0.0962, -0.0659,  0.0851],\n",
      "       device='cuda:0')), ('baby_feed_forward.4.weight', tensor([[ 1.3397e-01,  1.4743e-01, -3.1078e-02,  7.1285e-02, -1.5535e-02,\n",
      "         -1.2791e-01, -1.7898e-02, -3.7523e-02,  4.4121e-02, -1.6675e-01,\n",
      "         -6.3330e-02, -1.5573e-01,  1.2320e-01,  2.7313e-02,  1.0257e-01,\n",
      "         -9.2523e-02, -7.1413e-02,  4.0916e-02, -1.1433e-01,  1.5675e-02,\n",
      "         -1.0626e-01,  3.4366e-02,  1.1873e-01,  4.7951e-02, -7.6259e-02,\n",
      "         -1.5310e-01, -2.3869e-02,  5.9623e-05,  3.6537e-02,  1.0603e-01,\n",
      "         -1.0265e-01,  4.2676e-02],\n",
      "        [ 1.4760e-01,  8.5725e-02, -1.2558e-01, -8.7244e-02, -5.4743e-02,\n",
      "          8.6143e-02,  8.6083e-02,  6.2238e-02,  1.4529e-01, -1.6455e-01,\n",
      "         -1.2156e-01, -1.5971e-01,  1.3010e-01, -1.9805e-02, -1.3207e-01,\n",
      "          5.7777e-02,  4.1546e-02,  8.9267e-02, -7.6741e-02, -1.0259e-01,\n",
      "          1.2513e-01, -6.4096e-02,  9.7081e-02, -4.4234e-03,  1.1905e-01,\n",
      "          9.9017e-02, -1.5352e-02,  1.7583e-01,  1.1941e-01, -1.7617e-01,\n",
      "          7.8575e-02,  1.2679e-01],\n",
      "        [ 1.1176e-01, -3.8257e-02, -6.8157e-02,  1.3143e-01,  1.0426e-01,\n",
      "         -1.4503e-01, -1.1298e-01, -1.4305e-01, -9.0015e-02, -1.0613e-01,\n",
      "          2.8046e-02,  1.3895e-01,  1.3850e-01, -1.1796e-01, -2.3581e-02,\n",
      "          7.0193e-02, -8.7042e-03, -1.4539e-01,  8.9378e-02,  8.9467e-02,\n",
      "          3.4238e-03,  1.4262e-01, -1.2251e-01,  6.1649e-02,  1.3017e-02,\n",
      "         -8.4484e-02,  1.2268e-01,  1.3892e-01, -4.9129e-02,  5.2731e-05,\n",
      "          9.3046e-02, -1.2858e-01],\n",
      "        [ 5.0529e-02, -1.7338e-01, -1.0487e-01, -8.2548e-02,  1.4589e-01,\n",
      "          7.4324e-02,  1.4438e-01, -1.4227e-01, -1.5556e-01, -1.4361e-01,\n",
      "         -5.0544e-02, -1.4333e-02, -9.2439e-02, -7.9181e-02, -1.3714e-01,\n",
      "          5.5980e-02,  1.0821e-01,  1.5190e-01, -1.0706e-01,  5.2470e-02,\n",
      "         -1.6890e-01, -1.1142e-01,  9.9118e-02, -1.5448e-01,  4.2412e-02,\n",
      "          1.5138e-02,  6.5629e-02, -6.7689e-02,  1.5361e-01, -6.4117e-03,\n",
      "          7.9384e-02,  7.3119e-02],\n",
      "        [ 8.0418e-02, -1.6404e-01, -1.2329e-04,  8.6690e-02,  9.2530e-02,\n",
      "         -2.3404e-02,  1.0424e-01,  1.0043e-01,  5.5713e-02,  1.2684e-01,\n",
      "          5.6257e-05, -9.8960e-02, -1.0501e-01, -2.1500e-02, -9.7008e-02,\n",
      "         -1.2799e-02,  8.3128e-02, -1.0362e-01, -1.4547e-01,  6.6867e-03,\n",
      "          4.7826e-02, -3.4977e-02,  1.1675e-01,  8.5022e-02, -1.3341e-01,\n",
      "         -1.4710e-01,  7.4997e-02, -1.3014e-01, -5.3832e-04, -1.6871e-01,\n",
      "         -7.4735e-02,  7.6656e-02],\n",
      "        [-1.0449e-01, -1.1385e-01,  9.1859e-02,  1.2164e-01, -1.0743e-02,\n",
      "          3.5131e-02, -1.0469e-01, -7.9977e-03,  5.8468e-02,  4.9524e-02,\n",
      "         -1.6145e-01,  1.0953e-01,  6.8076e-02,  6.7613e-02,  1.0351e-01,\n",
      "          1.6076e-01, -1.3791e-02, -5.0034e-02,  1.3459e-02,  4.7391e-02,\n",
      "          6.8142e-02, -1.5616e-01,  4.8688e-02, -1.5495e-01,  1.0539e-02,\n",
      "         -2.2376e-02,  2.4433e-02, -1.5717e-01, -1.0463e-01, -1.3069e-01,\n",
      "         -1.0371e-01,  9.0631e-02],\n",
      "        [-1.1195e-01, -6.1818e-02,  1.3734e-02,  1.5198e-01, -1.3867e-01,\n",
      "         -1.1496e-01,  9.5698e-02, -1.0882e-01, -6.4123e-02,  7.8412e-02,\n",
      "          1.0140e-01,  4.9499e-02, -5.9599e-02, -6.9806e-02, -1.1356e-01,\n",
      "          3.4704e-02, -1.3699e-01, -1.0841e-01, -7.2713e-05, -8.7259e-02,\n",
      "         -1.1649e-02,  7.8538e-04,  1.3688e-01, -6.5839e-02,  1.0238e-01,\n",
      "          1.4128e-02,  1.0153e-01, -8.4750e-02, -5.6048e-05, -5.8022e-02,\n",
      "         -9.1634e-02, -1.3119e-02],\n",
      "        [-6.1995e-02,  1.4359e-01, -2.3686e-02,  5.7505e-03, -8.0055e-02,\n",
      "         -1.5408e-01, -3.0549e-02, -1.2216e-01, -8.5341e-02, -1.5656e-01,\n",
      "         -1.6618e-01,  1.5133e-01,  1.3479e-01,  5.0486e-02, -5.0230e-02,\n",
      "          1.3609e-01, -5.9326e-02, -3.7644e-02, -1.0963e-01,  1.9495e-07,\n",
      "         -1.6531e-02, -1.4097e-01, -1.2181e-01,  6.8591e-02, -2.5772e-03,\n",
      "          1.6429e-01, -1.4774e-01,  1.7659e-02,  1.0732e-01,  1.0020e-01,\n",
      "          6.7372e-02, -1.4984e-01],\n",
      "        [ 5.8466e-02,  1.5627e-01, -7.8966e-02,  9.7563e-02,  1.6723e-01,\n",
      "          1.2180e-01, -1.1121e-01,  9.3165e-02, -7.5623e-02, -8.8345e-02,\n",
      "          1.0892e-01, -1.4988e-02,  1.3688e-01,  4.9241e-02,  4.2161e-02,\n",
      "          1.7464e-01,  1.2646e-01, -1.2480e-01, -8.9041e-02,  1.0694e-01,\n",
      "          2.2901e-02, -1.0174e-01, -2.6213e-02,  1.4439e-01,  6.7233e-02,\n",
      "         -9.9953e-02,  7.6979e-02,  8.6346e-02,  1.4415e-02,  9.8707e-02,\n",
      "          5.9643e-02,  1.6612e-01],\n",
      "        [ 1.5646e-01,  5.3385e-02,  1.6317e-02,  1.5480e-01,  2.1367e-07,\n",
      "          1.7580e-01, -9.0202e-02,  9.3977e-02, -7.8237e-02, -3.0507e-02,\n",
      "         -2.2552e-02, -5.3164e-02,  2.3932e-02,  3.3090e-02,  1.3500e-01,\n",
      "          2.8918e-02, -6.9700e-02, -1.6470e-01,  1.5110e-01,  9.0685e-02,\n",
      "         -4.3130e-02,  3.7937e-02, -1.2656e-01,  1.4135e-01,  6.6561e-02,\n",
      "         -7.7243e-02, -1.3908e-01, -1.6621e-01,  1.4707e-01,  1.1782e-01,\n",
      "          1.4299e-02,  9.7045e-02],\n",
      "        [ 1.4104e-01, -3.6791e-02,  4.5322e-02,  5.4781e-02,  1.0395e-01,\n",
      "         -6.4768e-02, -1.0442e-01,  5.7078e-02,  3.6468e-02, -4.8271e-02,\n",
      "          5.7341e-02, -1.7207e-02,  1.0487e-01,  2.4163e-05,  3.1520e-02,\n",
      "          1.4415e-01, -9.1337e-02, -2.9654e-02,  2.2038e-02,  1.6488e-01,\n",
      "          5.6202e-02,  2.7582e-02,  1.8213e-02,  1.2307e-01, -1.3872e-02,\n",
      "         -2.3268e-02, -1.1012e-01, -9.3550e-02, -6.6991e-02, -1.4555e-01,\n",
      "          1.0443e-01, -3.6622e-03],\n",
      "        [ 1.5140e-01, -1.5743e-01, -4.0332e-02,  7.0965e-02,  1.2196e-01,\n",
      "         -1.1625e-01,  4.9773e-03, -2.1238e-03,  6.3105e-02,  1.6573e-01,\n",
      "          7.5333e-02, -1.1263e-01, -9.0609e-02, -2.3141e-02, -8.1114e-02,\n",
      "          1.7703e-01,  1.4996e-01,  5.5340e-02,  1.6570e-01,  1.3146e-01,\n",
      "          6.6550e-02,  1.2420e-01, -1.3918e-01, -1.2037e-01,  7.3552e-02,\n",
      "         -9.3724e-02,  2.8912e-02, -1.7569e-01,  1.3587e-01,  1.5924e-01,\n",
      "          5.1050e-02, -2.0155e-02],\n",
      "        [-1.0246e-01,  1.5803e-01,  1.2584e-01,  1.0122e-01,  7.7459e-02,\n",
      "         -5.2945e-02,  1.7164e-01,  5.6783e-02, -1.7560e-01, -8.3343e-02,\n",
      "          1.0711e-01,  7.4864e-02, -1.3935e-01,  2.6932e-02, -8.0518e-02,\n",
      "          2.7654e-02,  1.5544e-02, -1.5605e-01, -1.1070e-02,  4.0999e-03,\n",
      "         -1.6882e-01,  1.4823e-01,  7.5926e-02,  5.6560e-02,  1.0399e-01,\n",
      "         -3.9926e-02, -7.2514e-02,  1.4674e-01,  5.2468e-02, -9.4690e-02,\n",
      "         -1.0142e-01,  1.2720e-01],\n",
      "        [ 1.6454e-01,  1.3965e-01, -3.6272e-02, -1.5318e-01, -3.1811e-02,\n",
      "         -1.7446e-02, -1.6164e-01, -8.6944e-03, -6.7505e-02, -1.0218e-01,\n",
      "          1.2222e-01,  1.6298e-01, -1.6477e-01,  1.4517e-01, -3.2654e-02,\n",
      "          1.0328e-01, -3.9672e-02, -2.1562e-02, -9.7675e-02,  4.7927e-02,\n",
      "         -4.3384e-02,  1.5985e-01, -1.0436e-01,  1.2885e-01, -1.7058e-01,\n",
      "          9.3079e-02,  1.5000e-01,  6.7262e-02, -9.3229e-02,  2.4945e-02,\n",
      "          1.6568e-01, -1.3706e-01],\n",
      "        [ 1.0723e-01,  1.3682e-01, -4.7471e-02, -2.3745e-02,  1.1758e-01,\n",
      "          1.2077e-01, -1.5621e-01,  1.6913e-01, -8.8640e-02,  1.1893e-02,\n",
      "          6.9190e-02, -1.6401e-01,  1.4106e-02,  1.7447e-01,  1.5431e-02,\n",
      "          3.3562e-02,  9.2732e-02,  6.3135e-02,  1.5637e-01, -9.4696e-02,\n",
      "          2.9404e-02, -1.6716e-01, -6.2451e-02,  1.4365e-01,  1.0875e-01,\n",
      "          7.3936e-02, -6.2299e-03,  2.0447e-02,  1.2767e-01, -2.8886e-02,\n",
      "          3.1359e-02, -7.3537e-02],\n",
      "        [ 1.4683e-01,  1.4134e-01,  3.9960e-02, -1.4493e-01, -7.6458e-02,\n",
      "         -7.3813e-02,  1.6548e-01, -3.7471e-03,  4.2735e-02,  6.8085e-02,\n",
      "         -7.2734e-03,  4.0921e-02, -1.4545e-01,  1.5038e-01, -1.4218e-01,\n",
      "         -9.0557e-02,  1.6695e-02,  1.0357e-01,  6.2836e-02,  1.0461e-01,\n",
      "          1.7181e-01,  2.4144e-02, -6.1726e-02,  7.4125e-02,  3.4343e-02,\n",
      "         -1.1851e-02,  3.8546e-02, -3.5161e-02, -1.2486e-01, -1.5376e-01,\n",
      "         -1.0346e-01,  1.4846e-01]], device='cuda:0')), ('baby_feed_forward.4.bias', tensor([-0.0571, -0.0305, -0.1191, -0.0122, -0.0864, -0.1441, -0.0782, -0.0906,\n",
      "         0.1418, -0.1085, -0.1498,  0.0916,  0.0937,  0.1275,  0.0839,  0.0300],\n",
      "       device='cuda:0')), ('baby_feed_forward.6.weight', tensor([[-3.5205e-02, -1.7566e-01, -6.9923e-02,  8.9800e-02, -1.9561e-01,\n",
      "         -1.8826e-01,  2.0501e-01,  1.1190e-01,  1.6715e-01, -2.0009e-01,\n",
      "          7.9321e-02,  5.4686e-02,  6.4932e-02,  2.2664e-01, -8.7259e-02,\n",
      "         -3.3480e-02],\n",
      "        [-1.6600e-01, -5.7022e-04, -1.5320e-01, -1.3147e-01,  2.3537e-01,\n",
      "         -1.6660e-01, -2.1315e-01,  8.6233e-02, -2.2939e-01, -5.2068e-02,\n",
      "          1.5187e-01, -7.6279e-02,  1.7389e-01, -1.0082e-01,  3.5300e-02,\n",
      "         -2.3004e-01],\n",
      "        [ 5.9406e-05,  1.4483e-01,  4.2339e-02, -1.7589e-01,  1.4202e-01,\n",
      "         -2.3331e-01, -9.3240e-02,  3.7138e-02, -9.6501e-02,  8.2108e-02,\n",
      "          2.0817e-01, -1.6585e-01,  2.1366e-01, -1.9416e-01, -1.0635e-01,\n",
      "          1.8169e-01],\n",
      "        [-1.3985e-01,  2.0980e-01, -2.2316e-01, -2.3230e-01,  1.9841e-01,\n",
      "          2.0664e-01, -3.2585e-03,  1.0061e-01,  1.8382e-01, -7.8205e-02,\n",
      "          3.1572e-02, -2.2101e-02, -1.7503e-01, -9.8868e-02, -6.6705e-02,\n",
      "          2.3159e-01],\n",
      "        [ 3.1097e-02,  1.2758e-01,  2.0462e-01,  1.1597e-01, -2.6523e-02,\n",
      "          3.9452e-02,  1.9043e-01,  1.8224e-01, -3.6833e-02, -2.2055e-01,\n",
      "          1.8286e-01, -1.6151e-02, -1.2943e-01, -1.7458e-01,  6.6226e-02,\n",
      "         -2.0805e-01],\n",
      "        [ 1.3078e-01, -4.4831e-02,  1.4967e-01, -5.4420e-02, -1.2258e-01,\n",
      "          3.3748e-02,  8.4391e-02, -2.1806e-01,  2.2929e-01,  1.9990e-01,\n",
      "         -1.6986e-02, -1.1304e-01, -9.3599e-02, -1.8748e-01, -6.5610e-02,\n",
      "         -5.1047e-02],\n",
      "        [ 9.7974e-02, -1.6874e-01,  1.8064e-01,  1.2697e-01,  1.5928e-02,\n",
      "          1.5011e-01, -1.5292e-01,  3.0694e-02,  5.9292e-05, -3.8911e-02,\n",
      "         -2.9576e-03,  1.8278e-02, -4.3045e-02,  6.1726e-02,  1.3058e-01,\n",
      "         -2.3148e-01],\n",
      "        [ 1.7981e-02, -1.3944e-01, -1.8391e-01, -9.1182e-02, -1.4285e-01,\n",
      "         -5.5663e-02,  1.1535e-01,  2.4102e-01,  1.0296e-02, -1.8126e-01,\n",
      "         -1.4172e-01,  1.6877e-01, -1.4578e-02, -4.2570e-02, -1.1477e-01,\n",
      "          6.9251e-04]], device='cuda:0')), ('baby_feed_forward.6.bias', tensor([ 0.0352, -0.0142, -0.0698, -0.1443,  0.2469,  0.1425, -0.2305, -0.0332],\n",
      "       device='cuda:0')), ('baby_feed_forward.8.weight', tensor([[-0.2171,  0.3446,  0.1182,  0.0533, -0.0860,  0.2008,  0.1173, -0.1735]],\n",
      "       device='cuda:0')), ('baby_feed_forward.8.bias', tensor([-0.0912], device='cuda:0'))])\n",
      "optimizer_state_dict {'state': {0: {'step': tensor(60., device='cuda:0'), 'exp_avg': tensor([[-4.6323e-07, -5.2374e-07, -1.3013e-07,  ..., -2.1256e-07,\n",
      "          2.5500e-07, -6.8918e-07],\n",
      "        [-5.0357e-07, -4.5730e-07, -2.0759e-07,  ..., -3.0703e-09,\n",
      "          2.8937e-07,  4.3384e-07],\n",
      "        [ 2.3514e-10,  8.9206e-09,  1.8674e-10,  ..., -7.2316e-08,\n",
      "          7.0296e-12, -5.1888e-08],\n",
      "        ...,\n",
      "        [-6.1880e-07, -3.9316e-07,  4.2766e-08,  ...,  2.6041e-07,\n",
      "         -6.6534e-07,  6.0585e-07],\n",
      "        [ 4.2004e-07, -1.8849e-07, -5.9943e-08,  ..., -1.9884e-10,\n",
      "          2.6318e-07, -4.9500e-07],\n",
      "        [ 2.7777e-06,  8.2249e-06,  3.9482e-07,  ..., -2.0557e-07,\n",
      "          2.1444e-07,  1.0424e-06]], device='cuda:0'), 'exp_avg_sq': tensor([[2.7588e-12, 1.1243e-11, 5.5813e-15,  ..., 9.2378e-15, 2.1069e-13,\n",
      "         8.4483e-13],\n",
      "        [2.1984e-11, 1.1198e-11, 8.9955e-15,  ..., 7.2126e-17, 3.3818e-13,\n",
      "         5.9844e-13],\n",
      "        [6.8557e-18, 3.5754e-16, 9.0940e-19,  ..., 3.4576e-15, 1.7600e-20,\n",
      "         2.7851e-15],\n",
      "        ...,\n",
      "        [2.4798e-11, 3.1949e-14, 2.4955e-15,  ..., 1.1714e-14, 5.7660e-13,\n",
      "         1.3890e-12],\n",
      "        [6.4476e-12, 1.5747e-13, 3.0461e-15,  ..., 3.1372e-17, 6.3264e-14,\n",
      "         4.4500e-14],\n",
      "        [3.5151e-10, 6.8973e-10, 2.8967e-11,  ..., 8.8979e-15, 1.1288e-11,\n",
      "         1.0592e-10]], device='cuda:0')}, 1: {'step': tensor(60., device='cuda:0'), 'exp_avg': tensor([ 8.1891e-08,  5.7742e-07,  1.1134e-08,  ..., -9.5564e-08,\n",
      "         4.4160e-07,  2.8106e-06], device='cuda:0'), 'exp_avg_sq': tensor([2.0816e-12, 2.8692e-11, 5.2996e-16,  ..., 6.4907e-11, 6.4522e-12,\n",
      "        5.0680e-10], device='cuda:0')}, 2: {'step': tensor(60., device='cuda:0'), 'exp_avg': tensor([[ 2.7211e-07,  5.1274e-07, -3.2230e-09,  ..., -7.3777e-07,\n",
      "          8.2384e-07,  2.3536e-05],\n",
      "        [-3.0019e-06,  2.5933e-06, -5.1913e-09,  ..., -2.5744e-06,\n",
      "         -2.2288e-06, -4.9910e-05],\n",
      "        [ 8.6559e-08,  2.4295e-06,  1.5488e-06,  ..., -2.5602e-06,\n",
      "         -5.1233e-07, -2.6081e-05],\n",
      "        ...,\n",
      "        [-1.7738e-06,  6.5527e-07,  1.9370e-06,  ...,  8.1740e-07,\n",
      "          2.8830e-06,  1.1735e-04],\n",
      "        [ 1.6943e-06, -7.4151e-07,  1.2860e-09,  ...,  8.7008e-07,\n",
      "          1.0851e-06,  1.1419e-04],\n",
      "        [ 2.3894e-06, -1.3513e-08, -8.1148e-08,  ...,  2.9887e-06,\n",
      "         -4.6716e-08,  2.7190e-06]], device='cuda:0'), 'exp_avg_sq': tensor([[4.5432e-11, 6.4275e-10, 2.1733e-16,  ..., 4.2719e-10, 6.4863e-14,\n",
      "         2.6428e-07],\n",
      "        [3.8043e-12, 4.5640e-13, 2.5587e-16,  ..., 2.5867e-11, 1.0275e-11,\n",
      "         3.0099e-07],\n",
      "        [4.4448e-15, 1.1672e-10, 1.7865e-13,  ..., 1.0890e-12, 2.9118e-14,\n",
      "         6.0067e-07],\n",
      "        ...,\n",
      "        [9.8474e-13, 6.1012e-10, 2.6699e-13,  ..., 3.2935e-10, 7.4653e-12,\n",
      "         1.3274e-06],\n",
      "        [1.7819e-11, 1.7791e-10, 1.1932e-15,  ..., 9.2366e-11, 9.6236e-14,\n",
      "         5.3286e-07],\n",
      "        [2.5397e-10, 1.1406e-10, 3.7601e-15,  ..., 1.1018e-10, 1.0439e-13,\n",
      "         3.1281e-07]], device='cuda:0')}, 3: {'step': tensor(60., device='cuda:0'), 'exp_avg': tensor([ 1.2297e-05, -1.5663e-05,  6.9382e-05, -6.0620e-05, -1.2443e-05,\n",
      "         2.5586e-05,  3.1714e-05,  1.4498e-05, -1.0367e-06, -1.0276e-05,\n",
      "        -1.0814e-04, -1.6586e-05, -8.9759e-06,  8.0650e-05, -3.3748e-05,\n",
      "        -3.7742e-05, -8.0748e-06,  1.0808e-05,  1.9497e-05, -2.9025e-05,\n",
      "        -1.9943e-05, -6.1391e-05, -1.2054e-06,  1.4845e-05,  6.1490e-05,\n",
      "        -5.8415e-06, -1.4626e-04, -3.6098e-05,  1.2922e-06, -3.0404e-06,\n",
      "        -2.0014e-06, -2.4249e-05, -2.7872e-05,  1.3824e-06,  2.0641e-04,\n",
      "         1.7410e-05,  6.2209e-05,  2.3974e-05,  1.7317e-06,  2.3693e-06,\n",
      "         7.0897e-05, -3.9478e-05,  3.4471e-05, -1.7573e-05,  2.3029e-05,\n",
      "        -5.4141e-06, -4.0740e-05,  1.3795e-07, -1.5057e-05,  1.8654e-05,\n",
      "         6.9064e-05, -4.8465e-05,  2.4725e-05,  7.4783e-05,  4.0451e-05,\n",
      "         5.7590e-05,  2.6362e-05, -7.3982e-05, -1.0859e-05, -6.4762e-08,\n",
      "        -2.5391e-05, -8.5940e-06,  2.7681e-06, -1.4493e-05,  6.1534e-05,\n",
      "         2.6706e-05,  1.7516e-04, -1.9431e-06, -3.0684e-05,  1.2408e-04,\n",
      "        -5.2373e-05,  3.4870e-05, -4.4148e-05, -7.4979e-05,  3.9542e-05,\n",
      "        -4.4979e-05, -1.3216e-07,  1.8626e-05, -7.7334e-05,  3.8028e-06,\n",
      "         3.3148e-05, -2.0139e-05, -4.4909e-05,  6.7371e-07,  2.7942e-05,\n",
      "         3.2960e-05, -3.3907e-05, -7.4652e-06, -1.9959e-06,  5.9349e-05,\n",
      "         1.8427e-04, -5.6543e-05, -3.8862e-05,  8.7627e-06, -1.4120e-06,\n",
      "         2.0668e-05, -8.9214e-06,  9.1635e-07,  4.3285e-05,  1.6420e-05,\n",
      "        -4.7150e-05, -1.2051e-05, -1.1649e-05, -1.9798e-05,  1.7218e-05,\n",
      "         4.8352e-05,  1.8259e-06,  1.6149e-05, -2.3985e-06, -5.3331e-05,\n",
      "         1.0585e-05,  3.1086e-05, -2.9936e-05,  3.2005e-05, -3.6670e-05,\n",
      "        -3.1416e-05,  6.7759e-06, -4.0798e-06, -8.5344e-05,  8.7223e-06,\n",
      "        -1.1339e-05, -5.3457e-05, -3.2000e-07,  2.8402e-05,  2.6986e-05,\n",
      "        -5.5679e-05, -2.9093e-06,  9.2060e-05,  3.7417e-05, -4.7896e-05,\n",
      "         1.4888e-05, -5.0841e-05,  6.3020e-06, -2.8416e-06, -8.1735e-06,\n",
      "         5.0765e-06, -4.2679e-07, -4.0540e-05,  1.7266e-05, -1.6559e-05,\n",
      "         2.0296e-05,  3.2829e-05, -6.9870e-05, -6.0473e-05, -4.7715e-05,\n",
      "         1.6352e-05,  4.4060e-06,  3.6714e-05,  1.1508e-05, -9.3949e-07,\n",
      "        -5.7518e-07,  7.4262e-05, -2.0570e-06, -7.3339e-05, -6.2790e-05,\n",
      "        -1.7511e-05,  3.6143e-05,  2.5474e-05, -1.7321e-05, -6.4562e-05,\n",
      "        -1.6707e-06,  2.5211e-06,  1.0426e-05,  2.3196e-06, -7.6455e-06,\n",
      "         8.9578e-05, -1.7849e-06,  2.3134e-05, -7.3233e-06, -1.9396e-06,\n",
      "         1.2626e-04, -8.7296e-07, -1.1988e-05,  6.2209e-05,  2.5477e-05,\n",
      "        -4.4384e-05, -1.2078e-05,  6.2728e-05,  3.5927e-05,  2.0644e-05,\n",
      "        -1.7002e-05, -3.6723e-05,  1.8317e-05,  1.7558e-05, -3.4285e-05,\n",
      "        -2.7765e-05,  3.1659e-05,  1.5251e-04,  2.6932e-05,  6.4997e-06,\n",
      "         1.4711e-05,  8.2575e-07, -5.3401e-05, -1.2689e-05,  3.7675e-05,\n",
      "         1.5002e-04, -5.3845e-06, -4.6761e-07, -1.7999e-06, -4.4445e-05,\n",
      "        -1.8387e-06,  2.3914e-05, -9.9170e-05,  7.6839e-05, -6.1360e-06,\n",
      "        -2.9438e-05, -1.1874e-05, -1.3340e-05, -2.7069e-05, -1.6156e-05,\n",
      "        -3.7569e-06, -1.8654e-05, -3.7035e-05, -1.6795e-06, -1.5159e-05,\n",
      "        -4.8518e-05,  3.0193e-05, -2.7094e-05,  1.4375e-06,  3.0408e-05,\n",
      "        -1.7090e-06, -2.7556e-05, -1.5228e-05, -2.6606e-05,  2.5443e-05,\n",
      "         4.0994e-05, -1.2763e-05,  2.3019e-05, -1.0402e-05, -3.0000e-05,\n",
      "         2.1949e-05,  3.4849e-05,  3.8221e-05,  2.8282e-05, -8.9867e-05,\n",
      "         5.4459e-05,  7.5686e-05,  6.5296e-06,  8.1581e-06,  3.3665e-05,\n",
      "         8.1771e-05, -1.7244e-05,  7.1696e-05, -1.3945e-05,  6.3744e-05,\n",
      "         2.4484e-05,  1.2418e-05,  3.0961e-05, -3.4615e-06,  2.2447e-06,\n",
      "         6.0396e-05,  5.0995e-05,  8.7977e-05,  3.1193e-05,  6.8150e-05,\n",
      "         3.0591e-05, -2.5145e-05,  2.1671e-05,  1.5363e-05, -5.2780e-05,\n",
      "         2.2455e-06, -6.4498e-05,  2.4691e-05, -3.5024e-05,  2.3193e-05,\n",
      "        -4.7389e-05, -1.2988e-05,  1.5948e-05, -3.8214e-05,  3.2161e-06,\n",
      "         1.5737e-05,  1.7251e-05,  5.5836e-06,  7.9240e-06,  4.0688e-06,\n",
      "        -3.7419e-05,  3.3836e-05, -1.1308e-05, -1.6347e-05, -3.1487e-05,\n",
      "        -2.2487e-05,  3.3176e-07, -9.2357e-05,  5.2628e-06,  7.2532e-06,\n",
      "        -2.9025e-05,  9.0923e-06,  7.4422e-05, -7.4586e-06,  7.6661e-05,\n",
      "        -2.1690e-05, -4.4139e-06,  1.2470e-06,  5.1451e-08, -6.3338e-06,\n",
      "        -1.1144e-07,  1.4344e-07, -2.0816e-05, -7.7284e-06,  2.9677e-05,\n",
      "        -9.0829e-05, -4.7567e-06,  9.6362e-05, -2.7032e-05, -5.2275e-05,\n",
      "         5.2213e-05, -4.0653e-05,  1.5110e-06, -2.9402e-05, -1.6380e-05,\n",
      "         2.6825e-05,  1.1158e-05,  4.0037e-06,  5.6611e-05,  5.1424e-05,\n",
      "        -2.5836e-06,  1.9790e-05,  1.8509e-05, -2.4094e-07, -6.8724e-06,\n",
      "         7.8321e-05,  1.4554e-06, -1.1835e-05, -3.8487e-05, -9.9844e-07,\n",
      "        -3.2274e-05,  4.9188e-06, -7.4738e-06,  3.3311e-05, -3.4807e-05,\n",
      "        -2.8032e-05, -5.4561e-06, -1.2431e-05,  1.5566e-05,  3.6317e-05,\n",
      "        -5.1842e-06, -7.2581e-05,  2.1069e-05, -2.7371e-05, -1.4393e-05,\n",
      "        -3.5947e-05,  2.9209e-05, -5.7254e-08,  3.1499e-05, -6.5341e-05,\n",
      "         2.5868e-05, -6.6446e-06,  7.7783e-05, -6.0226e-05,  1.8468e-05,\n",
      "         2.9358e-07, -2.9496e-05, -4.1436e-05, -1.4986e-05, -5.5815e-05,\n",
      "         7.4167e-06, -9.2435e-06,  6.9261e-05, -8.5250e-07,  1.6039e-05,\n",
      "         1.2567e-05, -1.5157e-05, -1.1700e-08, -7.0263e-05,  5.8298e-05,\n",
      "        -3.1243e-05,  1.0923e-04, -9.5003e-05, -4.3394e-05,  1.1905e-05,\n",
      "         1.4588e-05, -1.6563e-07,  1.7616e-05, -1.1397e-06, -2.6507e-05,\n",
      "         2.6147e-05, -5.2403e-05, -6.2690e-06, -6.3686e-05,  2.3423e-05,\n",
      "         4.9409e-05, -5.9366e-05,  1.9919e-05, -2.1252e-06, -5.7914e-05,\n",
      "         1.6026e-05, -2.8185e-05, -9.1599e-06,  1.6813e-04,  3.9540e-05,\n",
      "         3.2050e-06, -9.5844e-07, -1.8724e-05,  2.9300e-05,  1.8698e-05,\n",
      "        -2.7847e-05,  2.2020e-05,  4.8907e-05, -2.8346e-05, -4.5364e-07,\n",
      "        -3.4755e-07,  8.4141e-07, -1.7017e-05,  3.5012e-06, -1.0649e-05,\n",
      "         3.7128e-06,  9.4317e-06,  1.2447e-05,  2.3597e-05,  1.2210e-05,\n",
      "        -1.0738e-05,  3.2541e-05, -5.4282e-05,  1.0080e-05,  8.6723e-06,\n",
      "        -1.3694e-05, -1.8908e-05, -1.9528e-05, -3.6282e-05,  1.0298e-06,\n",
      "        -1.2915e-05,  2.4735e-05,  1.3400e-06, -1.6497e-05,  9.9623e-06,\n",
      "        -6.3314e-05,  6.7529e-05,  1.1160e-05,  1.0170e-04, -2.4807e-06,\n",
      "         1.3387e-04, -1.1470e-05,  3.3925e-05,  5.2769e-05, -5.6178e-06,\n",
      "         1.2064e-05,  2.3462e-05,  1.9640e-05, -3.0968e-05, -9.0267e-06,\n",
      "         1.4632e-05,  1.7678e-05,  1.3634e-05,  1.2614e-06, -6.8441e-05,\n",
      "         6.7043e-05,  1.5808e-05,  3.7673e-05,  1.5261e-04,  4.6310e-05,\n",
      "         1.2350e-05,  5.8500e-06, -3.0652e-05,  2.1265e-06,  2.0620e-05,\n",
      "         2.1676e-06,  5.5080e-06, -5.2754e-05, -2.7587e-05,  7.8413e-06,\n",
      "         1.7383e-06,  2.6550e-05, -5.8099e-05, -1.1487e-05, -4.1699e-05,\n",
      "        -1.0835e-05,  5.5223e-06,  5.9194e-06, -1.9504e-05, -3.9219e-05,\n",
      "         8.6139e-06,  4.1976e-05,  1.7057e-05,  1.1210e-05,  3.5366e-05,\n",
      "        -1.1110e-05, -2.4404e-05, -2.1217e-05,  5.0781e-06, -1.3569e-05,\n",
      "        -3.6485e-05, -5.6998e-05, -6.0731e-05,  1.8504e-05,  5.0379e-06,\n",
      "        -2.9167e-05,  2.8930e-05, -3.3756e-05, -2.7548e-06,  3.2959e-07,\n",
      "         1.3771e-05, -6.7267e-05,  1.3109e-05,  1.1348e-05,  6.4391e-05,\n",
      "        -2.9920e-05,  8.3689e-08,  7.4724e-05, -1.2886e-05,  2.8644e-05,\n",
      "         3.6021e-05, -5.3626e-05,  3.5318e-05,  1.8994e-05,  1.4784e-05,\n",
      "        -3.7102e-05,  2.3401e-05,  4.4107e-06,  2.9392e-05,  3.1691e-05,\n",
      "        -3.9155e-06,  1.7060e-05], device='cuda:0'), 'exp_avg_sq': tensor([2.3582e-09, 3.2767e-09, 6.8840e-09, 5.3354e-09, 1.6544e-08, 3.2946e-09,\n",
      "        3.5459e-09, 5.0588e-09, 7.4777e-09, 9.6934e-10, 4.3802e-09, 9.8054e-10,\n",
      "        3.9607e-10, 7.7930e-09, 7.5339e-09, 6.4507e-09, 4.4816e-10, 1.9367e-09,\n",
      "        1.2950e-09, 2.7480e-09, 4.5479e-09, 3.3780e-09, 1.9357e-09, 1.5198e-09,\n",
      "        4.2610e-09, 2.5406e-09, 9.4838e-09, 4.3749e-09, 8.8194e-11, 1.2150e-09,\n",
      "        5.4642e-10, 6.2302e-09, 1.3569e-09, 1.4243e-09, 4.5088e-09, 3.1725e-09,\n",
      "        6.4995e-09, 1.6664e-09, 2.8185e-10, 1.3917e-09, 5.1850e-09, 5.4604e-09,\n",
      "        6.7336e-09, 1.5984e-09, 1.2755e-09, 7.1766e-10, 1.8069e-09, 1.7953e-09,\n",
      "        5.4794e-09, 1.8467e-09, 2.8999e-09, 3.7554e-09, 1.0907e-09, 7.8598e-09,\n",
      "        4.8438e-09, 7.1053e-09, 8.2989e-10, 4.7247e-09, 3.7973e-10, 2.1374e-09,\n",
      "        9.4404e-10, 3.9667e-09, 4.7895e-10, 7.2901e-09, 5.3022e-09, 7.4658e-09,\n",
      "        5.3708e-09, 5.7411e-10, 1.9002e-09, 1.0699e-08, 1.8012e-09, 1.5888e-09,\n",
      "        7.8048e-09, 2.9274e-09, 2.8853e-09, 9.8524e-09, 1.7860e-09, 2.3424e-09,\n",
      "        7.1548e-09, 3.1804e-11, 4.9095e-09, 4.6986e-09, 1.8277e-09, 8.0435e-10,\n",
      "        3.2225e-09, 3.4738e-09, 2.6944e-09, 5.0833e-09, 1.0245e-09, 6.3059e-09,\n",
      "        6.4501e-09, 9.9685e-10, 3.2036e-09, 1.5551e-09, 2.5302e-09, 2.4373e-09,\n",
      "        8.7326e-10, 5.7414e-10, 5.2564e-09, 5.1713e-09, 5.0717e-09, 3.6712e-09,\n",
      "        2.9279e-09, 9.5954e-10, 4.0612e-09, 2.1007e-09, 1.6095e-09, 6.1544e-10,\n",
      "        7.3212e-10, 3.1333e-09, 9.4824e-09, 5.5476e-09, 4.4389e-09, 8.3223e-09,\n",
      "        2.7795e-09, 8.1550e-10, 3.0236e-09, 2.0635e-09, 3.7681e-09, 2.9554e-10,\n",
      "        1.4510e-09, 6.2959e-09, 2.6359e-09, 2.9343e-09, 4.9059e-09, 1.4579e-09,\n",
      "        9.2734e-11, 7.7969e-09, 4.3498e-09, 5.9701e-09, 1.5413e-09, 5.5495e-09,\n",
      "        5.4260e-09, 1.7042e-09, 5.1043e-11, 3.3305e-09, 1.0706e-09, 2.1534e-09,\n",
      "        7.0412e-10, 2.8442e-09, 5.0159e-11, 2.2820e-09, 4.5925e-09, 9.9333e-09,\n",
      "        6.8513e-09, 1.9944e-09, 6.8211e-09, 1.8538e-09, 2.8570e-09, 3.0573e-09,\n",
      "        1.0404e-09, 7.1353e-09, 1.5794e-08, 6.6297e-09, 4.7738e-09, 8.2342e-09,\n",
      "        2.4938e-09, 2.4932e-09, 1.1706e-08, 5.0247e-09, 1.2058e-09, 7.3643e-09,\n",
      "        3.1962e-09, 2.0217e-10, 1.0912e-08, 8.5107e-09, 7.4769e-09, 5.8505e-09,\n",
      "        4.9808e-10, 3.6378e-09, 7.4747e-09, 1.7592e-09, 4.2275e-09, 3.1772e-09,\n",
      "        6.4787e-10, 4.9284e-09, 3.3070e-09, 3.8566e-09, 2.5699e-09, 5.9886e-09,\n",
      "        2.0155e-09, 4.8546e-10, 3.9377e-09, 5.6861e-09, 3.7064e-09, 1.9560e-09,\n",
      "        2.9535e-09, 7.4941e-09, 5.4441e-09, 1.0061e-08, 1.6565e-09, 1.5646e-10,\n",
      "        3.8573e-09, 6.0342e-09, 5.0360e-09, 6.3964e-09, 4.3874e-09, 9.5006e-11,\n",
      "        3.8163e-09, 2.2721e-09, 3.5067e-12, 5.5984e-09, 4.2680e-09, 7.5152e-09,\n",
      "        2.3524e-09, 4.3980e-09, 7.7899e-09, 6.7903e-10, 7.9486e-10, 6.0008e-09,\n",
      "        5.8335e-09, 5.2512e-09, 4.0116e-09, 1.8479e-09, 1.2981e-09, 5.0639e-09,\n",
      "        1.4191e-09, 8.7482e-09, 7.6239e-10, 3.5828e-09, 2.1657e-09, 4.3815e-09,\n",
      "        1.2931e-10, 2.6948e-09, 3.7632e-09, 5.8474e-09, 1.4510e-09, 8.4202e-09,\n",
      "        1.7960e-09, 1.6981e-09, 1.3833e-09, 3.6229e-09, 8.7367e-09, 4.6473e-09,\n",
      "        2.0577e-09, 5.4324e-09, 4.0897e-09, 5.3392e-09, 1.9696e-09, 3.0033e-09,\n",
      "        1.8491e-09, 1.4258e-09, 6.2333e-09, 6.4411e-09, 1.1801e-08, 4.8833e-09,\n",
      "        2.7608e-09, 3.2799e-09, 2.2240e-09, 6.6811e-10, 2.6886e-09, 4.1217e-09,\n",
      "        5.8274e-09, 5.4059e-09, 4.2671e-09, 2.7936e-09, 2.4231e-09, 2.5531e-09,\n",
      "        1.4695e-09, 3.6460e-09, 3.9273e-10, 6.1321e-09, 3.4438e-09, 1.7709e-09,\n",
      "        1.3571e-09, 5.2548e-09, 1.7700e-09, 5.9463e-09, 2.0234e-09, 6.8843e-10,\n",
      "        1.7742e-09, 2.1116e-09, 1.8587e-09, 3.3211e-09, 3.4769e-09, 1.4844e-09,\n",
      "        5.0732e-09, 1.8921e-09, 2.3232e-09, 3.4678e-09, 4.5520e-09, 2.7138e-10,\n",
      "        6.6294e-09, 1.0869e-10, 8.3900e-10, 1.1928e-08, 3.9506e-09, 4.9002e-09,\n",
      "        3.1532e-09, 1.3670e-08, 1.9101e-09, 4.4387e-09, 3.6999e-09, 3.9402e-09,\n",
      "        2.6969e-10, 8.2931e-10, 9.1087e-10, 3.9246e-09, 4.9957e-09, 1.0398e-09,\n",
      "        3.0927e-09, 1.4559e-09, 2.9962e-09, 3.4249e-09, 4.8759e-09, 5.1718e-09,\n",
      "        1.7358e-09, 1.3426e-09, 1.2130e-09, 8.8712e-10, 4.5650e-10, 1.5589e-09,\n",
      "        3.6896e-10, 6.8841e-09, 1.5083e-09, 8.0339e-10, 1.2016e-09, 6.9644e-10,\n",
      "        2.1175e-10, 3.8002e-09, 6.7870e-09, 1.8902e-10, 4.5459e-10, 3.1409e-09,\n",
      "        1.4264e-09, 2.9484e-09, 1.1456e-09, 4.7075e-09, 3.5722e-09, 6.6338e-09,\n",
      "        1.2703e-09, 3.2268e-09, 2.3195e-09, 7.2108e-09, 7.4669e-09, 9.0697e-10,\n",
      "        8.6472e-09, 5.0051e-09, 4.4018e-09, 1.0775e-09, 8.5329e-10, 6.7934e-09,\n",
      "        3.0581e-09, 5.0523e-09, 2.9327e-09, 9.6203e-09, 7.7492e-09, 6.9477e-09,\n",
      "        3.3517e-09, 3.4932e-09, 2.5445e-11, 5.2456e-09, 2.5053e-09, 2.7231e-09,\n",
      "        4.6248e-09, 1.1904e-08, 3.5105e-09, 4.9801e-09, 8.1051e-10, 1.7545e-09,\n",
      "        7.0526e-10, 2.2815e-09, 1.8250e-09, 3.9829e-09, 3.6637e-09, 4.7325e-09,\n",
      "        6.0933e-09, 2.8580e-09, 2.4157e-09, 2.1144e-09, 2.3774e-09, 5.4949e-10,\n",
      "        4.4536e-09, 1.4934e-10, 3.9549e-09, 1.8459e-09, 1.6987e-09, 4.8729e-09,\n",
      "        2.5631e-09, 1.8060e-09, 4.3500e-09, 2.6024e-09, 2.7931e-09, 2.2508e-11,\n",
      "        3.2298e-09, 1.1463e-09, 2.0299e-09, 5.3270e-11, 5.7190e-09, 3.6187e-09,\n",
      "        2.8801e-09, 2.1562e-10, 1.1738e-09, 8.7867e-09, 6.2652e-09, 3.1738e-09,\n",
      "        2.8848e-09, 3.9506e-09, 4.1042e-09, 4.6871e-09, 6.8756e-10, 2.9963e-09,\n",
      "        5.4338e-09, 6.3464e-09, 9.7192e-09, 1.6186e-10, 1.3447e-09, 7.4818e-10,\n",
      "        4.4228e-09, 3.7234e-09, 1.5875e-09, 6.8066e-09, 4.9052e-09, 4.2376e-09,\n",
      "        1.5779e-09, 4.0862e-09, 5.0161e-09, 1.9855e-09, 2.1373e-09, 2.0043e-10,\n",
      "        1.8435e-09, 5.0414e-09, 1.0463e-09, 1.0852e-09, 4.7947e-10, 6.6913e-09,\n",
      "        6.5809e-10, 3.1632e-09, 5.5233e-09, 8.7223e-11, 6.2534e-09, 1.4402e-09,\n",
      "        4.3857e-09, 6.3254e-09, 3.3950e-09, 7.8838e-10, 2.8176e-09, 5.4050e-09,\n",
      "        2.9958e-09, 1.9077e-09, 3.2968e-09, 4.8819e-10, 5.4906e-09, 3.2338e-09,\n",
      "        4.7753e-09, 6.5785e-09, 6.2294e-09, 5.9244e-09, 1.2527e-08, 1.7575e-09,\n",
      "        8.0742e-09, 3.9383e-10, 5.2004e-09, 9.7761e-10, 2.1118e-09, 1.0076e-10,\n",
      "        3.2669e-10, 1.4325e-08, 3.4668e-09, 2.1141e-09, 1.3887e-10, 3.1693e-09,\n",
      "        2.3019e-09, 1.4733e-09, 6.1228e-09, 5.5696e-09, 2.6522e-10, 4.3072e-09,\n",
      "        1.2284e-09, 2.0730e-09, 6.3846e-09, 6.3741e-10, 7.2200e-10, 1.8985e-09,\n",
      "        7.9736e-09, 2.0268e-09, 8.4622e-09, 6.1549e-10, 2.0347e-09, 2.8376e-09,\n",
      "        4.2628e-09, 6.3157e-09, 5.5283e-09, 1.0352e-08, 1.9610e-09, 1.6234e-09,\n",
      "        6.6666e-10, 3.3917e-09, 1.1835e-09, 6.3291e-10, 5.7667e-10, 1.3615e-09,\n",
      "        1.4208e-10, 2.7641e-09, 6.2219e-09, 8.8332e-10, 1.0606e-09, 3.4659e-09,\n",
      "        1.6636e-09, 9.1992e-09, 1.5151e-09, 5.4064e-09, 2.0447e-09, 7.0164e-09,\n",
      "        5.9714e-10, 3.7540e-09, 2.6705e-09, 4.3901e-09, 7.3331e-10, 8.0815e-09,\n",
      "        2.5544e-09, 2.0226e-09], device='cuda:0')}, 4: {'step': tensor(60., device='cuda:0'), 'exp_avg': tensor([[ 3.7038e-04, -4.4227e-04, -4.2648e-04,  ..., -1.1760e-03,\n",
      "         -2.6627e-04, -1.2242e-04],\n",
      "        [-1.2246e-03, -5.9612e-04, -4.3618e-04,  ..., -2.6533e-03,\n",
      "          4.1718e-04,  3.0959e-05],\n",
      "        [-8.5775e-04, -2.2764e-05, -8.4012e-04,  ..., -1.6258e-03,\n",
      "          1.0368e-04,  4.9397e-05],\n",
      "        ...,\n",
      "        [ 3.2592e-04, -4.8887e-06,  1.5497e-04,  ...,  4.5734e-04,\n",
      "         -8.2452e-04,  2.2320e-05],\n",
      "        [-1.0028e-03, -9.2409e-05,  3.8579e-04,  ...,  1.1374e-03,\n",
      "         -1.0619e-03,  2.8452e-05],\n",
      "        [ 5.4071e-04,  9.6431e-05, -7.4367e-05,  ...,  1.2587e-03,\n",
      "         -2.9067e-04,  1.7227e-05]], device='cuda:0'), 'exp_avg_sq': tensor([[1.2848e-07, 1.6018e-07, 1.1007e-06,  ..., 1.2832e-06, 4.6622e-07,\n",
      "         7.2728e-08],\n",
      "        [5.7391e-07, 4.9417e-07, 1.8382e-06,  ..., 3.4447e-06, 4.6566e-07,\n",
      "         1.0792e-07],\n",
      "        [5.0044e-07, 1.1435e-07, 3.3589e-06,  ..., 2.4639e-06, 3.7335e-07,\n",
      "         1.3960e-07],\n",
      "        ...,\n",
      "        [2.8936e-07, 2.4124e-07, 1.2886e-06,  ..., 1.2298e-06, 3.1028e-07,\n",
      "         2.7492e-08],\n",
      "        [2.6818e-07, 2.2743e-07, 9.7298e-07,  ..., 1.0818e-06, 9.9943e-07,\n",
      "         1.3317e-08],\n",
      "        [1.6039e-07, 1.1722e-07, 7.7374e-07,  ..., 1.7057e-06, 6.0491e-08,\n",
      "         1.8366e-08]], device='cuda:0')}, 5: {'step': tensor(60., device='cuda:0'), 'exp_avg': tensor([-6.1335e-05, -4.9864e-05, -1.3108e-04, -6.0940e-05, -6.2613e-05,\n",
      "        -4.1660e-06,  8.5445e-06, -3.2394e-05,  7.4063e-05, -6.2712e-05,\n",
      "         5.3297e-05,  4.8994e-05, -5.3181e-05,  6.9118e-05,  4.8106e-05,\n",
      "        -8.4992e-05,  7.6105e-05, -2.6312e-05, -2.6450e-05, -7.6983e-05,\n",
      "         4.7357e-05,  5.1217e-05,  4.8129e-05, -6.7276e-05,  2.4158e-04,\n",
      "         4.4853e-06, -9.2507e-05,  8.4030e-06, -1.1439e-04,  3.7408e-05,\n",
      "         5.3649e-05, -3.6025e-05, -5.6800e-05,  1.7503e-05,  4.1229e-06,\n",
      "        -1.7737e-04,  2.3243e-05, -6.2585e-05, -3.9503e-05,  6.1245e-05,\n",
      "         3.9257e-05,  9.8783e-05, -7.6221e-06,  1.0057e-04, -1.5768e-05,\n",
      "         9.8379e-05,  5.9129e-05, -6.0151e-05,  2.4271e-06,  4.1092e-05,\n",
      "        -1.0798e-04, -2.1471e-05, -1.2303e-04,  8.5327e-05, -9.1612e-05,\n",
      "         1.2801e-04, -1.8209e-05, -2.0609e-05,  4.9899e-05,  2.6214e-05,\n",
      "         3.6100e-05, -5.7094e-05, -6.3307e-05,  7.3452e-05,  4.8418e-05,\n",
      "        -1.5799e-04,  5.0053e-05,  9.5998e-05, -5.6663e-05, -1.9468e-05,\n",
      "         2.1499e-05, -9.0240e-06,  1.6157e-05,  1.1474e-04, -3.3193e-05,\n",
      "        -6.7470e-06,  1.9436e-05, -6.0610e-05, -2.5439e-05, -9.3087e-05,\n",
      "         1.0294e-04, -6.0814e-05,  7.7915e-05, -6.6550e-05, -5.7649e-05,\n",
      "         5.1728e-05, -3.2411e-05,  4.4059e-06,  7.2026e-05, -1.9768e-05,\n",
      "         3.6651e-05,  2.1584e-05, -5.3032e-05,  4.3766e-05, -1.8658e-04,\n",
      "        -4.0165e-05,  4.0978e-05,  5.4656e-05,  6.7024e-06,  1.0262e-05,\n",
      "         9.2928e-05,  1.7312e-04, -1.4327e-05, -3.2898e-05, -1.0034e-04,\n",
      "         1.6712e-05, -6.3373e-05,  3.0536e-05, -1.5965e-05,  1.4582e-04,\n",
      "         3.0413e-05,  1.8481e-05,  7.1892e-05,  9.5032e-05, -5.3265e-05,\n",
      "        -6.6005e-05, -4.7772e-06,  7.2911e-05,  5.3411e-05,  1.0633e-04,\n",
      "         1.4557e-05,  1.0901e-04,  1.6689e-04,  3.4364e-05,  4.9400e-05,\n",
      "         2.1316e-05,  9.9822e-05,  3.1410e-05, -3.7383e-05, -1.6082e-05,\n",
      "        -1.4221e-04, -4.4139e-05,  2.7021e-05,  1.1346e-05,  2.9344e-06,\n",
      "         7.4238e-05, -1.1930e-04,  1.5506e-05,  4.4472e-05, -9.1350e-05,\n",
      "        -9.4576e-05,  2.2333e-05, -2.9245e-06, -3.8039e-06, -1.5237e-04,\n",
      "        -1.1285e-05,  1.0438e-04, -1.0826e-05,  9.9975e-05, -2.1203e-05,\n",
      "         4.1876e-05,  9.4382e-06,  6.6680e-05, -5.3068e-05,  2.3507e-05,\n",
      "         1.4282e-05,  5.2832e-06,  9.9687e-05,  2.9200e-05,  7.5775e-05,\n",
      "         4.3488e-05, -6.3425e-07,  9.6051e-05,  7.3916e-07, -1.5310e-04,\n",
      "         4.9204e-07, -6.3911e-05, -1.5053e-05,  5.8386e-05,  7.7619e-05,\n",
      "        -2.2412e-04,  1.0907e-04,  8.7500e-05,  2.4945e-05, -5.0018e-05,\n",
      "         9.4478e-05,  1.2389e-04, -8.9985e-05,  1.9884e-05,  1.6900e-04,\n",
      "        -1.8350e-05, -8.5291e-06,  1.2289e-04, -6.2581e-05,  9.2043e-06,\n",
      "        -6.7712e-06,  3.8689e-05,  6.0813e-05, -1.1066e-05,  9.6782e-06,\n",
      "         2.6134e-05,  5.4858e-06, -2.0320e-05,  2.0675e-05,  7.3429e-05,\n",
      "        -5.2267e-05,  5.4640e-05,  1.2904e-05, -8.0192e-06, -5.7650e-05,\n",
      "        -1.1854e-04, -7.8731e-05,  2.6985e-05,  8.6458e-05,  8.7103e-05,\n",
      "         1.4653e-04,  3.7360e-05,  1.1877e-04,  4.3034e-05,  3.7480e-05,\n",
      "        -5.6554e-05,  7.2094e-08, -6.3298e-05, -3.5389e-05,  2.6142e-06,\n",
      "         4.8581e-06, -5.5864e-05,  4.2338e-05,  4.7937e-06,  7.5761e-05,\n",
      "        -7.6691e-05,  1.3747e-04,  1.3640e-05,  8.4102e-05, -2.5771e-05,\n",
      "        -6.7569e-05, -2.3663e-05, -4.2124e-05,  9.8905e-05,  4.7826e-05,\n",
      "         6.4893e-05,  3.5955e-07,  4.5318e-05,  6.3634e-06,  1.5458e-05,\n",
      "         1.1342e-04,  3.2626e-05, -1.8192e-04, -3.6903e-05, -6.6320e-06,\n",
      "        -5.0505e-05, -5.5465e-06,  2.0839e-06,  8.3138e-05, -7.8265e-05,\n",
      "         3.0177e-05,  1.3130e-05,  4.3193e-05, -5.1876e-05, -6.3532e-05,\n",
      "         1.4558e-04, -3.3245e-06,  3.9834e-05,  1.7271e-05, -1.4558e-05,\n",
      "         2.0828e-04,  3.0645e-06, -6.1684e-06,  4.3448e-05, -1.9213e-04,\n",
      "         5.2701e-05, -9.2091e-05,  2.3645e-05,  2.8470e-05,  6.3971e-05,\n",
      "         1.3670e-04,  5.4135e-05,  2.1776e-04,  5.9391e-06,  8.1048e-05,\n",
      "        -5.4126e-05,  1.1052e-05,  1.3483e-05, -2.7645e-06,  1.3617e-06,\n",
      "         1.3201e-05, -1.3989e-04, -2.7795e-06, -9.1687e-06, -1.3885e-04,\n",
      "         1.3009e-05,  5.7667e-05,  3.6265e-05,  6.2513e-05, -5.1573e-05,\n",
      "         1.5602e-05,  3.8679e-05, -1.9167e-05, -5.2673e-06,  2.9829e-05,\n",
      "        -5.4950e-05,  3.6467e-05, -2.0260e-05,  5.4668e-06,  1.7306e-05,\n",
      "         1.3567e-04, -7.9672e-05,  2.6267e-05,  3.9975e-05,  1.3860e-04,\n",
      "         8.6802e-05,  1.6983e-06,  4.3626e-06, -1.2511e-04,  2.0202e-06,\n",
      "         1.8820e-05,  5.0986e-06,  7.1041e-05,  2.6629e-05,  1.0985e-04,\n",
      "         1.3079e-04,  3.7827e-05,  1.4007e-04,  7.9571e-05,  8.3802e-05,\n",
      "         1.9583e-04, -4.4818e-05, -5.4083e-05,  4.4215e-05,  1.3671e-05,\n",
      "        -1.9659e-05, -6.1519e-05, -6.6331e-06, -5.2165e-05, -4.5000e-05,\n",
      "        -2.3654e-06,  3.9200e-05,  1.4471e-04,  8.6325e-05, -3.7551e-05,\n",
      "        -1.0980e-05,  1.0425e-04, -2.1279e-05,  3.3874e-05, -9.1444e-07,\n",
      "        -9.0052e-06,  1.3214e-06, -4.9570e-07,  4.4679e-05, -9.4795e-06,\n",
      "         6.5170e-05, -2.2315e-05,  7.0349e-05,  3.7397e-05, -7.4595e-05,\n",
      "        -4.3752e-05, -8.4698e-06, -7.0672e-05,  5.4665e-06,  2.9265e-05,\n",
      "         5.6126e-05,  6.9047e-06,  8.3093e-05,  1.8099e-04,  1.8126e-04,\n",
      "         1.4891e-04,  9.7780e-06,  5.9440e-05, -1.4335e-04,  5.6517e-05,\n",
      "        -4.7198e-06,  4.8917e-05,  2.5017e-05,  3.0451e-05,  9.4303e-05,\n",
      "        -3.1006e-05, -1.5385e-04,  2.3582e-05,  8.0695e-05, -1.4602e-04,\n",
      "        -2.7848e-05, -4.2288e-05,  1.5503e-04,  1.2126e-04, -6.4204e-05,\n",
      "        -9.9821e-05, -3.5461e-05, -3.4097e-05,  1.2877e-05,  5.1808e-05,\n",
      "         2.6421e-05, -1.2390e-05, -2.3004e-05,  7.6679e-05, -3.9337e-05,\n",
      "         3.1765e-04,  6.7561e-06, -1.9279e-05,  2.1423e-05, -8.2570e-05,\n",
      "         1.7676e-04,  6.1818e-06, -2.7621e-05,  3.8276e-05, -2.7158e-05,\n",
      "         8.0850e-05, -8.5253e-05,  7.7633e-05, -5.2446e-05,  1.0630e-04,\n",
      "         2.0209e-05,  4.7643e-05,  1.5755e-05, -2.5776e-05, -7.6514e-05,\n",
      "         7.2315e-05,  2.6852e-05,  1.2481e-04,  5.0869e-05,  1.5894e-05,\n",
      "         8.4212e-05, -1.5249e-04, -9.6854e-05, -1.3935e-05, -3.8580e-06,\n",
      "         3.0907e-05,  9.6833e-05,  7.8133e-05,  2.1899e-07, -6.9268e-05,\n",
      "        -8.0393e-05,  1.0100e-04,  1.4787e-04, -9.6958e-05, -1.2189e-05,\n",
      "         1.9414e-05,  3.3137e-05,  1.0119e-04, -9.3497e-05, -3.4642e-05,\n",
      "         9.6634e-05,  5.9841e-05, -4.5486e-05,  8.9784e-05, -1.2488e-04,\n",
      "         1.1602e-04, -4.6421e-05,  1.8983e-05,  1.5254e-04, -3.2762e-05,\n",
      "         2.9624e-05, -1.5938e-04, -2.7335e-05,  1.7848e-05, -6.5849e-06,\n",
      "         4.4591e-05,  5.3762e-05, -1.1100e-05, -4.3182e-05,  1.5689e-06,\n",
      "        -1.3935e-06,  4.1031e-05,  4.0811e-05, -1.0127e-04, -1.0812e-05,\n",
      "         3.6676e-05, -6.1888e-05,  5.8492e-05,  3.6074e-05, -9.1373e-05,\n",
      "         6.2791e-05, -1.8200e-05,  8.7440e-05,  4.8108e-05,  1.2697e-05,\n",
      "         3.0408e-05,  6.7333e-05,  5.6549e-05, -1.4937e-04, -6.6073e-05,\n",
      "        -1.2645e-04, -1.6754e-05, -7.8133e-05, -8.4706e-05,  8.2220e-06,\n",
      "         1.0451e-04, -1.2197e-05,  1.3532e-05, -2.2388e-06,  1.3670e-05,\n",
      "         4.8779e-06, -9.8479e-06, -9.2551e-05, -3.9746e-05,  1.5468e-04,\n",
      "        -3.7068e-06,  2.5883e-05, -1.4625e-04, -8.4405e-06,  5.3136e-05,\n",
      "        -8.2419e-05,  3.5849e-05,  5.6711e-05,  1.0470e-04,  9.0520e-06,\n",
      "        -7.2935e-06,  2.9253e-05,  3.8384e-05, -2.0667e-05,  1.5945e-04,\n",
      "        -1.8509e-04,  8.3902e-05, -6.7743e-05,  7.2341e-05, -4.5174e-05,\n",
      "         7.1986e-05,  3.5423e-05,  2.1320e-05,  2.0418e-05,  8.4137e-05,\n",
      "         6.0299e-06,  1.5478e-04], device='cuda:0'), 'exp_avg_sq': tensor([1.4724e-08, 1.9273e-08, 1.8685e-08, 1.4004e-08, 7.1409e-09, 6.9634e-09,\n",
      "        3.0497e-09, 1.3042e-08, 1.5847e-08, 4.3989e-09, 3.4559e-09, 3.4722e-09,\n",
      "        1.7799e-08, 2.9109e-09, 3.8314e-09, 1.8370e-08, 3.9103e-08, 6.1304e-09,\n",
      "        5.9520e-09, 3.9641e-09, 1.0268e-08, 3.5083e-08, 1.7049e-08, 1.0019e-08,\n",
      "        2.0576e-08, 2.7540e-08, 1.3770e-08, 4.8749e-09, 1.1843e-08, 1.2355e-08,\n",
      "        7.9745e-09, 1.0735e-08, 8.2268e-09, 5.1149e-09, 1.0370e-08, 2.0601e-08,\n",
      "        5.5462e-09, 1.5488e-08, 1.1191e-08, 5.5565e-09, 1.3245e-08, 1.8352e-08,\n",
      "        1.6040e-09, 1.1831e-08, 1.2917e-08, 2.4379e-08, 1.1679e-08, 3.2018e-09,\n",
      "        1.1141e-08, 8.5943e-09, 5.6571e-09, 7.7969e-09, 6.1545e-09, 3.3894e-09,\n",
      "        2.1013e-08, 1.2087e-08, 1.7127e-08, 9.9865e-09, 5.5259e-09, 1.0338e-08,\n",
      "        4.0651e-09, 1.5311e-08, 9.9023e-09, 1.4021e-08, 9.7120e-09, 7.3526e-09,\n",
      "        7.9084e-09, 9.0194e-09, 2.0957e-09, 2.6724e-09, 1.3396e-08, 3.5503e-09,\n",
      "        1.1492e-08, 9.4607e-09, 6.4847e-09, 3.3244e-09, 4.8341e-09, 1.7210e-08,\n",
      "        1.7870e-08, 7.1428e-09, 1.0973e-08, 3.5788e-09, 3.4008e-09, 4.8752e-09,\n",
      "        1.2448e-08, 1.9508e-09, 8.1197e-09, 9.4659e-09, 7.7610e-09, 1.6151e-09,\n",
      "        7.3609e-09, 6.1593e-09, 6.1907e-10, 4.5849e-09, 2.7504e-08, 3.4676e-09,\n",
      "        1.4030e-08, 1.9268e-09, 1.5905e-08, 1.2579e-08, 3.0362e-09, 2.0565e-08,\n",
      "        1.0776e-08, 1.0272e-08, 6.7088e-09, 5.5150e-09, 2.9921e-09, 1.8266e-08,\n",
      "        2.1321e-08, 1.5767e-08, 4.1774e-08, 7.7616e-09, 1.7805e-08, 2.1885e-08,\n",
      "        5.3109e-09, 1.1703e-08, 4.0703e-09, 1.5226e-08, 1.5639e-08, 7.7832e-09,\n",
      "        7.9310e-09, 9.7559e-09, 5.4644e-09, 1.0688e-08, 1.0067e-08, 1.2464e-08,\n",
      "        2.4712e-08, 1.1263e-08, 1.2899e-08, 1.6919e-08, 7.8762e-09, 1.1777e-08,\n",
      "        1.2271e-08, 1.4021e-08, 1.5981e-09, 9.4890e-09, 1.1491e-08, 1.7240e-08,\n",
      "        1.3616e-08, 1.7006e-08, 7.0262e-09, 1.3056e-08, 1.8143e-08, 1.4153e-08,\n",
      "        1.3515e-08, 3.9848e-09, 8.1201e-09, 1.1484e-09, 4.6615e-09, 1.5757e-08,\n",
      "        9.0947e-09, 4.3980e-09, 4.9097e-09, 1.4445e-08, 1.1587e-08, 4.9382e-09,\n",
      "        2.1866e-08, 9.0645e-09, 8.1606e-10, 1.0653e-08, 2.0917e-09, 1.4843e-08,\n",
      "        1.9173e-08, 1.6591e-08, 1.6091e-08, 1.7816e-08, 1.4189e-08, 3.2029e-08,\n",
      "        1.3719e-08, 7.9374e-09, 2.0426e-08, 6.3710e-09, 6.8449e-09, 2.2929e-08,\n",
      "        1.5849e-08, 2.1722e-08, 2.7220e-08, 1.3877e-08, 2.0447e-09, 2.0695e-08,\n",
      "        9.2250e-09, 9.0708e-09, 7.3064e-09, 1.9435e-09, 1.9372e-09, 1.2669e-09,\n",
      "        2.2427e-08, 4.4845e-09, 2.0082e-08, 7.1577e-09, 8.8170e-09, 8.7610e-09,\n",
      "        3.4519e-09, 7.5493e-09, 1.2752e-08, 9.6571e-09, 1.7969e-08, 1.0505e-08,\n",
      "        2.8208e-09, 1.0560e-08, 1.0172e-08, 8.4131e-09, 7.0665e-09, 9.5487e-09,\n",
      "        6.3736e-09, 1.8056e-08, 2.9517e-09, 1.7103e-08, 2.9890e-09, 4.4466e-08,\n",
      "        1.0456e-08, 9.2238e-09, 9.9282e-09, 4.8815e-09, 1.7578e-08, 9.7570e-10,\n",
      "        2.0924e-08, 7.8373e-09, 1.4423e-08, 2.0185e-08, 2.1303e-08, 1.6962e-08,\n",
      "        9.4862e-09, 2.3525e-08, 1.4586e-08, 5.7831e-09, 1.6346e-08, 3.8931e-09,\n",
      "        1.4146e-08, 1.5840e-08, 1.8280e-08, 3.8519e-09, 2.1571e-09, 3.7666e-09,\n",
      "        2.0212e-09, 1.0107e-08, 1.2747e-08, 1.5374e-08, 1.0769e-08, 7.8050e-09,\n",
      "        6.4972e-09, 1.6047e-08, 2.9739e-09, 1.0611e-08, 1.2808e-08, 3.1593e-09,\n",
      "        2.1315e-08, 3.7885e-09, 6.7748e-09, 9.3847e-09, 1.4466e-08, 8.7648e-09,\n",
      "        1.1285e-08, 1.2206e-08, 8.2009e-09, 8.3178e-09, 6.6230e-09, 5.3227e-09,\n",
      "        9.5559e-09, 1.4972e-08, 1.0217e-08, 4.5683e-08, 3.1319e-08, 9.2185e-09,\n",
      "        1.0421e-08, 1.7579e-08, 1.6550e-08, 2.1070e-08, 1.3827e-08, 1.4017e-08,\n",
      "        1.6252e-08, 6.9862e-09, 2.2706e-09, 6.5615e-09, 1.4373e-09, 7.4751e-09,\n",
      "        1.2926e-08, 1.0567e-09, 3.2868e-09, 9.4377e-09, 1.1018e-08, 9.6291e-09,\n",
      "        7.0498e-09, 1.2592e-08, 1.8684e-08, 7.7554e-09, 1.4798e-08, 5.1213e-09,\n",
      "        1.2466e-08, 1.2987e-08, 1.9676e-08, 2.1617e-08, 2.0813e-08, 2.6098e-08,\n",
      "        6.6009e-09, 2.4313e-08, 9.0455e-09, 1.8626e-08, 2.9846e-09, 2.0338e-08,\n",
      "        1.5333e-08, 9.7295e-09, 7.6421e-09, 1.4365e-08, 8.2016e-09, 1.3515e-08,\n",
      "        2.0070e-08, 2.2250e-08, 1.3311e-08, 2.8572e-08, 1.3957e-08, 8.4148e-09,\n",
      "        1.0090e-08, 1.2547e-08, 1.3924e-08, 1.4923e-08, 1.6362e-08, 1.1906e-08,\n",
      "        1.5789e-08, 1.5374e-08, 1.7639e-08, 7.8832e-09, 6.9603e-09, 1.1724e-08,\n",
      "        9.7485e-09, 4.6949e-10, 8.1337e-09, 6.2744e-09, 1.1976e-08, 5.2059e-09,\n",
      "        1.1220e-08, 8.7519e-09, 1.4966e-08, 6.8705e-09, 4.5961e-09, 6.0193e-09,\n",
      "        8.3016e-09, 4.0860e-09, 1.3413e-08, 6.3035e-09, 4.9910e-09, 6.1261e-09,\n",
      "        3.7394e-08, 4.2245e-09, 7.2802e-09, 1.2854e-08, 5.1462e-09, 4.3797e-08,\n",
      "        1.4635e-08, 2.1262e-08, 1.4579e-08, 1.2638e-08, 1.1153e-08, 1.4761e-08,\n",
      "        1.7260e-08, 1.4234e-08, 1.0262e-09, 9.2968e-09, 1.3771e-08, 2.1121e-08,\n",
      "        7.2136e-09, 2.6424e-09, 6.0486e-09, 1.3564e-08, 9.4984e-09, 2.2286e-08,\n",
      "        1.6813e-08, 6.5592e-09, 1.1307e-08, 1.1558e-08, 7.5656e-09, 4.6228e-09,\n",
      "        1.8519e-08, 3.8236e-09, 5.1548e-09, 1.2587e-08, 7.4396e-09, 1.1035e-08,\n",
      "        4.0164e-09, 1.8291e-08, 4.4955e-09, 3.4105e-09, 1.7551e-09, 3.6957e-09,\n",
      "        1.6963e-08, 2.2512e-08, 1.0088e-08, 2.7621e-08, 3.2476e-09, 1.4237e-08,\n",
      "        1.5594e-08, 1.4734e-09, 1.2166e-08, 5.6177e-09, 7.8208e-09, 1.0156e-08,\n",
      "        6.1481e-09, 1.5516e-08, 3.9426e-09, 1.4092e-08, 7.2412e-09, 1.2483e-08,\n",
      "        1.7679e-08, 1.3865e-08, 2.7095e-08, 1.2944e-08, 8.4525e-09, 1.5765e-08,\n",
      "        1.0773e-08, 1.0425e-08, 1.3757e-08, 2.0246e-08, 1.4860e-08, 5.1360e-09,\n",
      "        2.0224e-08, 4.2943e-09, 1.0198e-08, 5.3055e-09, 1.8032e-10, 1.6927e-08,\n",
      "        2.0906e-08, 2.7806e-08, 1.2394e-08, 3.4429e-08, 2.1309e-09, 8.8300e-09,\n",
      "        7.4600e-09, 6.8021e-09, 1.3718e-08, 2.6928e-09, 2.1799e-08, 1.9075e-08,\n",
      "        2.1641e-08, 2.4302e-08, 1.6802e-08, 8.2030e-09, 7.6944e-09, 1.4297e-08,\n",
      "        1.2805e-08, 1.5132e-08, 3.5700e-09, 1.5881e-08, 6.9084e-09, 2.2541e-09,\n",
      "        1.2812e-08, 8.5509e-09, 5.7682e-09, 3.9032e-09, 5.9208e-09, 9.9970e-09,\n",
      "        6.7205e-09, 1.4783e-08, 1.2288e-08, 7.1354e-09, 1.2113e-08, 6.3462e-09,\n",
      "        1.0478e-08, 1.4457e-08, 6.5985e-09, 1.2911e-08, 1.7235e-08, 4.9261e-09,\n",
      "        1.3238e-08, 1.5310e-08, 1.2317e-08, 1.2921e-08, 1.2582e-08, 7.7814e-09,\n",
      "        2.3644e-08, 5.1473e-09, 9.5426e-09, 5.1221e-09, 6.4955e-09, 6.3351e-09,\n",
      "        2.8426e-09, 1.6538e-08, 1.0566e-08, 7.1106e-09, 5.6717e-09, 8.4972e-09,\n",
      "        4.1097e-09, 1.5373e-08, 1.5902e-08, 1.6572e-08, 1.3693e-08, 2.7860e-09,\n",
      "        4.8996e-09, 1.6428e-08, 2.1522e-08, 8.4710e-09, 7.5328e-09, 2.4277e-08,\n",
      "        1.3822e-08, 2.2015e-08, 1.5343e-09, 1.9990e-08, 5.1687e-09, 6.0650e-09,\n",
      "        1.6068e-08, 3.4787e-08, 1.8247e-08, 2.3820e-08, 1.9363e-08, 2.7988e-08,\n",
      "        7.5989e-09, 8.2801e-09, 5.2979e-09, 5.4969e-09, 1.1673e-08, 1.3693e-08,\n",
      "        9.2667e-09, 8.7290e-09], device='cuda:0')}, 6: {'step': tensor(60., device='cuda:0'), 'exp_avg': tensor([[ 1.3544e-03, -3.0193e-03,  2.5468e-03,  ..., -2.8626e-05,\n",
      "          8.1397e-04,  1.4571e-03],\n",
      "        [ 1.2020e-03,  1.6594e-03,  1.6994e-03,  ...,  1.3251e-04,\n",
      "          5.4819e-04,  1.0327e-03],\n",
      "        [ 1.3152e-03,  1.0195e-03,  8.4935e-04,  ...,  6.6129e-04,\n",
      "          5.1864e-04,  1.7347e-04],\n",
      "        ...,\n",
      "        [ 2.8993e-04,  7.8037e-04, -2.7086e-04,  ...,  2.3232e-04,\n",
      "          1.2175e-03,  2.0412e-08],\n",
      "        [ 3.3797e-04, -2.2249e-04,  1.0261e-03,  ..., -6.0595e-04,\n",
      "          2.5294e-05, -3.3083e-05],\n",
      "        [-1.3387e-04,  8.9278e-05, -8.9864e-05,  ..., -5.7895e-04,\n",
      "          9.7008e-04, -8.3470e-04]], device='cuda:0'), 'exp_avg_sq': tensor([[1.4383e-06, 1.2513e-05, 4.5593e-06,  ..., 1.9891e-06, 3.2703e-06,\n",
      "         1.3747e-06],\n",
      "        [2.7122e-06, 2.5951e-06, 3.6532e-06,  ..., 1.7207e-06, 1.1979e-06,\n",
      "         5.3179e-07],\n",
      "        [5.9932e-07, 1.7272e-06, 1.5860e-06,  ..., 8.1227e-07, 8.0467e-07,\n",
      "         9.5861e-08],\n",
      "        ...,\n",
      "        [8.1745e-07, 1.2963e-06, 1.5592e-06,  ..., 4.7001e-07, 1.8910e-06,\n",
      "         5.2151e-07],\n",
      "        [8.6186e-07, 3.2627e-06, 1.1382e-06,  ..., 6.0681e-07, 2.7087e-06,\n",
      "         2.8754e-07],\n",
      "        [1.8582e-06, 9.2727e-07, 2.2862e-06,  ..., 1.2076e-06, 1.1297e-06,\n",
      "         1.0234e-06]], device='cuda:0')}, 7: {'step': tensor(60., device='cuda:0'), 'exp_avg': tensor([ 2.9172e-04,  3.7417e-04,  1.8896e-04,  8.4877e-05,  1.4521e-04,\n",
      "         5.2283e-05,  7.4106e-05,  1.1464e-04,  4.4381e-05,  5.6637e-05,\n",
      "        -8.4701e-05, -4.2905e-05, -3.2130e-04, -2.9565e-05,  1.0048e-04,\n",
      "        -1.6207e-04, -3.4562e-04,  2.7457e-04, -1.8522e-04, -4.7064e-05,\n",
      "        -1.2575e-04, -2.7963e-05, -8.5468e-05, -9.0168e-05,  1.2832e-04,\n",
      "        -2.2646e-05, -1.2847e-04,  4.7265e-05,  2.3878e-04, -1.0442e-04,\n",
      "         1.8106e-04,  7.2677e-04,  2.1563e-04, -9.5304e-05,  3.6115e-04,\n",
      "        -5.0059e-05,  1.9792e-04, -6.5425e-05, -6.5160e-05,  5.1629e-05,\n",
      "        -3.9638e-05, -1.2956e-04,  1.6704e-05,  4.3649e-04, -4.1887e-05,\n",
      "        -2.7777e-05, -1.8534e-04, -1.1938e-04,  2.8307e-04, -1.9222e-04,\n",
      "         1.5316e-05,  8.4801e-05,  1.5962e-06, -4.4132e-04, -5.7878e-05,\n",
      "         3.5011e-04,  4.3615e-05,  3.2547e-05,  1.1365e-04,  7.6617e-06,\n",
      "         4.2020e-04,  1.9181e-04, -3.0364e-05, -4.3073e-04,  2.5401e-04,\n",
      "         1.5460e-04,  3.7042e-04,  1.3773e-04,  1.6753e-04,  2.0576e-05,\n",
      "         7.5629e-05,  1.2662e-04,  1.9671e-04, -5.8557e-05, -2.8817e-05,\n",
      "         1.4297e-04, -2.9500e-04,  1.0206e-05, -2.2868e-05,  9.7849e-05,\n",
      "         7.2783e-05,  9.7031e-05, -5.8608e-05,  8.6329e-05,  2.8647e-05,\n",
      "         1.0877e-04,  1.3901e-04, -1.9571e-04, -1.4973e-04,  2.6024e-05,\n",
      "         6.2800e-04, -2.4673e-05,  3.3064e-05,  1.1463e-04, -3.7741e-04,\n",
      "        -8.4372e-05,  6.4826e-05, -3.0810e-05, -2.3936e-04, -8.0876e-05,\n",
      "         1.7641e-05,  3.8361e-05,  5.6608e-04,  3.1448e-04, -1.4743e-05,\n",
      "        -2.6285e-04, -2.0356e-04, -1.5474e-04,  7.2572e-05,  1.9473e-04,\n",
      "         1.0663e-04,  1.3969e-04,  5.5076e-05,  1.5022e-04,  1.4079e-04,\n",
      "         2.4258e-05,  2.4852e-04, -8.4672e-05,  7.1332e-05,  1.4639e-04,\n",
      "        -5.8429e-04, -1.3861e-04,  1.4531e-04, -1.2163e-04,  6.6398e-05,\n",
      "        -9.4135e-05,  5.8098e-05, -2.3800e-04,  3.3600e-04,  2.8271e-04,\n",
      "         5.3276e-04,  3.5933e-04, -7.4340e-05, -2.3685e-05, -1.6974e-04,\n",
      "         2.7438e-04, -1.0558e-04,  4.1753e-05,  4.1206e-04,  4.8515e-04,\n",
      "        -3.6452e-04, -7.9692e-05, -7.2698e-05,  2.7608e-04,  2.2877e-04,\n",
      "        -2.9075e-04,  2.6135e-04,  1.9732e-05,  1.4141e-04,  1.4198e-04,\n",
      "        -3.7421e-05,  3.0269e-05, -1.2991e-05,  8.6086e-05, -2.8475e-06,\n",
      "         5.3396e-05,  4.5366e-05,  6.2608e-05,  3.0342e-04, -6.0358e-05,\n",
      "        -2.0541e-04,  3.5564e-04, -2.8798e-04,  1.6913e-04, -1.9730e-04,\n",
      "         1.3986e-04, -3.3774e-04, -1.1767e-04,  1.7484e-05, -2.7854e-04,\n",
      "         6.0909e-05,  1.0940e-04,  2.9489e-05,  1.2863e-04,  3.0014e-05,\n",
      "        -1.5822e-04,  2.4937e-04,  2.2070e-05,  1.5095e-04, -7.1606e-05,\n",
      "         1.0303e-05,  1.7841e-04,  3.0750e-04,  2.1373e-04,  1.6183e-04,\n",
      "        -1.9454e-04,  6.3815e-05,  7.8058e-05,  4.2530e-05, -1.4060e-04,\n",
      "         6.9698e-05,  1.4493e-04, -2.1146e-04, -1.0610e-04, -4.1022e-05,\n",
      "         2.4533e-04, -1.5491e-04, -9.7465e-05,  1.1140e-04, -3.0813e-05,\n",
      "         1.0660e-04,  2.1010e-04,  3.0932e-04,  9.3450e-05,  1.9891e-05,\n",
      "        -8.0290e-05, -1.0456e-04, -1.7770e-04, -4.2503e-05, -1.5076e-04,\n",
      "        -1.4698e-04,  1.0756e-04, -4.2378e-04, -2.4596e-04, -5.0599e-06,\n",
      "         5.1331e-04, -1.9965e-05,  2.6297e-05, -1.2376e-05,  2.8914e-04,\n",
      "        -1.2646e-04,  2.6150e-04, -2.7151e-04, -1.1126e-04,  2.1513e-04,\n",
      "         3.8522e-04,  2.1506e-04, -3.3092e-05, -4.2794e-05,  1.0687e-04,\n",
      "        -1.7397e-04, -1.3921e-04, -4.0679e-06,  1.8981e-04,  1.7412e-04,\n",
      "         4.4411e-04,  8.5019e-05, -5.0643e-05,  4.2885e-05,  1.7397e-04,\n",
      "        -4.0839e-05,  2.1643e-04, -5.4618e-05,  3.4727e-05, -1.0532e-04,\n",
      "         5.7289e-05, -4.0545e-04,  5.5959e-05,  2.1820e-04,  1.2090e-04,\n",
      "        -7.4942e-05, -2.2182e-06, -2.5222e-05,  2.4875e-05,  1.5479e-04,\n",
      "         2.3809e-04], device='cuda:0'), 'exp_avg_sq': tensor([9.5206e-08, 7.8877e-08, 2.9663e-08, 6.9073e-08, 1.4318e-08, 5.1442e-08,\n",
      "        7.0376e-08, 4.2257e-08, 4.6815e-08, 2.6812e-08, 5.3319e-08, 8.9532e-08,\n",
      "        7.1056e-08, 1.4662e-07, 7.5350e-08, 5.0072e-08, 7.6529e-08, 8.3824e-08,\n",
      "        4.5000e-08, 4.2539e-08, 7.5022e-08, 3.1609e-08, 8.3424e-08, 8.6492e-08,\n",
      "        5.9734e-08, 3.7479e-08, 5.6041e-08, 2.3572e-08, 1.3574e-07, 7.1306e-08,\n",
      "        3.5754e-08, 1.6549e-07, 5.2437e-08, 9.9375e-08, 8.8818e-08, 1.0657e-07,\n",
      "        3.6766e-08, 3.7215e-08, 8.1732e-08, 2.3599e-08, 4.7913e-08, 7.3498e-08,\n",
      "        1.4747e-07, 8.5186e-08, 3.7115e-08, 1.2702e-07, 4.3037e-08, 4.5059e-08,\n",
      "        9.6035e-08, 1.3581e-07, 5.4823e-08, 3.4346e-08, 1.5817e-08, 1.0583e-07,\n",
      "        4.0947e-08, 6.6744e-08, 5.6403e-08, 2.2107e-08, 1.7437e-08, 3.0621e-08,\n",
      "        8.7912e-08, 1.1616e-07, 7.2805e-08, 9.0118e-08, 7.5039e-08, 5.8255e-08,\n",
      "        9.1808e-08, 5.0532e-08, 2.8437e-08, 1.1539e-07, 8.6657e-08, 1.1924e-08,\n",
      "        3.5244e-08, 7.9732e-08, 5.2342e-08, 4.2275e-08, 7.9035e-08, 3.9215e-08,\n",
      "        1.9377e-08, 1.0824e-07, 1.0792e-08, 5.9136e-08, 2.9779e-07, 4.9652e-08,\n",
      "        9.2954e-08, 2.8562e-08, 5.7665e-08, 1.1038e-07, 7.4369e-08, 1.1065e-07,\n",
      "        1.1742e-07, 1.1658e-08, 1.3839e-08, 1.3277e-07, 1.1880e-07, 2.2481e-08,\n",
      "        1.8793e-07, 2.1057e-08, 1.6253e-07, 4.7363e-08, 1.5524e-07, 3.8498e-08,\n",
      "        1.8560e-07, 7.4339e-08, 1.1763e-07, 2.7125e-08, 8.0982e-08, 8.9073e-08,\n",
      "        8.9428e-08, 4.3828e-08, 4.2080e-08, 4.5450e-08, 1.4653e-08, 4.9359e-08,\n",
      "        1.0001e-07, 9.2011e-08, 3.5719e-08, 3.8928e-08, 5.8724e-08, 9.8764e-08,\n",
      "        9.2473e-08, 4.0884e-08, 4.7876e-08, 2.2067e-08, 4.5431e-08, 6.3266e-08,\n",
      "        1.7882e-08, 1.4697e-07, 1.2290e-07, 1.1668e-07, 1.6629e-07, 4.0317e-08,\n",
      "        3.7643e-08, 1.5134e-08, 1.0628e-07, 1.0372e-07, 2.9818e-08, 3.3183e-08,\n",
      "        1.2170e-07, 6.2171e-08, 6.4452e-08, 1.0551e-07, 5.1955e-08, 2.4014e-07,\n",
      "        1.1810e-07, 6.8435e-08, 8.6624e-08, 4.9411e-08, 5.1667e-08, 7.3989e-08,\n",
      "        3.8745e-08, 3.3646e-08, 6.9972e-08, 8.7452e-08, 9.0626e-08, 1.6274e-07,\n",
      "        1.1157e-07, 8.1319e-08, 8.4576e-08, 2.9414e-08, 1.0969e-07, 5.4959e-08,\n",
      "        6.4670e-08, 3.8909e-08, 8.0715e-08, 7.1467e-08, 4.6352e-08, 2.8635e-08,\n",
      "        2.1655e-08, 4.0564e-08, 5.0781e-08, 1.9106e-08, 5.7859e-08, 1.2766e-07,\n",
      "        7.4334e-08, 4.1971e-08, 4.4200e-08, 9.7046e-09, 8.5883e-09, 6.3096e-08,\n",
      "        7.8577e-08, 2.6715e-08, 5.4013e-08, 2.3234e-08, 9.3727e-08, 4.3145e-08,\n",
      "        7.6998e-08, 4.9387e-08, 6.9860e-08, 5.4602e-08, 1.4732e-08, 7.3265e-08,\n",
      "        6.1506e-08, 1.0984e-07, 9.2887e-08, 1.3580e-08, 3.3541e-09, 3.7586e-08,\n",
      "        5.5078e-08, 8.6574e-08, 1.6943e-08, 1.0012e-07, 5.9005e-08, 4.7148e-08,\n",
      "        3.0340e-08, 9.8131e-08, 1.1272e-07, 2.4312e-08, 1.0842e-07, 2.6766e-08,\n",
      "        1.3113e-07, 1.4885e-07, 1.0588e-07, 8.2448e-08, 4.4186e-08, 7.7863e-08,\n",
      "        7.4940e-08, 1.3567e-07, 3.3525e-08, 2.7797e-07, 6.5575e-08, 8.3500e-08,\n",
      "        8.5879e-08, 4.7337e-08, 3.3637e-08, 1.1139e-07, 6.1460e-08, 2.3708e-08,\n",
      "        4.7702e-09, 2.7336e-08, 6.7509e-08, 1.2078e-07, 4.6522e-08, 8.1225e-08,\n",
      "        3.8698e-08, 7.0577e-08, 4.3839e-08, 9.1897e-08, 3.2818e-08, 8.9156e-08,\n",
      "        6.1947e-08, 1.7682e-08, 5.3106e-08, 1.7822e-08, 1.0905e-07, 3.5310e-08,\n",
      "        1.1582e-07, 5.6223e-08, 7.1117e-08, 9.3623e-08, 5.7256e-08, 3.2609e-08,\n",
      "        3.5566e-08, 3.1322e-08, 3.4608e-08, 4.0159e-08], device='cuda:0')}, 8: {'step': tensor(60., device='cuda:0'), 'exp_avg': tensor([[-4.9648e-04, -4.0265e-04, -4.0541e-05,  ...,  3.0901e-04,\n",
      "         -6.4063e-05, -1.6495e-04],\n",
      "        [ 3.0937e-03,  2.5428e-03,  1.0410e-04,  ...,  4.9864e-04,\n",
      "          6.2970e-04,  3.7186e-03],\n",
      "        [-2.5222e-03,  1.2886e-04, -1.2943e-03,  ...,  1.5600e-04,\n",
      "         -2.3314e-04, -1.2884e-03],\n",
      "        ...,\n",
      "        [-3.1812e-03, -7.2333e-04,  1.0246e-04,  ..., -3.3618e-04,\n",
      "         -4.2059e-04,  1.2764e-03],\n",
      "        [-1.2502e-03,  2.6488e-04,  2.8472e-04,  ..., -7.0127e-05,\n",
      "         -3.6533e-05,  1.2159e-04],\n",
      "        [ 1.2885e-03,  5.7124e-05,  1.5163e-04,  ..., -1.3225e-04,\n",
      "          1.6848e-05,  8.7755e-05]], device='cuda:0'), 'exp_avg_sq': tensor([[1.7133e-06, 5.0995e-07, 6.7138e-08,  ..., 2.4013e-07, 2.2247e-07,\n",
      "         1.7467e-07],\n",
      "        [7.1855e-06, 2.0530e-06, 3.8423e-07,  ..., 5.5248e-07, 5.2715e-07,\n",
      "         1.7176e-06],\n",
      "        [5.8715e-06, 2.1463e-06, 8.7876e-07,  ..., 7.4818e-07, 4.4715e-07,\n",
      "         6.6605e-07],\n",
      "        ...,\n",
      "        [3.8388e-06, 1.0134e-06, 4.8565e-07,  ..., 9.1062e-07, 5.4897e-07,\n",
      "         8.2476e-07],\n",
      "        [6.2658e-06, 2.4028e-07, 2.4037e-07,  ..., 2.1614e-07, 3.7532e-08,\n",
      "         6.8130e-07],\n",
      "        [7.4815e-07, 1.7073e-06, 6.7481e-08,  ..., 7.9296e-07, 5.8517e-07,\n",
      "         1.8086e-07]], device='cuda:0')}, 9: {'step': tensor(60., device='cuda:0'), 'exp_avg': tensor([-1.7014e-04,  3.0667e-04,  1.0076e-04,  1.2863e-04,  2.3712e-04,\n",
      "         3.6471e-04, -7.6167e-05, -2.2531e-04,  2.5758e-04,  7.3332e-04,\n",
      "        -1.5497e-04, -8.1692e-04, -2.9629e-04,  3.2206e-05, -1.6741e-04,\n",
      "         2.7543e-05,  3.1355e-04,  5.2291e-04, -4.2330e-05,  3.8963e-04,\n",
      "        -1.4028e-04, -2.4594e-04,  2.3031e-05, -2.7182e-04, -6.8110e-05,\n",
      "        -2.4798e-04, -1.9287e-04,  7.7391e-04,  3.1366e-05,  3.2698e-04,\n",
      "         1.1943e-04,  1.0819e-04, -6.0880e-04,  3.1345e-04,  6.6780e-04,\n",
      "        -3.6693e-04, -2.5319e-04,  2.1284e-04,  2.3323e-04,  2.6228e-05,\n",
      "        -3.1667e-04, -8.7303e-05,  1.0334e-04, -2.2145e-05,  2.5756e-04,\n",
      "        -3.4513e-04,  3.4382e-04, -5.3174e-04,  3.7147e-04, -5.2417e-04,\n",
      "         4.1143e-04,  1.5566e-04,  2.4963e-04,  5.7412e-04, -6.7272e-06,\n",
      "         6.2253e-05,  1.4798e-04, -1.6175e-04, -1.6405e-04,  3.4389e-04,\n",
      "         1.6840e-04, -5.9809e-05, -3.4442e-05,  1.9989e-04,  1.9790e-04,\n",
      "        -1.2068e-04,  1.0142e-05,  5.0151e-05,  3.7932e-04, -1.1547e-04,\n",
      "         2.2607e-04, -1.4904e-04, -1.4192e-05, -4.0287e-04,  2.3459e-04,\n",
      "        -3.6593e-04, -1.9046e-04,  1.5907e-04,  5.2141e-04, -1.0658e-04,\n",
      "         1.1768e-04,  2.4309e-04, -1.9212e-04, -3.6586e-04,  3.5401e-05,\n",
      "         1.4226e-03,  1.2647e-04, -2.5076e-04,  3.9942e-04, -2.5218e-04,\n",
      "        -9.3691e-05, -6.3055e-05,  1.7288e-04, -3.6468e-04,  4.6106e-04,\n",
      "        -5.0708e-04,  3.3045e-04, -3.2593e-04, -3.4624e-04,  1.3283e-04,\n",
      "        -1.2705e-04, -3.1138e-04,  5.3408e-04, -4.6531e-04,  5.6700e-04,\n",
      "         1.7249e-06, -5.2367e-04,  1.5215e-04,  1.7380e-04, -3.8661e-04,\n",
      "        -4.0967e-04,  4.3155e-05,  6.2148e-05,  7.8594e-04,  2.4764e-05,\n",
      "        -4.5476e-04, -1.0329e-03, -3.2369e-04,  4.1178e-04, -2.3748e-05,\n",
      "         8.2116e-04,  2.4502e-04,  9.2552e-05,  3.0172e-05, -3.2312e-04,\n",
      "        -3.4505e-05,  8.6512e-04, -4.5049e-04,  7.7869e-04, -2.6303e-04,\n",
      "         9.0091e-04,  9.4079e-06,  1.7561e-04,  3.3007e-04, -6.1321e-04,\n",
      "         2.8522e-04,  5.8257e-05, -1.1133e-04,  1.1855e-03, -4.9758e-04,\n",
      "         1.0666e-04, -1.7712e-04, -3.8193e-05,  3.5628e-04,  1.8474e-04,\n",
      "        -1.4219e-04, -1.8842e-07, -1.1844e-04, -3.1907e-04, -2.3192e-04,\n",
      "        -2.6723e-04, -4.3776e-05,  1.3820e-04, -5.2192e-04,  5.3657e-04,\n",
      "         4.0191e-04,  2.9290e-05,  6.1630e-04,  5.0191e-04,  6.9134e-05,\n",
      "        -2.9365e-04,  3.0300e-04,  5.9764e-06, -3.4913e-05, -4.8900e-05,\n",
      "        -7.4324e-05,  6.0050e-05, -4.0655e-05, -4.9478e-04,  2.6826e-04,\n",
      "         8.3292e-04,  6.6148e-05, -1.0655e-05,  2.5386e-04,  4.9845e-04,\n",
      "         3.0073e-04,  6.2660e-04, -3.6736e-05, -7.4156e-05, -3.7755e-04,\n",
      "        -4.0912e-04, -1.3959e-04,  9.1325e-05,  5.3843e-05,  6.2346e-04,\n",
      "        -2.0508e-05,  1.6031e-05,  5.9231e-04,  3.0396e-04, -4.4892e-04,\n",
      "        -6.8388e-04,  1.1662e-04, -3.0738e-05, -3.0145e-05, -2.9308e-04,\n",
      "        -3.3611e-06, -3.7977e-04, -3.8894e-04, -4.0819e-05,  5.0593e-04,\n",
      "        -4.7399e-04,  3.6197e-04,  3.9499e-04, -5.0706e-04, -6.6424e-05,\n",
      "         5.8665e-05, -3.7411e-05,  4.4067e-05,  2.6980e-04,  3.8199e-04,\n",
      "         1.8472e-04,  4.7922e-04, -4.2251e-05,  3.6292e-04,  1.6765e-04,\n",
      "         3.0135e-05,  4.5232e-04, -1.4998e-04,  1.3604e-04,  3.9874e-04,\n",
      "        -2.3687e-05,  2.2616e-05,  5.4667e-04,  5.0314e-04,  3.0951e-04,\n",
      "         1.7151e-04,  5.5533e-04,  3.5787e-05,  7.5826e-04,  3.4534e-04,\n",
      "        -1.7573e-04,  2.3407e-04, -1.7435e-04, -2.9924e-04, -1.9187e-04,\n",
      "         3.3931e-05, -1.7195e-04, -1.5489e-04,  4.7366e-04,  2.8898e-04,\n",
      "         5.1330e-04, -3.5944e-05, -3.0627e-05, -7.3757e-05, -1.8619e-04,\n",
      "        -1.8916e-04, -4.2923e-04, -4.2010e-04,  2.3330e-04,  3.6609e-04,\n",
      "        -3.2228e-04,  5.9163e-05,  5.2557e-05, -1.5378e-04, -1.3290e-04,\n",
      "        -2.7855e-04], device='cuda:0'), 'exp_avg_sq': tensor([5.7674e-08, 1.9748e-07, 3.1551e-07, 1.3295e-07, 3.0150e-07, 1.3998e-07,\n",
      "        1.0934e-07, 1.5596e-07, 1.1675e-07, 3.6183e-07, 6.1462e-08, 9.0450e-08,\n",
      "        1.8564e-07, 7.9243e-08, 1.0360e-07, 1.0803e-07, 1.7467e-07, 2.6984e-07,\n",
      "        1.3888e-07, 4.8599e-08, 1.5021e-07, 1.6386e-07, 9.0911e-08, 3.1171e-07,\n",
      "        1.9994e-07, 1.1111e-07, 1.3825e-07, 2.0651e-07, 2.5761e-07, 1.9336e-07,\n",
      "        4.4323e-07, 1.3732e-07, 2.5891e-07, 3.8085e-07, 3.1429e-07, 1.8309e-07,\n",
      "        1.5656e-07, 3.0767e-07, 7.3991e-08, 7.2544e-08, 2.7826e-07, 3.5063e-07,\n",
      "        6.3911e-08, 3.4221e-07, 1.1035e-07, 5.5070e-07, 8.1452e-08, 3.3062e-07,\n",
      "        2.7043e-07, 2.5356e-07, 1.0178e-06, 1.3975e-07, 1.2793e-07, 2.2070e-07,\n",
      "        3.1254e-08, 3.2523e-08, 1.6601e-07, 1.8774e-07, 2.6514e-07, 1.9960e-07,\n",
      "        1.2386e-07, 1.5738e-07, 6.5653e-08, 1.3883e-07, 1.1949e-07, 3.6337e-07,\n",
      "        3.7447e-08, 1.3256e-07, 8.3452e-08, 3.8392e-07, 5.9596e-08, 9.3250e-08,\n",
      "        2.2492e-07, 1.3110e-07, 2.2605e-07, 8.1441e-08, 9.1838e-08, 2.0728e-07,\n",
      "        2.3113e-07, 5.1059e-08, 2.8937e-07, 2.0955e-07, 2.6765e-07, 2.8087e-08,\n",
      "        1.8397e-07, 2.7646e-07, 3.0540e-07, 2.6572e-07, 1.7886e-07, 1.7171e-07,\n",
      "        9.3492e-08, 1.6265e-07, 9.6398e-08, 1.2285e-07, 2.1986e-07, 1.4462e-07,\n",
      "        1.5545e-07, 2.0503e-07, 8.6509e-08, 1.6500e-07, 2.7807e-07, 1.7794e-07,\n",
      "        2.2502e-07, 6.1597e-08, 3.1498e-07, 2.7181e-07, 2.6802e-07, 1.9195e-07,\n",
      "        1.6340e-07, 1.2619e-07, 3.5816e-07, 1.3378e-07, 1.9310e-07, 3.8982e-07,\n",
      "        1.2971e-07, 3.9688e-07, 2.8451e-07, 2.7824e-07, 1.9635e-07, 2.2756e-08,\n",
      "        2.5409e-07, 5.8481e-08, 2.0306e-07, 6.3540e-08, 5.7169e-08, 5.0956e-08,\n",
      "        5.2177e-07, 2.2530e-07, 2.8425e-07, 7.2924e-08, 2.9634e-07, 2.7610e-07,\n",
      "        8.7395e-08, 2.1726e-07, 5.2346e-07, 3.4820e-07, 4.0412e-07, 5.9077e-08,\n",
      "        4.6127e-07, 2.3803e-07, 3.8434e-07, 2.7891e-08, 4.7233e-08, 3.1206e-07,\n",
      "        4.0506e-07, 2.3963e-07, 2.3816e-07, 9.3001e-08, 1.2859e-07, 1.0275e-07,\n",
      "        1.5047e-07, 6.8937e-08, 4.5407e-07, 3.2742e-07, 9.2709e-08, 4.3218e-07,\n",
      "        9.8045e-08, 3.0165e-07, 1.1382e-07, 1.3576e-07, 2.5395e-07, 2.3013e-07,\n",
      "        1.4647e-08, 2.7068e-08, 8.4233e-08, 1.9008e-07, 2.5151e-07, 2.1451e-07,\n",
      "        8.6228e-08, 2.2014e-07, 1.3274e-07, 3.9031e-08, 2.1474e-07, 2.0047e-07,\n",
      "        2.8667e-07, 1.5105e-07, 4.3444e-07, 2.5997e-07, 2.6091e-07, 2.7302e-07,\n",
      "        1.8580e-07, 1.4978e-07, 3.2133e-07, 1.3937e-07, 3.0420e-07, 1.7640e-07,\n",
      "        1.0261e-07, 2.2186e-07, 3.0152e-07, 2.6880e-07, 2.5676e-07, 1.7310e-07,\n",
      "        1.6129e-07, 1.1900e-07, 1.8911e-07, 1.6668e-07, 1.6844e-07, 2.9828e-07,\n",
      "        1.1957e-07, 1.5395e-07, 2.1463e-07, 4.1448e-07, 1.8274e-07, 2.3200e-07,\n",
      "        2.0313e-07, 1.7149e-07, 2.8947e-07, 1.9439e-07, 3.2139e-07, 3.1243e-07,\n",
      "        4.9408e-07, 1.8321e-07, 6.4481e-08, 3.0707e-07, 2.6228e-07, 2.4130e-07,\n",
      "        3.6787e-07, 4.2266e-08, 1.5620e-07, 2.7465e-07, 2.5990e-07, 1.7058e-07,\n",
      "        2.8672e-07, 4.3036e-07, 1.2684e-07, 2.9173e-07, 2.7961e-07, 1.6577e-07,\n",
      "        2.1441e-07, 1.5785e-07, 2.4193e-07, 2.2979e-07, 2.4902e-07, 1.8723e-07,\n",
      "        1.2822e-07, 4.0849e-08, 4.2226e-07, 1.9823e-07, 1.7833e-07, 4.4535e-07,\n",
      "        3.9108e-07, 4.0500e-07, 1.8890e-07, 1.3952e-07, 2.3732e-07, 8.6947e-08,\n",
      "        2.2072e-07, 6.3397e-07, 1.3373e-07, 3.1590e-07, 1.0959e-07, 2.4753e-07,\n",
      "        1.2415e-07, 1.6081e-07, 1.6996e-07, 1.0718e-07], device='cuda:0')}, 10: {'step': tensor(60., device='cuda:0'), 'exp_avg': tensor([[-2.8772e-05, -4.3064e-03, -1.0680e-03,  ..., -1.6495e-04,\n",
      "         -1.0446e-03, -1.3941e-03],\n",
      "        [-4.3550e-04, -4.4053e-05, -1.5016e-04,  ...,  1.6548e-03,\n",
      "         -2.7294e-05,  1.6639e-04],\n",
      "        [-7.1853e-04,  1.3156e-03,  1.0298e-03,  ...,  7.7156e-04,\n",
      "          3.1670e-04, -3.0661e-04],\n",
      "        ...,\n",
      "        [ 1.4109e-03,  6.5064e-04,  4.2303e-04,  ...,  1.0667e-03,\n",
      "          8.0158e-04, -5.7611e-04],\n",
      "        [-2.3840e-04,  1.1334e-03,  4.0445e-04,  ..., -6.8229e-05,\n",
      "          1.6326e-04,  7.1141e-04],\n",
      "        [-7.0653e-04, -1.6915e-03, -2.2593e-03,  ..., -2.4116e-03,\n",
      "         -3.1721e-03, -2.2332e-04]], device='cuda:0'), 'exp_avg_sq': tensor([[9.5749e-07, 2.6038e-06, 8.1033e-06,  ..., 1.7662e-06, 5.4884e-07,\n",
      "         6.2203e-07],\n",
      "        [9.4192e-08, 2.5505e-06, 1.1526e-06,  ..., 1.2160e-06, 1.0757e-07,\n",
      "         1.7085e-07],\n",
      "        [3.9616e-07, 1.2361e-06, 1.0515e-05,  ..., 4.0739e-06, 1.4072e-06,\n",
      "         3.7348e-07],\n",
      "        ...,\n",
      "        [6.5858e-07, 4.6837e-06, 6.6826e-06,  ..., 5.2996e-06, 2.4400e-06,\n",
      "         1.4340e-05],\n",
      "        [7.6637e-08, 4.4521e-06, 1.0692e-06,  ..., 5.0797e-06, 1.0280e-06,\n",
      "         5.8396e-06],\n",
      "        [4.8530e-06, 4.2334e-06, 1.7866e-05,  ..., 6.0906e-06, 1.4499e-06,\n",
      "         1.8521e-06]], device='cuda:0')}, 11: {'step': tensor(60., device='cuda:0'), 'exp_avg': tensor([-2.0216e-03,  7.2796e-04,  4.9351e-04, -4.8047e-04,  1.0288e-04,\n",
      "         1.2594e-03, -2.2261e-04, -1.2563e-03,  2.1311e-03,  1.0356e-03,\n",
      "        -1.4430e-03, -8.4873e-04,  8.8620e-04, -3.5916e-04,  8.2008e-04,\n",
      "         1.0219e-03,  6.0997e-04,  1.7797e-04, -5.8453e-04,  1.1665e-03,\n",
      "         9.6345e-05,  4.7722e-04,  4.9149e-04,  2.6595e-04, -7.4132e-04,\n",
      "         1.6889e-03, -6.2892e-04,  3.5166e-04,  6.1559e-04, -8.7628e-04,\n",
      "         1.6894e-03, -2.7899e-04,  1.9377e-03,  7.4319e-04, -8.1252e-04,\n",
      "         1.0754e-03, -1.6165e-04, -4.2186e-04,  1.4999e-04,  3.2304e-04,\n",
      "         4.3521e-04,  2.2176e-04,  8.0511e-04,  8.3290e-04,  1.0776e-04,\n",
      "         1.3734e-03, -4.5982e-04, -2.1849e-04,  9.6633e-04, -8.4455e-05,\n",
      "        -2.5055e-04,  4.5536e-04, -1.9872e-03,  3.6479e-04,  1.0733e-03,\n",
      "        -7.1202e-04,  1.1066e-03,  1.3967e-03,  1.8930e-04, -6.7976e-05,\n",
      "         1.0987e-03,  7.4550e-04, -4.3215e-04, -1.0801e-03,  6.5546e-04,\n",
      "         1.8571e-04, -5.4068e-05,  1.1218e-03,  8.6875e-04, -1.1479e-03,\n",
      "        -6.7608e-04, -1.6283e-03, -9.5466e-04, -7.5353e-04,  1.0656e-03,\n",
      "         2.2086e-04,  2.4359e-05, -2.9854e-04,  7.1559e-04, -3.9789e-05,\n",
      "        -1.0312e-04,  3.3820e-04,  1.1355e-03, -6.0129e-04,  3.7732e-04,\n",
      "        -4.0560e-04, -1.1059e-04,  1.0881e-03,  1.4685e-03, -3.0130e-04,\n",
      "         3.7263e-04,  7.2105e-06, -9.4739e-04,  2.1393e-03,  3.4699e-04,\n",
      "        -9.4334e-04, -6.7375e-04,  1.7114e-03,  8.9112e-04,  2.6190e-04,\n",
      "         1.2047e-05,  3.2749e-04,  2.9894e-04,  7.5866e-05,  1.4091e-04,\n",
      "         4.9196e-04, -7.8267e-04, -4.0395e-04,  1.8630e-04, -4.2080e-04,\n",
      "        -3.0524e-04,  1.8350e-03, -2.2705e-04,  8.5409e-04, -4.0783e-04,\n",
      "         2.7504e-04,  5.9909e-05,  5.3183e-04, -5.7373e-05, -3.5907e-04,\n",
      "        -6.7419e-04, -3.4627e-04,  6.2464e-04,  1.6750e-04, -4.7852e-04,\n",
      "         1.0941e-03,  5.8495e-04, -1.1553e-03], device='cuda:0'), 'exp_avg_sq': tensor([1.3131e-06, 7.6868e-07, 1.0737e-06, 5.8093e-07, 5.7723e-07, 1.7575e-06,\n",
      "        5.3985e-07, 1.4371e-06, 2.5188e-06, 1.4295e-06, 3.4257e-06, 2.1214e-06,\n",
      "        1.6378e-06, 2.1461e-07, 1.4813e-06, 6.0895e-07, 2.5852e-06, 8.3793e-07,\n",
      "        1.8350e-06, 1.3330e-06, 2.7139e-06, 1.1171e-06, 1.3631e-06, 2.1369e-06,\n",
      "        6.6753e-07, 1.7002e-06, 6.9908e-07, 8.7929e-07, 6.8082e-07, 1.1116e-06,\n",
      "        3.3450e-06, 2.5309e-06, 4.0725e-06, 6.5986e-07, 1.1184e-06, 1.3055e-06,\n",
      "        1.3927e-06, 7.5076e-07, 6.9370e-07, 5.1296e-07, 1.4865e-06, 1.0111e-06,\n",
      "        4.0821e-07, 1.2728e-06, 2.4990e-06, 1.6829e-06, 8.9012e-07, 3.9333e-07,\n",
      "        8.4798e-07, 7.2032e-07, 1.5805e-06, 5.8545e-07, 2.0192e-06, 1.5162e-06,\n",
      "        1.7064e-06, 8.1872e-07, 2.1747e-06, 1.8070e-06, 8.8324e-07, 2.1353e-06,\n",
      "        1.0018e-06, 1.3674e-06, 1.3858e-06, 1.6520e-06, 1.4399e-06, 2.5188e-06,\n",
      "        5.7731e-07, 1.0609e-06, 1.6403e-06, 3.1422e-06, 1.1599e-06, 1.0219e-06,\n",
      "        8.3026e-07, 2.4360e-06, 1.1620e-06, 9.7684e-07, 1.4671e-06, 2.3206e-06,\n",
      "        9.8992e-07, 5.8016e-07, 8.3520e-07, 1.9785e-06, 3.0340e-07, 6.2410e-07,\n",
      "        1.5129e-06, 1.8701e-06, 1.6910e-06, 7.7193e-07, 1.4224e-06, 6.2485e-07,\n",
      "        8.7844e-07, 1.2434e-06, 3.2781e-07, 1.1895e-06, 5.9191e-07, 1.4795e-06,\n",
      "        6.5404e-07, 2.5536e-06, 1.0652e-06, 7.7025e-07, 5.0755e-07, 1.9865e-06,\n",
      "        1.0196e-06, 5.0161e-07, 9.3791e-07, 4.4932e-07, 5.7078e-07, 1.2162e-06,\n",
      "        1.9618e-06, 1.8311e-06, 9.8610e-07, 1.4195e-06, 1.6956e-06, 1.6723e-06,\n",
      "        7.4828e-07, 1.0475e-06, 7.7442e-07, 1.3866e-06, 1.9374e-06, 1.0992e-06,\n",
      "        8.1068e-07, 1.1561e-06, 2.8844e-07, 1.6747e-06, 1.5810e-06, 2.5518e-06,\n",
      "        3.5832e-06, 2.7958e-06], device='cuda:0')}, 12: {'step': tensor(60., device='cuda:0'), 'exp_avg': tensor([[ 4.9836e-03,  2.9122e-03,  3.0069e-03,  ...,  3.9067e-05,\n",
      "          1.3672e-04,  1.3333e-03],\n",
      "        [-3.3142e-04, -4.9361e-05, -1.4702e-03,  ..., -1.5900e-03,\n",
      "         -1.0039e-04, -2.3909e-03],\n",
      "        [ 8.6264e-03,  4.2423e-03,  6.3916e-03,  ...,  1.9975e-03,\n",
      "         -9.3597e-05,  1.7534e-03],\n",
      "        ...,\n",
      "        [ 1.0809e-04,  6.7708e-04, -1.0146e-03,  ...,  2.5754e-03,\n",
      "          1.8926e-05, -1.4879e-03],\n",
      "        [-1.4614e-04, -7.3060e-04,  2.1318e-03,  ..., -4.9800e-05,\n",
      "         -3.8362e-04, -1.7812e-03],\n",
      "        [ 4.9679e-03,  2.6013e-03,  4.5731e-03,  ...,  2.0903e-03,\n",
      "         -1.2410e-03,  3.3100e-03]], device='cuda:0'), 'exp_avg_sq': tensor([[4.0947e-06, 4.4237e-06, 5.8552e-06,  ..., 5.9812e-05, 6.6121e-06,\n",
      "         2.3967e-05],\n",
      "        [7.6926e-07, 1.2229e-07, 1.3154e-06,  ..., 9.5491e-07, 1.0324e-07,\n",
      "         1.9492e-06],\n",
      "        [1.7287e-05, 5.3694e-06, 1.2142e-05,  ..., 1.2456e-05, 2.6086e-06,\n",
      "         1.5749e-05],\n",
      "        ...,\n",
      "        [5.8511e-06, 2.5211e-06, 2.0032e-06,  ..., 7.9930e-06, 2.8346e-06,\n",
      "         7.0249e-06],\n",
      "        [5.6148e-07, 8.3347e-07, 3.8762e-06,  ..., 1.3000e-06, 1.5032e-06,\n",
      "         5.2445e-06],\n",
      "        [3.0446e-06, 4.7475e-06, 3.5562e-06,  ..., 5.1735e-06, 1.7804e-06,\n",
      "         4.3324e-06]], device='cuda:0')}, 13: {'step': tensor(60., device='cuda:0'), 'exp_avg': tensor([ 8.4199e-04, -3.5746e-04,  2.4899e-03,  3.1616e-03, -1.3480e-03,\n",
      "         2.5332e-03, -1.5541e-03, -3.9873e-03,  1.1276e-03, -1.8436e-03,\n",
      "         2.2292e-03, -1.3298e-03,  4.0987e-03, -2.7546e-03,  1.0305e-03,\n",
      "         1.0031e-03, -7.2361e-04,  2.0667e-03,  1.2986e-03,  3.2351e-04,\n",
      "         1.8395e-03,  1.4152e-03,  6.1584e-04, -7.3703e-04, -2.3498e-03,\n",
      "        -4.0798e-04, -4.2791e-03,  5.7181e-04, -5.0585e-04,  1.5323e-05,\n",
      "        -6.9961e-04,  7.0044e-04,  3.7024e-04, -5.0426e-04,  2.3875e-03,\n",
      "        -7.0635e-04, -1.1688e-04,  1.6083e-03, -1.1987e-03, -1.8067e-03,\n",
      "        -1.3371e-03,  1.1283e-03,  2.6276e-03, -6.6795e-04, -5.3497e-05,\n",
      "         7.8480e-04,  5.5487e-04,  1.2031e-03,  1.0056e-04, -1.6913e-03,\n",
      "         1.6754e-03, -1.8588e-03,  7.5668e-04,  8.1397e-04,  2.4173e-04,\n",
      "         2.0058e-03,  1.6414e-03,  1.5821e-03, -1.0698e-03,  1.1602e-03,\n",
      "        -8.2738e-05,  9.7396e-04,  3.4990e-04, -2.0016e-03,  3.9735e-03,\n",
      "        -1.6124e-03, -5.4362e-04,  1.7437e-03,  8.9628e-04,  1.1757e-03,\n",
      "         9.5179e-04,  2.7137e-03, -4.9426e-05,  9.0422e-04,  8.4499e-05,\n",
      "         4.2218e-04,  3.6120e-03,  7.4515e-04,  1.5153e-03,  2.8678e-03,\n",
      "         8.4279e-04, -7.5283e-04,  1.5031e-03,  3.4501e-04,  1.4454e-03,\n",
      "         4.7587e-04,  4.8589e-04,  2.8279e-04,  2.0931e-03,  1.8800e-04,\n",
      "         1.4646e-03,  1.6091e-04,  1.8806e-03, -9.4657e-04,  4.8953e-03,\n",
      "         6.8475e-04,  5.3158e-04, -5.2203e-04, -1.0078e-03,  2.0061e-04,\n",
      "         4.7171e-04, -9.7714e-04,  6.0188e-04,  2.7248e-04, -1.2633e-03,\n",
      "        -2.5072e-03,  7.5845e-04,  4.6515e-04,  5.9382e-04,  2.5631e-05,\n",
      "         3.3778e-04, -4.3274e-04, -5.5105e-05,  3.3805e-04, -2.0870e-04,\n",
      "         3.1527e-03,  1.2561e-03, -3.7736e-04,  9.1011e-04, -9.6122e-04,\n",
      "        -7.8680e-04, -2.6214e-04, -1.3416e-03, -5.6420e-04,  1.8411e-03,\n",
      "        -6.9321e-04,  3.7183e-04,  2.2501e-03], device='cuda:0'), 'exp_avg_sq': tensor([4.7781e-06, 5.4391e-07, 7.8284e-06, 7.1727e-06, 5.7993e-06, 7.2473e-06,\n",
      "        4.2814e-06, 4.0452e-06, 2.5624e-06, 2.0320e-06, 4.1443e-06, 4.3374e-06,\n",
      "        1.0148e-05, 4.6090e-06, 3.3819e-06, 3.7840e-06, 5.3315e-06, 4.7765e-06,\n",
      "        3.8246e-06, 5.5028e-06, 2.0353e-06, 3.5142e-06, 3.2085e-06, 3.1704e-06,\n",
      "        5.9751e-06, 1.8814e-06, 8.1576e-06, 1.2825e-06, 4.1514e-06, 1.0049e-06,\n",
      "        2.4370e-06, 2.4508e-06, 3.1113e-06, 1.1012e-06, 1.6851e-06, 1.3581e-06,\n",
      "        3.7477e-06, 3.3855e-06, 3.6041e-06, 5.2310e-06, 2.0372e-06, 1.2560e-06,\n",
      "        3.0121e-06, 5.8371e-06, 4.2009e-06, 5.7090e-06, 2.0849e-06, 3.4508e-06,\n",
      "        1.0169e-06, 2.8484e-06, 5.3668e-06, 6.6501e-06, 5.0025e-06, 3.4891e-06,\n",
      "        5.3825e-06, 7.4103e-06, 3.2122e-06, 5.3811e-06, 3.6177e-06, 5.1733e-06,\n",
      "        2.2148e-06, 2.2237e-06, 8.3003e-06, 5.1290e-06, 4.6526e-06, 8.4060e-06,\n",
      "        2.9472e-06, 5.5015e-06, 1.7276e-06, 9.3666e-06, 7.5661e-06, 2.8144e-06,\n",
      "        2.6447e-06, 2.7500e-06, 2.8877e-06, 5.1859e-06, 6.9092e-06, 2.8695e-06,\n",
      "        3.2448e-06, 5.4482e-06, 2.4857e-06, 3.8315e-06, 2.4145e-06, 7.5220e-06,\n",
      "        2.8665e-06, 1.2821e-06, 3.3921e-06, 3.7404e-06, 2.9722e-06, 1.9652e-06,\n",
      "        1.8855e-06, 2.6668e-06, 6.6043e-06, 3.1144e-06, 1.0738e-05, 2.4301e-06,\n",
      "        4.5154e-06, 3.1423e-06, 2.0374e-06, 1.8989e-06, 2.3431e-06, 5.7154e-06,\n",
      "        2.3688e-06, 3.3407e-06, 5.9564e-07, 3.0188e-06, 3.1554e-06, 9.1385e-07,\n",
      "        5.6560e-06, 4.0929e-06, 4.7304e-06, 8.7846e-06, 4.7076e-06, 3.3017e-06,\n",
      "        1.8233e-06, 3.5861e-06, 4.5208e-06, 5.9460e-07, 1.4627e-06, 5.9957e-06,\n",
      "        2.7844e-06, 2.2294e-06, 2.2363e-06, 3.1192e-06, 2.8400e-06, 4.2912e-06,\n",
      "        2.6845e-06, 2.6369e-06], device='cuda:0')}, 14: {'step': tensor(60., device='cuda:0'), 'exp_avg': tensor([[ 5.7221e-03, -2.6363e-05,  1.1501e-04,  ...,  4.0021e-03,\n",
      "          2.3724e-03, -1.0280e-03],\n",
      "        [ 4.2604e-05, -1.1287e-03,  1.9419e-03,  ...,  1.6951e-03,\n",
      "          5.6999e-04, -1.2693e-03],\n",
      "        [ 9.9805e-04, -1.2665e-04,  1.7988e-03,  ..., -2.8425e-04,\n",
      "          1.4147e-03,  7.0427e-05],\n",
      "        ...,\n",
      "        [ 1.5039e-03,  2.1431e-04, -1.9636e-03,  ...,  6.4398e-04,\n",
      "          8.9885e-04,  2.3645e-03],\n",
      "        [-2.6199e-04,  1.1549e-04,  5.0163e-03,  ..., -1.7547e-04,\n",
      "         -1.3983e-03,  2.0964e-03],\n",
      "        [ 3.8136e-04,  2.2597e-03, -2.7621e-03,  ...,  4.9609e-04,\n",
      "         -3.5441e-03, -4.3736e-03]], device='cuda:0'), 'exp_avg_sq': tensor([[5.2065e-06, 4.7047e-07, 2.8502e-05,  ..., 8.1963e-06, 1.4857e-06,\n",
      "         2.5346e-06],\n",
      "        [1.9134e-06, 1.1680e-06, 5.5469e-06,  ..., 5.6689e-06, 2.9225e-06,\n",
      "         3.4599e-06],\n",
      "        [4.2879e-06, 8.5050e-08, 5.5731e-06,  ..., 9.6494e-07, 1.6918e-06,\n",
      "         1.6565e-06],\n",
      "        ...,\n",
      "        [1.6319e-06, 1.9132e-07, 1.9129e-06,  ..., 9.2603e-07, 2.9995e-07,\n",
      "         6.2006e-06],\n",
      "        [1.8339e-05, 4.5761e-07, 1.4108e-05,  ..., 1.7437e-05, 3.0900e-06,\n",
      "         6.6195e-06],\n",
      "        [1.3003e-05, 2.8111e-06, 1.5562e-05,  ..., 8.4135e-06, 1.7665e-05,\n",
      "         1.7762e-05]], device='cuda:0')}, 15: {'step': tensor(60., device='cuda:0'), 'exp_avg': tensor([ 3.0863e-03,  5.4064e-04, -5.9973e-04,  7.5392e-03, -3.1141e-03,\n",
      "         7.0288e-03,  1.1716e-03,  3.2919e-04, -4.6881e-04,  1.7762e-03,\n",
      "        -2.1870e-03,  1.4367e-04, -2.0197e-04, -4.4139e-03,  6.9905e-03,\n",
      "        -8.5963e-04,  2.4601e-03,  5.3517e-03, -5.8084e-04,  2.6084e-03,\n",
      "         6.4009e-03,  1.5939e-03, -2.5391e-03,  2.8178e-03, -4.7679e-04,\n",
      "        -2.2187e-03, -3.4689e-03,  3.4960e-04, -4.6081e-03,  6.8584e-03,\n",
      "        -1.3900e-03, -3.9575e-03, -1.4270e-03,  4.4122e-03,  8.2928e-05,\n",
      "        -3.8773e-03, -4.4337e-04,  3.0285e-03,  3.8407e-03, -3.8122e-03,\n",
      "         9.1166e-04, -6.1733e-05, -9.4138e-04, -5.3551e-03, -9.5715e-03,\n",
      "         5.9816e-03, -6.6384e-04,  9.1643e-03, -4.0426e-04, -1.7889e-03,\n",
      "        -5.8760e-04,  1.9264e-04,  8.8129e-04,  2.5749e-03, -2.5286e-03,\n",
      "        -3.2679e-03,  4.2280e-03,  1.7599e-02,  7.4231e-03,  1.8699e-03,\n",
      "         3.1099e-03,  2.1859e-03,  3.9603e-03, -6.1110e-03], device='cuda:0'), 'exp_avg_sq': tensor([3.2311e-05, 1.2747e-05, 1.3953e-05, 1.3761e-05, 2.8070e-05, 5.9999e-05,\n",
      "        3.2716e-05, 4.2634e-05, 1.2218e-05, 1.3860e-05, 1.7881e-05, 1.8814e-05,\n",
      "        6.6986e-06, 2.8175e-05, 4.0745e-05, 1.7060e-05, 3.8468e-05, 7.6325e-06,\n",
      "        2.2607e-05, 2.7640e-05, 5.3720e-05, 1.0417e-05, 2.8053e-05, 1.7083e-05,\n",
      "        3.2603e-05, 1.5767e-05, 2.2603e-05, 1.8561e-05, 3.1569e-05, 2.4437e-05,\n",
      "        2.8569e-05, 2.0605e-05, 2.7833e-05, 2.6637e-05, 2.6385e-05, 1.2290e-05,\n",
      "        1.8879e-05, 8.5879e-06, 3.8288e-05, 1.7493e-05, 2.9379e-05, 2.7408e-05,\n",
      "        4.2624e-05, 8.3778e-06, 3.5714e-05, 1.9002e-05, 8.0131e-06, 7.0373e-05,\n",
      "        1.3108e-05, 7.5145e-06, 1.4456e-05, 1.4580e-05, 4.7989e-06, 1.1458e-05,\n",
      "        2.4248e-05, 8.2655e-06, 2.3500e-05, 3.2444e-05, 2.7280e-05, 2.2516e-05,\n",
      "        2.2187e-05, 1.0780e-05, 3.9653e-05, 6.2422e-05], device='cuda:0')}, 16: {'step': tensor(60., device='cuda:0'), 'exp_avg': tensor([[ 8.4097e-03,  1.1204e-03,  8.4045e-04,  ...,  2.6040e-03,\n",
      "          3.3393e-03,  1.3785e-03],\n",
      "        [ 7.5451e-04, -5.1355e-03, -2.8646e-04,  ..., -1.5130e-03,\n",
      "          1.6150e-03, -6.8394e-04],\n",
      "        [-2.5241e-03, -3.4744e-04, -8.7824e-04,  ..., -3.6087e-04,\n",
      "          2.0148e-03,  3.8537e-04],\n",
      "        ...,\n",
      "        [-4.8808e-04, -1.6172e-04,  3.2242e-03,  ...,  2.7257e-04,\n",
      "          5.7999e-04,  2.4859e-03],\n",
      "        [ 4.0023e-04,  1.0119e-04,  1.7744e-04,  ...,  1.7462e-03,\n",
      "          3.0603e-03,  7.8608e-04],\n",
      "        [-4.8028e-03,  1.8387e-03,  7.3310e-04,  ...,  3.2165e-03,\n",
      "          4.2364e-05,  1.3388e-03]], device='cuda:0'), 'exp_avg_sq': tensor([[2.4202e-05, 2.3174e-06, 3.4751e-06,  ..., 2.3152e-06, 6.9664e-06,\n",
      "         1.9619e-05],\n",
      "        [9.3623e-06, 1.0670e-05, 2.0693e-06,  ..., 1.3724e-06, 7.4222e-06,\n",
      "         6.2979e-06],\n",
      "        [1.3840e-05, 1.6374e-05, 2.8595e-06,  ..., 3.1715e-07, 1.6005e-05,\n",
      "         2.6365e-06],\n",
      "        ...,\n",
      "        [2.4832e-05, 2.6705e-05, 4.9440e-06,  ..., 1.2135e-06, 1.2831e-05,\n",
      "         1.5756e-05],\n",
      "        [2.2883e-07, 2.7375e-06, 1.2271e-06,  ..., 2.4297e-06, 1.1564e-05,\n",
      "         2.3917e-06],\n",
      "        [3.9284e-06, 4.6583e-06, 3.4449e-06,  ..., 6.2599e-06, 2.1529e-06,\n",
      "         3.3671e-06]], device='cuda:0')}, 17: {'step': tensor(60., device='cuda:0'), 'exp_avg': tensor([ 1.0866e-02, -5.7139e-03,  2.5939e-03,  7.9963e-03,  6.5359e-03,\n",
      "         4.0638e-03,  1.9027e-03, -7.1883e-03, -1.0625e-03, -3.1901e-03,\n",
      "         3.2254e-03, -8.2953e-03,  4.3256e-03,  7.8215e-03,  9.2142e-03,\n",
      "         3.0007e-03,  4.5145e-03,  1.0989e-03,  4.7781e-03,  3.2639e-03,\n",
      "        -5.8628e-03,  7.8803e-03, -1.6940e-03, -2.5251e-03, -6.1439e-03,\n",
      "        -6.8409e-03,  1.7059e-02,  1.1148e-02, -1.2807e-03,  4.2737e-03,\n",
      "         9.9488e-04, -3.5775e-03,  3.5185e-05,  2.7561e-03, -7.3402e-03,\n",
      "         1.3783e-03,  1.2966e-02, -3.5393e-03,  2.6857e-03, -1.3438e-02,\n",
      "        -5.1506e-03,  3.9208e-03, -1.0924e-04, -1.6308e-03,  1.0475e-02,\n",
      "         4.3848e-03,  1.4888e-02,  8.5821e-03, -3.3336e-03, -7.2127e-03,\n",
      "         5.8539e-03, -1.6730e-03, -3.1388e-03,  1.0206e-02,  8.6663e-03,\n",
      "         1.7564e-03,  3.9197e-03,  6.6260e-03,  4.9911e-04,  1.2995e-02,\n",
      "         6.1453e-03, -1.4361e-03,  2.2272e-03, -2.1654e-03], device='cuda:0'), 'exp_avg_sq': tensor([1.3730e-04, 4.9855e-05, 7.2916e-05, 1.0357e-04, 5.0122e-05, 1.0297e-05,\n",
      "        1.3901e-04, 3.8028e-05, 3.9760e-05, 1.1137e-04, 5.4243e-05, 1.0181e-04,\n",
      "        5.9853e-05, 5.0925e-05, 1.4341e-04, 4.0583e-05, 2.9101e-05, 7.1584e-05,\n",
      "        4.0806e-05, 9.3816e-05, 2.9936e-05, 6.6712e-05, 7.6323e-05, 5.9770e-05,\n",
      "        6.4740e-05, 6.6668e-05, 6.7365e-05, 1.3876e-04, 9.1590e-06, 3.8301e-05,\n",
      "        1.5622e-04, 6.8917e-05, 9.2869e-06, 1.1952e-04, 2.6896e-05, 5.7955e-05,\n",
      "        7.1541e-05, 3.9452e-05, 1.7052e-05, 1.7603e-04, 3.8766e-05, 3.3137e-05,\n",
      "        3.6539e-05, 7.0082e-05, 1.5775e-04, 1.7842e-05, 1.2892e-04, 5.1324e-05,\n",
      "        3.7022e-05, 5.6162e-05, 1.1082e-04, 1.2239e-04, 1.0918e-04, 6.3984e-05,\n",
      "        9.4740e-05, 2.6740e-05, 1.5735e-05, 1.3135e-04, 1.0724e-06, 5.3918e-05,\n",
      "        4.5094e-05, 8.0840e-05, 3.3318e-05, 4.5528e-05], device='cuda:0')}, 18: {'step': tensor(60., device='cuda:0'), 'exp_avg': tensor([[ 5.8389e-04,  5.6678e-03, -8.9661e-05,  ...,  4.0496e-03,\n",
      "         -5.0248e-04, -3.0464e-03],\n",
      "        [ 1.4849e-04,  9.7172e-04, -2.6554e-03,  ..., -2.1678e-03,\n",
      "         -6.0057e-04,  1.9097e-04],\n",
      "        [-1.2819e-05,  1.2829e-04,  4.3098e-05,  ..., -8.2313e-04,\n",
      "         -9.3010e-04,  2.0743e-07],\n",
      "        ...,\n",
      "        [ 4.0757e-04, -5.5751e-04,  1.1386e-04,  ...,  1.2923e-03,\n",
      "         -1.5032e-05,  5.2727e-04],\n",
      "        [-3.7263e-03, -1.4793e-03,  1.4823e-03,  ..., -7.3260e-03,\n",
      "          1.8222e-04, -8.9116e-04],\n",
      "        [-1.1475e-03, -5.5588e-03,  3.9767e-03,  ..., -3.0454e-03,\n",
      "          1.6103e-03, -1.8971e-03]], device='cuda:0'), 'exp_avg_sq': tensor([[3.8018e-06, 1.5294e-05, 7.1130e-06,  ..., 1.7254e-05, 6.1334e-06,\n",
      "         3.6632e-06],\n",
      "        [1.2458e-07, 1.9203e-06, 1.6123e-06,  ..., 4.7235e-06, 6.5998e-07,\n",
      "         1.6655e-07],\n",
      "        [1.8434e-09, 5.9065e-08, 4.5050e-07,  ..., 8.0204e-07, 2.0090e-07,\n",
      "         3.3794e-08],\n",
      "        ...,\n",
      "        [4.5280e-07, 1.0568e-05, 8.8745e-07,  ..., 3.1918e-06, 7.0758e-07,\n",
      "         6.0613e-07],\n",
      "        [8.0884e-06, 1.5773e-05, 1.1570e-05,  ..., 1.8619e-05, 2.9243e-06,\n",
      "         1.3861e-06],\n",
      "        [3.1633e-06, 3.1652e-05, 1.5895e-05,  ..., 2.8088e-05, 5.0397e-06,\n",
      "         9.1905e-06]], device='cuda:0')}, 19: {'step': tensor(60., device='cuda:0'), 'exp_avg': tensor([ 0.0213, -0.0051, -0.0040, -0.0029,  0.0041,  0.0081,  0.0052,  0.0040,\n",
      "         0.0328,  0.0110, -0.0263,  0.0049,  0.0233,  0.0356, -0.0222, -0.0012,\n",
      "         0.0004,  0.0184,  0.0123,  0.0169,  0.0059,  0.0329,  0.0115,  0.0219,\n",
      "        -0.0157, -0.0040, -0.0027,  0.0042,  0.0196,  0.0018, -0.0260, -0.0036],\n",
      "       device='cuda:0'), 'exp_avg_sq': tensor([4.5634e-04, 4.2287e-05, 1.8074e-05, 2.6888e-05, 4.8993e-05, 7.9071e-04,\n",
      "        6.8979e-04, 2.7799e-04, 4.0741e-04, 2.6085e-04, 4.5382e-04, 5.6915e-04,\n",
      "        1.4286e-04, 7.3679e-04, 1.0037e-03, 3.1341e-04, 3.3609e-06, 6.2365e-04,\n",
      "        6.1950e-04, 7.1768e-04, 5.0591e-05, 3.8187e-04, 4.8172e-04, 3.2030e-04,\n",
      "        8.4346e-04, 5.0808e-04, 1.1235e-04, 5.5808e-04, 1.9482e-04, 7.2718e-05,\n",
      "        2.5122e-04, 3.8304e-04], device='cuda:0')}, 20: {'step': tensor(60., device='cuda:0'), 'exp_avg': tensor([[ 1.8428e-03,  3.6564e-04,  1.6088e-04,  ...,  2.9041e-05,\n",
      "          1.0168e-03,  4.6062e-03],\n",
      "        [ 3.3340e-03,  4.4738e-03, -3.8851e-04,  ...,  8.1812e-04,\n",
      "          2.7673e-03,  1.3966e-02],\n",
      "        [ 4.9925e-03,  1.6173e-03, -5.4968e-04,  ...,  6.1886e-04,\n",
      "         -1.7422e-03,  5.7391e-04],\n",
      "        ...,\n",
      "        [-6.9619e-04, -8.1095e-05, -4.1628e-05,  ..., -5.7470e-05,\n",
      "         -1.6765e-03,  7.2119e-04],\n",
      "        [ 1.1756e-02,  1.8821e-03,  6.6572e-04,  ..., -1.5318e-03,\n",
      "          2.0020e-02,  3.2884e-03],\n",
      "        [ 3.4199e-03,  3.6658e-03, -2.5189e-04,  ..., -1.4523e-05,\n",
      "         -4.1750e-03,  1.9560e-03]], device='cuda:0'), 'exp_avg_sq': tensor([[5.8535e-06, 5.2168e-08, 2.0458e-08,  ..., 4.7936e-08, 4.6343e-06,\n",
      "         2.5988e-06],\n",
      "        [1.0020e-04, 2.3601e-06, 3.4009e-07,  ..., 1.4814e-06, 2.9981e-05,\n",
      "         4.1192e-05],\n",
      "        [1.7116e-05, 5.4861e-07, 1.4613e-07,  ..., 3.3635e-07, 5.2621e-06,\n",
      "         3.9568e-06],\n",
      "        ...,\n",
      "        [1.1959e-05, 4.9114e-08, 1.1858e-07,  ..., 8.0964e-09, 3.9385e-06,\n",
      "         2.1931e-06],\n",
      "        [3.4734e-04, 4.5096e-07, 1.0598e-07,  ..., 1.0047e-06, 7.1500e-05,\n",
      "         1.6370e-05],\n",
      "        [6.4495e-05, 1.6600e-06, 1.9077e-08,  ..., 5.7732e-09, 1.0278e-05,\n",
      "         3.7181e-06]], device='cuda:0')}, 21: {'step': tensor(60., device='cuda:0'), 'exp_avg': tensor([ 0.0082,  0.0476,  0.0102,  0.1017,  0.0436,  0.0648,  0.0151,  0.0032,\n",
      "         0.0017, -0.0070,  0.0024,  0.0161,  0.0041,  0.0308, -0.0053, -0.0002,\n",
      "         0.0427,  0.0051,  0.0167,  0.0237,  0.0126,  0.0046,  0.0691,  0.0195,\n",
      "        -0.0111, -0.0021, -0.0017, -0.0022, -0.0246, -0.0092,  0.0983, -0.0150],\n",
      "       device='cuda:0'), 'exp_avg_sq': tensor([2.6097e-04, 2.6314e-03, 3.5515e-04, 2.5172e-03, 1.5011e-03, 1.2964e-03,\n",
      "        1.0366e-04, 2.9869e-03, 1.0812e-04, 4.9920e-04, 1.8350e-04, 2.7350e-03,\n",
      "        3.5613e-04, 9.8615e-04, 7.4736e-04, 2.3440e-05, 8.6710e-04, 3.0140e-04,\n",
      "        2.7733e-03, 8.7000e-04, 8.1638e-05, 4.8839e-05, 1.7131e-03, 3.9098e-04,\n",
      "        2.6456e-04, 1.5466e-05, 3.3342e-06, 4.3854e-04, 2.0054e-04, 3.5755e-04,\n",
      "        6.2966e-03, 5.5618e-04], device='cuda:0')}, 22: {'step': tensor(60., device='cuda:0'), 'exp_avg': tensor([[[-1.6180e-02],\n",
      "         [-2.3277e-03],\n",
      "         [-4.3510e-04],\n",
      "         ...,\n",
      "         [-9.4950e-03],\n",
      "         [ 3.0951e-03],\n",
      "         [-4.7490e-04]],\n",
      "\n",
      "        [[-3.2788e-03],\n",
      "         [ 1.3124e-04],\n",
      "         [-1.2421e-03],\n",
      "         ...,\n",
      "         [-2.6941e-03],\n",
      "         [-1.4686e-03],\n",
      "         [-2.9721e-05]],\n",
      "\n",
      "        [[ 8.0303e-03],\n",
      "         [-4.2915e-04],\n",
      "         [-8.5145e-04],\n",
      "         ...,\n",
      "         [ 2.1696e-03],\n",
      "         [-1.6205e-03],\n",
      "         [-7.0403e-04]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 4.9320e-03],\n",
      "         [-6.3782e-04],\n",
      "         [-1.9327e-03],\n",
      "         ...,\n",
      "         [ 4.1117e-03],\n",
      "         [-5.1666e-03],\n",
      "         [ 1.2554e-04]],\n",
      "\n",
      "        [[-6.8040e-03],\n",
      "         [-1.5928e-03],\n",
      "         [-2.0845e-03],\n",
      "         ...,\n",
      "         [-5.6112e-03],\n",
      "         [-1.2061e-03],\n",
      "         [-2.0659e-03]],\n",
      "\n",
      "        [[-4.0457e-03],\n",
      "         [-1.0193e-03],\n",
      "         [-8.2549e-04],\n",
      "         ...,\n",
      "         [-1.3598e-03],\n",
      "         [-4.6035e-04],\n",
      "         [-1.6430e-03]]], device='cuda:0'), 'exp_avg_sq': tensor([[[2.9065e-04],\n",
      "         [1.8056e-05],\n",
      "         [3.0163e-05],\n",
      "         ...,\n",
      "         [1.9440e-04],\n",
      "         [4.6368e-05],\n",
      "         [2.1891e-05]],\n",
      "\n",
      "        [[1.7113e-05],\n",
      "         [5.2368e-07],\n",
      "         [1.5198e-06],\n",
      "         ...,\n",
      "         [4.8824e-06],\n",
      "         [5.1059e-07],\n",
      "         [1.9988e-06]],\n",
      "\n",
      "        [[1.4269e-04],\n",
      "         [1.0384e-05],\n",
      "         [1.7487e-05],\n",
      "         ...,\n",
      "         [6.0195e-05],\n",
      "         [1.1880e-05],\n",
      "         [1.7004e-05]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[2.5656e-04],\n",
      "         [1.4978e-05],\n",
      "         [3.9663e-05],\n",
      "         ...,\n",
      "         [1.2688e-04],\n",
      "         [5.3217e-05],\n",
      "         [3.1920e-05]],\n",
      "\n",
      "        [[3.9130e-05],\n",
      "         [1.9981e-06],\n",
      "         [2.0236e-06],\n",
      "         ...,\n",
      "         [2.2265e-05],\n",
      "         [1.9468e-06],\n",
      "         [2.4527e-06]],\n",
      "\n",
      "        [[1.4097e-04],\n",
      "         [6.7948e-06],\n",
      "         [7.7807e-06],\n",
      "         ...,\n",
      "         [7.7374e-05],\n",
      "         [3.9255e-06],\n",
      "         [1.1594e-05]]], device='cuda:0')}, 23: {'step': tensor(60., device='cuda:0'), 'exp_avg': tensor([-5.1202e-03, -2.2103e-03, -3.9961e-03,  7.0227e-05, -3.1855e-03,\n",
      "        -4.1023e-03, -1.0119e-04, -7.3170e-03,  3.0840e-05, -1.1767e-03,\n",
      "        -1.8838e-03, -1.4976e-05, -1.4347e-04,  2.7058e-04,  1.4612e-03,\n",
      "        -9.1241e-03, -1.1560e-03,  2.1443e-03, -1.0857e-02, -2.3572e-03,\n",
      "        -1.4932e-03, -1.7020e-03, -3.9416e-04,  7.0078e-07,  1.2510e-04,\n",
      "         2.4123e-03, -3.5380e-03,  4.6737e-03, -8.5108e-04,  2.3288e-03,\n",
      "        -8.0980e-04, -8.0372e-03, -4.9700e-03, -2.7361e-03,  2.4567e-03,\n",
      "        -4.3660e-03,  1.2772e-04, -8.8327e-03, -4.1577e-03, -5.6591e-04,\n",
      "         2.3315e-03,  1.8374e-05, -8.9138e-03, -3.7721e-03,  8.9860e-04,\n",
      "        -8.1886e-04, -9.0683e-04,  2.8667e-03,  2.5611e-03, -5.4326e-03,\n",
      "         7.2555e-04, -9.8313e-03, -1.0525e-02,  2.7995e-03, -2.3637e-03,\n",
      "        -4.5588e-03, -1.6048e-04,  3.0611e-03,  1.3314e-03,  4.0753e-03,\n",
      "        -3.3553e-03,  3.0944e-03, -5.2260e-03, -8.8776e-04], device='cuda:0'), 'exp_avg_sq': tensor([1.6968e-04, 7.7600e-06, 5.3171e-05, 9.3372e-05, 6.0661e-05, 1.7013e-05,\n",
      "        2.6771e-08, 8.1168e-05, 1.9937e-08, 1.6435e-05, 2.1450e-05, 9.8103e-09,\n",
      "        1.0118e-07, 8.6846e-05, 2.8981e-05, 1.4018e-04, 4.0939e-05, 7.6500e-05,\n",
      "        6.0073e-05, 3.4068e-06, 4.9052e-05, 5.2487e-05, 8.3664e-07, 8.9893e-05,\n",
      "        1.9656e-05, 4.1085e-06, 1.7870e-05, 1.1574e-04, 4.1318e-05, 8.2452e-06,\n",
      "        2.8812e-05, 9.9220e-05, 1.3230e-04, 9.4405e-05, 9.7468e-06, 3.7168e-05,\n",
      "        2.2536e-07, 5.4047e-05, 7.1332e-06, 7.0886e-06, 8.7427e-05, 6.6705e-05,\n",
      "        9.8037e-05, 2.1802e-05, 1.2074e-05, 1.5575e-04, 1.0444e-04, 1.4433e-05,\n",
      "        1.5669e-04, 2.6493e-05, 4.8148e-06, 5.9669e-05, 1.4337e-04, 1.7832e-05,\n",
      "        2.8675e-05, 7.7949e-05, 3.3956e-08, 5.6092e-05, 1.9071e-06, 2.2244e-05,\n",
      "        4.4961e-05, 1.1034e-04, 2.4706e-05, 9.6196e-05], device='cuda:0')}, 24: {'step': tensor(60., device='cuda:0'), 'exp_avg': tensor([[ 5.1294e-05,  3.5770e-06,  9.5968e-05,  ..., -6.4813e-05,\n",
      "          2.0855e-05,  5.0724e-05],\n",
      "        [-1.7736e-05, -1.9318e-05, -1.2902e-04,  ...,  8.0338e-05,\n",
      "         -1.4660e-05, -3.7088e-05],\n",
      "        [ 1.1471e-04,  3.6533e-05,  1.9543e-04,  ..., -1.5674e-04,\n",
      "          4.1044e-05,  6.7807e-05],\n",
      "        ...,\n",
      "        [-5.6722e-05, -2.1483e-05, -7.7002e-05,  ...,  4.4697e-05,\n",
      "         -6.7614e-06, -3.1070e-05],\n",
      "        [-1.9729e-05, -1.4664e-05, -8.0296e-05,  ...,  3.3062e-05,\n",
      "         -6.9249e-06, -4.9767e-07],\n",
      "        [ 5.9042e-05,  1.4662e-05,  8.8190e-05,  ..., -1.9749e-05,\n",
      "          2.4955e-05,  4.3176e-05]], device='cuda:0'), 'exp_avg_sq': tensor([[1.8631e-08, 2.5939e-10, 5.6773e-09,  ..., 3.7169e-09, 1.1751e-09,\n",
      "         4.6735e-09],\n",
      "        [2.8067e-08, 4.6009e-10, 1.1395e-08,  ..., 7.1776e-09, 2.0878e-09,\n",
      "         8.8281e-09],\n",
      "        [1.0726e-07, 1.5228e-09, 3.6432e-08,  ..., 2.3989e-08, 7.3724e-09,\n",
      "         2.8632e-08],\n",
      "        ...,\n",
      "        [1.1703e-08, 1.8207e-10, 4.2282e-09,  ..., 2.6817e-09, 8.2688e-10,\n",
      "         3.2535e-09],\n",
      "        [7.7127e-09, 1.2384e-10, 2.9929e-09,  ..., 1.8053e-09, 4.9852e-10,\n",
      "         2.6214e-09],\n",
      "        [9.1802e-09, 1.2722e-10, 2.9629e-09,  ..., 1.8372e-09, 5.8907e-10,\n",
      "         2.3645e-09]], device='cuda:0')}, 25: {'step': tensor(60., device='cuda:0'), 'exp_avg': tensor([ 1.7284e-06,  4.5399e-05, -2.7531e-05, -5.3482e-06, -3.4922e-06,\n",
      "         4.7290e-05, -1.8390e-04,  5.8728e-06, -2.2251e-05, -2.9554e-05,\n",
      "        -6.5584e-05, -1.0722e-04,  1.3029e-04, -2.2876e-05, -7.2034e-06,\n",
      "         9.1334e-06,  2.6497e-05,  1.8286e-05,  1.2304e-04, -1.3320e-05,\n",
      "        -1.1163e-05, -2.1130e-04,  2.3020e-05,  2.3857e-06, -7.8707e-05,\n",
      "         1.0849e-05, -2.0727e-05,  1.4793e-05, -7.7625e-07,  2.9601e-05,\n",
      "        -6.9178e-05, -1.0067e-05,  3.1605e-06, -3.6295e-05,  1.0359e-05,\n",
      "        -1.3921e-04,  1.3741e-04, -5.6765e-05, -9.5660e-05, -2.8552e-05,\n",
      "         6.1991e-05, -5.1162e-06, -1.9213e-05,  2.1873e-04, -1.6507e-05,\n",
      "         2.9014e-05, -2.6774e-04,  1.0170e-05, -2.3454e-05, -4.8675e-06,\n",
      "         5.6686e-05,  2.6773e-05, -1.1979e-05,  1.5197e-05, -5.6726e-05,\n",
      "        -6.9752e-06, -6.7479e-05, -1.0835e-04, -3.2465e-05,  1.2390e-05,\n",
      "        -6.3975e-06, -8.6378e-06, -1.0767e-05,  4.6034e-05], device='cuda:0'), 'exp_avg_sq': tensor([1.2398e-10, 4.3533e-10, 2.4695e-10, 1.3865e-11, 1.7364e-11, 1.8726e-10,\n",
      "        2.9010e-09, 2.9792e-12, 2.8774e-09, 3.2226e-10, 5.9541e-10, 2.7507e-09,\n",
      "        4.1700e-09, 3.5391e-10, 3.8643e-11, 6.4504e-11, 7.6214e-10, 4.3476e-11,\n",
      "        3.1510e-09, 4.9859e-10, 6.9820e-11, 5.2557e-09, 5.1857e-11, 4.7914e-13,\n",
      "        7.2995e-10, 1.6335e-10, 1.8120e-10, 7.0006e-11, 1.5714e-13, 9.7822e-10,\n",
      "        1.1922e-09, 2.7058e-11, 7.4405e-13, 8.7625e-11, 1.0934e-09, 6.1732e-09,\n",
      "        1.7637e-09, 4.3901e-10, 1.0497e-09, 1.7396e-09, 5.9194e-10, 5.5208e-10,\n",
      "        1.0201e-09, 1.0315e-08, 2.1335e-11, 2.8251e-10, 9.3357e-09, 3.8022e-10,\n",
      "        4.4294e-11, 2.7004e-11, 9.2294e-10, 9.7305e-10, 5.4225e-11, 9.6853e-11,\n",
      "        3.3529e-10, 1.2059e-10, 1.7986e-09, 7.2422e-10, 2.5881e-10, 1.1774e-11,\n",
      "        3.4528e-11, 3.0073e-11, 5.7680e-10, 1.7243e-10], device='cuda:0')}, 26: {'step': tensor(60., device='cuda:0'), 'exp_avg': tensor([[ 1.5545e-03, -1.2853e-03,  5.2881e-03,  2.6328e-03,  5.5524e-04,\n",
      "         -4.6585e-03,  3.6977e-03, -1.6717e-03,  4.6502e-04,  2.1701e-03,\n",
      "          3.8680e-03, -2.0841e-03,  3.2593e-03, -4.6498e-04, -1.8100e-03,\n",
      "          7.8727e-04, -9.9328e-04, -1.7878e-03, -1.8852e-03,  1.1670e-03,\n",
      "         -1.6382e-03,  4.9530e-03,  3.6269e-04,  2.7101e-04, -2.0967e-03,\n",
      "          1.5781e-03,  1.2097e-03,  1.7942e-03, -1.2616e-03, -1.6328e-03,\n",
      "         -6.3927e-04, -3.6104e-05,  1.2628e-03, -3.5475e-03,  5.8361e-04,\n",
      "          2.6537e-03, -3.2796e-03, -2.4446e-03, -3.7392e-03,  3.5446e-04,\n",
      "          3.3953e-03, -9.2306e-04, -4.1786e-04,  3.6457e-03, -1.8801e-03,\n",
      "         -2.1335e-03,  5.0074e-03, -2.6111e-03, -2.6756e-03, -3.5576e-04,\n",
      "         -1.4847e-03,  6.3509e-03, -1.1061e-03,  1.3329e-03, -4.6484e-03,\n",
      "         -1.7651e-03,  2.6207e-03,  3.6463e-03, -1.7886e-03,  3.0239e-03,\n",
      "         -6.4661e-04, -1.9976e-03,  9.9006e-05,  6.0462e-03]], device='cuda:0'), 'exp_avg_sq': tensor([[1.3075e-06, 1.4092e-06, 2.1581e-06, 1.7283e-06, 6.7663e-07, 1.5873e-06,\n",
      "         2.3968e-06, 5.0760e-07, 1.7260e-06, 1.5842e-06, 3.9774e-06, 1.3125e-06,\n",
      "         2.0968e-06, 5.9657e-07, 1.3557e-06, 5.6084e-07, 7.9065e-07, 1.6979e-06,\n",
      "         9.0756e-07, 1.0382e-06, 1.3032e-06, 2.7309e-06, 4.6029e-07, 8.5576e-07,\n",
      "         9.2266e-07, 7.3820e-07, 9.1631e-07, 1.2845e-06, 8.6774e-07, 3.4521e-06,\n",
      "         1.8512e-06, 1.3895e-06, 4.3071e-07, 1.3765e-06, 1.1780e-06, 2.9226e-06,\n",
      "         1.3802e-06, 1.0226e-06, 2.0262e-06, 2.4567e-06, 1.9835e-06, 1.1475e-06,\n",
      "         2.0485e-06, 2.7418e-06, 5.1266e-07, 1.4456e-06, 4.1603e-06, 1.5031e-06,\n",
      "         1.7761e-06, 5.6632e-07, 2.2417e-06, 5.5246e-06, 9.8573e-07, 1.3797e-06,\n",
      "         2.9377e-06, 8.1948e-07, 1.5522e-06, 7.6010e-07, 1.0007e-06, 7.4739e-07,\n",
      "         1.6916e-06, 7.4713e-07, 1.5372e-06, 3.2438e-06]], device='cuda:0')}, 27: {'step': tensor(60., device='cuda:0'), 'exp_avg': tensor([-2.1388e-06], device='cuda:0'), 'exp_avg_sq': tensor([3.2006e-13], device='cuda:0')}, 28: {'step': tensor(60., device='cuda:0'), 'exp_avg': tensor([[ 9.6601e-06,  4.9025e-06,  3.4039e-08,  ..., -7.6303e-06,\n",
      "         -3.8417e-06,  6.3016e-06],\n",
      "        [-8.7909e-06, -6.2671e-06,  5.8009e-08,  ..., -3.9000e-06,\n",
      "         -2.7050e-06,  8.2048e-06],\n",
      "        [ 4.4549e-05,  3.8824e-05,  1.4914e-04,  ...,  4.5207e-04,\n",
      "          9.5000e-05,  6.8178e-04],\n",
      "        ...,\n",
      "        [-5.6388e-04, -6.9267e-04, -1.2213e-03,  ..., -1.6959e-04,\n",
      "         -1.8032e-04,  5.2920e-04],\n",
      "        [ 5.8078e-03,  4.3614e-03, -1.8148e-03,  ...,  4.1132e-03,\n",
      "         -4.1161e-04, -1.4788e-03],\n",
      "        [ 9.3429e-04,  8.3963e-03,  2.0531e-03,  ..., -8.7540e-04,\n",
      "          1.7371e-04, -5.8258e-03]], device='cuda:0'), 'exp_avg_sq': tensor([[5.6873e-12, 1.5233e-12, 2.2233e-15,  ..., 3.5870e-12, 9.5575e-13,\n",
      "         2.4731e-12],\n",
      "        [4.7289e-12, 2.4469e-12, 2.9829e-15,  ..., 9.8352e-13, 4.9365e-13,\n",
      "         4.1326e-12],\n",
      "        [1.5825e-05, 8.9364e-07, 1.2466e-05,  ..., 1.0400e-05, 2.6001e-06,\n",
      "         7.0088e-05],\n",
      "        ...,\n",
      "        [1.2439e-05, 1.0041e-05, 1.9887e-05,  ..., 7.8754e-06, 1.8109e-06,\n",
      "         4.9590e-05],\n",
      "        [4.3138e-05, 9.8218e-06, 3.7552e-05,  ..., 2.3624e-05, 4.6747e-06,\n",
      "         7.5039e-05],\n",
      "        [3.4013e-05, 2.5262e-05, 3.1348e-05,  ..., 1.2436e-05, 3.1940e-06,\n",
      "         4.9178e-05]], device='cuda:0')}, 29: {'step': tensor(60., device='cuda:0'), 'exp_avg': tensor([-7.1268e-06, -5.2818e-06,  1.7946e-03,  1.0310e-02, -6.4729e-03,\n",
      "         2.5426e-03,  1.8113e-02,  2.7078e-02, -5.1645e-06, -2.7255e-02,\n",
      "        -6.1103e-03, -8.1810e-04,  7.9730e-04,  1.0681e-02,  1.3561e-03,\n",
      "        -1.2857e-03, -9.5618e-03, -8.6148e-08, -2.1016e-03,  2.6730e-02,\n",
      "        -6.9709e-03, -5.5530e-03,  7.7594e-03,  7.0215e-03,  9.3257e-03,\n",
      "        -8.4437e-03, -3.0533e-05,  7.9428e-03, -1.0686e-02, -4.5047e-02,\n",
      "        -1.2036e-02, -1.5953e-02,  2.9683e-03,  1.9634e-05, -4.5870e-03,\n",
      "         6.3860e-03, -6.8799e-07,  3.6416e-03, -9.9457e-03,  5.8266e-02,\n",
      "        -9.2524e-03,  1.3070e-03,  2.1290e-04, -8.2875e-03,  4.8706e-03,\n",
      "        -6.8372e-06,  7.0259e-03, -5.7638e-03, -7.2547e-03, -2.7258e-02,\n",
      "        -8.1552e-03,  7.2427e-03,  8.6632e-03, -2.2571e-02,  3.6374e-02,\n",
      "        -1.7665e-03, -3.1666e-04,  8.5958e-03,  4.5022e-06, -3.0884e-03,\n",
      "        -1.6835e-02,  5.1366e-04, -2.9343e-03, -1.1600e-02], device='cuda:0'), 'exp_avg_sq': tensor([3.1406e-12, 1.7582e-12, 3.6642e-04, 1.3175e-04, 9.8101e-04, 1.3455e-05,\n",
      "        4.2883e-04, 2.6419e-03, 1.6837e-12, 1.8340e-04, 1.5737e-03, 2.1186e-04,\n",
      "        4.7741e-04, 1.3904e-03, 8.9128e-05, 1.3400e-05, 4.4939e-04, 3.9346e-15,\n",
      "        1.1494e-03, 1.4535e-04, 4.1417e-04, 2.7567e-04, 1.2208e-03, 2.0659e-04,\n",
      "        4.9488e-04, 3.9176e-04, 9.7853e-06, 2.0995e-04, 2.3336e-04, 2.2870e-03,\n",
      "        4.4295e-04, 1.1337e-03, 2.8233e-04, 3.0850e-07, 1.1130e-03, 1.3592e-03,\n",
      "        4.5627e-14, 3.6745e-04, 1.0018e-04, 1.4281e-03, 3.7712e-04, 2.2417e-04,\n",
      "        2.3774e-04, 2.2339e-04, 1.4411e-04, 2.8973e-12, 1.8314e-04, 5.5269e-04,\n",
      "        1.6865e-04, 1.5337e-03, 3.6080e-04, 7.7150e-05, 1.6727e-04, 1.8106e-03,\n",
      "        6.1130e-04, 6.6530e-04, 1.2741e-04, 2.2884e-04, 1.2936e-12, 3.8603e-04,\n",
      "        2.9777e-03, 2.0473e-04, 3.5008e-04, 2.3301e-04], device='cuda:0')}, 30: {'step': tensor(60., device='cuda:0'), 'exp_avg': tensor([[-9.2092e-06, -1.8440e-06,  1.6405e-04,  ...,  1.2331e-03,\n",
      "         -9.0366e-03, -7.5484e-03],\n",
      "        [-8.0981e-07,  4.7178e-06, -1.0854e-06,  ..., -6.5577e-04,\n",
      "          4.0384e-03,  5.5287e-03],\n",
      "        [ 1.5745e-06, -8.1460e-06,  6.5751e-06,  ..., -4.1215e-04,\n",
      "         -3.0042e-03, -2.2737e-03],\n",
      "        ...,\n",
      "        [ 8.2950e-06,  5.0996e-06,  1.6771e-04,  ...,  9.6285e-04,\n",
      "         -7.0138e-03, -4.1887e-03],\n",
      "        [-3.4176e-06,  7.8087e-06,  1.3373e-06,  ..., -1.0971e-06,\n",
      "          2.0687e-06, -1.0140e-05],\n",
      "        [ 1.7810e-06,  1.1967e-05, -2.4108e-04,  ..., -1.1577e-03,\n",
      "          9.4002e-03,  6.1606e-03]], device='cuda:0'), 'exp_avg_sq': tensor([[5.1791e-12, 2.4421e-13, 2.1527e-05,  ..., 2.0099e-05, 1.7297e-04,\n",
      "         2.5274e-04],\n",
      "        [5.9192e-14, 1.4150e-12, 2.9782e-06,  ..., 4.0747e-06, 1.7837e-04,\n",
      "         3.1406e-04],\n",
      "        [1.8396e-13, 4.0749e-12, 8.8164e-07,  ..., 9.6990e-07, 6.5130e-05,\n",
      "         1.2725e-04],\n",
      "        ...,\n",
      "        [4.2218e-12, 1.6433e-12, 2.0066e-05,  ..., 1.6546e-05, 1.4807e-04,\n",
      "         2.0348e-04],\n",
      "        [7.6567e-13, 3.7523e-12, 1.3794e-13,  ..., 9.8052e-14, 3.0095e-13,\n",
      "         6.2539e-12],\n",
      "        [2.2936e-13, 8.6588e-12, 4.0098e-05,  ..., 2.8997e-05, 3.1421e-04,\n",
      "         2.8759e-04]], device='cuda:0')}, 31: {'step': tensor(60., device='cuda:0'), 'exp_avg': tensor([-3.8206e-03,  1.4126e-02, -1.4477e-02, -7.4255e-03, -1.1859e-05,\n",
      "        -5.7138e-03, -1.1754e-02,  1.7065e-02,  9.4957e-03, -6.0955e-06,\n",
      "        -8.7849e-06,  1.0115e-03, -7.3271e-06,  8.3753e-03,  7.4700e-02,\n",
      "        -4.4405e-03, -8.8028e-03, -1.0172e-02,  8.8993e-03, -8.0685e-06,\n",
      "        -1.0150e-02,  9.6997e-03, -6.0953e-06,  3.5735e-03, -3.3089e-03,\n",
      "        -1.2729e-03, -5.4435e-03, -7.6514e-03, -9.5630e-06,  4.4351e-03,\n",
      "        -6.6751e-06, -5.7346e-03], device='cuda:0'), 'exp_avg_sq': tensor([1.4300e-03, 4.3355e-03, 1.8520e-03, 8.1545e-04, 8.5057e-12, 2.1218e-03,\n",
      "        3.2333e-03, 4.1223e-04, 6.4448e-03, 2.3188e-12, 4.7227e-12, 1.9656e-04,\n",
      "        3.3146e-12, 1.7897e-03, 5.8291e-03, 4.6569e-04, 1.8272e-03, 2.8154e-03,\n",
      "        2.6033e-03, 3.9996e-12, 4.3782e-03, 1.8397e-03, 2.3187e-12, 8.9147e-04,\n",
      "        4.4426e-04, 2.8481e-04, 1.4185e-03, 2.9575e-03, 5.5759e-12, 1.2908e-03,\n",
      "        2.7654e-12, 1.1551e-03], device='cuda:0')}, 32: {'step': tensor(60., device='cuda:0'), 'exp_avg': tensor([[ 1.3470e-05,  1.4814e-05, -3.1960e-06,  7.2122e-06, -1.6405e-06,\n",
      "         -1.2865e-05, -1.8774e-06, -3.8402e-06,  4.4993e-06, -1.6742e-05,\n",
      "         -6.4178e-06, -1.5643e-05,  1.2395e-05,  2.8196e-06,  1.0335e-05,\n",
      "         -9.3326e-06, -7.2250e-06,  4.1791e-06, -1.1510e-05,  1.6545e-06,\n",
      "         -1.0704e-05,  3.5247e-06,  1.1949e-05,  4.8819e-06, -7.7088e-06,\n",
      "         -1.5380e-05, -2.4752e-06,  4.0131e-10,  3.7416e-06,  1.0681e-05,\n",
      "         -1.0343e-05,  4.3549e-06],\n",
      "        [ 1.3730e-02, -1.2430e-02, -2.6890e-02,  2.9472e-04, -5.5603e-06,\n",
      "          1.4850e-02,  3.4887e-03,  2.8388e-04, -2.9998e-03, -1.6523e-05,\n",
      "         -1.2231e-05,  1.0898e-03,  1.3084e-05,  2.7136e-02,  3.5677e-03,\n",
      "         -4.4702e-03, -1.4122e-03, -7.0430e-03, -2.1106e-02, -1.0337e-05,\n",
      "         -2.1191e-03, -1.5364e-02,  9.7878e-06,  2.0905e-03, -7.5484e-03,\n",
      "          3.5146e-03,  8.3873e-03, -1.4380e-03,  1.2017e-05, -4.8787e-03,\n",
      "          7.9400e-06,  1.4417e-02],\n",
      "        [ 1.1253e-05, -3.9135e-06, -6.8998e-06,  1.3217e-05,  1.0504e-05,\n",
      "         -1.4575e-05, -1.1375e-05, -1.4377e-05, -9.0822e-06, -1.0691e-05,\n",
      "          2.8929e-06,  1.3967e-05,  1.3923e-05, -1.1872e-05, -2.4463e-06,\n",
      "          7.1031e-06, -9.5350e-07, -1.4611e-05,  9.0187e-06,  9.0276e-06,\n",
      "          4.1479e-07,  1.4334e-05, -1.2327e-05,  6.2500e-06,  1.3878e-06,\n",
      "         -8.5301e-06,  1.2344e-05,  1.3965e-05, -4.9996e-06,  2.3045e-09,\n",
      "          9.3848e-06, -1.2933e-05],\n",
      "        [-4.1732e-02,  1.7956e-02,  3.9383e-02,  2.2969e-05,  1.4660e-05,\n",
      "         -4.6549e-02, -1.6789e-02, -3.1176e-04,  1.9234e-03, -1.4433e-05,\n",
      "         -5.1409e-06, -6.1946e-03, -9.3242e-06, -5.3534e-02, -6.9188e-03,\n",
      "         -2.1503e-03, -1.4716e-02,  1.6384e-02,  2.9504e-02,  5.3333e-06,\n",
      "         -1.1570e-03,  1.7370e-02,  9.9911e-06, -3.5321e-03,  7.8347e-03,\n",
      "         -2.8292e-02, -2.0159e-02, -1.0974e-03,  1.5431e-05,  3.7562e-03,\n",
      "          8.0208e-06, -2.1398e-02],\n",
      "        [ 8.1240e-06, -1.6472e-05,  5.4391e-09,  8.7503e-06,  9.3333e-06,\n",
      "         -2.4286e-06,  1.0503e-05,  1.0122e-05,  5.6571e-06,  1.2759e-05,\n",
      "          3.7799e-08, -9.9753e-06, -1.0579e-05, -2.2380e-06, -9.7804e-06,\n",
      "         -1.3658e-06,  8.3946e-06, -1.0441e-05, -1.4619e-05,  7.4922e-07,\n",
      "          4.8694e-06, -3.5857e-06,  1.1752e-05,  8.5837e-06, -1.3414e-05,\n",
      "         -1.4782e-05,  7.5828e-06, -1.3088e-05, -1.0101e-07, -1.6938e-05,\n",
      "         -7.5566e-06,  7.7484e-06],\n",
      "        [-1.0527e-05, -1.1462e-05,  9.2663e-06,  1.2240e-05, -1.1590e-06,\n",
      "          3.6011e-06, -1.0547e-05, -8.8209e-07,  5.9323e-06,  5.0390e-06,\n",
      "         -1.6214e-05,  1.1031e-05,  6.8917e-06,  6.8455e-06,  1.0430e-05,\n",
      "          1.6145e-05, -1.4655e-06, -5.0900e-06,  1.4321e-06,  4.8259e-06,\n",
      "          6.8983e-06, -1.5686e-05,  4.9556e-06, -1.5565e-05,  1.1386e-06,\n",
      "         -2.3258e-06,  2.5316e-06, -1.5786e-05, -1.0541e-05, -1.3143e-05,\n",
      "         -1.0449e-05,  9.1438e-06],\n",
      "        [-1.1273e-05, -6.2668e-06,  1.4597e-06,  1.5269e-05, -1.3940e-05,\n",
      "         -1.1572e-05,  9.6496e-06, -1.0960e-05, -6.4970e-06,  7.9237e-06,\n",
      "          1.0219e-05,  5.0365e-06, -6.0452e-06, -7.0644e-06, -1.1432e-05,\n",
      "          3.5585e-06, -1.3772e-05, -1.0919e-05, -1.0964e-08, -8.8071e-06,\n",
      "         -1.2502e-06,  1.3029e-07,  1.3761e-05, -6.6684e-06,  1.0317e-05,\n",
      "          1.4993e-06,  1.0232e-05, -8.5566e-06, -1.8815e-09, -5.8877e-06,\n",
      "         -9.2439e-06, -1.3980e-06],\n",
      "        [-6.2845e-06,  1.4430e-05, -2.4569e-06,  6.5396e-07, -8.0879e-06,\n",
      "         -1.5478e-05, -3.1431e-06, -1.2291e-05, -8.6156e-06, -1.5725e-05,\n",
      "         -1.6686e-05,  1.5203e-05,  1.3552e-05,  5.1351e-06, -5.1096e-06,\n",
      "          1.3682e-05, -6.0180e-06, -3.8523e-06, -1.1040e-05, -4.4297e-11,\n",
      "         -1.7404e-06, -1.4170e-05, -1.2257e-05,  6.9432e-06, -3.2618e-07,\n",
      "          1.6497e-05, -1.4846e-05,  1.8534e-06,  1.0810e-05,  1.0100e-05,\n",
      "          6.8214e-06, -1.5055e-05],\n",
      "        [ 9.8372e-03, -8.9034e-03, -1.9252e-02,  2.2905e-04,  1.6791e-05,\n",
      "          1.0644e-02,  2.4777e-03,  2.0898e-04, -2.1766e-03, -8.9155e-06,\n",
      "          1.0969e-05,  8.0330e-04,  1.3761e-05,  1.9462e-02,  2.5866e-03,\n",
      "         -3.1895e-03, -1.0089e-03, -5.0408e-03, -1.5109e-02,  1.0772e-05,\n",
      "         -1.5422e-03, -1.1050e-02, -2.7096e-06,  1.5192e-03, -5.4167e-03,\n",
      "          2.5025e-03,  6.0498e-03, -1.0212e-03,  1.5281e-06, -3.4904e-03,\n",
      "          6.0496e-06,  1.0340e-02],\n",
      "        [ 3.3908e-04,  1.6569e-04,  1.1638e-04,  1.5550e-05, -4.5043e-10,\n",
      "          3.1399e-04,  1.6725e-04,  9.4778e-06,  4.0582e-05, -3.1389e-06,\n",
      "         -2.3433e-06,  8.2251e-05,  2.4814e-06,  3.2390e-05,  1.3573e-05,\n",
      "          1.5784e-04,  1.7101e-04, -1.6539e-05,  2.6784e-04,  9.1491e-06,\n",
      "          6.9735e-06,  1.0969e-04, -1.2731e-05,  1.4207e-05,  1.8707e-04,\n",
      "          1.6258e-04,  4.7777e-06,  3.3085e-05,  1.4778e-05,  1.4999e-04,\n",
      "          1.5164e-06,  1.9012e-04],\n",
      "        [ 1.4176e-05, -3.7670e-06,  4.6193e-06,  5.5641e-06,  1.0473e-05,\n",
      "         -6.5614e-06, -1.0520e-05,  5.7934e-06,  3.7348e-06, -4.9139e-06,\n",
      "          5.8197e-06, -1.8081e-06,  1.0566e-05,  3.1990e-09,  3.2402e-06,\n",
      "          1.4487e-05, -9.2142e-06, -3.0537e-06,  2.2919e-06,  1.6556e-05,\n",
      "          5.7059e-06,  2.8465e-06,  1.9089e-06,  1.2382e-05, -1.4736e-06,\n",
      "         -2.4150e-06, -1.1089e-05, -9.4351e-06, -6.7834e-06, -1.4626e-05,\n",
      "          1.0521e-05, -4.3954e-07],\n",
      "        [-2.4972e-02,  2.2695e-02,  4.8908e-02, -5.4873e-04,  1.2271e-05,\n",
      "         -2.6946e-02, -6.3588e-03, -4.9828e-04,  5.5350e-03,  1.6641e-05,\n",
      "          7.6164e-06, -2.0039e-03, -9.1416e-06, -4.9453e-02, -6.5184e-03,\n",
      "          8.3088e-03,  2.6125e-03,  1.2976e-02,  3.8554e-02,  1.3220e-05,\n",
      "          4.0316e-03,  2.8047e-02, -1.3991e-05, -3.7957e-03,  1.3879e-02,\n",
      "         -6.3155e-03, -1.5235e-02,  2.5484e-03,  1.3660e-05,  8.8748e-03,\n",
      "          5.1915e-06, -2.6304e-02],\n",
      "        [-1.6473e-02,  1.4946e-02,  3.2267e-02, -3.5482e-04,  7.8287e-06,\n",
      "         -1.7821e-02, -4.1571e-03, -3.2842e-04,  3.6025e-03, -8.4161e-06,\n",
      "          1.0789e-05, -1.3276e-03, -1.4007e-05, -3.2575e-02, -4.3146e-03,\n",
      "          5.3686e-03,  1.7059e-03,  8.4336e-03,  2.5311e-02,  4.8479e-07,\n",
      "          2.5414e-03,  1.8464e-02,  7.6756e-06, -2.5079e-03,  9.0840e-03,\n",
      "         -4.2134e-03, -1.0094e-02,  1.7617e-03,  5.3331e-06,  5.8327e-03,\n",
      "         -1.0221e-05, -1.7272e-02],\n",
      "        [-5.3799e-02,  4.8944e-02,  1.0543e-01, -1.2028e-03, -3.2693e-06,\n",
      "         -5.8017e-02, -1.3733e-02, -1.0671e-03,  1.1887e-02, -1.0296e-05,\n",
      "          1.2297e-05, -4.2166e-03, -1.6545e-05, -1.0644e-01, -1.3932e-02,\n",
      "          1.7895e-02,  5.5745e-03,  2.8131e-02,  8.3124e-02,  4.8795e-06,\n",
      "          8.6229e-03,  6.0245e-02, -1.0515e-05, -8.0967e-03,  2.9823e-02,\n",
      "         -1.3516e-02, -3.2585e-02,  5.5762e-03, -9.4031e-06,  1.8923e-02,\n",
      "          1.6636e-05, -5.6710e-02],\n",
      "        [ 1.6844e-04, -9.8533e-05, -3.0976e-04,  2.6308e-06,  1.1834e-05,\n",
      "          2.3126e-04,  6.0428e-06,  2.5607e-05, -3.0531e-05,  1.2748e-06,\n",
      "          7.0029e-06,  2.1125e-05,  1.4971e-06,  3.3324e-04,  7.5473e-05,\n",
      "          3.0125e-05,  3.1176e-06,  3.9455e-05, -1.3446e-04, -9.5496e-06,\n",
      "          3.7810e-05, -2.0616e-04, -6.3300e-06,  6.1199e-05, -3.2594e-05,\n",
      "          1.0051e-04,  1.6941e-04, -4.3700e-05,  1.2841e-05, -9.3217e-05,\n",
      "          3.2241e-06,  1.1173e-04],\n",
      "        [ 1.1268e-02, -1.0192e-02, -2.2030e-02,  2.3412e-04, -7.7286e-06,\n",
      "          1.2133e-02,  2.8770e-03,  2.2608e-04, -2.4660e-03,  6.8926e-06,\n",
      "         -8.0874e-07,  9.0987e-04, -1.4617e-05,  2.2279e-02,  2.9233e-03,\n",
      "         -3.7006e-03, -1.1696e-03, -5.7997e-03, -1.7319e-02,  1.0539e-05,\n",
      "         -1.7482e-03, -1.2599e-02, -6.2576e-06,  1.7176e-03, -6.2106e-03,\n",
      "          2.8565e-03,  6.8776e-03, -1.1892e-03, -1.2561e-05, -4.0104e-03,\n",
      "         -1.0425e-05,  1.1833e-02]], device='cuda:0'), 'exp_avg_sq': tensor([[1.0931e-11, 1.3185e-11, 6.7472e-13, 3.2142e-12, 1.9792e-13, 9.9849e-12,\n",
      "         2.5228e-13, 9.5502e-13, 1.2921e-12, 1.6789e-11, 2.5622e-12, 1.4681e-11,\n",
      "         9.2799e-12, 5.3341e-13, 6.4927e-12, 5.3158e-12, 3.2253e-12, 1.1220e-12,\n",
      "         8.0212e-12, 2.0095e-13, 6.9547e-12, 8.1168e-13, 8.6335e-12, 1.5110e-12,\n",
      "         3.6593e-12, 1.4197e-11, 4.1859e-13, 1.5471e-16, 9.0901e-13, 6.9255e-12,\n",
      "         6.5026e-12, 1.2139e-12],\n",
      "        [8.9648e-05, 7.6189e-05, 2.8444e-04, 1.1206e-06, 1.9413e-12, 2.5635e-04,\n",
      "         7.2600e-05, 7.5546e-07, 7.4072e-05, 1.6357e-11, 9.0398e-12, 5.8797e-05,\n",
      "         1.0321e-11, 1.1205e-04, 1.0396e-05, 1.0813e-04, 1.3205e-04, 7.2841e-05,\n",
      "         8.5070e-05, 6.4953e-12, 1.5431e-04, 1.3836e-04, 5.8355e-12, 1.0157e-05,\n",
      "         6.9648e-05, 9.6378e-05, 1.3746e-04, 9.9022e-05, 8.7302e-12, 1.2257e-04,\n",
      "         3.8764e-12, 1.2240e-04],\n",
      "        [7.6732e-12, 9.9003e-13, 2.9491e-12, 1.0529e-11, 6.7026e-12, 1.2769e-11,\n",
      "         7.8370e-12, 1.2429e-11, 5.0403e-12, 6.9390e-12, 5.5962e-13, 1.1740e-11,\n",
      "         1.1666e-11, 8.5245e-12, 4.0959e-13, 3.1203e-12, 7.7420e-14, 1.2831e-11,\n",
      "         4.9716e-12, 4.9811e-12, 2.1505e-14, 1.2355e-11, 9.1788e-12, 2.4340e-12,\n",
      "         1.4718e-13, 4.4586e-12, 9.2039e-12, 1.1736e-11, 1.5818e-12, 1.1859e-16,\n",
      "         5.3742e-12, 1.0088e-11],\n",
      "        [6.2715e-03, 1.4660e-03, 9.3263e-04, 4.0800e-06, 1.2917e-11, 5.2355e-03,\n",
      "         2.6050e-03, 5.5832e-07, 6.6193e-04, 1.2525e-11, 1.6690e-12, 6.8139e-04,\n",
      "         5.3065e-12, 8.4073e-04, 2.1756e-05, 3.2505e-03, 1.8469e-03, 6.0060e-04,\n",
      "         2.6193e-03, 1.7913e-12, 1.0911e-03, 9.9124e-04, 6.0755e-12, 3.6323e-05,\n",
      "         2.2899e-03, 5.4938e-03, 2.0668e-03, 4.3903e-04, 1.4291e-11, 9.3726e-04,\n",
      "         3.9537e-12, 1.8586e-03],\n",
      "        [4.0535e-12, 1.6257e-11, 1.3325e-15, 4.6863e-12, 5.3166e-12, 4.0412e-13,\n",
      "         6.7005e-12, 6.2326e-12, 2.0072e-12, 9.8229e-12, 2.3401e-15, 6.0567e-12,\n",
      "         6.7966e-12, 3.4762e-13, 5.8269e-12, 1.4313e-13, 4.3213e-12, 6.6237e-12,\n",
      "         1.2845e-11, 5.2228e-14, 1.5036e-12, 8.3852e-13, 8.3558e-12, 4.5136e-12,\n",
      "         1.0842e-11, 1.3128e-11, 3.5436e-12, 1.0328e-11, 4.4685e-15, 1.7180e-11,\n",
      "         3.5198e-12, 3.6960e-12],\n",
      "        [6.7313e-12, 7.9558e-12, 5.2422e-12, 9.0518e-12, 1.0769e-13, 8.4533e-13,\n",
      "         6.7563e-12, 6.8059e-14, 2.2002e-12, 1.6059e-12, 1.5758e-11, 7.3782e-12,\n",
      "         2.9423e-12, 2.9041e-12, 6.6096e-12, 1.5625e-11, 1.6199e-13, 1.6373e-12,\n",
      "         1.5555e-13, 1.4779e-12, 2.9478e-12, 1.4761e-11, 1.5551e-12, 1.4537e-11,\n",
      "         1.0445e-13, 3.7311e-13, 4.3645e-13, 1.4948e-11, 6.7491e-12, 1.0414e-11,\n",
      "         6.6340e-12, 5.1074e-12],\n",
      "        [7.6992e-12, 2.4467e-12, 1.6087e-13, 1.3996e-11, 1.1694e-11, 8.1070e-12,\n",
      "         5.6753e-12, 7.2850e-12, 2.6239e-12, 3.8608e-12, 6.3499e-12, 1.6044e-12,\n",
      "         2.2819e-12, 3.0874e-12, 7.9152e-12, 8.2648e-13, 1.1419e-11, 7.2318e-12,\n",
      "         4.8607e-16, 4.7460e-12, 1.2270e-13, 5.5876e-15, 1.1400e-11, 2.7599e-12,\n",
      "         6.4702e-12, 1.6865e-13, 6.3662e-12, 4.4857e-12, 1.2761e-16, 2.1683e-12,\n",
      "         5.2173e-12, 1.4908e-13],\n",
      "        [2.4601e-12, 1.2520e-11, 4.1288e-13, 4.2147e-14, 4.0184e-12, 1.4377e-11,\n",
      "         6.5387e-13, 9.1270e-12, 4.5464e-12, 1.4834e-11, 1.6678e-11, 1.3877e-11,\n",
      "         1.1062e-11, 1.6654e-12, 1.6494e-12, 1.1272e-11, 2.2621e-12, 9.6075e-13,\n",
      "         7.3908e-12, 7.4843e-20, 2.2004e-13, 1.2078e-11, 9.0766e-12, 2.9852e-12,\n",
      "         1.5547e-14, 1.6307e-11, 1.3241e-11, 2.4647e-13, 7.0904e-12, 6.2055e-12,\n",
      "         2.8843e-12, 1.3612e-11],\n",
      "        [4.7133e-05, 4.0101e-05, 1.4892e-04, 5.8484e-07, 1.6886e-11, 1.3386e-04,\n",
      "         3.8162e-05, 3.9874e-07, 3.9477e-05, 4.8609e-12, 7.2975e-12, 3.1370e-05,\n",
      "         1.1400e-11, 5.8757e-05, 5.3998e-06, 5.6820e-05, 6.9617e-05, 3.8060e-05,\n",
      "         4.4521e-05, 7.0416e-12, 8.1082e-05, 7.3801e-05, 4.9523e-13, 5.3035e-06,\n",
      "         3.6599e-05, 5.0823e-05, 7.2114e-05, 5.1727e-05, 1.7444e-13, 6.3877e-05,\n",
      "         2.2851e-12, 6.4253e-05],\n",
      "        [2.4740e-03, 6.0807e-04, 3.1136e-04, 1.4509e-11, 3.7812e-18, 2.0779e-03,\n",
      "         7.3453e-04, 5.4790e-12, 5.5368e-05, 6.5223e-13, 3.7832e-13, 1.8127e-04,\n",
      "         4.2056e-13, 2.0006e-05, 1.1095e-11, 5.6775e-04, 7.4886e-04, 1.6388e-11,\n",
      "         1.5107e-03, 5.1132e-12, 3.0072e-06, 2.6519e-04, 9.7805e-12, 1.2141e-11,\n",
      "         7.6976e-04, 6.8569e-04, 8.2309e-06, 5.8341e-05, 1.3122e-11, 4.5179e-04,\n",
      "         1.7208e-13, 7.6978e-04],\n",
      "        [1.2089e-11, 9.2073e-13, 1.3589e-12, 1.9439e-12, 6.6639e-12, 2.6747e-12,\n",
      "         6.7226e-12, 2.1016e-12, 9.0584e-13, 1.5301e-12, 2.1201e-12, 2.3569e-13,\n",
      "         6.7798e-12, 8.1333e-17, 6.9240e-13, 1.2617e-11, 5.1847e-12, 6.1935e-13,\n",
      "         3.6316e-13, 1.6423e-11, 2.0407e-12, 5.4295e-13, 2.6000e-13, 9.2605e-12,\n",
      "         1.6357e-13, 3.9995e-13, 7.4548e-12, 5.4308e-12, 2.8532e-12, 1.2858e-11,\n",
      "         6.7242e-12, 2.3331e-14],\n",
      "        [2.8042e-04, 2.3742e-04, 8.8750e-04, 3.4868e-06, 9.0977e-12, 8.0905e-04,\n",
      "         2.2900e-04, 2.3082e-06, 2.3009e-04, 1.6589e-11, 3.5743e-12, 1.8239e-04,\n",
      "         5.1050e-12, 3.5290e-04, 3.4317e-05, 3.3810e-04, 4.1122e-04, 2.2999e-04,\n",
      "         2.6642e-04, 1.0535e-11, 4.8242e-04, 4.3074e-04, 1.1780e-11, 3.1502e-05,\n",
      "         2.2000e-04, 3.0106e-04, 4.2997e-04, 3.1145e-04, 1.1236e-11, 3.8504e-04,\n",
      "         1.7007e-12, 3.8281e-04],\n",
      "        [1.2971e-04, 1.1015e-04, 4.1189e-04, 1.6224e-06, 3.7710e-12, 3.7083e-04,\n",
      "         1.0499e-04, 1.0848e-06, 1.0732e-04, 4.3430e-12, 7.0644e-12, 8.5074e-05,\n",
      "         1.1806e-11, 1.6165e-04, 1.5044e-05, 1.5641e-04, 1.9083e-04, 1.0536e-04,\n",
      "         1.2304e-04, 2.6856e-14, 2.2319e-04, 2.0038e-04, 3.6286e-12, 1.4727e-05,\n",
      "         1.0074e-04, 1.3938e-04, 1.9856e-04, 1.4335e-04, 1.7912e-12, 1.7727e-04,\n",
      "         6.3531e-12, 1.7698e-04],\n",
      "        [1.2827e-03, 1.0859e-03, 4.0609e-03, 1.5931e-05, 7.0419e-13, 3.7040e-03,\n",
      "         1.0495e-03, 1.0517e-05, 1.0506e-03, 6.4449e-12, 9.1355e-12, 8.3281e-04,\n",
      "         1.6401e-11, 1.6140e-03, 1.5725e-04, 1.5483e-03, 1.8793e-03, 1.0549e-03,\n",
      "         1.2209e-03, 1.5096e-12, 2.2056e-03, 1.9673e-03, 6.7159e-12, 1.4380e-04,\n",
      "         1.0085e-03, 1.3753e-03, 1.9666e-03, 1.4263e-03, 5.3948e-12, 1.7605e-03,\n",
      "         1.6578e-11, 1.7532e-03],\n",
      "        [2.0917e-07, 1.9525e-07, 6.7225e-07, 2.8964e-09, 8.4711e-12, 5.2174e-07,\n",
      "         1.5808e-07, 2.8015e-09, 2.1002e-07, 1.2691e-13, 3.0353e-12, 1.7717e-07,\n",
      "         1.6822e-13, 2.5732e-07, 5.4014e-09, 2.6439e-07, 3.5267e-07, 1.4431e-07,\n",
      "         1.9136e-07, 5.5606e-12, 3.7727e-07, 3.9677e-07, 2.4948e-12, 2.4822e-08,\n",
      "         1.4972e-07, 2.4652e-07, 3.4770e-07, 2.1341e-07, 9.9480e-12, 2.7116e-07,\n",
      "         6.8594e-13, 2.9125e-07],\n",
      "        [5.8298e-05, 4.9352e-05, 1.8525e-04, 7.3074e-07, 3.6777e-12, 1.6792e-04,\n",
      "         4.7254e-05, 4.8098e-07, 4.7550e-05, 2.9430e-12, 5.9065e-14, 3.7592e-05,\n",
      "         1.2841e-11, 7.3080e-05, 6.9908e-06, 7.0150e-05, 8.5244e-05, 4.7676e-05,\n",
      "         5.5507e-05, 6.7463e-12, 1.0026e-04, 8.8716e-05, 2.4397e-12, 6.6450e-06,\n",
      "         4.5360e-05, 6.2341e-05, 8.9179e-05, 6.4747e-05, 9.5257e-12, 8.0149e-05,\n",
      "         6.6037e-12, 7.9510e-05]], device='cuda:0')}, 33: {'step': tensor(60., device='cuda:0'), 'exp_avg': tensor([-5.7932e-06, -1.5558e-06, -1.1983e-05, -8.0897e-02, -8.7248e-06,\n",
      "        -1.4480e-05, -7.8993e-06, -9.1391e-06,  1.5403e-05,  1.3484e-03,\n",
      "        -1.5051e-05,  6.4508e-06,  7.5271e-06,  6.7833e-06,  8.4779e-06,\n",
      "         4.2614e-06], device='cuda:0'), 'exp_avg_sq': tensor([2.1014e-12, 1.6706e-11, 8.6815e-12, 1.3983e-01, 4.6596e-12, 1.2605e-11,\n",
      "        3.8376e-12, 5.1022e-12, 2.4849e-11, 4.3686e-02, 1.3605e-11, 5.1560e-11,\n",
      "        2.6086e-11, 2.3107e-10, 4.5924e-12, 1.2242e-11], device='cuda:0')}, 34: {'step': tensor(60., device='cuda:0'), 'exp_avg': tensor([[-3.6086e-06, -8.8439e-02, -7.0762e-06, -8.4191e-02, -1.9624e-05,\n",
      "         -1.8890e-05,  2.0562e-05,  1.1267e-05, -1.1165e-01, -2.0551e-05,\n",
      "          8.0146e-06,  7.7543e-02,  7.0460e-02, -6.1077e-02, -5.2370e-02,\n",
      "         -3.3893e-02],\n",
      "        [-1.6668e-05, -1.0486e-07, -1.5390e-05, -1.3221e-05,  2.3593e-05,\n",
      "         -1.6728e-05, -2.1374e-05,  8.7046e-06, -2.2996e-05, -5.2932e-06,\n",
      "          1.5257e-05, -7.7108e-06,  1.7455e-05, -1.0161e-05,  3.6180e-06,\n",
      "         -2.3061e-05],\n",
      "        [ 9.3532e-11,  1.4555e-05,  4.3213e-06, -1.7656e-05,  1.4275e-05,\n",
      "         -2.3387e-05, -9.4042e-06,  3.8017e-06, -9.7298e-06,  8.2928e-06,\n",
      "          2.0878e-05, -1.6653e-05,  2.1425e-05, -1.9479e-05, -1.0713e-05,\n",
      "          1.8234e-05],\n",
      "        [-1.4057e-05,  2.1040e-05, -2.2374e-05, -2.3287e-05,  1.9904e-05,\n",
      "          2.0725e-05, -3.9759e-07,  1.0140e-05,  1.8447e-05, -7.9031e-06,\n",
      "          3.2454e-06, -2.2982e-06, -1.7569e-05, -9.9661e-06, -6.7549e-06,\n",
      "          2.3216e-05],\n",
      "        [ 3.1980e-06, -3.4941e-02,  2.0523e-05, -3.3292e-02, -2.7406e-06,\n",
      "          4.0329e-06,  1.9107e-05,  1.8290e-05, -4.4174e-02, -2.2251e-05,\n",
      "          1.8351e-05,  3.0705e-02,  2.7810e-02, -2.4177e-02, -2.0646e-02,\n",
      "         -1.3408e-02],\n",
      "        [ 1.3152e-05,  8.1855e-02,  1.5038e-05,  7.7966e-02, -1.2334e-05,\n",
      "          3.4629e-06,  8.5208e-06, -2.1864e-05,  1.0341e-01,  2.0491e-05,\n",
      "         -1.7859e-06, -7.1826e-02, -6.5245e-02,  5.6557e-02,  4.8490e-02,\n",
      "          3.1375e-02],\n",
      "        [ 9.8769e-06, -1.6941e-05,  1.8129e-05,  1.2772e-05,  1.6799e-06,\n",
      "          1.5081e-05, -1.5362e-05,  3.1577e-06, -3.7185e-13, -3.9788e-06,\n",
      "         -3.6616e-07,  1.9154e-06, -4.3919e-06,  6.2576e-06,  1.3132e-05,\n",
      "         -2.3204e-05],\n",
      "        [ 1.8856e-06, -1.4017e-05, -1.8456e-05, -9.1988e-06, -1.4357e-05,\n",
      "         -5.6521e-06,  1.1611e-05,  2.4156e-05,  1.1141e-06, -1.8191e-05,\n",
      "         -1.4244e-05,  1.6944e-05, -1.5445e-06, -4.3444e-06, -1.1554e-05,\n",
      "          1.1942e-07]], device='cuda:0'), 'exp_avg_sq': tensor([[8.4866e-13, 5.4155e-03, 3.0974e-12, 1.7480e-03, 2.2985e-11, 2.1315e-11,\n",
      "         2.5212e-11, 7.6916e-12, 4.0442e-03, 7.8612e-09, 3.9477e-12, 2.9353e-03,\n",
      "         3.5448e-03, 1.6226e-03, 4.2045e-03, 1.8078e-03],\n",
      "        [1.6643e-11, 4.6105e-15, 1.4217e-11, 1.0535e-11, 3.3109e-11, 1.6761e-11,\n",
      "         2.7223e-11, 4.6386e-12, 3.1469e-11, 1.7655e-12, 1.3975e-11, 3.6611e-12,\n",
      "         1.8232e-11, 6.2798e-12, 8.5287e-13, 3.1646e-11],\n",
      "        [1.5999e-16, 1.2734e-11, 1.1960e-12, 1.8648e-11, 1.2255e-11, 3.2539e-11,\n",
      "         5.3960e-12, 9.3692e-13, 5.7680e-12, 4.2196e-12, 2.5984e-11, 1.6613e-11,\n",
      "         2.7351e-11, 2.2649e-11, 6.9664e-12, 1.9876e-11],\n",
      "        [1.1890e-11, 2.6386e-11, 2.9803e-11, 3.2262e-11, 2.3638e-11, 2.5608e-11,\n",
      "         2.0277e-14, 6.2543e-12, 2.0338e-11, 3.8413e-12, 6.9450e-13, 3.6500e-13,\n",
      "         1.8467e-11, 6.0458e-12, 2.8299e-12, 3.2068e-11],\n",
      "        [6.7550e-13, 8.3111e-04, 2.5117e-11, 2.6854e-04, 5.0584e-13, 1.0483e-12,\n",
      "         2.1802e-11, 1.9995e-11, 6.1937e-04, 1.2318e-09, 2.0128e-11, 4.5232e-04,\n",
      "         5.4292e-04, 2.4886e-04, 6.4506e-04, 2.7867e-04],\n",
      "        [1.0428e-11, 4.6548e-03, 1.3582e-11, 1.5026e-03, 9.1893e-12, 7.8498e-13,\n",
      "         4.4491e-12, 2.8473e-11, 3.4770e-03, 6.7844e-09, 2.3052e-13, 2.5217e-03,\n",
      "         3.0473e-03, 1.3951e-03, 3.6130e-03, 1.5524e-03],\n",
      "        [5.9401e-12, 1.7186e-11, 1.9650e-11, 9.8427e-12, 2.0652e-13, 1.3659e-11,\n",
      "         1.4166e-11, 6.5957e-13, 1.6159e-16, 1.0217e-12, 1.8122e-14, 2.6161e-13,\n",
      "         1.2337e-12, 2.4398e-12, 1.0396e-11, 3.2036e-11],\n",
      "        [2.5429e-13, 1.1822e-11, 2.0356e-11, 5.1677e-12, 1.2395e-11, 2.0037e-12,\n",
      "         8.1605e-12, 3.4696e-11, 1.0065e-13, 1.9784e-11, 1.2203e-11, 1.7192e-11,\n",
      "         1.7777e-13, 1.2083e-12, 8.0817e-12, 5.1614e-15]], device='cuda:0')}, 35: {'step': tensor(60., device='cuda:0'), 'exp_avg': tensor([-1.4255e-05, -1.5091e-06, -7.0601e-06, -1.4498e-05,  1.7361e-05,\n",
      "         3.1056e-05, -2.3110e-05, -3.4105e-06], device='cuda:0'), 'exp_avg_sq': tensor([2.1768e-09, 1.7061e-13, 3.0837e-12, 1.2636e-11, 3.2973e-10, 1.9452e-09,\n",
      "        3.1778e-11, 7.6268e-13], device='cuda:0')}, 36: {'step': tensor(60., device='cuda:0'), 'exp_avg': tensor([[ 4.5079e-02,  3.4500e-05,  1.1900e-05,  5.4170e-06,  5.9045e-02,\n",
      "          7.3922e-02,  1.1807e-05, -1.7419e-05]], device='cuda:0'), 'exp_avg_sq': tensor([[2.4202e-03, 7.0417e-11, 8.5646e-12, 1.8460e-12, 5.2693e-03, 3.0466e-03,\n",
      "         8.4331e-12, 1.8156e-11]], device='cuda:0')}, 37: {'step': tensor(60., device='cuda:0'), 'exp_avg': tensor([7.4280e-05], device='cuda:0'), 'exp_avg_sq': tensor([4.6272e-08], device='cuda:0')}}, 'param_groups': [{'lr': 0.0001, 'betas': (0.9, 0.999), 'eps': 1e-08, 'weight_decay': 0.0001, 'amsgrad': False, 'maximize': False, 'foreach': None, 'capturable': False, 'differentiable': False, 'fused': None, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37]}]}\n",
      "batch_size 32\n",
      "dropout_ratio 0.5\n",
      "learning_rate 0.0001\n",
      "weight_decay 0.0001\n",
      "n_epochs 5\n",
      "random_seed 0\n",
      "val_c_index 0.688588007736944\n",
      "hidden [1024, 512, 512, 256, 256, 128, 128, 64, 64, 32]\n"
     ]
    }
   ],
   "source": [
    "model_chkpt = FusionNetwork()\n",
    "model_chkpt.to(device)\n",
    "optimizer = optim.Adam(model_chkpt.parameters())\n",
    "\n",
    "# load from last check point\n",
    "checkpoint_path = r\"..\\checkpoints\\trained-model_2025-03-01_0.688588.pth\"\n",
    "checkpoint = torch.load(checkpoint_path, map_location=device)\n",
    "model_chkpt.load_state_dict(checkpoint['model_state_dict'])\n",
    "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "val_c_index = checkpoint['val_c_index']\n",
    "\n",
    "for k, v in checkpoint.items():\n",
    "    print(k, v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clinical_rna_feedforward.feedforward.0.weight: torch.Size([512, 19975])\n",
      "clinical_rna_feedforward.feedforward.0.bias: torch.Size([512])\n",
      "clinical_rna_feedforward.feedforward.3.weight: torch.Size([256, 512])\n",
      "clinical_rna_feedforward.feedforward.3.bias: torch.Size([256])\n",
      "clinical_rna_feedforward.feedforward.6.weight: torch.Size([256, 256])\n",
      "clinical_rna_feedforward.feedforward.6.bias: torch.Size([256])\n",
      "clinical_rna_feedforward.feedforward.9.weight: torch.Size([64, 256])\n",
      "clinical_rna_feedforward.feedforward.9.bias: torch.Size([64])\n",
      "clinical_rna_feedforward.feedforward.12.weight: torch.Size([64, 64])\n",
      "clinical_rna_feedforward.feedforward.12.bias: torch.Size([64])\n",
      "clinical_rna_feedforward.feedforward.15.weight: torch.Size([32, 64])\n",
      "clinical_rna_feedforward.feedforward.15.bias: torch.Size([32])\n",
      "clinical_rna_feedforward.feedforward.18.weight: torch.Size([32, 32])\n",
      "clinical_rna_feedforward.feedforward.18.bias: torch.Size([32])\n",
      "wsi_fcn.conv.weight: torch.Size([64, 512, 1])\n",
      "wsi_fcn.conv.bias: torch.Size([64])\n",
      "attention.attention.0.weight: torch.Size([64, 64])\n",
      "attention.attention.0.bias: torch.Size([64])\n",
      "attention.attention.2.weight: torch.Size([1, 64])\n",
      "attention.attention.2.bias: torch.Size([1])\n",
      "baby_feed_forward.0.weight: torch.Size([64, 96])\n",
      "baby_feed_forward.0.bias: torch.Size([64])\n",
      "baby_feed_forward.2.weight: torch.Size([32, 64])\n",
      "baby_feed_forward.2.bias: torch.Size([32])\n",
      "baby_feed_forward.4.weight: torch.Size([16, 32])\n",
      "baby_feed_forward.4.bias: torch.Size([16])\n",
      "baby_feed_forward.6.weight: torch.Size([8, 16])\n",
      "baby_feed_forward.6.bias: torch.Size([8])\n",
      "baby_feed_forward.8.weight: torch.Size([1, 8])\n",
      "baby_feed_forward.8.bias: torch.Size([1])\n"
     ]
    }
   ],
   "source": [
    "for name, param in checkpoint['model_state_dict'].items():\n",
    "    print(f\"{name}: {param.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_9248\\3821337774.py:27: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(checkpoint_path, map_location=device)\n",
      "100%|██████████| 1/1 [02:10<00:00, 130.27s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test c-index: 0.7354965585054081\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'evaluation-results/test set-baseline.png'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 58\u001b[0m\n\u001b[0;32m     56\u001b[0m test_c_index \u001b[38;5;241m=\u001b[39m concordance_index(test_times, \u001b[38;5;241m-\u001b[39mnp\u001b[38;5;241m.\u001b[39marray(test_risks), test_events)\n\u001b[0;32m     57\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest c-index: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtest_c_index\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 58\u001b[0m \u001b[43mdisplay_km_curves_fusion\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_risks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_times\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_events\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtest set\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msave_figure\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\ASUS\\pprojects\\project_kirc\\notebooks\\utils.py:334\u001b[0m, in \u001b[0;36mdisplay_km_curves_fusion\u001b[1;34m(risks, times, events, title_name, save_figure)\u001b[0m\n\u001b[0;32m    332\u001b[0m plt\u001b[38;5;241m.\u001b[39mlegend()\n\u001b[0;32m    333\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m save_figure:\n\u001b[1;32m--> 334\u001b[0m     \u001b[43mplt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msavefig\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mevaluation-results/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mtitle_name\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m-baseline.png\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    335\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    336\u001b[0m     plt\u001b[38;5;241m.\u001b[39mshow()\n",
      "File \u001b[1;32mc:\\Users\\ASUS\\pprojects\\base\\Lib\\site-packages\\matplotlib\\pyplot.py:1243\u001b[0m, in \u001b[0;36msavefig\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1240\u001b[0m fig \u001b[38;5;241m=\u001b[39m gcf()\n\u001b[0;32m   1241\u001b[0m \u001b[38;5;66;03m# savefig default implementation has no return, so mypy is unhappy\u001b[39;00m\n\u001b[0;32m   1242\u001b[0m \u001b[38;5;66;03m# presumably this is here because subclasses can return?\u001b[39;00m\n\u001b[1;32m-> 1243\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msavefig\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[func-returns-value]\u001b[39;00m\n\u001b[0;32m   1244\u001b[0m fig\u001b[38;5;241m.\u001b[39mcanvas\u001b[38;5;241m.\u001b[39mdraw_idle()  \u001b[38;5;66;03m# Need this if 'transparent=True', to reset colors.\u001b[39;00m\n\u001b[0;32m   1245\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m res\n",
      "File \u001b[1;32mc:\\Users\\ASUS\\pprojects\\base\\Lib\\site-packages\\matplotlib\\figure.py:3490\u001b[0m, in \u001b[0;36mFigure.savefig\u001b[1;34m(self, fname, transparent, **kwargs)\u001b[0m\n\u001b[0;32m   3488\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m ax \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes:\n\u001b[0;32m   3489\u001b[0m         _recursively_make_axes_transparent(stack, ax)\n\u001b[1;32m-> 3490\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcanvas\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprint_figure\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\ASUS\\pprojects\\base\\Lib\\site-packages\\matplotlib\\backend_bases.py:2184\u001b[0m, in \u001b[0;36mFigureCanvasBase.print_figure\u001b[1;34m(self, filename, dpi, facecolor, edgecolor, orientation, format, bbox_inches, pad_inches, bbox_extra_artists, backend, **kwargs)\u001b[0m\n\u001b[0;32m   2180\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   2181\u001b[0m     \u001b[38;5;66;03m# _get_renderer may change the figure dpi (as vector formats\u001b[39;00m\n\u001b[0;32m   2182\u001b[0m     \u001b[38;5;66;03m# force the figure dpi to 72), so we need to set it again here.\u001b[39;00m\n\u001b[0;32m   2183\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m cbook\u001b[38;5;241m.\u001b[39m_setattr_cm(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfigure, dpi\u001b[38;5;241m=\u001b[39mdpi):\n\u001b[1;32m-> 2184\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[43mprint_method\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2185\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2186\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfacecolor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfacecolor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2187\u001b[0m \u001b[43m            \u001b[49m\u001b[43medgecolor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43medgecolor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2188\u001b[0m \u001b[43m            \u001b[49m\u001b[43morientation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morientation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2189\u001b[0m \u001b[43m            \u001b[49m\u001b[43mbbox_inches_restore\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_bbox_inches_restore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2190\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2191\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m   2192\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m bbox_inches \u001b[38;5;129;01mand\u001b[39;00m restore_bbox:\n",
      "File \u001b[1;32mc:\\Users\\ASUS\\pprojects\\base\\Lib\\site-packages\\matplotlib\\backend_bases.py:2040\u001b[0m, in \u001b[0;36mFigureCanvasBase._switch_canvas_and_return_print_method.<locals>.<lambda>\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   2036\u001b[0m     optional_kws \u001b[38;5;241m=\u001b[39m {  \u001b[38;5;66;03m# Passed by print_figure for other renderers.\u001b[39;00m\n\u001b[0;32m   2037\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdpi\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfacecolor\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124medgecolor\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124morientation\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   2038\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbbox_inches_restore\u001b[39m\u001b[38;5;124m\"\u001b[39m}\n\u001b[0;32m   2039\u001b[0m     skip \u001b[38;5;241m=\u001b[39m optional_kws \u001b[38;5;241m-\u001b[39m {\u001b[38;5;241m*\u001b[39minspect\u001b[38;5;241m.\u001b[39msignature(meth)\u001b[38;5;241m.\u001b[39mparameters}\n\u001b[1;32m-> 2040\u001b[0m     print_method \u001b[38;5;241m=\u001b[39m functools\u001b[38;5;241m.\u001b[39mwraps(meth)(\u001b[38;5;28;01mlambda\u001b[39;00m \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: \u001b[43mmeth\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2041\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m{\u001b[49m\u001b[43mk\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mskip\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m   2042\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:  \u001b[38;5;66;03m# Let third-parties do as they see fit.\u001b[39;00m\n\u001b[0;32m   2043\u001b[0m     print_method \u001b[38;5;241m=\u001b[39m meth\n",
      "File \u001b[1;32mc:\\Users\\ASUS\\pprojects\\base\\Lib\\site-packages\\matplotlib\\backends\\backend_agg.py:481\u001b[0m, in \u001b[0;36mFigureCanvasAgg.print_png\u001b[1;34m(self, filename_or_obj, metadata, pil_kwargs)\u001b[0m\n\u001b[0;32m    434\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mprint_png\u001b[39m(\u001b[38;5;28mself\u001b[39m, filename_or_obj, \u001b[38;5;241m*\u001b[39m, metadata\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, pil_kwargs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    435\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    436\u001b[0m \u001b[38;5;124;03m    Write the figure to a PNG file.\u001b[39;00m\n\u001b[0;32m    437\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    479\u001b[0m \u001b[38;5;124;03m        *metadata*, including the default 'Software' key.\u001b[39;00m\n\u001b[0;32m    480\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 481\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_print_pil\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename_or_obj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpng\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpil_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\ASUS\\pprojects\\base\\Lib\\site-packages\\matplotlib\\backends\\backend_agg.py:430\u001b[0m, in \u001b[0;36mFigureCanvasAgg._print_pil\u001b[1;34m(self, filename_or_obj, fmt, pil_kwargs, metadata)\u001b[0m\n\u001b[0;32m    425\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    426\u001b[0m \u001b[38;5;124;03mDraw the canvas, then save it using `.image.imsave` (to which\u001b[39;00m\n\u001b[0;32m    427\u001b[0m \u001b[38;5;124;03m*pil_kwargs* and *metadata* are forwarded).\u001b[39;00m\n\u001b[0;32m    428\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    429\u001b[0m FigureCanvasAgg\u001b[38;5;241m.\u001b[39mdraw(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m--> 430\u001b[0m \u001b[43mmpl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimsave\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    431\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfilename_or_obj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuffer_rgba\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfmt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morigin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mupper\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    432\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdpi\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfigure\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdpi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpil_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpil_kwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\ASUS\\pprojects\\base\\Lib\\site-packages\\matplotlib\\image.py:1634\u001b[0m, in \u001b[0;36mimsave\u001b[1;34m(fname, arr, vmin, vmax, cmap, format, origin, dpi, metadata, pil_kwargs)\u001b[0m\n\u001b[0;32m   1632\u001b[0m pil_kwargs\u001b[38;5;241m.\u001b[39msetdefault(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mformat\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mformat\u001b[39m)\n\u001b[0;32m   1633\u001b[0m pil_kwargs\u001b[38;5;241m.\u001b[39msetdefault(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdpi\u001b[39m\u001b[38;5;124m\"\u001b[39m, (dpi, dpi))\n\u001b[1;32m-> 1634\u001b[0m \u001b[43mimage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpil_kwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\ASUS\\pprojects\\base\\Lib\\site-packages\\PIL\\Image.py:2591\u001b[0m, in \u001b[0;36mImage.save\u001b[1;34m(self, fp, format, **params)\u001b[0m\n\u001b[0;32m   2589\u001b[0m         fp \u001b[38;5;241m=\u001b[39m builtins\u001b[38;5;241m.\u001b[39mopen(filename, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr+b\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   2590\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 2591\u001b[0m         fp \u001b[38;5;241m=\u001b[39m \u001b[43mbuiltins\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mw+b\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2592\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   2593\u001b[0m     fp \u001b[38;5;241m=\u001b[39m cast(IO[\u001b[38;5;28mbytes\u001b[39m], fp)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'evaluation-results/test set-baseline.png'"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA04AAAK9CAYAAAAT0TyCAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAYyBJREFUeJzt3QmYU9X5x/E3yywMMCwiq6Cyi2zKDipUURBB0aqUuiAq/lHEhWoFa1m0Cqi1WEVpbam1FQGtohWLC4K44AK4o1B0kEVWkW1mmEyS+3/eQzNmhpm5yZDkTpLv53kik+QmObk3ifd3zznvdVmWZQkAAAAAoELuiu8CAAAAACiCEwAAAADYIDgBAAAAgA2CEwAAAADYIDgBAAAAgA2CEwAAAADYIDgBAAAAgA2CEwAAAADYIDgBAAAAgA2CEwDHbdy4UVwulzz55JOSivR96fvT94noLVmyRLp27SrZ2dlmPe7duzeur/fRRx9J3759pWbNmub1PvnkE5k6dar5O56WL19uXkP/TdXva7K8RwAoD8EJQKmd+1WrVpW6fd++fdKzZ0+z06o7sKlI37derr322nLv/81vflOyzO7duxPevnT2ww8/yKWXXio1atSQ2bNnyz/+8Q8TaOKluLhYLrnkEtmzZ4/84Q9/MK93/PHHx+314KxXXnnFhOJ4KigoMK/hRFhcu3ateW0O2gCxQXACUKH9+/fLOeecI5999pm88MILMnjwYElVGgz/9a9/ic/nO+K+Z555xtxfVVdccYUUFhayA17F3p8DBw7IPffcI9dcc41cfvnlkpGREbfX++abb+S7776T2267Ta677jrzevXq1ZO77rrLbEOkXnCaNm1a3IOTvoZTwUlfm+AExAbBCUC5dGd10KBBZpiSBopzzz1XUpmGQg2K//nPf0rd/t5770leXp6cd955VX5uj8dTMswsFvLz88UplmUlNEDs3LnT/Fu3bt2YPWdl66+i1/N6vUcVngEAyY/gBOAIBw8eNEFizZo1JjSVDQ0vvviiua1p06aSlZUlrVq1Mj0CgUCg1HIDBgyQjh07yurVq82cER1udeKJJ8qcOXNs26C9XFdddZW0bNnS7LA2btxYrr76ajN0K1xo7smGDRvM8rrDW6dOHRk9erQ50hupZs2ayRlnnCHz5s0rdfvTTz8tnTp1Mu+jPB988IFZV/qaOTk50r9/f3n33XcjmuOkIe300083Q89q165t1umXX35Zahl9T7Vq1TI9IUOGDDHLXXbZZZW+l61bt5remdD20XV+/fXXl/SmVTRfp7x2nnDCCTJ06FB59dVXpXv37mYb/ulPfzLr42c/+9kRzxEMBs26vPjii0vdNmvWLDn55JPNtmzUqJH83//9n/z444+Vvg/9/IwaNcr83aNHD9M2XR8hzz77rHTr1s20qUGDBqZ3SN97VdefLqvbT+lwPX09bUNF60yv33jjjbJo0SKzPnRd63ssO6RVe7BuuOEGadeunWnrMcccY56/qr0AobasX7/evGf97B177LHy29/+1gTbzZs3ywUXXCC5ubnme/P73/++3IConxHdFrpNunTpIn//+9+PWE7nk+l60dfQ75Zuj4rmmH399ddmu9evX988p35eXnrpJamqjz/+2Byw0feh2/Css86S999/v9zPrH7nJkyYYNaDfp8uvPBC2bVrV6XPr+9Lh3+q0FDc8G0c6edWhzfrQSb9DIZ+4/S3Suk21jYp7fkJvUZlwwN1uKgu26ZNG/O6+nk57bTT5PXXX49qfeu60c+Z0u9q6LWZXwZUnfcoHgsgBenReN1Z0SFSzz33nNlpLkv/h6w7Mrqjov+++eabMnnyZNNj88ADD5RaVncydIdV56mMHDlSFi5caHbiMzMzS3YuyqM7Cd9++60JQLrzp4Hiz3/+s/lXd57K7sTq8+sOy/Tp003g+8tf/iINGzaUmTNnRvzef/nLX8rNN99sgqO+L7/fb3bO9X0eOnToiOX1feu60p33KVOmiNvtlr/97W9y5plnyttvv23mhlVE587oTqjucGkbNeQ9/vjjZgdJdxg1sIRoO3Q5ve/BBx80Aa0i33//vXld3bnVoWbt27c3YUK3pb6GrvdorVu3zmw73WkcM2aMCQAjRowwO3/bt2832yfknXfeMW34xS9+UXKbPk4/M7otb7rpJtOD9+ijj5r3qTu8FQ2907ll+lq63e+++26zfTWkq9DzaaDSbb5jxw55+OGHzfPp84b3GEW6/rSdGvruu+8+0059bt1Zroy+3+eff94EIw1lf/zjH+XnP/+5bNq0yezwKv0uac+lrpPjjjvO7EzrttZQpkOpKtueldFtcNJJJ8mMGTNk8eLF8rvf/c7sRGuw1c+gfq40+OuwQ30vemBAaY+hvrYebNDgp+tVP+caJPRzo98BpSFMA5i+x7Fjx5rX0iG7oTAbTr+X/fr1M+tv4sSJJrzod3348OHm4IsGmWjo8+lBBQ1Nv/71r81nRN+Xtvutt96SXr16lVp+/PjxZkilfg91/Wrg0fe2YMGCCl9Dt7d+VvW3Rr+P5d1v97nVAKrDmTUc6fvWz52+vn4mlN6u21p/83QdXHTRReb2zp07V9gu/V7pZ1rnXOp3WX9XNZzp79rZZ58d8frW7a3t1s/knXfeabafCv0LoAosALAs629/+5ulPwnHH3+8lZGRYS1atKjCZQsKCo647f/+7/+snJwc69ChQyW39e/f3zzn73//+5LbioqKrK5du1oNGza0fD6fuS0vL88sp22o7DWeeeYZs9yKFStKbpsyZYq57eqrry617IUXXmgdc8wxEb13ffy4ceOsPXv2WJmZmdY//vEPc/vixYstl8tlbdy4seR1du3aZe4LBoNWmzZtrEGDBpm/w9t94oknWmefffYR61bfpzpw4IBVt25da8yYMaXasX37dqtOnTqlbh81apR57MSJEyN6L1deeaXldrutjz766Ij7Qu0MvZeyyrZT6edBb1uyZEmpZdetW2duf+SRR0rdfsMNN1i1atUq2X5vv/22We7pp58utZw+X3m3V9Sm8Pejnxv9/HTs2NEqLCwsuf3ll182y06ePLnK62/ZsmVm+WeffbbU7eWtM72un5cNGzaU3Pbpp58esV7K+yyvXLnSLPfUU08d8dr6b2VCbbnuuutKbvP7/dZxxx1nPq8zZswouf3HH3+0atSoYdZDyKxZs8zj//nPf5Zap3369DHbbv/+/eY2/Q3Q5e6///5Sr3P66acf8X0966yzrE6dOpX6/uvnrW/fvuZ7Eu17HD58uFm333zzTclt33//vVW7dm3rjDPOOOLzMXDgwFLfw1tvvdXyeDzW3r17K30d/d6X912I9HP7wgsvHPH5LEt/M3QZ3W6R6NKli3XeeedVukyk61s/x5GsbwCRYagegFL0yL0O+2jevHmFy+hwlPC5UFppTo8Oa4+GDh8pOzdEj9yGaI+HXtcjtTqEL5LX0N4efY3evXub63rktSw9Ih5O26PD+vRobaT0iLUOu9NiEEqH7ekQw/KKOujcr//+97+ml0pfR9unF+2x0yFFK1asMEN9yqNHuPXIvvbihB6nF50LpUfSly1bdsRj9Ii1HX09HTY2bNgwM2ynrKrOsdIeCe2xCde2bVtTIjz8iL4O1dSeLX390PbTngwd5qVHysPfq/bSaa9eee/Vjh5918+P9vKEzzvSoY7aw6a9L1VZf1UxcODAkl6wUE+C9pJob2l5n2UdhqWfl9atW5veifI+y5EKrwKpnx3d5prndAheiL6G9tqFt0cLImgvoX7+QrT3RHsntLdVe3RCy+n3N3zd6eto7044rUCova/a6xv6PdCLvk/93Oj3pOwQysro5+i1114zvSc6VDekSZMm5vumPWBlv9fauxr++dbvvz6PDpOsikg/t6GezZdfftls21jQ59QeJV1v5Yn1+gYQOYITgFJ0OIyGGw0QOkSrPPo/dR0KojsWupOow1F0rkWofHk4nWdTtny07nSryuZ46M6BDhnSoVK646mvoTvw5b2GatGixREhSIXmI+jz6bCy0KW851C6Y6bBRodaaQjR6+UJ7dTosCVtW/hFhwkWFRVV+Bqhx+pwqrKP1R3GUIGCEN151SFednROh+5QVjQfq6pC6728oWI6ZCm0k6ZzJ7Ttenv4e9X1oMMmy75X3Ukv+14jEdoZ1kBQlgansjvLka6/qij7uQt99sLnwejQOB3KqgcjdB6UzoXR96/huaLPSFVeW7+PGiT1+cveHt4eXT86f0aHloYLDeEKrT/9V8OKBoVwZde7DvnTwKZzrMpuYx06p6LZzvo51oMw5W1fbaMeINB5XNF8/6MV6edW58Tp0Eydk6TrXYc26nBd/f5XlQ5L1c+G/k7q/Mrbb7/dzPmM1/oGEDnmOAEopUOHDuZIs/aa6NFW3TEO733S/6HrzoIGJv0fvB5t1501PXJ+xx13VNjLEi09mqrzQnSnQXs2dOdNn1sDXXmvoUfCy3N4RJWYuQWhI+mhwFPeCTzPP/98s3Or9+vOj7ajPKE26JwubV95yu5wln2szqsInx8UvqMfTttTdif3aFTU81S2uEd5PSbhNCBNmjTJHJ2/5ZZbzBwL3UkPL1uv71V3PnWuTXlCE+fjKdbrL5rPndIeGt2Z1nXUp08fs450G+icp6P5vpT32pG0J9ZC70HnUpXtmQzRHrZ4ivX7jvRzq9tRe1l13uW///1vU0RF525qQQ69raLfgMro3CQtZqJFePRAih6I0XOKaVEd7WWsDusbSFcEJwBH0AnJ2tuiQ580PGmhg9COgvYq6JAQnfwcmmyudOJ0eXTytQ5fC+910mpgKrwAQjg9Srx06VJzFFeP1IdUNHQlErojE370WXvCKgoJOkTon//8pyn8UPbofUhoeJYGSB2uFY3QY3XHLNrHVka3kbbniy++qHS50NF4DcHhRRSiHdakPVH6WdHhejoRXz8Tuu40qIS/1zfeeMNMZK8ogEUrNHRSe0S11y6c3lbdzpelO9YaxMOr2+nw04qq08Wbrh/twdAd8PBAGRpmG1p/+q9+D0PFUkLK9kSHhtPpcL9YfJ71c6wFM8rr8dY2apsrG0oci4MI0X5udRixXu69914zxFcrN86fP98EnaoMkdUiH1qUQi+6/vW3VotG6PNFs75jdQoEAIcxVA9AubTHSef66LCQ0DmOwo/shh/J1TLXjz32WLnPoxXNdPhf+LJ6XXeOdL5Aecp7DaWVsqpKX0t3MkIX7VmriB7J1SEvOhSmsufTnSut0qY7NmVVVgpZjxJrwNHqbeXNi7Aro1wR3aHU4KJHvnUeUFmh9RkKbjoPK0TDbXnlqO1or5MeWZ87d66ZZxE+TE9pj532ZGm5+vI+G1UJDzqXR0OnHoEPHxKl5d2/+uqrozrnVjzo57nsZ/mRRx6psIcv3rTKpQ5XDZ+fpttC26QBKVSSXZfT27UqXIi2WZcLp9tCq93p93rbtm1H/XnW9aWV6rTHJXw4r86/1FCi1RH1+xMLoQM6ZT+HkX5u9WBM2W0b6oEOfTZDVRMj/ayXPeWCbhPtQQo9XzTru6L3B6Bq6HECUCGdx/TEE0+YoSc6hE3PT6PFErTHQo+g62RyPaKpQ84qGhKjPTtaFll3gHTMvu6saWEFLTFdURlq3SnSI6z333+/CRZacleHrFTUqxVrek4bvdiFFB1Co71Sep4XPTKs7dT5PjpxXN+DBpjy6H26M3rFFVfIqaeeaoZsaZDUeVVa2ECPcmvZ46rQMKbrSnd+dcK8zgnRnSsdTqeT6rWHSXdKdU6IFhHQoZC6o6rBJ9SGaOgOpgZNvehR8rJHwLUdWgxEyyvrdtfX1u2uvYfaJi0hHn7Op0jo4/Uzpetcn1+LHITKkWsv5q233irViZb01++IDtHTwL5y5UrTmxEqV55o+rnQnW4tP64FWnSdaa+YDsvVgxNaVl1pkQ/9LGq5a/3+atu1V7G8eVl6PiQNNDonR0vWa6+IbhN9r1u2bJFPP/00qjZqaXWda6jPqUVAdPiqtlnDg/4uxEro4I3+lukBDf0u6Pcx0s+tHmzQg0b6W6kHJLRYg/5m6ndcg6fSHitdd/rbp7+B+j3ReYgVzUXUZTUYadt0WT0IottHe3WjXd8a4vQ96fdFt5v2BmsvrYYvAFUQYfU9ACmuvLLPIQ8++KC5b+jQoVZxcbH17rvvWr179zZljps2bWr9+te/tl599dUjyt5qOfKTTz7ZWrVqlSl1nJ2dbcpbP/roo6Wev7xy5Fu2bDElxbVst5bovuSSS0w54rJlfcuWCa+stLZdOfLKVPQ6H3/8sXXRRReZ0udZWVnm/V166aXW0qVLbdui60rLmev703XTqlUr66qrrjLrK0TLSNesWdOKxnfffWfKkh977LGmTS1btjTvT0vBh6xevdrq1auXKfncokUL66GHHqqwHLldaeR+/fqZx1177bUVLvPnP//Z6tatm/nMaElpLaWsnxvdplX9XC5YsMA65ZRTzHusX7++ddlll5nPTbho11+05cjL+9zoOgsv/60lwUePHm01aNDAlPvWbf71118fsVy05cjLfhYreq+h72G4HTt2lLRJPwO6PcK/fyE//PCDdcUVV1i5ubnmc6p/62e+7PdVaelw/dw1btzYnNKgWbNm5jfjueeei/o9qjVr1ph1petMT3Xws5/9zHrvvfci+nxE+jpaXn38+PHmu6Kl3MtuY7vPrbZx5MiR5jukn0Mtk6/vOfw7rLTd+jy6ru1Kk//ud7+zevbsaX779HXbt29v3XvvvSWnb4hmfasnnnjC/AZoeXZKkwNHx6X/qUrgAgA7etRUh2/ZzbkBAACo7pjjBAAAAAA2CE4AAAAAYIPgBAAAAAA2mOMEAAAAADbocQIAAAAAGwQnAAAAALCRdifADQaD8v3335sT/OmJOwEAAACkJ8uyzMmrmzZtak5uX5m0C04ampo3b+50MwAAAABUE5s3b5bjjjuu0mXSLjhpT1No5eTm5jrdHAAAAAAO2b9/v+lUCWWEyqRdcAoNz9PQRHACAAAA4IpgCg/FIQAAAADABsEJAAAAAGwQnAAAAADARtrNcQIAAACOpny13++XQCDgdFMQoYyMDPF4PHK0CE4AAABABHw+n2zbtk0KCgqcbgqiLPygpcZr1aolR4PgBAAAANgIBoOSl5dnei70ZKmZmZkRVWKD8z2Eu3btki1btkibNm2OqueJ4AQAAABE0Nuk4UnP+ZOTk+N0cxCFY489VjZu3CjFxcVHFZwoDgEAAABEyO1m9znZxKpnkC0PAAAAADYITgAAAABgg+AEAAAAIKGWL19uhtDt3bs3psvGE8EJAAAASGFXXXWVDB8+XKqTvn37mtLuderUkWRBVT0AAAAACVNcXGzKuTdu3FiSCT1OAAAAQBXPEVTg8zty0deOlbfeekt69uwpWVlZ0qRJE5k4caL4/X5z38svvyx169aVQCBgrn/yySdm2JwuE3LttdfK5ZdfXuHz6/KPP/64nH/++VKzZk259957jxh+991338mwYcOkXr16ZpmTTz5ZXnnllXKfT09AfO6550q/fv0SOnyPHicAAACgCgqLA9Jh8quOvPbauwdJTubR78pv3bpVhgwZYobzPfXUU/L111/LmDFjJDs7W6ZOnSqnn366HDhwQD7++GPp3r27CVkNGjQwwSdEb7vjjjsqfR19rhkzZsisWbPE6/XKt99+W+r+cePGmXNlrVixwgSntWvXSq1atY54Hg1K5513nrnv9ddfT+g5tQhOAAAAQJp67LHHzEl9H330UdMD1L59e/n+++9NEJo8ebKZg9S1a1cTlDQ46b+33nqrTJs2TQ4ePCj79u2TDRs2SP/+/St9nV/+8pcyevTokutlg9OmTZvk5z//uXTq1Mlcb9my5RHPsX37dhkxYoS0adNG5s2bZ4b7JRLBCQAAAKiCGhke0/Pj1GvHwldffSV9+vQpdZJYHQKnoWjLli3SokULE4qWL18uv/rVr+Ttt9+W6dOny8KFC+Wdd96RPXv2SNOmTU2YqYyGrsrcdNNNcv3118trr70mAwcONCGqc+fOpZY5++yzzZDCBQsWiMcTm/cfDeY4AQAAAFWgYUOHyzlxCQ868TZgwAATkj799FPJyMgwvVJ6m4YpHaZn19ukdPhdZXSelPZCXXHFFfL555+boPXII4+UWkaH6OlQPh3G5wSCEwAAAJCmTjrpJFm5cmWpYhPvvvuu1K5dW4477jhzPTTP6Q9/+ENJSAoFJ73o37GgQwbHjh0rzz//vOndeuKJJ0rdr3OkRo0aJWeddZYj4YmhegAAAECK07lIWhEv3DHHHCM33HCDKdgwfvx4ufHGG2XdunUyZcoUmTBhgrjdh/tYtNJd586d5emnnzZzodQZZ5whl156qSktHkmPk51bbrnFVMpr27at/Pjjj7Js2TIT6sp68MEHTYW/M88804Q27f1KFIITAAAAkOI0ZJxyyimlbrvmmmvkL3/5iyn7ffvtt0uXLl2kfv365va77rqr1LL9+/c3wSvUu6TLdejQQXbs2CHt2rU76vZpGNLKejqvKjc3VwYPHmx6uMqjt4eHJw1bieCyYlkEPko6RvGBBx6Q1atXmzMHv/DCC7ZnNdaVown4yy+/NN15ulG1fGKk9u/fb6qDaOrWjQIAAADYOXTokOTl5cmJJ55oSnUjNbZdNNnA0TlO+fn5JtnOnj07ouX1DeuksJ/97Gcm8WqXnk4ke/VVZ+rnAwAAAEgPjg7V03GMeonUnDlzTFL8/e9/b67ruEet8KHddYMGOVMK8mhYwaAUFhw4uifJyNGSLrFqEqIoAZrIajYAAABwVlLNcdKKH1rXPZwGJu15qkhRUZG5hHfHVRcamnIebHFUz/FRsK1c4puioy5j1i7Y69q8rrxwQ1/CEwAAQJpIqnLkerbgRo0albpNr2sYKiwsLPcxeoIuHbcYuui8qFTSw71eashPwRCJ8cnmvbJt7yGnmwEAAIAESaoep6qYNGmSKSYRoiGruoSnGjm1peC2TbL/xx/EXxTdTrjLXyjN5p9p/n7jqhMkkHu4zr7l8ohk1IhLeyFSWByQwQ+/bf7ef6hYcosyEt4Gr9sl2TE6WzgAAABSMDg1btzYlDwMp9e1AkaNGuWHhaysLHOpjlxut+TUqmMuUfPll/zZrPBrkeK8w1cya4q0HEB4ipMCn7/k78+37pX1O45yjloV5GR55bTWDQhPAAAACZRUwalPnz6mzny4119/3dye1twZIlm1RfxFhwNV8Kede8SP1+OWWlmJ7XEq8gekoMgv/qBjZxEAAABIS44Gp4MHD8qGDRtKlRvXMuN6Qq0WLVqYYXZbt26Vp556ytw/duxYc7biX//613L11VfLm2++KQsXLpTFixdLWsvIOlxdTwV8TrcmbWR7PFIjM/G9PsWBYMJfEwAAIN05Whxi1apV5gzGobMY61wk/Xvy5Mnmup4Ud9OmTSXLaylyDUnay6Tnf9Ky5Hq242QsRQ4AAAAgeTja4zRgwACxrIqHHD355JPlPubjjz+Oc8uSXHGhiNvLPCcAAABETPe99TQ/e/fujfgxV111lVl+0aJFR/36up/ftWtXmTVrVkyXTcty5LChFfV0jlPeCpFvlx8OUAAAAEhrGm6GDx9+xO3Lly8356QMBaURI0bI+vXrxSnPP/+83HPPPVJdJVVxCNjwZonkNhMpLqBIRIor9AXMv5QmBwAAsaJVqiuqVB1PPp9PMjMzTZ2D6owep1QMT3pBSvK4XZLv88vKb3bLm1/tkHc27JZDxYdDFAAASDCdcqIHq524VDLd5WiG6tWtW7fUbb/73e+kYcOGUrt2bbn22mtl4sSJZohcWQ8++KA0adJEjjnmGBk3bpwUFxdX+DpTp041z6G1CrSGQXZ2dsnwOx0qGPLYY49JmzZtzP2NGjWSiy++uMLn1DoIderUkaefflrihR4nIIlket3StE6OBIIWpckBAHCajvK5r6kzr33n94fP3xlHGkLuvfdeE2D69esn8+fPN8XZNOyEW7ZsmQlN+q9WzNYhfxqMxowZU+Fz63L/+te/zPA8j8dTbhG5m266Sf7xj39I3759Zc+ePfL222+X+1zz5s0z1bf136FDh0q8EJyAJAxPIZQmBwAAkXj55ZelVq1apW4LBCoftfLII4/INddcI6NHjzbXtfL1a6+9Zk4pFK5evXrmlEEagNq3by/nnXeeLF26tNLgpMPz9JRDxx57bLn3a2XtmjVrmiCkvV3HH398SSXucLNnz5bf/OY38u9//1v69+8v8URwAgAAAKpCz6OpPT9OvXYUfvazn8njjz9e6rYPPvhALr/88gofs27dOrnhhhtK3dazZ09zLtVwJ598cqleI+19+vzzzyttjwahikKTOvvss80yLVu2lMGDB5vLhRdeKDk5P73v5557Tnbu3Cnvvvuu9OjRQ+KN4JQK/EUixYcO/838JgAAgMRwueI+XC5WtPemdevWpW7bsmVLTJ47IyOj1HWt1BcMBm3bUxntZVqzZo2p/Ke9XNrbpXOjPvroo5J5WNoDpcvMnTtXunfvbl43nigOkQqeHyMy7+LDlyV3/DRZUMuRFx2o/ELJcgAAAJSjXbt2JqiE+6jM9Xjyer0ycOBAuf/+++Wzzz6TjRs3lurtatWqlZlX9eKLL8r48ePj3564vwLi1z17XA+RLWU+vDvXHi5DHjqfkx09StJyACfLrYIif9CRinZZXnfcj6gAAABoGNF5Stqb07dvX1mwYIEJMDp8LhFzsr799ls544wzzByqV155xfRiaZgL17ZtWxOetCKfBq14nhCX4JSsdMf58udFvvq3SJZO9HOLLPzfGFXP/87nZAXsh/hxvqcqu2XhJ468brtGtWXKsA6OvDYAAEgfl112mQkvt912mxw6dEguvfRSczLdDz/8MO6vrcPxtOKeDs/T19ay5M8884yZT1WWhintidLwpHOttPJfPLgsKw5F4Kux/fv3mxrv+/btk9zcXElqOtRu/asiWbUPBycdqqd++ZxIxuF6+LYlNPU52g7633PAjn5dLnr8Pfl40+EzbDvlb1f1MCMyDxYVS59WDaRGJifBDeGkwACAeNCd97y8vFLnHUpHZ599tjRu3NiUCU+FbRdNNqDHCYiCDpF76uqesuSLbVIrM0OyExhYdGjg2H+uLvdkuPhJTpZXTmvdQLIzCJMAAByNgoICmTNnjgwaNMj05GiPzxtvvCGvv/66pCOCE1CF8JTl9UhWhsfRnfPwk+HiME4KDABAbPd5dG6RngT30KFDZkicnrRWCzakI4ITkCInw8VhnBQYAIDYqFGjhulhwmHsdQEAAACADXqckPhzObm9lD8HAABJKc3qqqUEK0bbjOCUzlyeyM/3FEucOwoAACSZjIyMkoIJOoQNycPn85l/tcDF0SA4pTNvhOd7iiXOHQUAAJKQ7nTruYV27txprufk5HBC+iSgJ83dtWuX2V56gtyjQXBKdxqeEi1wOPUDAAAkEz1/kQqFJyQHt9stLVq0OOqgS3ACAAAAIqA73k2aNJGGDRtKcXGx081BhDIzM014OloEJwAAACDKYXtHO18GyYdy5KnIf0jLhzjdCgAAACBl0OOUihZeLtKwg8jgmdqn7HRrgIQr9CWw4AmApON1uyQ7g94CANEhOKVSkQcNSzvXHr6u/2oFu4xsp1sGJIzH7ZJ8n19WfrPb6aYAqMZysrxyWusGhCcAUSE4pQrtWdIepkP7Dvc4AWko0+uWpnVyJBBkqCqA8hX5A1JQ5Bc/vxMAokRwSrXw5E2SHqbiwvg9t9vLyXXTPDwBQGWKA0GnmwAgCRGckFguz+ET4OatiN9rZNYUaTmA8AQAAICYITgh8XOxcpuJWHGavK/zujSYBf3xeX4AAACkJYITnAlP8RTwSaor8h8eZpLldR/1WbABAABgj+AEJKGx/1xt/m3XqLZMGdaB8AQAABBnzKIGkoT2LmlQCrdux4GS3icAAADEDz1OQJLQXiXtXdKgpJdQrxMAAADij+AEJFl44oSNAAAAicdQPQAAAACwQXACAAAAABsM1UNqKi6Mz/O69SuTEZ/nBgAAQLVFcEpl/kORnVMplUpZuzyHT4CbtyI+z59ZU6TZafF5bgAAAFRbBKdUtvBy+2UadhAZPDN1wpMGwdxmIlYg9s/tLzocyoL+2D83AAAAqjWCU6rR4KBhaOfayJbX5TQQZGRLSq2DeAn44vfcAAAAqLYITqlGe460B0nDkN0wvkh6pAAAAAAQnFI2PKVSDxIAAADgMMqRAwAAAIANepwAAEDaKfTFoYgQkMa8bpdkZ3gklRGcAABA2vC4XZLv88vKb3Y73RQgpeRkeeW01g1SOjwRnAAAQNrI9LqlaZ0cCQQtp5sCpIwif0AKivziT/HvFcEJAACkXXgCEFvFgaCkOn45AAAAAMAGPU5AlFz+QvEU54vH7RW3yyPi8krQ61z59yJ/6h/hiUaW1y0uLckPAAAQQwQnIFIaknz54t74jjTavs9MftThHoGMHNnfuJ9j4WnsP1c78rrVVbtGtWXKsA6EJwAAEFMM1QMi5c0SyW0mklVL/N6a4s+oJUF3pniKC0Qsf8J7VTQg4EjrdhygFw4AAMQcPU5AtOHJ8krAWyRBr1csKRIJ+hLeDO1N0V4VAsJPdF3Q+wYAAOKF4AQR/6HEhw+GUcUkPKXyuRIAAACqE4ITRBZentjXa9hBZPBMwhMAAACSBnOc0pX2+miAccLOtSL+ImdeGwAAAKgCepzSlfb2aK9PIgOMDglMdO8WAAAAEAMEp3QPTxnOnX8IAAAASBYM1QMAAAAAGwQnAAAAALBBcAIAAAAAG8xxAmLA4y+UpObyStDLfDcAAICKEJyAo2C5POL250vu9vclmQUycmR/436EJwAAgAoQnICjYHkyxZfTVFxWQJKVK+ATT3GBiOV3uikAAADVFsEJiEF4siTJJzoGfU43AwAAoFqjOAQAAAAA2CA4AQAAAIANghMAAAAA2CA4AQAAAIANikPAGf5D8Xtub5aIyxW/5wcAAEDaITjBGQsvj99zN+wgMngm4SmNFfmDTjcBQDWW5XWLi/9HAIgSwQmJoz1BGmp2ro3v6+jz+4tEMjiZa7oa+8/VTjcBQDXWrlFtmTKsA+EJQFQITkgc/R+U9gRpqInX8L949mSh2h9B1p2hdTsOON0UANWc/k5oz3R2hsfppgBIIgQnJD480ROEONAjx3oEmWF6ACqivw/0SAOoKoITAMPjL4zPE7u8EvRmJyw8cQQZAADEA8EJSHOWyyNuf77kbn8/Ls8fyMiR/Y37JSw8AQAAxAPBCUhzlidTfDlNxWUFYv7croBPPMUFIpY/5s8NAACQSAQnACY8WfE6w3bQF4dnBgAASCyzXwMAAAAAqBjBCQAAAABsEJwAAAAAwAbBCQAAAABsEJwAAAAAwAbBCQAAAABsEJwAAAAAwAbBCQAAAABscAJcpCb/ofg8rzcrPs8LAACAao3ghNS08PL4PG/DDiJn3Ref505h7oBPghlOtwIAAKDqGKqH1KG9QRps4mnnWpFAUXxfI4VYLo+4/flSa/fH4o5XLyAAAEAC0OOE1OFyiQyeKeKPQ7DRnf549WKlMMuTKf6s+uIpLhCx/E43BwAAoMoITki98JSR7XQrEMZyZ9BLBwAAkh5D9QAAAADABsEJAAAAAGwwVC8VhM/pcXkomQ0AAADEGMEpmbm9Ipk1RXz5IgHf4dv079xmhCcAAAAghghOySyjhkjLASLB/1UrKy4UyVshYgWcbhkAAACQUghOqRCeAAAAAMQVxSEAAAAAwAbBCQAAAABsEJwAAAAAwAbBCQAAAABsUBwCQEJ4/IVVf7DLK0FvdiybAwAAEBWCExAt/yFxB4rEHfCLy+UWy50l4nI53apqy3J5xO3Pl9zt71f5OQIZObK/cT/CEwAA1VihL/JT4njdLsnO8EgycTw4zZ49Wx544AHZvn27dOnSRR555BHp2bNnhcvPmjVLHn/8cdm0aZM0aNBALr74Ypk+fbpkZ7NDhcSo8fwo6RN2Pb9uW9nYfQrhqQKWJ1N8OU3FVcXzi7kCPvEUF4hY/ztfGQAAqFY8bpfk+/yy8pvdET8mJ8srp7VukFThydHgtGDBApkwYYLMmTNHevXqZULRoEGDZN26ddKwYcMjlp83b55MnDhR5s6dK3379pX169fLVVddJS6XSx566CFH3gPShDdLpGEHkZ1rj7ir5t714goWieUhvFcWnqyjmYgZ9MW2QQAAIGYyvW5pWidHAsHI/m9f5A9IQZFf/BEuX104Gpw07IwZM0ZGjx5trmuAWrx4sQlGGpDKeu+996Rfv37yy1/+0lw/4YQTZOTIkfLBBx8kvO3Vmr9IxOU5vLOP2NDepMEzzbot9Afkk017pabHL53fHed0ywAAAKpFeIpGcSAoycaxqno+n09Wr14tAwcO/Kkxbre5vnLlynIfo71M+pgPP/zQXP/222/llVdekSFDhlT4OkVFRbJ///5Sl5Tl9opk1hQJ+ET2bz0coBDb8JSRLeLNlqAny1wAAACQHhzrcdq9e7cEAgFp1KhRqdv1+tdff13uY7SnSR932mmniWVZ4vf7ZezYsXLnnXdW+Do6/2natGmSFjJqiLQcIFJ0QCRvhUgV55Qg+iMlPn9QglZijpy4Nb95OJMAAABAIiXV3tfy5cvlvvvuk8cee0zWrFkjzz//vBnad88991T4mEmTJsm+fftKLps3b5aUD096QVwnQGZnesQfsEpVkSn0+RNy+SG/KCm7twEAAJKZYz1OWhHP4/HIjh07St2u1xs3blzuY37729/KFVdcIddee6253qlTJ8nPz5frrrtOfvOb35ihfmVlZWWZCxArmR63dGpWRwK+TJH/Vdju2qKuGcIXb0X+oHy5dZ8k2VxKAACApOdYcMrMzJRu3brJ0qVLZfjw4ea2YDBort94443lPqagoOCIcKThS+nQPSCR4Um8P5XPrKF/J1E5TQAAACRRVT0tRT5q1Cjp3r27OXeTliPXHqRQlb0rr7xSmjVrZuYpqWHDhplKfKeccoopX75hwwbTC6W3hwIUAAAAAKRUcBoxYoTs2rVLJk+ebE6A27VrV1myZElJwQg9yW14D9Ndd91lztmk/27dulWOPfZYE5ruvfdeB98FAAAAgFTnaHBSOiyvoqF5WgwinNfrlSlTppgLAAAAACRKUlXVAwAAAAAnEJwAAAAAoLoP1QOASHj8hU43ARVxeSWYgHL8AAA4ieAEoFqzXB5x+/Mld/v/TpqFaieQkSP7G/cjPAEAUhrBCUC1ZnkyxZfTVFxWwOmmoByugE88xQUilt/ppgBRn1AcQOxked2m+nUqIzgBseA/lKDXCYg7UCTugF9crthNUbTcWSLV+MdOwxOnuK6ezKcw6HO6GUDUxv5ztdNNAFJKu0a1ZcqwDikdnghOQCwsvDwhL1NDRPrE4Xnz67aVjd2nVOvwBACxOCKuO3frdhxwuilAylm344Dpyc3O8EiqIjgBVeXNEmnYQWTnWkl2NfeuF1ewSCwPc1QApC49Eq5HxBmmB8ROkT+YNj24BCegqrR3ZvBMEX9Rwl6y0B+QTzbtlRqZHsn0Hv1QPR321/6t62PSNgBIlvCUykfEAcQPwSmVRbJD7/Ic7jlB1cNTRiJ7aQIS9GRJ0OMVy3P0wYljrgAAAJEhOKUit1cks6aIL18kYDNpW5fJbUZ4AgAAACpBcEpFGTVEWg4QCdqUBy4uFMlbIUKZZwAAAKBSBKdUDk8AAAAAYiJ2J4IBAAAAgBRFjxOQhIoDh4dXurU2RQyKRAAAAKBy7HEBScTjdkl2pkf8AUsKfX75Ib9IigPUxgMAAIg3epyAJJLpcUunZnUkELTMCee+3LpPgpbTrQIAAEh9BCcgCcOTcO5GAACAhGKoHgAAAADYIDgBAAAAgA2G6gEAjprHX1jxnS6vBL3ZiWwOAAAxR3ACAFSZ5fKI258vudvfr3CZQEaO7G/cj/AEAEhqBCcAQJVZnkzx5TQVl3X43GJluQI+8RQXiFj+hLcNAIBYIjgBMNyBIonHGaEsd5aIyxWHZ0Z1Ck9WZRNpg77ENggAgDggOAEw2r91fVyeN79uW9nYfQrhCQAAJDWq6gFpTHuDNNjEU82968UVLIrrawAAAMQbPU5AOnO5TG9QPIKNDv2LVy8WAABAohGcIOJPcG+AyyPizUrsa6JiLpdYnthXO4vHfCkAAACnEJzSmdsrkllTxJcvEkjg5G19vdxmhCcAAAAkDYJTOsuoIdJygEgwgWWCiwtF8laIVFC6GAAAAKiOCE7pTsMTAAAAgEpRVQ8AAAAAbBCcAAAAAMAGwQkAAAAAbBCcAAAAAMAGwQkAAAAAbBCcAAAAAMAG5ciBJFccqJ7nxHIHgiV/+/xBCVrBxLyuSyTDwzEhAAAQWwQnIEl53C7JzvTIIV9A/IEEnsQ4Qu6wQFfoC0jQk5g2HvIH5JiaWYQnAAAQUwQnIElletzSqVkdCQQtqZb8h0TeP/xn1xZ1RbzZcX/JIn9Qvty6T6rrKgEAAMmL4AQkeXgSj1RTPzWshtej4+ccbQ2c5fEXSlpweSWYgIMEAIDEIzgBSAC6gNKV5fKI258vudv/1/2Y4gIZObK/cT/CEwCkIIITgPhbcofI0IdFXC6nW4IEszyZ4stpKi6rehYxiSVXwCee4gIRq/rNOQQAHD2CE4D48GaJ1G8psufbwxd/kUgGR+HTNTylQ5+jKUcS9DndDABAnFB2CkB8aO/S4JlOtwIAACAmCE4A4oiheQAAIDUwVA/O0GFb8eLyHB4mBgAAAMQIwQmJ5faKZNYU8eWLBOI0F0CfO7cZ4QkAAAAxQ3BCYmXUEGk5QCQYp6pTxYUieStE0qCCFwAAABKH4ARnwhMAAACQRCgOAQAAAAA2CE4AAAAAYIPgBAAAAAA2CE4AAAAAYIPgBAAAAAA2CE4AAAAAYIPgBAAAAAA2CE4AAAAAYIPgBAAAAAA2vHYLAEBM+A9V/bHeLBGXK5atAQAAiArBCUBiLLy86o9t2EFk8EzCEwAAcAxD9QDEj/YUaeg5WjvXiviLYtEiAACAKqHHCUD8aA+R9hRVNfTo8L6j6akCAACIEYITgPiHp4zshL5kcSCQ0NcDlNsfFK8/KId8AQlYfAarM4/bJZleBt0AiA7BCUBK7QxlZ3rMjqs/4He6OUgzHr9fvP6AHCzySyBY7HRzUIl8n1+a1skhPAGICsEJQMrI9LilU7M6EghaTjcF6ag4S6TIK+1bHyuSVdvp1qAChb6ArPxmN78TAKJGcEJqilchAZfncMEDVOvwJB6nW4H05BEJukWyvIcvAICUwi87UovbK5JZU8SXLxLwxf759XlzmxGeAAAA0gzBCaklo4ZIywEiwTjMbykuFMlbIcKkbwAAgLRDcEJqhicAcIoeZIm2p5zfLQCo9ghOAADEag6kDufVnulo6PBi7SknPAFAtUZwAgAgFnTuo86BjGY4rxay0bAVj+HFAICYIjgBABArVSkcE49CNgCAmOPMbwAAAABgg+AEAAAAADYITgAAAABgg+AEAAAAADYITgAAAABgg6p6AJKD/5DTLUBlleRcLqdbAQBAXBGcACSHhZc73QJUpGEHkcEzCU8AgJTGUD0A1bsnQ3fKUb3tXHv4RK4AAKQwepwAVF/ag6E9GeyUV9/hk/QEAgDSBMEJQPUPTxnZTrcCAACkOYbqAQAAAIANghMAAAAA2CA4AQAAAIAN5jgB0SpbqMDlOVz9DQAAACmL4AREyu0Vyawp4ssXCfh+ul2v5zYjPAEAAKQwghMQqYwaIi0HiAT9P91WXCiSt0LECjjZMgAAAMQZwQmINjwBAAAg7VAcAgAAAABsEJwAAAAAwAbBCQAAAABsEJwAAAAAwAbBCQAAAABiHZymTJki3333XbQPAwAAAID0CU4vvviitGrVSs466yyZN2+eFBUVxadlAAAAAJCswemTTz6Rjz76SE4++WS5+eabpXHjxnL99deb2wAAAAAgFVVpjtMpp5wif/zjH+X777+Xv/71r7Jlyxbp16+fdO7cWR5++GHZt29f7FsKAAAAAMlYHMKyLCkuLhafz2f+rlevnjz66KPSvHlzWbBgQexaCQAAAADJFpxWr14tN954ozRp0kRuvfVW0wP11VdfyVtvvSX//e9/5d5775Wbbrop9q0FAAAAgGQITp06dZLevXtLXl6eGaa3efNmmTFjhrRu3bpkmZEjR8quXbsier7Zs2fLCSecINnZ2dKrVy/58MMPK11+7969Mm7cOBPasrKypG3btvLKK69E+zYAAAAAIGJeidKll14qV199tTRr1qzCZRo0aCDBYND2uXQ434QJE2TOnDkmNM2aNUsGDRok69atk4YNGx6xvA4JPPvss819zz33nGmDlkavW7dutG8DABBL/kMV3+fNEnG5EtkaAACcD06huUxlFRYWygMPPCCTJ0+O+LkeeughGTNmjIwePdpc1wC1ePFimTt3rkycOPGI5fX2PXv2yHvvvScZGRnmNu2tAgA4bOHlFd/XsIPI4JmEJwBAeg3VmzZtmhw8ePCI2wsKCsx9kdLeI50rNXDgwJ8a43ab6ytXriz3MS+99JL06dPHDNVr1KiRdOzYUe677z4JBAIVvo6eZ2r//v2lLkDM+YtEiguS96LtB6KlPUkaiuzsXMtnDACQnj1OrnKOGn766adSv379iJ9n9+7dJvBoAAqn17/++utyH/Ptt9/Km2++KZdddpmZ17Rhwwa54YYbTGW/KVOmlPuY6dOnRxXogKi4vSKZNUV8+SIBnyQtbX9us8M7wkCk9P8F2pNUUSjS4XuV9UQBAJCKwUmH52lg0osWZAgPTxqAtBdq7NixEk86b0rnN/35z38Wj8cj3bp1k61bt5ohghUFp0mTJpl5VCHa46Tl0oGYyKgh0nKASNAvSau4UCRvhYhVcc8tUCH9f0FGttOtAACg+gQnLdygvU1aGEJ7cOrUqVNyX2ZmpplrpMPoIqUFJDT87Nixo9Tter1x48blPkYr6encJn1cyEknnSTbt283Q/+0HWVp5T29AHENTwAAAEhpEQenUaNGmX9PPPFE6du3b0lxhqrSkKM9RkuXLpXhw4eX9CjpdT1HVHn69esn8+bNM8vpfCi1fv16E6jKC00AACRNzy8So8gvnuJ88bi94nb9dCAWEXJ5JeillxnpKaLgpMPbcnNzzd96slutoKeX8oSWi4QOodNA1r17d+nZs6fp1crPzy+psnfllVeakuM6T0ldf/318uijj8rNN98s48ePNyfb1eIQnGwXAJCUdMdd5xjqcFkkhKc4KI2275PsDI9keqOukZX2Ahk5sr9xP8IT0pI30vlN27ZtM/OL9JxJ5RWHCBWNqKzCXVkjRowwJ8rVEuY63K5r166yZMmSkoIRmzZtKulZUjo36dVXX5Vbb71VOnfubEKVhqg77rgj4tcEAKDa0IIsWpiFOYaJ4w6I3+sXf4ZXPASnqLgCPvFoJVYrief1AvEOTlrJLlQxb9myZRJLOiyvoqF5y5cvP+I2nUf1/vvvx7QNAAA4hmqWCRaQgLdIgl4dckZwioZZW8EkriALJCI49e/fv9y/AQAAACAdRBScPvvss4ifUIfQAQAAAEDaBSede6Tzl3QeU2WineMEAAAAACkTnPLy8uLfEgAAAABI5uB0/PHHx78lAAAAAJDMwemll16Sc88915z0Vv+uzPnnnx+rtgEAAABA8gSn4cOHm/Ms6Xmc9O+KMMcJAAAAQNoGp2AwWO7fAAAAAJAOOPMbAAAAAMQjOC1dulSGDh0qrVq1Mhf9+4033qjKUwEAAABA6gWnxx57TAYPHiy1a9eWm2++2Vxyc3NlyJAhMnv27Pi0EgAAAACq+xyncPfdd5/84Q9/kBtvvLHktptuukn69etn7hs3blys2wgAAAAAydXjtHfvXtPjVNY555wj+/bti1W7AAAAACB5g5Oep+mFF1444vYXX3zRzHUCkKT8RSLFBbG/6PMCAACkw1C9P/7xjyV/d+jQQe69915Zvny59OnTx9z2/vvvy7vvviu/+tWv4tdSAPHh9opk1hTx5YsEfLF/fn3e3GYi3qzYPzcAAEB1Ck46pylcvXr1ZO3ateYSUrduXZk7d67cddddsW8lgPjJqCHScoBI0B/75y4uFMlbIWJxYmwAAJAGwSkvLy/+LQHgbHgC4sl/SNKC9qy6XE63AgBQHarqAQAQtYWXS1po2EFk8EzCEwCkoCoFpy1btshLL70kmzZtEp+v9JyIhx56KFZtAwAke++LBomdPw3rTnn6XrUgSka20y0BADgdnJYuXWoq67Vs2VK+/vpr6dixo2zcuFEsy5JTTz011u0DACQr7XXR3pd0qKyoQxHTpVcNANJU1MFp0qRJctttt8m0adOkdu3a8q9//UsaNmwol112WbnndwIApHl4ovcFAJCO53H66quv5MorrzR/e71eKSwslFq1asndd98tM2fOjEcbAQAAACC5glPNmjVL5jU1adJEvvnmm5L7du/eHdvWAQAAAEAyDtXr3bu3vPPOO3LSSSfJkCFDzElvP//8c3n++efNfQAAAAAg6R6ctGrewYMHzd86z0n/XrBggbRp04aKegAAAABSUtTBSavphQ/bmzNnTqzbBAAAAACpcQLcVatWmUIRqkOHDtKtW7dYtgsAAAAAkjc46clvR44cKe+++67UrVvX3LZ3717p27evzJ8/X4477rh4tBMAAAAAkqeq3rXXXivFxcWmt2nPnj3mon8Hg0FzHwAAAABIuvc4vfXWW/Lee+9Ju3btSm7Tvx955BE5/fTTY90+AAAAAEi+HqfmzZubHqeyAoGANG3aNFbtAgAAAIDkDU4PPPCAjB8/3hSHCNG/b775ZnnwwQdj3T4AAAAASI6hevXq1ROXy1VyPT8/X3r16iVe7+GH+/1+8/fVV18tw4cPj19rAQAAAKC6BqdZs2bFvyUAUlegWCTD6UYAAADEOTiNGjXqKF4CQNpye0Uya4oc3CnizRbxZjndIgAAgMSdAFcLQSxatKjkBLgnn3yynH/++eLxeKrWCgCpKaOGyHE9Rb5dJmIFnG4NAABA4oLThg0bZMiQIbJ169aSkuTTp0831fYWL14srVq1qnprAKQeb6bTLQAAAEh8Vb2bbrrJhKPNmzfLmjVrzGXTpk1y4oknmvsAAAAAINVU6QS477//vtSvX7/ktmOOOUZmzJgh/fr1i3X7AAAAACD5epyysrLkwIEDR9x+8OBBycxkSA4AAACA1BN1cBo6dKhcd9118sEHH4hlWeaiPVBjx441BSIAAAAAQNI9OP3xj380c5z69Okj2dnZ5qJD9Fq3bi0PP/xwfFoJAAAAAMkyx0l7l/bv3y/z5883VfVC5chPOukkE5wAAAAAIBVFHZw0IH355ZfSpk0bwhIAAACAtBDVUD23220C0w8//BC/FgEAAABAss9x0rLjt99+u3zxxRfxaREAAAAAJPt5nK688kopKCiQLl26mPLjNWrUKHX/nj17Ytk+AACAmCsOBJxuQtJx+4Pi9QflkC8gAYv1h8OKitPnsxB1cJo1a1Z8WgIAABBnHrdLsjM9ZuffH/A73Zyk4vH7xesPyMEivwSCxU43B9VEkf+n4FTsD0p2hkdSVdTBadSoUfFpCQAAQJxletzSqVkdCQQtp5uSfIqzRIq80r71sSJZtZ1uDaqJAt9PByBS/XsVdXBSgUBAXnjhhZJy5B06dJALLrhAvN4qPR0AAEBCw5Ok7kHxOPKIBN0iWd7DF0BE3C5JG1F/6rUU+fnnny/bt2+Xdu3amdtmzpwpxx57rPz73/+Wjh07xqOdAAAAAJA8VfWuvfZaOfnkk2XLli2yZs0ac9m8ebN07txZrrvuuvi0EgAAAACSqcfpk08+kVWrVkm9evVKbtO/7733XunRo0es2wcgVfiLqv5Yl0fEmxXL1gAAAMQ3OLVt21Z27Nhhep3C7dy5U1q3bh3t0wFIdW6vSGZNEV++SMBXtefQx+Y2IzwBAIDkCU7Tp0+Xm266SaZOnSq9e/c2t73//vty9913m7lO+/fvL1k2Nzc3tq0FkHwyaoi0HCASrGLZ3+JCkbwVIpwzBAAAJFNwGjp0qPn30ksvFZfrcBkNyzpcenDYsGEl1/U+rb4HACY8AQAApFNwWrZsWXxaAgAAAACpEpz69+8fn5YAAAAAQKqUIwcAAACAdENwAgAAAAAbBCcAAAAAsEFwAgAAAAAbBCcAAAAAiEVVvVNOOaXknE121qxZE9FyAAAAAJBSwWn48OHxbwkAAAAAJHNwmjJlSvxbAgAAAADVFHOcAAAAACAWPU7hAoGA/OEPf5CFCxfKpk2bxOfzlbp/z5490T4lAAAAAKRWj9O0adPkoYcekhEjRsi+fftkwoQJctFFF4nb7ZapU6fGp5UAACQL/yGR4iguluV0iwEA8ehxevrpp+WJJ56Q8847zwSlkSNHSqtWraRz587y/vvvy0033RTtUwIAkDoWXh7d8g07iAyeKRJh9VoAQJL0OG3fvl06depk/q5Vq5bpdVJDhw6VxYsXx76FAABUd96swwGoKnauFfEXxbpFAACne5yOO+442bZtm7Ro0cL0NL322mty6qmnykcffSRZWVmxbh8AANWf9hZpr1E0AUiH9EXbOwUASJ7gdOGFF8rSpUulV69eMn78eLn88svlr3/9qykUceutt8anlQDAEfnqy+U53OOS7jQ8ZWQ73QoAQHUJTjNmzCj5WwtEHH/88fLee+9JmzZtZNiwYbFuH4B05/aKZNYU8eWLBEpX8UQ1odsmtxnhCQCQ0qIOTocOHZLs7J+OqPXu3dtcACAuMmqItBwgEvQ73RKUp7hQJG+FiBVwuiUAAFSv4NSwYUMzXE+H6J111lmmDDkAxD08AQAAOCjq1PP3v/9dCgoK5IILLpBmzZrJLbfcIqtWrYpP6wAAAAAgGYOT9jY9++yzsmPHDrnvvvtk7dq1Zqhe27Zt5e67745PKwEAAADAQVUeZ1e7dm0ZPXq0KUf+2WefSc2aNWXatGmxbR0AAAAAJHNw0iIRCxculOHDh5vzOO3Zs0duv/322LYOAAAAAJKxOMSrr74q8+bNk0WLFonX65WLL77Y9DqdccYZ8WkhAAAAACTjCXCHDh0qTz31lAwZMkQyMjLi0zIAAAAASNbgpEUhdH4TAAAAAKSLiILT/v37JTc31/xtWZa5XpHQcgAAAACQVsGpXr16sm3bNnPy27p164rL5TpiGQ1UensgwNnjAQAAAKRhcHrzzTelfv36JX+XF5wAAAAAIK2DU//+/Uv+HjBgQDzbAwAAAADJfx6nNm3ayNSpU+W///1vfFoEAAAAAMkenG644QZZvHixtG/fXnr06CEPP/ywbN++PT6tAwAAAIBkDE633nqrfPTRR/LVV1+Z8zjNnj1bmjdvLuecc445txMAAAAASLoHp5C2bdvKtGnTZP369fL222/Lrl27ZPTo0bFtHQAAAAAk4wlww3344Ycyb948WbBggTm30yWXXBK7lgEAAABAsgYn7WF6+umn5ZlnnpG8vDw588wzZebMmXLRRRdJrVq14tNKAAAAAEim4BQqCjFu3Dj5xS9+IY0aNYpPywAAAAAgGYNTIBCQP/3pT3LxxRdLvXr14tcqAAAAAEjW4hAej0fGjx8ve/fujV+LAAAAACDZq+p17NhRvv322/i0BgAAAABSITj97ne/k9tuu01efvll2bZtm6mmF34BAAAAAEn34hB60lt1/vnni8vlKrndsixzXedBAQAAAEBaB6dly5bFpyUAgOTlL6r4PpdHxJuVyNYAAOB8cOrfv3/sWwEASE5ur0hmTRFfvkjAV/4yel9uM8ITACC9gtOKFSsqvf+MM86IuhGzZ8+WBx54QLZv3y5dunSRRx55RHr27Gn7uPnz58vIkSPlggsukEWLFkX9ugCAo5RRQ6TlAJGgv/z7iwtF8laIWAzjBgCkWXAaMGDAEbeFz3WKdo7TggULZMKECTJnzhzp1auXzJo1SwYNGiTr1q2Thg0bVvi4jRs3miIVp59+epTvAAAQ8/AEAECKi7qq3o8//ljqsnPnTlmyZIn06NFDXnvttagb8NBDD8mYMWNk9OjR0qFDBxOgcnJyZO7cuRU+RsPZZZddJtOmTZOWLVtG/ZoAAAAAENcepzp16hxx29lnny2ZmZmm52j16tURP5fP5zPLT5o0qeQ2t9stAwcOlJUrV1b4uLvvvtv0Rl1zzTXy9ttvV/oaRUVF5hJCyXQAAAAAce9xqkijRo3M8Lpo7N692/Qe6WPLPpfOdyrPO++8I3/961/liSeeiOg1pk+fbsJe6NK8efOo2ggAAAAAUfc4ffbZZ6Wu6/mb9ES4M2bMkK5du0o8HThwQK644goTmho0aBDRY7Q3S3vCwnucCE8AAAAA4hqcNBxpMQgNTOF69+5d6byk8mj48Xg8smPHjlK36/XGjRsfsfw333xjikIMGzas5LZgMGj+9Xq9pserVatWpR6TlZVlLgAAAACQsOCUl5dX6rrOSTr22GMlOzs76hfXeVHdunWTpUuXyvDhw0uCkF6/8cYbj1i+ffv28vnnn5e67a677jI9UQ8//DA9SQAAAACqR3A6/vjjY9oAHUY3atQo6d69uzl3k5Yjz8/PN1X21JVXXinNmjUzc5U0nHXs2LHU4+vWrWv+LXs7AAAAgMQp8gflULH9qYmKigNHjF5LqeCkVe5++OEHGTp0aMltTz31lEyZMsUEHe0x0hPXRjssbsSIEbJr1y6ZPHmyKQihQwG1vHmoYMSmTZtMrxYAAACA6uuWhZ9EvGzLBjXlzJNKF4hLmeCkJcD15Leh4KRD5rQc+FVXXSUnnXSSPPDAA9K0aVOZOnVq1I3QYXnlDc1Ty5cvr/SxTz75ZNSvBwAAAODo1cjwyCkt6srHm/ZG9bhvd+dLYXFAamdnSMoFp08++UTuueeekuvz58+XXr16lZQF1/lF2vtUleAEAAAAIPm4XC556uqesuSLbVIrM0OyMz22w/nG/jPy874mZXD68ccfS51v6a233pJzzz235HqPHj1k8+bNsW8hAAAAgGodnrK8HsnK8Eh2RuXBKZlFPHlIQ1Ooop7P55M1a9aYEuQhWtkuIyN5utoAAAAAIObBaciQITJx4kR5++23zUllc3Jy5PTTTy91Ytyy51ACAAAAgFQQ8VA9nd900UUXSf/+/aVWrVry97//3ZyHKURPfnvOOefEq50AAAAAUP2DU4MGDWTFihWyb98+E5w8ntLjF5999llzOwAAAABIup8At06dOuXeXr9+/Vi0BwAAAACqHc4sCwAAAAA2CE4AAAAAYIPgBAAAAAA2CE4AAAAAYIPgBAAAAAA2CE4AAAAAYIPgBAAAAAA2CE4AAAAAEOsT4AIAEDV/kaQFl0fEm+V0KwAAcUBwAgDEj9srkllTxJcvEvBJytP3mduM8AQAKYjgBACIn4waIi0HiAT9kvKKC0XyVohYAadbAgCIA4ITACD+4QkAgCRHcQgAAAAAsEFwAgAAAAAbDNUDAMBp/kNOtwCI7HOqFTIty+mWAI4gOAEA4LSFlzvdAiByrQeKZOc63Qog4RiqBwCAE7RkecMOTrcCABAhepwAAHCCyyUyeGb6nBwYyc9fIFJ0kEqZSFsEJwAAnAxPGdlOtwKIUFAkUHz4cwukIYbqAQAAAIANghMAAAAA2CA4AQAAAIANghMAAAAA2CA4AQAAAIANghMAAAAA2CA4AQAAAIANghMAAAAA2CA4AQAAAIANghMAAAAA2CA4AQAAAIANghMAAAAA2CA4AQAAAIANghMAAAAA2CA4AQAAAIANghMAAAAA2CA4AQAAAIANghMAAAAA2CA4AQAAAIANghMAAAAA2CA4AQAAAIANghMAAAAA2CA4AQAAAIANghMAAAAA2CA4AQAAAIANghMAAAAA2CA4AQAAAIANghMAAAAA2CA4AQAAAIANghMAAAAA2CA4AQAAAIANghMAAAAA2CA4AQAAAIANghMAAAAA2CA4AQAAAIANghMAAAAA2CA4AQAAAIANghMAAAAA2CA4AQAAAIANghMAAAAA2CA4AQAAAIANghMAAAAA2CA4AQAAAIANghMAAAAA2CA4AQAAAIANghMAAAAA2CA4AQAAAIANghMAAAAA2CA4AQAAAIANghMAAAAA2CA4AQAAAIANghMAAAAA2CA4AQAAAIANghMAAAAA2CA4AQAAAIANghMAAAAA2CA4AQAAAIANghMAAAAA2PDaLQAAAKLgL4pueZdHxJsVr9YAAGKE4AQAQCy4vSKZNUV8+SIBX+SP0+VzmxGeAKCaIzgBABALGTVEWg4QCfojf0xxoUjeChErEM+WAQBigOAEAEAswxMAICVRHAIAAAAAbBCcAAAAAMAGwQkAAAAAbBCcAAAAAMAGwQkAAAAAbBCcAAAAAMAGwQkAAAAAbBCcAAAAAMAGwQkAAAAAbBCcAAAAAMAGwQkAAAAAbBCcAAAAAMAGwQkAAAAAkiE4zZ49W0444QTJzs6WXr16yYcffljhsk888YScfvrpUq9ePXMZOHBgpcsDAAAAQNIHpwULFsiECRNkypQpsmbNGunSpYsMGjRIdu7cWe7yy5cvl5EjR8qyZctk5cqV0rx5cznnnHNk69atCW87AAAAgPTgeHB66KGHZMyYMTJ69Gjp0KGDzJkzR3JycmTu3LnlLv/000/LDTfcIF27dpX27dvLX/7yFwkGg7J06dKEtx0AAABAenA0OPl8Plm9erUZblfSILfbXNfepEgUFBRIcXGx1K9fv9z7i4qKZP/+/aUuAAAAAJA0wWn37t0SCASkUaNGpW7X69u3b4/oOe644w5p2rRpqfAVbvr06VKnTp2Siw7tAwAAAICkGqp3NGbMmCHz58+XF154wRSWKM+kSZNk3759JZfNmzcnvJ0AAAAAkpvXyRdv0KCBeDwe2bFjR6nb9Xrjxo0rfeyDDz5ogtMbb7whnTt3rnC5rKwscwEAAACApOxxyszMlG7dupUq7BAq9NCnT58KH3f//ffLPffcI0uWLJHu3bsnqLUAAAAA0pWjPU5KS5GPGjXKBKCePXvKrFmzJD8/31TZU1deeaU0a9bMzFVSM2fOlMmTJ8u8efPMuZ9Cc6Fq1aplLgAAAAAQa44HpxEjRsiuXbtMGNIQpGXGtScpVDBi06ZNptJeyOOPP26q8V188cWlnkfPAzV16tSEtx8AAABA6nM8OKkbb7zRXCo64W24jRs3JqhVAAAAAJACVfUAAAAAIBEITgAAAABgg+AEAAAAADYITgAAAABgg+AEAAAAADYITgAAAABgg+AEAAAAADYITgAAAABgg+AEAAAAADYITgAAAABgg+AEAAAAADYITgAAAABgg+AEAAAAADYITgAAAABgg+AEAAAAADYITgAAAABgg+AEAAAAADYITgAAAABgg+AEAAAAADYITgAAAABgg+AEAAAAADYITgAAAABgg+AEAAAAADYITgAAAABgg+AEAAAAADYITgAAAABgg+AEAAAAADYITgAAAABgg+AEAAAAADYITgAAAABgg+AEAAAAADYITgAAAABgg+AEAAAAADYITgAAAABgg+AEAAAAADYITgAAAABgg+AEAAAAADYITgAAAABgw2u3AAAAiDN/kdMtAOzxOUWaIzgBAOAUt1cks6aIL18k4HO6NYA9/bzq5xZIQ3zyAQBwSkYNkZYDRIJ+p1sCREZDk35ugTREcAIAwEnshAJAUqA4BAAAAADYIDgBAAAAgA2CEwAAAADYIDgBAAAAgA2CEwAAAADYIDgBAAAAgA2CEwAAAADYIDgBAAAAgA2CEwAAAADYIDgBAAAAgA2CEwAAAADYIDgBAAAAgA2CEwAAAADYIDgBAAAAgA2CEwAAAADYIDgBAAAAgA2CEwAAAADYIDgBAAAAgA2CEwAAAADYIDgBAAAAgA2CEwAAAADYIDgBAAAAgA2CEwAAAADYIDgBAAAAgA2CEwAAAADYIDgBAAAAgA2CEwAAAADYIDgBAAAAgA2CEwAAAADYIDgBAAAAgA2CEwAAAADYIDgBAAAAgA2CEwAAAADYIDgBAAAAgA2CEwAAAADYIDgBAAAAgA2CEwAAAADYIDgBAAAAgA2CEwAAAADYIDgBAAAAgA2CEwAAAADYIDgBAAAAgA2CEwAAAADYIDgBAAAAgA2CEwAAAADYIDgBAAAAgA2CEwAAAADYIDgBAAAAgA2CEwAAAADYIDgBAAAAgA2CEwAAAADYIDgBAAAAgA2CEwAAAADY8NotAAAAAAB2ivwB+2WK7ZeprghOAAAAAKrM63ZJTpZXCor8UhwIRhyuioorX7a6ITgBAAAAqLLsDI+c1rqB+IOW7bIFPn/J38EIlq9OCE4AAAAAjjo8RcLtkqRFcQgAAAAAsEFwAgAAAIBkCE6zZ8+WE044QbKzs6VXr17y4YcfVrr8s88+K+3btzfLd+rUSV555ZWEtRUAAABA+nE8OC1YsEAmTJggU6ZMkTVr1kiXLl1k0KBBsnPnznKXf++992TkyJFyzTXXyMcffyzDhw83ly+++CLhbQcAAACQHlyWZTlazkJ7mHr06CGPPvqouR4MBqV58+Yyfvx4mThx4hHLjxgxQvLz8+Xll18uua13797StWtXmTNnju3r7d+/X+rUqSP79u2T3NzcGL8bAAAAAJVV1esw+VXz91u3DZDjG9QUJ0WTDRztcfL5fLJ69WoZOHDgTw1yu831lStXlvsYvT18eaU9VBUtX1RUZFZI+AUAAAAAouFocNq9e7cEAgFp1KhRqdv1+vbt28t9jN4ezfLTp083KTJ00d4sAAAAAM7K9Do+aygqydXaKpg0aZLpegtdNm/e7HSTAAAAgLRUI8Mja+8eJKvvGiiN62RLMnH0BLgNGjQQj8cjO3bsKHW7Xm/cuHG5j9Hbo1k+KyvLXAAAAAA4y+VySU6m11ySjaM9TpmZmdKtWzdZunRpyW1aHEKv9+nTp9zH6O3hy6vXX3+9wuUBAAAA4Gg5HvW0FPmoUaOke/fu0rNnT5k1a5apmjd69Ghz/5VXXinNmjUzc5XUzTffLP3795ff//73ct5558n8+fNl1apV8uc//9nhdwIAAAAgVTkenLS8+K5du2Ty5MmmwIOWFV+yZElJAYhNmzaZSnshffv2lXnz5sldd90ld955p7Rp00YWLVokHTt2dPBdAAAAAEhljp/HKdE4jxMAAACApDqPEwAAAAAkA4ITAAAAANggOAEAAACADYITAAAAANggOAEAAACADYITAAAAANggOAEAAACADYITAAAAANggOAEAAACADYITAAAAANggOAEAAACADYITAAAAANggOAEAAACADYITAAAAANggOAEAAACADYITAAAAANggOAEAAACADYITAAAAANggOAEAAACADYITAAAAANjwSpqxLMv8u3//fqebAgAAAMBBoUwQygiVSbvgdODAAfNv8+bNnW4KAAAAgGqSEerUqVPpMi4rkniVQoLBoHz//fdSu3Ztcblc1SLlaojbvHmz5ObmOt2ctMQ2cB7boHpgOziPbVA9sB2cxzaoHtJhO1iWZUJT06ZNxe2ufBZT2vU46Qo57rjjpLrRD2OqfiCTBdvAeWyD6oHt4Dy2QfXAdnAe26B6SPXtUMempymE4hAAAAAAYIPgBAAAAAA2CE4Oy8rKkilTpph/4Qy2gfPYBtUD28F5bIPqge3gPLZB9cB2SPPiEAAAAAAQLXqcAAAAAMAGwQkAAAAAbBCcAAAAAMAGwQkAAAAAbBCcHDR79mw54YQTJDs7W3r16iUffvih001KGVOnThWXy1Xq0r59+5L7Dx06JOPGjZNjjjlGatWqJT//+c9lx44dpZ5j06ZNct5550lOTo40bNhQbr/9dvH7/Q68m+SwYsUKGTZsmDnztq7vRYsWlbpf69BMnjxZmjRpIjVq1JCBAwfKf//731LL7NmzRy677DJzkr26devKNddcIwcPHiy1zGeffSann366+d7o2czvv//+hLy/VNkOV1111RHfjcGDB5dahu1wdKZPny49evSQ2rVrm9+O4cOHy7p160otE6vfoOXLl8upp55qKl61bt1annzyyYS8x1TYBgMGDDjiuzB27NhSy7ANjs7jjz8unTt3Ljl5ap8+feQ///lPyf18D5zfBnwPoqRV9ZB48+fPtzIzM625c+daX375pTVmzBirbt261o4dO5xuWkqYMmWKdfLJJ1vbtm0ruezatavk/rFjx1rNmze3li5daq1atcrq3bu31bdv35L7/X6/1bFjR2vgwIHWxx9/bL3yyitWgwYNrEmTJjn0jqo/XUe/+c1vrOeff14rdVovvPBCqftnzJhh1alTx1q0aJH16aefWueff7514oknWoWFhSXLDB482OrSpYv1/vvvW2+//bbVunVra+TIkSX379u3z2rUqJF12WWXWV988YX1zDPPWDVq1LD+9Kc/JfS9JvN2GDVqlFnP4d+NPXv2lFqG7XB0Bg0aZP3tb38z6+aTTz6xhgwZYrVo0cI6ePBgTH+Dvv32WysnJ8eaMGGCtXbtWuuRRx6xPB6PtWTJEivdRbIN+vfvb/7fG/5d0M92CNvg6L300kvW4sWLrfXr11vr1q2z7rzzTisjI8NsF8X3wPltwPcgOgQnh/Ts2dMaN25cyfVAIGA1bdrUmj59uqPtSqXgpDt+5dm7d6/50Xj22WdLbvvqq6/MTubKlSvNdf1hcLvd1vbt20uWefzxx63c3FyrqKgoAe8guZXdYQ8Gg1bjxo2tBx54oNR2yMrKMjvdSn9s9XEfffRRyTL/+c9/LJfLZW3dutVcf+yxx6x69eqV2gZ33HGH1a5duwS9s+RSUXC64IILKnwM2yH2du7cadbpW2+9FdPfoF//+tfmAFG4ESNGmNCAyrdBaIfx5ptvrvAxbIP40N+Ov/zlL3wPqsE2UHwPosNQPQf4fD5ZvXq1GaoU4na7zfWVK1c62rZUosPAdLhSy5YtzbAj7WpWuu6Li4tLrX8dxteiRYuS9a//durUSRo1alSyzKBBg2T//v3y5ZdfOvBuklteXp5s37691DqvU6eOGaIavs51WFj37t1LltHl9bvxwQcflCxzxhlnSGZmZqntokNwfvzxx4S+p2SmQyp0uEW7du3k+uuvlx9++KHkPrZD7O3bt8/8W79+/Zj+Buky4c8RWob/j9hvg5Cnn35aGjRoIB07dpRJkyZJQUFByX1sg9gKBAIyf/58yc/PN8PF+B44vw1C+B5EzhvFsoiR3bt3mw9v+IdQ6fWvv/7asXalEt0h1/G1umO4bds2mTZtmpmP8cUXX5gdeN3h053Dsutf71P6b3nbJ3QfohNaZ+Wt0/B1rjvz4bxer9nRCV/mxBNPPOI5QvfVq1cvru8jFeh8posuusisx2+++UbuvPNOOffcc83/4DweD9shxoLBoNxyyy3Sr18/s1OiYvUbVNEyukNTWFho5hKi/G2gfvnLX8rxxx9vDrDpnL077rjDhP/nn3/e3M82iI3PP//c7KTrfCadx/TCCy9Ihw4d5JNPPuF74PA2UHwPokNwQkrSHcEQnRSpQUp/GBYuXJhSX2AgWr/4xS9K/tajiPr9aNWqlemFOuussxxtWyrSie96wOadd95xuilpq6JtcN1115X6LmjhGv0O6AEF/U4gNvQApoYk7fV77rnnZNSoUfLWW2853ay0UtE20PDE9yA6DNVzgHaH6pHdspVj9Hrjxo0da1cq0yNabdu2lQ0bNph1rMMl9+7dW+H613/L2z6h+xCd0Dqr7DOv/+7cubPU/Vq1Ryu8sV3iR4ey6m+SfjcU2yF2brzxRnn55Zdl2bJlctxxx5XcHqvfoIqW0cpZHCCqfBuURw+wqfDvAtvg6GmvklZZ69atm6l22KVLF3n44Yf5HlSDbVAevgeVIzg59AHWD+/SpUtLDSXQ6+FjThE7WkpZj57okRRd9xkZGaXWv3ZL6xyo0PrXf7VrO3wH8vXXXzc/AqHubUROh3XpD2v4OtcufJ0zE77O9X+gOu495M033zTfjdAPuS6j5bZ1XHz4dtGjaQwPq5otW7aYOU763VBsh6OndTl0h12Hw+i6KzusMVa/QbpM+HOEluH/I/bboDx6RF6FfxfYBrGnvyVFRUV8D6rBNigP3wMbURaTQAzLkWtFsSeffNJUsbruuutMOfLwqiWoul/96lfW8uXLrby8POvdd981ZTS1fKZWVgqVQNXStG+++aYpgdqnTx9zKVt+85xzzjGlbLWk5rHHHks58kocOHDAlCrVi/60PPTQQ+bv7777rqQcuX7GX3zxReuzzz4zld3KK0d+yimnWB988IH1zjvvWG3atClVBlurMGkZ7CuuuMKUUtXvkZZApQx2ZNtB77vttttMxSr9brzxxhvWqaeeatbzoUOHSp6D7XB0rr/+elN6X3+Dwkv8FhQUlCwTi9+gUAng22+/3VQjmz17dsqWAI71NtiwYYN19913m3Wv3wX9XWrZsqV1xhlnlDwH2+DoTZw40VQy1HWsv/t6XSt0vvbaa+Z+vgfObgO+B9EjODlI69zrD4aez0nLk+s5UxAbWgazSZMmZt02a9bMXNcfiBDdWb/hhhtMSU79sl944YXmf6rhNm7caJ177rnm/DQaujSMFRcXO/BuksOyZcvMjnrZi5a/DpUk/+1vf2t2uPWgwVlnnWXOKRHuhx9+MDvotWrVMqVOR48ebXb2w+k5oE477TTzHLptNZAhsu2gO436Pz/9n56WAT7++OPN+TvKHrBhOxyd8ta/XvS8QrH+DdLt3bVrV/Nbpzs84a+Rzuy2waZNm8zOYf369c1nWM9Vpjt94eevUWyDo3P11Veb3xldN/q7o7/7odCk+B44uw34HkTPpf+x65UCAAAAgHTGHCcAAAAAsEFwAgAAAAAbBCcAAAAAsEFwAgAAAAAbBCcAAAAAsEFwAgAAAAAbBCcAAAAAsEFwAgAAAAAbBCcAQMq66qqrZPjw4U43AwCQArxONwAAgKpwuVyV3j9lyhR5+OGHxbKshLUJAJC6CE4AgKS0bdu2kr8XLFggkydPlnXr1pXcVqtWLXMBACAWGKoHAEhKjRs3LrnUqVPH9ECF36ahqexQvQEDBsj48ePllltukXr16kmjRo3kiSeekPz8fBk9erTUrl1bWrduLf/5z39KvdYXX3wh5557rnlOfcwVV1whu3fvduBdAwCcQnACAKSVv//979KgQQP58MMPTYi6/vrr5ZJLLpG+ffvKmjVr5JxzzjHBqKCgwCy/d+9eOfPMM+WUU06RVatWyZIlS2THjh1y6aWXOv1WAAAJRHACAKSVLl26yF133SVt2rSRSZMmSXZ2tglSY8aMMbfpkL8ffvhBPvvsM7P8o48+akLTfffdJ+3btzd/z507V5YtWybr1693+u0AABKEOU4AgLTSuXPnkr89Ho8cc8wx0qlTp5LbdCie2rlzp/n3008/NSGpvPlS33zzjbRt2zYh7QYAOIvgBABIKxkZGaWu69yo8NtC1fqCwaD59+DBgzJs2DCZOXPmEc/VpEmTuLcXAFA9EJwAAKjEqaeeKv/617/khBNOEK+X/20CQLpijhMAAJUYN26c7NmzR0aOHCkfffSRGZ736quvmip8gUDA6eYBABKE4AQAQCWaNm0q7777rglJWnFP50NpOfO6deuK283/RgEgXbgsTqkOAAAAAJXiUBkAAAAA2CA4AQAAAIANghMAAAAA2CA4AQAAAIANghMAAAAA2CA4AQAAAIANghMAAAAA2CA4AQAAAIANghMAAAAA2CA4AQAAAIANghMAAAAASOX+H/ujo/E6GhU1AAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 1000x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import random\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import csv\n",
    "\n",
    "from lifelines.utils import concordance_index\n",
    "from utils import display_km_curves_fusion\n",
    "\n",
    "# from models import *\n",
    "# from train import test_loader\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "############################# FINAL ###########################################\n",
    "\n",
    "checkpoint_path = r\"..\\\\checkpoints\\trained-model_2025-03-02_0.720503.pth\" # TODO: to choose\n",
    "\n",
    "model_chkpt = FusionNetwork()\n",
    "model_chkpt.to(device)\n",
    "optimizer = optim.Adam(model_chkpt.parameters())\n",
    "\n",
    "# load from last check point\n",
    "checkpoint = torch.load(checkpoint_path, map_location=device)\n",
    "model_chkpt.load_state_dict(checkpoint['model_state_dict'])\n",
    "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "val_c_index = checkpoint['val_c_index']\n",
    "\n",
    "model_chkpt.eval()\n",
    "\n",
    "test_risks = []\n",
    "test_times = []\n",
    "test_events = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(test_loader):\n",
    "        # unpack the batch\n",
    "        batch_clinical_rna_features, batch_lists_phenotype_clusters, batch_times, batch_events = batch\n",
    "        \n",
    "        # move times and events to the device\n",
    "        batch_times = batch_times.to(device)\n",
    "        batch_events = batch_events.to(device)\n",
    "        \n",
    "        # tterate over each sample in the batch\n",
    "        for i, (clinical_rna_features, list_of_phenotype_tensors) in enumerate(zip(batch_clinical_rna_features, batch_lists_phenotype_clusters)):\n",
    "            \n",
    "            risk_score = model_chkpt(clinical_rna_features, list_of_phenotype_tensors)\n",
    "            \n",
    "            test_risks.append(risk_score.item())\n",
    "            test_times.append(batch_times[i].item())\n",
    "            test_events.append(batch_events[i].item())\n",
    "\n",
    "test_c_index = concordance_index(test_times, -np.array(test_risks), test_events)\n",
    "print(f\"test c-index: {test_c_index}\")\n",
    "display_km_curves_fusion(test_risks, test_times, test_events, \"test set\", save_figure=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concordance_index_custom(hazards, times, events):\n",
    "    \"\"\"\n",
    "    computes the c-index for survival prediction\n",
    "    - hazards: predicted risk scores (higher means higher risk)\n",
    "    - times: observed survival times\n",
    "    - events: event indicators (1 if event occurred, 0 if censored)\n",
    "    \"\"\"\n",
    "    n = len(times)\n",
    "    concordant = 0.0\n",
    "    permissible = 0.0\n",
    "    for i in range(n):\n",
    "        for j in range(n):\n",
    "            # only compare if i had an event and its time is earlier than j\n",
    "            if times[i] < times[j] and events[i] == 1:\n",
    "                permissible += 1\n",
    "                if hazards[i] > hazards[j]:\n",
    "                    concordant += 1\n",
    "                elif hazards[i] == hazards[j]:\n",
    "                    concordant += 0.5\n",
    "    return concordant / permissible if permissible > 0 else 0"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
