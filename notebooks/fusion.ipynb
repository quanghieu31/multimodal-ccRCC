{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "import configparser\n",
    "config = configparser.ConfigParser()\n",
    "config.read(\"../config.ini\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "import configparser\n",
    "config = configparser.ConfigParser()\n",
    "config.read(\"config.ini\")\n",
    "\n",
    "device = torch.device(\"cude\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "print(device)\n",
    "\n",
    "class PatientClinicalDataset(Dataset):\n",
    "    \"\"\"\n",
    "    from csv, so getitem would be something like .loc[idx]\n",
    "    \"\"\"\n",
    "    def __init__(self, csv_file_path):\n",
    "        self.csv_file_path = csv_file_path\n",
    "        self.df = pd.read_csv(self.csv_file_path).drop([\"time\", \"event\"], axis=1)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        patient_series = self.df.iloc[idx]\n",
    "        return patient_series # includes the submitter_id!\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.df.shape[0]\n",
    "\n",
    "\n",
    "class PatientRNASeqDataset(Dataset):\n",
    "    \"\"\"\n",
    "    a csv file, 534 rows and ~20000 columns for normalized RNA-seq counts\n",
    "    \"\"\"\n",
    "    def __init__(self, rna_file_path):\n",
    "        self.rna_file_path = rna_file_path\n",
    "        self.df = pd.read_csv(self.rna_file_path)\n",
    "        self.df.set_index(\"submitter_id\", inplace=True)\n",
    "\n",
    "    def __getitem__(self, case_id):\n",
    "        gene_expressions = list(self.df.loc[case_id])\n",
    "        tensor_gene_expressions = torch.tensor(gene_expressions, dtype=torch.float32).unsqueeze(0)\n",
    "        return tensor_gene_expressions # [1, 19962]\n",
    "\n",
    "\n",
    "class PatientWSIDataset(Dataset):\n",
    "    \"\"\"\n",
    "    dataset for accessing a patient's list of patches features, each is of shape (1, n_patches, n_features)\n",
    "    \"\"\"\n",
    "    def __init__(self, wsi_dir):\n",
    "\n",
    "        self.wsi_dir = wsi_dir\n",
    "        self.case_ids = list(LABELS_DF[\"submitter_id\"].values)\n",
    "        self.dict_case_id_path = {\n",
    "            c: os.path.join(self.wsi_dir, c) + \"/patches_features.npy\" for c in self.case_ids\n",
    "        }\n",
    "\n",
    "    def __getitem__(self, case_id):\n",
    "        # grab the list of 5 clusters for this case_id\n",
    "\n",
    "        case_npy_file = self.dict_case_id_path[case_id]\n",
    "        patches_features = np.load(case_npy_file, allow_pickle=True).item()\n",
    "        \n",
    "        cluster_ids = self.clustering(patches_features)\n",
    "\n",
    "        features_list = list(patches_features.values())\n",
    "        unique_clusters = np.unique(cluster_ids)\n",
    "        n_clusters = len(unique_clusters)\n",
    "\n",
    "        list_phenotype_tensors = [] # list of tensors, each tensor is a cluster's features of shape i.e. (1, 15 patches in this cluster, 512 as output of resnet18)\n",
    "\n",
    "        for cluster in unique_clusters:\n",
    "            cluster_features = [features for features, c in zip(features_list, cluster_ids) if c == cluster]\n",
    "            tensor_cluster_features = torch.from_numpy(np.array(cluster_features)).float().unsqueeze(0) # (1, n_patches, n_features)\n",
    "\n",
    "            list_phenotype_tensors.append(tensor_cluster_features.to(device))\n",
    "\n",
    "        return list_phenotype_tensors # [t1,t2,t3,t4,t5]\n",
    "\n",
    "    def clustering(self, patches_features, n_clusters=5):\n",
    "        feature_vectors = list(patches_features.values())\n",
    "        kmeans = KMeans(n_clusters=n_clusters, random_state=0, n_init=50)\n",
    "        cluster_ids = kmeans.fit_predict(feature_vectors)\n",
    "        return cluster_ids\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.case_ids)\n",
    "\n",
    "\n",
    "\n",
    "## Fusion multimodal\n",
    "\n",
    "class MultimodalDataset(Dataset):\n",
    "    \"\"\"\n",
    "    takes three data paths (clinical, rna-seq, histopath images)\n",
    "    build a data out of 'em\n",
    "    \"\"\"\n",
    "    def __init__(self, \n",
    "        clinical_data_path, \n",
    "        rna_seq_data_path, \n",
    "        wsi_data_path\n",
    "    ):\n",
    "        # prepare labels from the clinical data path\n",
    "        self.LABELS_DF = pd.read_csv(clinical_data_path)[[\"submitter_id\", \"event\", \"time\"]]\n",
    "        # then by initializing the clinical_dataset, remove the time and event from the clinical features:\n",
    "        self.clinical_dataset = PatientClinicalDataset(clinical_data_path)\n",
    "\n",
    "        # initialize the datasets for each modality\n",
    "        self.wsi_dataset = PatientWSIDataset(wsi_data_path)\n",
    "        self.rna_dataset = PatientRNASeqDataset(rna_seq_data_path)\n",
    "\n",
    "        # label dictionary with key=submitter_id and value=(event,time) for easy lookup\n",
    "        self.labels_dict = {}\n",
    "        for submitter_id, event, time in zip(self.LABELS_DF[\"submitter_id\"], self.LABELS_DF[\"event\"], self.LABELS_DF[\"time\"]):\n",
    "            self.labels_dict[submitter_id] = {\"event\": event, \"time\": time}\n",
    "\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        # (1) start from clinical dataset\n",
    "        patient_series = self.clinical_dataset[idx]\n",
    "        case_id = patient_series[\"submitter_id\"]\n",
    "        clinical_features = list(patient_series.drop([\"submitter_id\"]))\n",
    "        tensor_clinical_features = torch.tensor(clinical_features, dtype=torch.float32).unsqueeze(0) \n",
    "        # above: add batch dim (1, 18) instead of (18)\n",
    "\n",
    "        # (2) grab the tensor for 20000 (processed) gene counts for that case id\n",
    "        tensor_rna_genes = self.rna_dataset[case_id] # (1, 19962)\n",
    "\n",
    "        # (3) collect the list of phenotype tensor for that case id\n",
    "        list_of_phenotype_tensors = self.wsi_dataset[case_id]\n",
    "\n",
    "        # (4) labels\n",
    "        time = self.labels_dict[case_id][\"time\"]\n",
    "        event = self.labels_dict[case_id][\"event\"]\n",
    "\n",
    "        return (\n",
    "            tensor_clinical_features, \n",
    "            tensor_rna_genes, \n",
    "            list_of_phenotype_tensors,\n",
    "            time,\n",
    "            event\n",
    "        )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
